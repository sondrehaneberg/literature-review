ID,DOI,Title,Abstract,Keywords,Origin
10.1007/978-981-96-6291-3_3,10.1007/978-981-96-6291-3_3,Stock Price Prediction Using Univariate and Multivariate Historical Data with Post-Interpretation via Large Language Models,"In this study, we propose a hybrid approach that utilizes both univariate and multivariate historical data from key variables and related factors across four distinct groups. We developed a hybrid approach combining Volume Features, Valuation Metrics, Technical Indicators, and Market Sentiment for stock price prediction and investigate several state-of-the-art models, including Artificial Neural Networks (ANN), Gated Recurrent Units (GRU), Bidirectional GRU (BI-GRU), and Transformer-based Time Series (TST) models, while experimenting with different lags of inputs to capture intricate temporal patterns in stock price movements. Our experiments, conducted on seven stocks from various sectors, allow us to evaluate the robustness and generalizability of the models across different industries. To enhance interpretability, we employ large language models (LLMs) in the post-prediction phase, which transform the predictive outputs into human-readable narratives explaining the factors driving stock price predictions. Empirical results demonstrate that our approach, incorporating advanced deep learning models like ANN, GRU, BI-GRU, and TST with varying input lags, significantly improves prediction accuracy over traditional methods while providing actionable insights for financial decision-making. © 2025 Elsevier B.V., All rights reserved.",Large Language Models (LLM); Multivariate Analysis; Stock Price Prediction; Time Series Forecasting; Univariate Data,Scopus
10.1016/j.eswa.2025.128676,10.1016/j.eswa.2025.128676,In the beginning was the Word: LLM-VaR and LLM-ES,"This study introduces LLM-VaR and LLM-ES, novel risk estimation metrics that utilize general-purpose large language models (LLMs) for the forecasting tasks of Value at Risk (VaR) and Expected Shortfall (ES) in a zero-shot setting. Building on the input encoding mechanism of the LLMTime framework, we extend its application by defining new financial risk measures and performing an empirical evaluation of three generations of GPT models, GPT-3.5, GPT-4 and GPT-4o, versus advanced benchmark models such as GARCH with Student innovations and EWMA with Dynamic Conditional Score (DCS). Financial time series are encoded as numerical strings, allowing for model-free inference without requiring retraining. Results show that LLMs perform well when short rolling windows are used, particularly in volatile markets like cryptocurrencies. GPT-3.5 frequently outperforms or matches the performance of newer models, raising questions about model complexity, alignment, and biases. In contrast, performance deteriorates with longer windows, where the econometric models prove more reliable. Our findings demonstrate the potential of general-purpose LLMs as adaptive tools for short-horizon financial risk assessment and contribute a first-of-its-kind benchmark for LLM-based VaR/ES estimation. © 2025 Elsevier B.V., All rights reserved.",Expected shortfall; GPT; Large language models; LLM-ES; LLM-VaR; Value at risk,Scopus
10.1186/s40854-025-00789-6,10.1186/s40854-025-00789-6,The power of ChatGPT in processing text: Evidence from analysis and prediction in the exchange rate markets,"This study investigates the application of large language models in analyzing sentiment features within the exchange rate markets. Traditional natural language processing methods, such as LDA and BERT, are effective in extracting topics from text; however, they fail to assess the relative importance of these topics in relation to target exchange rates. To bridge this gap, this paper employs ChatGPT to extract topics from texts and evaluate their importance scores, further enhancing exchange rate forecasting by integrating topic importance into the sentiment analysis framework. Through empirical analysis, the superiority of ChatGPT over LDA and BERT in both topic extraction and importance assessment is demonstrated. Furthermore, this study utilizes the topic importance scores generated by ChatGPT to develop a novel interval-valued sentiment index (TIS index). This index not only accounts for the relative importance of various events influencing exchange rate fluctuations but also captures the dynamic evolution of market sentiment within an interval. Empirical results highlight that the TIS Index significantly enhances the forecasting accuracy of interval models such as TARI and IMLP for exchange rates. These findings further demonstrate the advantages of ChatGPT in sentiment analysis within the foreign exchange market. These findings offer new insights into the application of ChatGPT in financial text research. © 2025 Elsevier B.V., All rights reserved.",ChatGPT; Exchange rate; Interval; Sentiment analysis; Topic analysis,Scopus
10.1016/j.frl.2025.108489,10.1016/j.frl.2025.108489,Readability of financial reports and stock price crash risk,"The rapid evolution of machine learning makes text analysis more feasible. Utilizing a large language model, BERT, this article explores whether and how the readability of financial reports predicts firms’ stock price crash risk. Grounded in Chinese evidence, this research uncovers that the degree of readability is strongly negatively linked to firm stock price crash risk. This effect is stronger among firms led by more entrenched CEOs. These findings remain robust to various model specifications and to the instrumental variable method. Overall, this study, by shedding light on a novel driver of stock price crash risk, advances corporate finance literature. © 2025 Elsevier B.V., All rights reserved.",BERT; Crash risk; Large language model; Readability; Text analysis,Scopus
10.1007/s12525-025-00815-6,10.1007/s12525-025-00815-6,Wisdom of the crowd signals: Predictive power of social media trading signals for cryptocurrencies,"The emergence of cryptocurrencies and decentralized finance (DeFi) applications brings unique challenges, including high volatility, limited fundamental valuation methods, and significant informational reliance on social media. Consequently, traditional trading algorithms and decision support systems (DSS) often fall short in effectively capturing these dynamics, underscoring the need for tailored solutions. Recent research on sentiment analysis in cryptocurrency trading has provided mixed evidence regarding its predictive power, highlighting limitations in generalizability and reliability due to the inherent noise of social media content. Addressing these limitations, this study explores crowd-based trading signals, explicit buy and sell recommendations shared by users on social media platforms including X (formerly Twitter), Reddit, Stocktwits, and Telegram. We apply an event study methodology to analyze over 28,000 trading signals extracted using natural language processing (NLP) techniques based on large language models (LLMs). Our findings demonstrate that these explicit crowd-based signals significantly predict short-term cryptocurrency price movements, particularly for assets with lower market capitalization and recent negative returns. An out-of-sample trading strategy using these signals achieves superior risk-adjusted returns, outperforming both a standard cryptocurrency index (CCI30) and the S&P 500. Additionally, we uncover the role of automated accounts (signal bots) actively disseminating trading recommendations. This research advances literature by introducing a precise alternative to sentiment analysis, contributing to the understanding of social media as a distributed financial information environment, and raising theoretical considerations about algorithmic agency and trust. Practical implications span investors, social media platforms, and regulators. © 2025 Elsevier B.V., All rights reserved.",Collective intelligence; Cryptocurrencies; Predictive power; Social media signals; Trading signals; Wisdom of crowds,Scopus
10.1038/s41467-025-61292-1,10.1038/s41467-025-61292-1,Utility of synthetic musculoskeletal gaits for generalizable healthcare applications,"Deep-neural-network-based artificial intelligence enables quantitative gait analysis with commodity sensors. However, current gait-analysis models are usually specialized for specific clinical populations and sensor settings due to the limited size and diversity of available datasets. We propose an approach that involves using synthetic gaits generated using a generative model learned via physics-based simulation with a broad spectrum of musculoskeletal parameters and evaluated its utility for data-efficient generalization of gait-analysis models across different clinical populations and sensor settings. The model trained solely on synthetic data estimates gait parameters with comparable or superior performance compared with real-data-trained models specialized for specific populations and sensor settings. Pre-training on synthetic data with self-supervised learning consistently enhances model performance and data efficiency in adapting to multiple gait-based downstream tasks. The results indicate that our approach offers an efficient means to augment data size and diversity for developing generalizable healthcare applications involving sensor-based gait analysis. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.1007/s10791-025-09573-7,10.1007/s10791-025-09573-7,Leveraging large language model as news sentiment predictor in stock markets: a knowledge-enhanced strategy,"In the fast-evolving artificial intelligence era, the intersection of natural language processing and financial analysis has attracted significant attention, primarily due to its potential to provide valuable insights into financial market behavior. Sentiment analysis of financial news articles is a crucial aspect of this intersection, providing cues about market sentiment that may affect stock price dynamics. Traditional sentiment analysis methods often rely on rules or machine learning algorithms trained on labeled datasets, but these methods face challenges in capturing the context within the text. This paper proposes a framework that incorporates prompt engineering strategies, including a novel Domain Knowledge Chain-of-Thought (DK-CoT) strategy, integrating domain-specific financial knowledge with chain-of-thought reasoning, designed to leverage and enhance the performance of large language models (LLMs) in financial news sentiment analysis. DK-CoT has been compared with various prompt engineering techniques, including zero-shot, few-shot, and chain-of-thought, as well as other benchmark models like BERT and RoBERTa. Through comprehensive experiments and evaluations, we introduce the weighted F1 score as a more practical metric, emphasizing the disproportionate impact of negative news on financial markets, which better reflects real-world financial dynamics, as negative sentiments often lead to more significant market reactions than positive or neutral sentiments. Experimental results have shown that DK-CoT adopted in an LLM called GLM is effective in improving the performance and reliability of financial news sentiment analysis. Our findings provide insights into optimal prompt designs and highlight the importance of incorporating financial knowledge to uplift LLM performance while reducing the need for extensive computational resources and fine-tuning. © 2025 Elsevier B.V., All rights reserved.",Accessible machine learning; Financial news; Large language model; Natural language processing; Prompt engineering; Sentiment analysis,Scopus
10.1016/j.knosys.2025.114449,10.1016/j.knosys.2025.114449,Enhancing large language models for bitcoin time series forecasting,"In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection. © 2025 Elsevier B.V., All rights reserved.",Financial time series; Language models; Time series forecasting,Scopus
10.1016/j.econlet.2025.112602,10.1016/j.econlet.2025.112602,,[No abstract available],,Scopus
10.1007/s11063-025-11787-1,10.1007/s11063-025-11787-1,Detecting Bitcoin Sentiment: Leveraging Language Model Applications in Sentiment Analysis for Bitcoin Price Prediction,"As Bitcoin continues to establish itself as a global asset and discussions around relevant regulations become more active, there is an increasing demand for a comprehensive price prediction framework. To address this necessity, this study aims to enhance the accuracy of Bitcoin price predictions by integrating sentiment information with technical indicators, on-chain data, and cryptocurrency price data. Recognizing Bitcoin’s sensitivity to market sentiment, the proposed framework incorporates sentiment features derived from both lexicon-based methods and large language models. As unsupervised sentiment tools can introduce label noise particularly in domain-specific or ambiguous financial contexts, this study combines the outputs of multiple sentiment models at the feature level to construct a more stable representation. This design improves the robustness of downstream regression performance and distinguishes the framework from previous hybrid models that relied on a single sentiment source without component-wise evaluation. Experimental results using a dataset spanning 2700 days showed that the long short-term memory (LSTM) model with a 3-day window achieves the best performance with mean absolute percentage error (MAPE) of 3.93% and R-squared value of 0.99106. Feature importance analysis further demonstrates sentiment index as the most impactful feature, as excluding it resulted in the largest decline in predictive accuracy. Additionally, the model's performance was evaluated under four major volatility periods, revealing MAPE values ranging from 1.49 to 4.03%, highlighting the framework’s practical capability in rapidly adapting to sudden market shifts. In summary, integrating sentiment information attained from multiple language models significantly enhanced prediction accuracy compared to single source approaches. These findings highlight the framework’s practical value for sentiment-informed investment strategies and risk alerts, with a modular design that enables flexible adaptation and potential integration into automated trading systems. © 2025 Elsevier B.V., All rights reserved.",Bitcoin; Large language models; Price prediction; Sentiment analysis; Time series analysis,Scopus
10.1016/j.comnet.2025.111508,10.1016/j.comnet.2025.111508,MGGPT: A Multi-Graph GPT-enhanced framework for dynamic fraud detection in cryptocurrency networks,"The rapid increase in cryptocurrency transactions has increased demand for advanced fraud detection systems. Conventional methods are often rigid and do not effectively capture cryptocurrency networks’ intricate temporal and structural patterns, while existing dynamic approaches struggle with incomplete or missing information. To tackle this issue, we present MGGPT, a new hybrid framework that integrates Graph Attention Neural Networks (GAT) with GPT-based transformers to improve fraud detection within cryptocurrency transaction networks. Our approach utilizes temporal graph structures through reachability networks (reach-nets) to derive essential node features, while also directly integrating edge labels into the embedding vectors, and introduces an innovative mechanism for predicting missing information to address the challenges posed by incomplete data in blockchain networks. The model features a dual-perspective learning strategy, employing local graph structures via GAT Networks and global contextual patterns through GPT-based sequence modeling to capture both structural and temporal dynamics in transaction networks. Our MGGPT framework implements a sophisticated edge classification mechanism using Support Vector Machines (SVM) for the final prediction. Experimental findings on actual cryptocurrency transaction datasets indicate superior efficacy in identifying fraudulent patterns, achieving notable improvements of 8.5% AUC, a 10.2% increase in Precision, 29.5% increment in recall, and 20.5% improvement in F1-score. Compared to baseline models such as STA-GT and CTGN, the proposed MGGPT improves the representation of dynamic relationships and faster convergence. Overall, the analysis reveals that our framework is not only more accurate but also more robust and scalable for real-world temporal graph applications. Ultimately, we assessed the robustness of our framework against adversarial attacks to show its practical applications in blockchains. © 2025 Elsevier B.V., All rights reserved.",Cryptocurrency fraud detection; GPT-2 transformers; Graph neural networks; Missing information prediction; Temporal graph analysis,Scopus
10.3390/jrfm18090475,10.3390/jrfm18090475,AI and Financial Fragility: A Framework for Measuring Systemic Risk in Deployment of Generative AI for Stock Price Predictions,"In a few years, most investment firms will deploy Generative AI (GenAI) and large language models (LLMs) for reduced-cost stock trading decisions. If GenAI-run investment decisions from most firms are heavily coordinated, they could all give a “sell” signal simultaneously, triggering market crashes. Likewise, simultaneous “buy” signals from GenAI-run investment decisions could cause market bubbles with algorithmically inflated prices. In this way, coordinated actions from LLMs introduce systemic risk into the global financial system. Existing risk analysis for GenAI focuses on endogenous risk from model performance. In comparison, exogenous risk from external factors like macroeconomic changes, natural disasters, or sudden regulatory changes, is understudied. This research fills the gap by creating a framework for measuring exogenous (systemic) risk from LLMs acting in the stock trading system. This research develops a concrete, quantitative framework to understand the systemic risk brought by using GenAI in stock investment by measuring the covariance between LLM stock price predictions across three industries (technology, automobiles, and communications) produced by eight large language models developed across the United States, Europe, and China. This paper also identifies potential data-driven technical, cultural, and regulatory mechanisms for governing AI to prevent negative financial and societal consequences. © 2025 Elsevier B.V., All rights reserved.",artificial intelligence; geopolitical risk; large language models; machine learning; market conditions; policy; stock investment; systemic risk,Scopus
10.1016/j.fraope.2025.100359,10.1016/j.fraope.2025.100359,LLM-guided semantic feature selection for interpretable financial market forecasting in low-resource financial markets,"Feature selection is critical for accurate and interpretable financial forecasting, particularly in data-scarce environments. This study introduces a semantic feature selection framework empowered by GPT-4, which ranks financial indicators through prompt engineering and retrieval-augmented descriptions. Using weekly macro-financial data from the Malaysian equity market, including the FTSE Bursa Malaysia KLCI index obtained via the yfinance API, the proposed method is integrated with XGBoost and evaluated against multiple baselines. Results show that the LLM-based approach achieves the best forecasting accuracy, with RMSE = 12.82, MSE = 164.38, and R2 = 0.75, consistently outperforming alternatives across different feature sizes and time windows. These findings highlight the effectiveness of semantic feature selection in improving predictive accuracy, robustness, and interpretability, offering a promising direction for financial forecasting in low-resource settings. © 2025 Elsevier B.V., All rights reserved.",Data-centric AI; Financial forecasting; Large language models; Semantic feature selection; Time series,Scopus
10.1016/j.econlet.2025.112511,10.1016/j.econlet.2025.112511,Finfluencer recommendations,"Using a novel dataset of videos posted by prominent Financial YouTubers in India, we analyse the factors affecting Financial Influencers’ stock recommendations. Our findings reveal that finfluencers are more likely to positively recommend stocks with strong past performance and high trading volumes, valuations and intraday activity. Additionally, the number of recommendations made by finfluencers predicts future stock returns. © 2025 Elsevier B.V., All rights reserved.",Asset-pricing; Finfluencers; India; Large language models; Social media; YouTube,Scopus
10.1016/j.gfj.2025.101151,10.1016/j.gfj.2025.101151,Disaggregated geopolitical risks and global stock returns,"We introduce a novel framework to measure how geopolitical risk exposure (GRE) affects stock returns. Using data from 40 countries over 1995–2022, we construct three factors: geopolitical risk factor (GPRF), geopolitical act factor (GPAF), and geopolitical threat factor (GPTF). This study documents four main findings. First, geopolitical threats (GPTs) have markedly stronger GRE than geopolitical acts (GPAs), with 58% of countries showing significant GPTF results vs. 35% for GPAF. Second, predictability is strongest at shorter horizons, with 68% of countries demonstrating significant one-month predictability for GPTF effects. Third, these effects persist even after accounting for established market risk factors, with 33% of countries maintaining significant GPTF relationships. Fourth, our factors provide economically meaningful out-of-sample forecasting ability, yielding positive R2 values in 60% of countries and utility gains for mean–variance investors. The findings offer a practical framework for integrating GRE assessments into portfolio management decisions. © 2025 Elsevier B.V., All rights reserved.",Generalized Autoregressive Conditional Heteroskedasticity; Geopolitical act; Geopolitical risk; Geopolitical risk exposure; Geopolitical threat; Stock return,Scopus
10.1016/j.iref.2025.104281,10.1016/j.iref.2025.104281,A multifactor model using large language models and multimodal investor sentiment,"This study constructs multimodal investor sentiment indices using news and image data from the China News Service, covering the period from January 1, 2017, to December 31, 2024. We employ the RoBERTa model for text-based sentiment measurement and the Google Inception(v3) model for image-based sentiment measurement. We use a multimodal semantic correlation fusion model to integrate textual and visual sentiment features. These sentiment indices are categorised as industry-specific and market-wide investor sentiment, enabling separate analyses of their effects on stock markets. Furthermore, we develop a multifactor stock selection model that incorporates these sentiment indices with other microeconomic factors. Our findings demonstrate that multimodal sentiment analysis yields superior predictive accuracy. Industry-specific investor sentiment influences stock market returns, which in turn exacerbates changes in market-wide investor sentiment. Incorporating industry-specific sentiment into the multifactor stock selection model enhances portfolio returns, and combining market-wide sentiment with timing strategies further improves performance. © 2025 Elsevier B.V., All rights reserved.",Deep learning; Investor sentiment; Large language model; Multifactor model,Scopus
10.1007/s12530-025-09694-w,10.1007/s12530-025-09694-w,Information diffusion prediction using hybrid GCNN–LSTM and stock market based sentiment analysis in social media,"With the advancement of social media, the information diffusion popularity prediction has attracted wide attention in many applications. However, due to the real-time changes in networks and the complexity of social interactions, analyzing the exact mechanism of the information dissemination process remains extremely difficult. However, conventional popularity prediction methods rely heavily on human expertise to create features and define the generative model, or completely depend on the underlying user relation network for embedding learning. To address these concerns, this proposed work designed an information diffusion prediction model using a Hybrid Graph Convolutional Neural Network–Long Short Term Memory (GCNN–LSTM). The sentiment of the diffused information is analyzed through a hybrid Long Short Term Memory–Support Vector Machine (LSTM–SVM) in social media applications. The proposed work comprises two phases: the first phase is for effective popularity prediction of information diffusion, and the second phase is for analyzing the users' sentiment based on the influence of diffused information. In the detection of the information diffusion phase, the user data from social media is gathered to make a graphical representation based on the comment node attributes, and the effective features are extracted with the assistance of the graph convolutional neural network. After that, the features are given in the LSTM model for the detection of popularity. The diffused information in social media is considered in the sentimental analysis phase; initially, the data is subjected to preprocessing, and features are extracted with Term Frequency Inverse Document Frequency (TFIDF). Finally, with the help of a hybrid LSTM–SVM, the sentiment of the social media data is detected. The proposed model is implemented in MATLAB software and achieved 96% accuracy for phase 1 and 96% for phase 2. Thus, the proposed model effectively detects the spread of information in social media, which can assist various applications. © 2025 Elsevier B.V., All rights reserved.",Hybrid GCNN–LSTM; Hybrid LSTM–SVM; Information diffusion prediction; Popularity prediction sentiment analysis; TFIDF,Scopus
10.1007/s00521-025-11432-x,10.1007/s00521-025-11432-x,Multimodal deep learning model for bitcoin price prediction with news and market prices,"Bitcoin volatility has posed significant challenges to investors, making it a focal point for researchers. With increasing use of the internet, daily news is considered to have a substantial influence on bitcoin prices. Traditional methods relying solely on technical indicators or social sentiment often fail to capture the nuanced relationships between these factors, leaving a significant gap in accurately predicting price movements. In this research, we predict bitcoin prices by leveraging news data extracted from Common Crawl News dataset, in conjunction with bitcoin prices obtained from Coinbase Application Programming Interface. We propose a multimodal deep learning model named, Generative Pre-Trained Transformer 3.5 (GPT3.5) enhanced Convolutional Neural Network (CNN) Positional encoding-based Transformer Encoder (GPT-CNN-PTEN), designed to predict Bitcoin prices during both bullish and bearish market phases. To achieve this, we employ transformer encoder layers with CNN positional encoding to capture relations in the text and bitcoin prices and handle temporal dependence associated with bitcoin prices. The word embeddings generated using the Ada002 model from the text summarized by GPT3.5 turbo model captures the context of lengthy news articles into concise and meaningful inputs to the model. The dataset from October 2022 to January 2023 was used to train the model. The model was tested on three distinct datasets representing various market conditions. The results are noteworthy achieving mean squared error of 0.001, mean absolute percentage error of 7%. Moreover, the model demonstrated its predictive power by accurately forecasting a bull run hours before it occurred in January 2023. © 2025 Elsevier B.V., All rights reserved.",Bitcoin; News data; Price prediction; Time series; Transformers,Scopus
10.1016/j.econlet.2025.112404,10.1016/j.econlet.2025.112404,Predicting stock price trends using language models to extract the sentiment from analyst reports: Evidence from IBEX 35-listed companies,"This study investigates the utility of large language models to extract sentiment from sell-side equity analysts’ reports and their potential ability to predict stock price trends, using the IBEX 35 index as a case study. The RoBERTa, FinBERT, and GPT natural language processing models are employed to analyze a corpus of analysts’ equity research reports over 2016–2022. The results indicate that the extracted sentiment can serve as a valuable tool for forecasting stock price movements, avoiding the potential bias in analyst reports when assigning a target price. This highlights the transformative potential of language models in the financial industry and their role in assisting investors in making informed investment decisions. © 2025 Elsevier B.V., All rights reserved.",Analyst recommendations; Large language models; Natural language processing; Stock market prediction,Scopus
10.1016/j.eswa.2025.127864,10.1016/j.eswa.2025.127864,"Investigating the impact of sentiments on stock market using digital proxies: Current trends, challenges, and future directions","Social media and online news have emerged as significant sources of market sentiment, influencing stock market dynamics globally. With the growing availability of digital data, the current research focus is on leveraging advanced computational techniques for sentiment-driven stock market prediction. The era of financial forecasting has been revolutionized by integrating cutting-edge technologies such as Machine Learning, Deep Learning, and Large Language Models. In this paper, a comprehensive survey of 108 research articles has been undertaken to explore the recent advancements in these technologies, with a focus on utilizing sentiment data extracted from social media platforms and news sources. The technology-wise state-of-the-art findings, current trends, challenges, and literature gaps in this domain are analyzed, and potential future directions are proposed to address these gaps. Additionally, publicly available benchmark datasets for social media and news sentiment indices are compiled and analyzed, with insights into their limitations and potential improvements. A comparative evaluation of prediction methods across heterogeneous user-generated datasets is performed, identifying the most effective techniques for various data types and problem formulations. Recommendations are offered for selecting suitable techniques based on the nature of the data and the specific problem formulation. By incorporating the latest advancements in the field of sentiment analysis and stock market prediction, this work provides actionable insights for researchers and practitioners, advancing the understanding and development of sentiment-driven financial forecasting. © 2025 Elsevier B.V., All rights reserved.",Deep learning; Digital news; Large language models; Machine learning; Social media; Stock market prediction,Scopus
10.1007/s10614-024-10668-4,10.1007/s10614-024-10668-4,Modeling Asset Price Process: An Approach for Imaging Price Chart with Generative Diffusion Models,"Artificial Intelligence (AI) models have been recently studied to discover data patterns for prediction and forecasting tasks in finance. However, the use of deep generative models in finance remains relatively unexplored. In this paper, we investigate the potential of deep generative diffusion models to estimate unknown dynamics using multiple simulations based on stock chart images. We first demonstrate a novel pre-processing framework and synthetic image generation using opening, high, low, and closing stock chart images to train neural networks. Without assuming the specific process as the underlying asset price process, we can generate synthetic data without predetermined assumptions of the underlying movements of stock prices by trained generative diffusion models. The experimental results demonstrate that the proposed method successfully replicates well-known asset price processes. With various simulation paths, we can also accurately estimate option pricing on the S &P 500. We conclude that financial simulation with AI can be a novel approach to financial decision-making. © 2025 Elsevier B.V., All rights reserved.",Asset price process; Deep learning; Financial simulation; Generative diffusion model; Option pricing; Price chart,Scopus
10.1016/j.frl.2025.107472,10.1016/j.frl.2025.107472,Decoding risk sentiment in 10-K filings: Predictability for U.S. stock indices,"This study demonstrates that the tone of the risk factors section in the 10-K reports of U.S. public companies predicts returns on major U.S. stock indices. We created five tone indicators using text mining, the Loughran-McDonald dictionary, and AI-calibrated alternatives (GPT-3.5-turbo-0125, GPT-4, GPT-4o, and GPT-4o-mini). These indicators showed significant predictive power for weekly returns, with optimism correlated with higher returns. Tone measurements based on GPT-4 outperformed the others in terms of predictive accuracy. We analyzed the Loughran-McDonald dictionary's utility and highlighted the underexplored risk factors section, offering novel insights into sentiment analysis and financial forecasting. © 2025 Elsevier B.V., All rights reserved.",Artificial intelligence; QVAR; Risk factors tone metrics; Textual analysis; TVP-VAR,Scopus
10.1016/j.iswa.2025.200496,10.1016/j.iswa.2025.200496,Emulating fundamental analysts: Analytical stage-based multi-agent framework enhanced with expert guidance and Preference-Anchored Likelihood Adjustment,"With the rapid advancement of large language models (LLMs), some studies have explored their potential for predicting stock prices based on financial texts. However, previous research often overlooked the depth of analysis generated by LLMs, resulting in reasoning processes inferior to those of human analysts. In fundamental investing, which requires in-depth company analysis, conclusions from imperfect reasoning lack persuasiveness. In this study, inspired by the analysis process of human analysts, we propose an “Analytical Stage-Based Multi-Agent Framework” to enable LLMs to perform in-depth fundamental analysis. This framework divides the analysis into multiple stages, assigning an LLM agent to each. We enhance each agent's capabilities for its specific task through expert guidance or fine-tuning, allowing them to collectively emulate the workflow of human analysts. Furthermore, we introduce Preference-Anchored Likelihood Adjustment, a new method for fine-tuning LLMs. This approach addresses the decline in likelihood of generating correct responses that occurs after using existing preference alignment methods. It employs an objective function with two terms: one to increase likelihood and another to preserve aligned preference. We conducted experiments using our framework to analyze company earnings releases. We evaluated the analysis quality based on comprehensiveness and logical soundness, while correctness was assessed by using stock prices as the ground truth to calculate the Matthews correlation coefficient and F1 score. Results demonstrate that even without expert guidance and fine-tuning, our multi-agent framework can enhance LLMs in both analysis quality and correctness. When combined with expert guidance and fine-tuning, the performance is further improved. © 2025 Elsevier B.V., All rights reserved.",Financial fundamental analysis; Fine-tuning; LLMs; Multi-agent; Stock price analysis,Scopus
10.1515/til-2025-0004,10.1515/til-2025-0004,Data is infrastructure,"Data is a contextual phenomenon. It reflects the social and material context from which it is derived and in which it is generated. It embeds the purposes, assumptions and rationales of those who produce, collect, use, share and monetize it. In the AI and digital platform economy, data's role is primarily infrastructural. Its core uses are internal to companies. Data only rarely serves as a medium of exchange or commodity, and more frequently serves to profile users, train models, produce predictions, and bundle and extend product capabilities, which in turn are sold to advertisers and other customers. Insofar as they focus on the former, many technical, economic and legal attempts at defining data have inspired reductive policy efforts that include data protection, data ownership, and limited data sharing remedies. This Article argues that understanding data as part of infrastructural pipelines can have significant conceptual and policy implications, and can redirect the way privacy, property and antitrust experts understand and govern data. This argument becomes more salient as market actors and regulators grapple with the catalyzing effects of neural networks and generative AI models on digital markets. In antitrust and competition law especially, regulators are consciously adopting a view of data as an infrastructural input into AI and other digital markets. Treating data as an input in regard to which certain firms have competitive advantages can have significant implications for nascent AI markets, and yet the views in antitrust remain too narrow. Understanding data infrastructurally means viewing it not only as a critical input but also as inseparable from other material digital resources such as protocols, algorithms, semiconductors, and platform interfaces; as having important collective functions; and as calling for public-interest regulation. Understanding data as infrastructure can move us past limited legal efforts and remedial solutions such as data separations, data sharing, and individual controls, and help reorient how data is produced, stored and managed toward public uses. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.3390/bdcc9060162,10.3390/bdcc9060162,Semantic Reasoning Using Standard Attention-Based Models: An Application to Chronic Disease Literature,"Large-language-model (LLM) APIs demonstrate impressive reasoning capabilities, but their size, cost, and closed weights limit the deployment of knowledge-aware AI within biomedical research groups. At the other extreme, standard attention-based neural language models (SANLMs)—including encoder–decoder architectures such as Transformers, Gated Recurrent Units (GRUs), and Long Short-Term Memory (LSTM) networks—are computationally inexpensive. However, their capacity for semantic reasoning in noisy, open-vocabulary knowledge bases (KBs) remains unquantified. Therefore, we investigate whether compact SANLMs can (i) reason over hybrid OpenIE-derived KBs that integrate commonsense, general-purpose, and non-communicable-disease (NCD) literature; (ii) operate effectively on commodity GPUs; and (iii) exhibit semantic coherence as assessed through manual linguistic inspection. To this end, we constructed four training KBs by integrating ConceptNet (600k triples), a 39k-triple general-purpose OpenIE set, and an 18.6k-triple OpenNCDKB extracted from 1200 PubMed abstracts. Encoder–decoder GRU, LSTM, and Transformer models (1–2 blocks) were trained to predict the object phrase given the subject + predicate. Beyond token-level cross-entropy, we introduced the Meaning-based Selectional-Preference Test (MSPT): for each withheld triple, we masked the object, generated a candidate, and measured its surplus cosine similarity over a random baseline using word embeddings, with significance assessed via a one-sided t-test. Hyperparameter sensitivity (311 GRU/168 LSTM runs) was analyzed, and qualitative frame–role diagnostics completed the evaluation. Our results showed that all SANLMs learned effectively from the point of view of the cross entropy loss. In addition, our MSPT provided meaningful semantic insights: for the GRUs (256-dim, 2048-unit, 1-layer): mean similarity (Formula presented.) of 0.641 to the ground truth vs. 0.542 to the random baseline (gap 12.1%; (Formula presented.)). For the 1-block Transformer: (Formula presented.) vs. (Formula presented.) (gap 4%; (Formula presented.)). While Transformers minimized loss and accuracy variance, GRUs captured finer selectional preferences. Both architectures trained within <24 GB GPU VRAM and produced linguistically acceptable, albeit over-generalized, biomedical assertions. Due to their observed performance, LSTM results were designated as baseline models for comparison. Therefore, properly tuned SANLMs can achieve statistically robust semantic reasoning over noisy, domain-specific KBs without reliance on massive LLMs. Their interpretability, minimal hardware footprint, and open weights promote equitable AI research, opening new avenues for automated NCD knowledge synthesis, surveillance, and decision support. © 2025 Elsevier B.V., All rights reserved.",chronic diseases; common-sense knowledge; natural language processing; semantic reasoning,Scopus
10.3390/e27060550,10.3390/e27060550,"Artificial Intelligence Models for Predicting Stock Returns Using Fundamental, Technical, and Entropy-Based Strategies: A Semantic-Augmented Hybrid Approach","This study examines the effectiveness of combining semantic intelligence drawn from large language models (LLMs) such as ChatGPT-4o with traditional machine-learning (ML) algorithms to develop predictive portfolio strategies for NASDAQ-100 stocks over the 2020–2025 period. Three different predictive frameworks––fundamental, technical, and entropy-based––are tested through examination of novel combinations of ML- and LLM-derived semantic metrics. The empirical results reveal a considerable divergence in optimal blending methods across the methodologies; namely, the technical methodology exhibits the best performance when using only ML predictions, with around 1978% cumulative returns with monthly rebalancing. In contrast, the fundamental methodology achieves its full potential when it is based primarily on LLM-derived semantic insights. The Entropy methodology is improved by a balanced combination of both semantic and ML signals, thus highlighting the potential of LLMs to improve predictive power by offering interpretative context for complex market interactions. These findings highlight the strategic importance of tailoring the semantic–algorithmic fusion to suit the nature of the predictive data and the investment horizon, with significant implications for portfolio management and future research in financial modeling. © 2025 Elsevier B.V., All rights reserved.",artificial intelligence; fundamental; fuzzy logic; technical; trading,Scopus
10.1371/journal.pone.0326034,10.1371/journal.pone.0326034,Enhancing stock timing predictions based on multimodal architecture: Leveraging large language models (LLMs) for text quality improvement,"This study aims to enhance stock timing predictions by leveraging large language models (LLMs), specifically GPT-4, to filter and analyze online investor comment data. Recognizing challenges such as variable comment quality, redundancy, and authenticity issues, we propose a multimodal architecture that integrates filtered comment data with stock price dynamics and technical indicators. Using data from nine Chinese banks, we compare four filtering models and demonstrate that employing GPT-4 significantly improves financial metrics like profit-loss ratio, win rate, and excess return rate. The multimodal architecture outperforms baseline models by effectively preprocessing comment data and combining it with quantitative financial data. While focused on Chinese banks, the approach can be adapted to broader markets by modifying the prompts of large language models. Our findings highlight the potential of LLMs in financial forecasting and provide more reliable decision support for investors. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.1111/1911-3846.13036,10.1111/1911-3846.13036,Can investors learn from patent documents? Evidence from textual analysis,"This paper examines the role of patent texts in the stock market valuation of patents. Utilizing the large language model BERT (Bidirectional Encoder Representations from Transformers) to summarize contextual information within patent texts, I find that patent texts explain 31.5% of the variation in the stock market valuation of patents and provide large incremental explanatory power beyond other structured patent characteristics, firm characteristics, and technological trends. Additionally, patent texts significantly predict the level, volatility, and cumulation speed of future earnings, suggesting they contain genuine information about firms' performance. However, investors do not fully incorporate such information within patent texts into stock prices, as evidenced by the predictive power of patent texts for future stock returns. This underreaction is diminished after the pre-grant publication of patent applications is mandated. My findings underscore the value of patent texts as a source of information on internally developed intangibles and have implications for academics, practitioners, and regulators. © 2025 Elsevier B.V., All rights reserved.",BERT; big data; patent; textual analysis; voluntary disclosure,Scopus
10.1145/3701716.3715235,10.1145/3701716.3715235,HRFT: Mining High-Frequency Risk Factor Collections End-to-End via Transformer,"In quantitative trading, transforming historical stock data into interpretable, formulaic risk factors enhances the identification of market volatility and risk. Despite recent advancements in neural networks for extracting latent risk factors, these models remain limited to feature extraction and lack explicit, formulaic risk factor designs. By viewing symbolic mathematics as a language-where valid mathematical expressions serve as meaningful ""sentences""-we propose framing the task of mining formulaic risk factors as a language modeling problem. In this paper, we introduce an end-to-end methodology, Intraday Risk Factor Transformer (IRFT), to directly generate complete formulaic risk factors, including constants. We use a hybrid symbolic-numeric vocabulary where symbolic tokens represent operators and stock features, and numeric tokens represent constants. We train a Transformer model on high-frequency trading (HFT) datasets to generate risk factors without relying on a predefined skeleton of operators (e.g., +, ×, /, √x, log x, cos x). It determines the general form of the stock volatility law, including constants; for example, f (x) = tan(ax + b), where x is the stock price. We refine the predicted constants (a, b) using the Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm to mitigate non-linear issues. Compared to the ten approaches in SRBench, an active benchmark for symbolic regression (SR), IRFT achieves a 30% higher investment return on the HS300 and S&P500 datasets, while achieving inference times that are orders of magnitude faster than existing methods in HF risk factor mining tasks. Our code and dataset are publicly accessible via the following GitHub repository: https://github.com/wencyxu/IRF-LLM-accepted-at-WWW25-. © 2025 Elsevier B.V., All rights reserved.",Computational Finance; Stock Volatility Forecasting; Transformer; Factor Analysis,Scopus
10.1145/3672608.3707874,10.1145/3672608.3707874,Deep Generative Calibration on Stochastic Volatility Models with Applications in FX Barrier Options,"This paper proposes a two-step approach to efficiently calibrate the stochastic models for the foreign exchange (FX) barrier options by utilising the predictive and generative power of machine learning. To tackle the limited availability of market prices from brokers, we propose a framework to first augment the model parameters via a generative model, the Variational Autoencoder Generative Adversarial Network (VAE-GAN) model, and then calibrate the model parameters with neural networks to approximate the mapping between synthetic market data and model parameters. In this work, we examine the performance of our two-step calibration approach by comparing it with the traditional calibration process in terms of robustness and efficiency. We evaluate our calibration using two performance metrics employed by major financial institutions. The results indicate that our method not only speeds up the calibration process from hours to seconds but also increases the variety of the dataset, covering a broader range of market conditions. Finally, we use the values output by our calibration method as initial values in the traditional calibrator. This approach helps the traditional calibrator achieve optimal parameters by either improving running time or the quality of the solutions, resulting in a closer match between the model-implied prices and the market prices. © 2025 Elsevier B.V., All rights reserved.",financial model calibration; generative adversarial network; generative models; stochastic local volatility models; variational autoencoder,Scopus
10.1145/3724154.3724240,10.1145/3724154.3724240,Optimizing Stock Market Return Forecasts with Uncertainty Sentiment: Leveraging LLM-based Insights,"Accurately predicting stock market returns is crucial for both investors and policy makers. This study proposes an innovative hybrid Particle Swarm Optimization Support Vector Regression (PSO-SVR) machine learning framework that integrates uncertainty sentiment to improve the accuracy of stock market return prediction. Uncertainty sentiment and historical stock market returns are identified as the main input factors, and the PSO algorithm is used to fine-tune the parameters of SVR to obtain the integrated PSO-SVR model. Empirical results show that the PSO-SVR model significantly reduces the root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) when uncertainty sentiment is added. This provides a novel and effective method for predicting stock market returns. © 2025 Elsevier B.V., All rights reserved.",Empirical asset pricing; Machine learning; PSO-SVR hybrid model; Uncertainty sentiment,Scopus
10.3390/math13101599,10.3390/math13101599,MambaLLM: Integrating Macro-Index and Micro-Stock Data for Enhanced Stock Price Prediction,"Accurate stock price prediction requires the integration of heterogeneous data streams, yet conventional techniques struggle to simultaneously leverage fine-grained micro-stock features and broader macroeconomic indicators. To address this gap, we propose MambaLLM, a novel framework that fuses macro-index and micro-stock inputs through the synergistic use of state-space models (SSMs) and large language models (LLMs). Our two-branch architecture comprises (i) Micro-Stock Encoder, a Mamba-based temporal encoder for processing granular stock-level data (prices, volumes, and technical indicators), and (ii) Macro-Index Analyzer, an LLM module—employing DeepSeek R1 7B distillation—capable of interpreting market-level index trends (e.g., S&P 500) to produce textual summaries. These summaries are then distilled into compact embeddings via FinBERT. By merging these multi-scale representations through a concatenation mechanism and subsequently refining them with multi-layer perceptrons (MLPs), MambaLLM dynamically captures both asset-specific price behavior and systemic market fluctuations. Extensive experiments on six major U.S. stocks (AAPL, AMZN, MSFT, TSLA, GOOGL, and META) reveal that MambaLLM delivers up to a 28.50% reduction in RMSE compared with suboptimal models, surpassing traditional recurrent neural networks and MAMBA-based baselines under volatile market conditions. This marked performance gain highlights the framework’s unique ability to merge structured financial time series with semantically rich macroeconomic narratives. Altogether, our findings underscore the scalability and adaptability of MambaLLM, offering a powerful, next-generation tool for financial forecasting and risk management. © 2025 Elsevier B.V., All rights reserved.",large language model; Mamba; stock price prediction; time series forecasting,Scopus
10.3390/ai6050095,10.3390/ai6050095,Cybersecure XAI Algorithm for Generating Recommendations Based on Financial Fundamentals Using DeepSeek,"Background: Investment decisions in stocks are one of the most complex tasks due to the uncertainty of which stocks will increase or decrease in their values. A diversified portfolio statistically reduces the risk; however, stock choice still substantially influences the profitability. Methods: This work proposes a methodology to automate investment decision recommendations with clear explanations. It utilizes generative AI, guided by prompt engineering, to interpret price predictions derived from neural networks. The methodology also includes the Artificial Intelligence Trust, Risk, and Security Management (AI TRiSM) model to provide robust security recommendations for the system. The proposed system provides long-term investment recommendations based on the financial fundamentals of companies, such as the price-to-earnings ratio (PER) and the net margin of profits over the total revenue. The proposed explainable artificial intelligence (XAI) system uses DeepSeek for describing recommendations and suggested companies, as well as several charts based on Shapley additive explanation (SHAP) values and local-interpretable model-agnostic explanations (LIMEs) for showing feature importance. Results: In the experiments, we compared the profitability of the proposed portfolios, ranging from 8 to 28 stock values, with the maximum expected price increases for 4 years in the NASDAQ-100 and S&P-500, where both bull and bear markets were, respectively, considered before and after the custom duties increases in international trade by the USA in April 2025. The proposed system achieved an average profitability of 56.62% while considering 120 different portfolio recommendations. Conclusions: A t-Student test confirmed that the difference in profitability compared to the index was statistically significant. A user study revealed that the participants agreed that the portfolio explanations were useful for trusting the system, with an average score of 6.14 in a 7-point Likert scale. © 2025 Elsevier B.V., All rights reserved.",DeepSeek; explainable artificial intelligence; financial fundamentals; investment recommendation; stock price prediction; XAI security,Scopus
10.1093/rof/rfaf015,10.1093/rof/rfaf015,"CEO turnover, sequential disclosure, and stock returns","We document that firms experience large negative stock returns during, and positive returns following, the first informational events after forced CEO turnovers. This V-shaped return pattern is driven by the strategic sequential disclosure of bad news and good news, aligned with incoming CEOs’ incentives to manage expectations. The pattern is more pronounced when these incentives are stronger, such as when firms earn higher stock returns and have higher valuation uncertainty leading up to the informational events. Evidence from firms’ earnings surprises, analysts’ forecast revisions, and large language model-based measures of disclosure behavior indicates that incoming CEOs often initially release bad news about realized and short-term earnings, projecting a broadly pessimistic outlook for the firm’s future performance, and subsequently disclose favorable news about longer-term earnings prospects. Our findings suggest that investors make the costly mistake of failing to discern the incentives behind managers’ disclosure. © 2025 Elsevier B.V., All rights reserved.",CEO turnover; expectation management; stock returns,Scopus
10.1145/3696410.3714588,10.1145/3696410.3714588,The Poorest Man in Babylon: A Longitudinal Study of Cryptocurrency Investment Scams,"Governments and regulatory bodies have recognized investment scams as a prevalent form of cryptocurrency fraud. These scams typically use professional-looking websites to lure unsuspecting victims with promises of unrealistically high returns. In this paper, we introduce Crimson, a distributed system designed to continuously detect cryptocurrency investment scam websites as they are created in the wild. During the first 8 months of 2024, Crimson processed approximately 6 billion domain names and classified 43, 572 unique cryptocurrency investment scam websites in real-time. Beyond detection, we provide insights into the design and infrastructure of these websites that can help users recognize scam patterns and assist hosting providers in detecting and blocking such sites. Furthermore, we investigate the inclusion of our detected scam websites in block-lists used by popular web browsers and applications, finding that the vast majority of these websites were absent. On the financial side, by analyzing the transactions incoming to scammer wallets on 6.7% of the sites detected by Crimson, we observe an estimated lower bound of 2.04M USD in losses due to cryptocurrency investment scams. © 2025 Elsevier B.V., All rights reserved.",Blockchain; Cryptocurrency; Financial Loss; LLM; Scam,Scopus
10.1021/acs.analchem.4c05046,10.1021/acs.analchem.4c05046,Large Language Models (such as ChatGPT) as Tools for Machine Learning-Based Data Insights in Analytical Chemistry,"Artificial intelligence (AI), especially through the development of deep learning techniques like convolutional neural networks (CNNs), has revolutionized numerous fields. CNNs, introduced by Yann LeCun in the 1990s (Hubbard, W.; Jackel, L. D. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Comput. 1989, 1 (4), 541− 551. https://doi.org/10.1162/neco.1989.1.4.541), have found applications in healthcare for medical diagnostics, autonomous vehicles in transportation, stock market prediction in finance, and image recognition in computer vision to name just a few. Similarly, in analytical chemistry, deep learning has enhanced data analysis from techniques like MS spectrometry, NMR, fluorescence spectroscopy, and chromatography. Another AI branch, Natural Language Processing (NLP), has surged recently with the advent of Large Language Models (LLMs), such as OpenAI’s ChatGPT. This paper demonstrates the application of an LLM via a smartphone to conduct multivariate data analyses, in an interactive conversational manner, of a hyper-spectral imaging data set from laser-induced breakdown spectroscopy (LIBS). We demonstrate the potential of LLMs to process and analyze data sets, which automatically generate and execute code in response to user queries, and anticipate their growing role in the future of analytical chemistry. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.1111/exsy.70018,10.1111/exsy.70018,"Generative AI for Finance: Applications, Case Studies and Challenges","Generative AI (GAI), which has become increasingly popular nowadays, can be considered a brilliant computational machine that can not only assist with simple searching and organising tasks but also possesses the capability to propose new ideas, make decisions on its own and derive better conclusions from complex inputs. Finance comprises various difficult and time-consuming tasks that require significant human effort and are highly prone to errors, such as creating and managing financial documents and reports. Hence, incorporating GAI to simplify processes and make them hassle-free will be consequential. Integrating GAI with finance can open new doors of possibility. With its capacity to enhance decision-making and provide more effective personalised insights, it has the power to optimise financial procedures. In this paper, we address the research gap of the lack of a detailed study exploring the possibilities and advancements of the integration of GAI with finance. We discuss applications that include providing financial consultations to customers, making predictions about the stock market, identifying and addressing fraudulent activities, evaluating risks, and organising unstructured data. We explore real-world examples of GAI, including Finance generative pre-trained transformer (GPT), Bloomberg GPT, and so forth. We look closer at how finance professionals work with AI-integrated systems and tools and how this affects the overall process. We address the challenges presented by comprehensibility, bias, resource demands, and security issues while at the same time emphasising solutions such as GPTs specialised in financial contexts. To the best of our knowledge, this is the first comprehensive paper dealing with GAI for finance. © 2025 Elsevier B.V., All rights reserved.",applications; case studies; finance; generative AI; large language models,Scopus
10.1002/fut.22568,10.1002/fut.22568,ChatGPT and Commodity Return,"This paper investigates the ability of a ChatGPT-based indicator to forecast excess returns of the commodity futures index. Using ChatGPT to extract information from over 2.5 million articles from nine international newspapers, we demonstrate that our constructed commodity news ratio index significantly predicts future commodity returns, both in-sample and out-of-sample. Furthermore, it outperforms traditional textual analysis methods, including Bidirectional Encoder Representations from Transformers (BERT) and Bag-of-Words (BoW), while indicating economic significance within an asset allocation framework. The results highlight the critical role of ChatGPT in forecasting commodity market dynamics and provide valuable insights for both financial market participants and researchers. © 2025 Elsevier B.V., All rights reserved.",ChatGPT; commodity return analysis; textual analysis,Scopus
10.1016/j.techfore.2024.123965,10.1016/j.techfore.2024.123965,"Quantifying a firm's AI engagement: Constructing objective, data-driven, AI stock indices using 10-K filings","This paper proposes an objective, data-driven approach using natural language processing (NLP) techniques to classify AI stocks by analyzing annual 10-K filings from 3395 NASDAQ-listed firms between 2010 and 2022. Each company's engagement with AI is classified through binary and weighted AI scores based on the frequency of AI-related terms. Using these metrics, we construct four AI stock indices—the Equally Weighted AI Index (AII), the Size-Weighted AI Index (SAII), and two Time-Discounted AI Indices (TAII05 and TAII5X)—offering different perspectives on AI investment. We validate our methodology through an event study on the launch of OpenAI's ChatGPT, demonstrating that companies with higher AI engagement saw significantly greater positive abnormal returns, with analyses supporting the predictive power of our AI measures. Our indices perform on par with or surpass 14 existing AI-themed ETFs and the Nasdaq Composite Index in risk-return profiles, market responsiveness, and overall performance, achieving higher average daily returns and risk-adjusted metrics without increased volatility. These results suggest our NLP-based approach offers a reliable, market-responsive, and cost-effective alternative to existing AI-related ETF products. Our methodology can also guide investors, asset managers, and policymakers in using corporate data to construct other thematic portfolios, contributing to a more transparent, data-driven, and competitive approach. © 2025 Elsevier B.V., All rights reserved.",Artificial intelligence; ChatGPT; Corporate disclosures; Exchange-traded funds; Market efficiency; Natural language processing,Scopus
10.1016/j.dss.2024.114362,10.1016/j.dss.2024.114362,Revisiting time-varying dynamics in stock market forecasting: A multi-source sentiment analysis approach with large language model,"This paper presents the Heterogeneous Dynamic Seemingly Unrelated Regression with Dynamic Linear Models (HD-SURDLM), an innovative framework for stock return prediction that combines cutting-edge sentiment analysis with dynamic financial modeling. The model integrates sentiment data from 2.5 million Twitter posts and various news sources, utilizing state-of-the-art sentiment analysis tools such as VADER, TextBlob, and RoBERTa. HD-SURDLM refines Gibbs sampling for enhanced numerical stability and efficiency while capturing cross-sectional dependencies across multiple assets such as a portfolio. The model consistently outperforms traditional methods like LSTM, Random Forest, and RNN in forecasting accuracy. Empirical results show a 1.02% improvement in 1-day horizon forecasts, a 0.42% gain for 20-day predictions, and a 0.36% increase for 50-day forecasts. By effectively merging public sentiment with dynamic asset modeling, HD-SURDLM offers substantial improvements in short- and long-term prediction accuracy. Its capacity to capture both cross-sectional insights and temporal dynamics makes it an invaluable tool for investors, traders, and financial institutions navigating sentiment-driven markets. HD-SURDLM not only enhances predictive accuracy but also provides a robust decision-support system for financial stakeholders. © 2025 Elsevier B.V., All rights reserved.",Decision system; Dynamic linear models; Large language model; Seemingly unrelated regression; Sentiment analysis; Time series prediction,Scopus
10.1007/s12144-025-07430-w,10.1007/s12144-025-07430-w,Beyond the hype: AI advice and investor dissonance in crypto trading,"This study examines the impact of cognitive dissonance on the relationship between investors’ intentions to use AI advice and their investment behaviour in the cryptocurrency market. The study recruited 348 individuals through a non-random snow-ball sampling technique. Utilising ChatGPT for investment recommendations, the research involves a trading experiment accompanied by a two-stage survey to evaluate investor attitudes towards AI before and their cognitive dissonance levels after the experiment. Structural Equation Modelling (SEM) identifies the connection between the intent to use AI and the influence of cognitive dissonance on investment decisions. Results indicate that investors following AI advice outperformed those who did not, attributable not to AI’s predictive power but to reduced cognitive dissonance. This reduction allowed investors using AI to cut losses more effectively, in contrast to those who eschewed AI advice and tended to hold onto losing positions longer, leading to worse performance. Although focused on the cryptocurrency market, the findings suggest a potential for broader applicability in conventional financial markets. The study’s key contribution is demonstrating that AI recommendations can mitigate the disposition effect, implying that AI’s broader implementation could enhance market efficiency. © 2025 Elsevier B.V., All rights reserved.",Artificial intelligence; ChatGPT; Cognitive dissonance; Cryptocurrency; Investment behaviour,Scopus
10.3390/electronics14061090,10.3390/electronics14061090,Comparative Investigation of GPT and FinBERT’s Sentiment Analysis Performance in News Across Different Sectors,"GPT (Generative Pre-trained Transformer) is a groundbreaking generative model that has facilitated substantial progress in natural language processing (NLP). As the GPT-n series has continued to evolve, its applications have garnered considerable attention across various industries, particularly in finance. In contrast, traditional financial research has primarily focused on analyzing structured data such as stock prices. However, recent trends highlight the growing importance of natural language techniques that address unstructured factors like investor sentiment and the impact of news. Positive or negative information about specific companies, industries, or the overall economy found in news or social media can influence investor behavior and market volatility, highlighting the critical need for robust sentiment analysis. In this context, we utilize the state-of-the-art language model GPT and the finance-specific sentiment analysis model FinBERT to perform sentiment and time-series analyses on financial news data, comparing the performance of the two models to demonstrate the potential of GPT. Furthermore, by examining the relationship between sentiment shifts in financial markets and news events, we aim to provide actionable insights for investment decision-making, emphasizing both the performance and interpretability of the models. To enhance the performance of GPT-4o, we employed a systematic approach to prompt design and optimization. This process involved iterative refinement, guided by insights derived from a labeled dataset. This approach emphasized the pivotal importance of prompt design in improving model accuracy, resulting in GPT-4o achieving higher performance than FinBERT. During the experiment phase, sentiment scores were generated from New York Times news data and visualized through time-series graphs for both models. Although both models exhibited similar trends, significant differences arose depending on news content characteristics across categories. According to the results, the performance of GPT-4o, optimized through prompt engineering, outperformed that of FinBERT by up to 10% depending on the sector. These findings emphasize the importance of prompt engineering and demonstrate GPT-4o’s potential to improve sentiment analysis. Furthermore, the categorized news data approach suggests potential applications in predicting the outlook of categorized financial products. © 2025 Elsevier B.V., All rights reserved.",FinBERT; GPT; prompt design; sentiment analysis; The New York Times,Scopus
10.3390/jrfm18020099,10.3390/jrfm18020099,A First Look at Financial Data Analysis Using ChatGPT-4o,"OpenAI’s new flagship model, ChatGPT-4o, released on 13 May 2024, offers enhanced natural language understanding and more coherent responses. This paper investigates ChatGPT-4o’s capabilities in financial data analysis, including zero-shot prompting, time series analysis, risk and return analysis, and ARMA-GARCH estimation. ChatGPT-4o’s performance is generally comparable to traditional statistical software like Stata, though some errors and discrepancies arise due to differences in implementation. Despite these issues, our findings indicate that ChatGPT-4o has significant potential for real-world financial analysis. Integrating ChatGPT-4o into financial research and practice may lead to more efficient data processing, improved analytical capabilities, and better-informed investment decisions. © 2025 Elsevier B.V., All rights reserved.",academia; artificial intelligence (AI); ChatGPT; data analysis; finance research; financial analysis; generative AI (GenAI); large language models; stock return,Scopus
10.3390/math13030487,10.3390/math13030487,LLM-Augmented Linear Transformer–CNN for Enhanced Stock Price Prediction,"Accurately predicting stock prices remains a challenging task due to the volatile and complex nature of financial markets. In this study, we propose a novel hybrid deep learning framework that integrates a large language model (LLM), a Linear Transformer (LT), and a Convolutional Neural Network (CNN) to enhance stock price prediction using solely historical market data. The framework leverages the LLM as a professional financial analyst to perform daily technical analysis. The technical indicators, including moving averages (MAs), relative strength index (RSI), and Bollinger Bands (BBs), are calculated directly from historical stock data. These indicators are then analyzed by the LLM, generating descriptive textual summaries. The textual summaries are further transformed into vector representations using FinBERT, a pre-trained financial language model, to enhance the dataset with contextual insights. The FinBERT embeddings are integrated with features from two additional branches: the Linear Transformer branch, which captures long-term dependencies in time-series stock data through a linearized self-attention mechanism, and the CNN branch, which extracts spatial features from visual representations of stock chart data. The combined features from these three modalities are then processed by a Feedforward Neural Network (FNN) for final stock price prediction. Experimental results on the S&P 500 dataset demonstrate that the proposed framework significantly improves stock prediction accuracy by effectively capturing temporal, spatial, and contextual dependencies in the data. This multimodal approach highlights the importance of integrating advanced technical analysis with deep learning architectures for enhanced financial forecasting. © 2025 Elsevier B.V., All rights reserved.",CNN; deep learning; financial forecasting; Linear Transformer; LLM; stock price prediction,Scopus
10.1111/exsy.13681,10.1111/exsy.13681,Integrating spotted hyena optimization technique with generative artificial intelligence for time series forecasting,"Generative artificial intelligence (AI) has developed as an effective tool for time series predicting, revolutionizing the typical methods of prediction. Different classical approaches that depend on existing approaches and assumptions, generative AI controls advanced deep learning (DL) approaches like generative adversarial networks (GANs) and recurrent neural networks (RNNs), to identify designs and connections in time series data. DL has accomplished major success in optimizing performances connected with AI. In the financial area, it can be extremely utilized for the stock market predictive, trade implementation approaches, and set of optimizers. Stock market predictive is the most important use case in this field. GANs with advanced AI approaches have become more significant in recent times. However, it can be utilized in image-image-translation and other computer vision (CV) conditions. GANs could not utilized greatly for stock market prediction because of their effort to establish the proper set of hyperparameters. This study develops an integrated spotted hyena optimization algorithm with generative artificial intelligence for time series forecasting (SHOAGAI-TSF) technique. The purpose of the SHOAGAI-TSF technique is to accomplish a forecasting process for the utilization of stock price prediction. The SHOAGAI-TSF technique uses probabilistic forecasting with a conditional GAN (CGAN) approach for the prediction of stock prices. The CGAN model learns the data generation distribution and determines the probabilistic prediction from it. To boost the prediction results of the CGAN approach, the hyperparameter tuning can be performed by the use of the SHOA. The simulation result analysis of the SHOAGAI-TSF technique takes place on the stock market dataset. The experimental outcomes determine the significant solution of the SHOAGAI-TSF algorithm with other compared methods in terms of distinct metrics. © 2024 Elsevier B.V., All rights reserved.",artificial intelligence; generative adversarial network; spotted hyena optimization; stock market prediction; time series forecasting,Scopus
10.1145/3708036.3708236,10.1145/3708036.3708236,Enhancing Stock Prediction with Sentimental and Relational InformationDistilled from Large Models,"An increasing number of investors are dedicating their efforts to enhancing the accuracy of stock market predictions, a crucial factor in financial markets that aids in making well-informed decisions and optimizing their investment strategies. The development of deep learning methods has evolved from solely considering fundamental price information to a broader spectrum of information, such as sentiment features from news articles. However, these methods often struggle to effectively extract such features when multiple companies are mentioned in a single news article (more details can be referred to Section 1). With the advancement of large language models (LLMs), which can more precisely extract the knowledge people require from text. To overcome the shortcomings of previous work, we propose a novel distillation method for precise knowledge extraction, including sentimental and fine-grained relational knowledge. After that, we incorporate the knowledge as augmented features to assist in the predictions of stock forecasting models. Through experiments on the real Chinese stock market, CSI300 and CSI500, our proposed method can indeed lead to significant improvements in the performance of stock prediction models, demonstrating a performance improvement of baseline models up to 3.23% in terms of accuracy. © 2025 Elsevier B.V., All rights reserved.",Deep learning; Knowledge distill; Large language models; Stock prediction,Scopus
10.1007/978-3-031-78541-2_28,10.1007/978-3-031-78541-2_28,Exploring Relationships Between Cryptocurrency News Outlets and Influencers’ Twitter Activity and Market Prices,"Academics increasingly acknowledge the predictive power of social media for a wide variety of events and, more specifically, for financial markets. Anecdotal and empirical findings show that cryptocurrencies are among the financial assets that have been affected by news and influencers’ activities on Twitter. However, the extent to which Twitter crypto influencer’s posts about trading signals and their effect on market prices is mostly unexplored. In this paper, we use LLMs to uncover buy and not-buy signals from influencers and news outlets’ Twitter posts and use a VAR analysis with Granger Causality tests and cross-correlation analysis to understand how these trading signals are temporally correlated with the top nine major cryptocurrencies’ prices. Overall, the results show a mixed pattern across cryptocurrencies and temporal periods. However, we found that for the top three cryptocurrencies with the highest presence within news and influencer posts, their aggregated LLM-detected trading signal over the preceding 24 h granger-causes fluctuations in their market prices, exhibiting a lag of at least 6 h. In addition, the results reveal fundamental differences in how influencers and news outlets cover cryptocurrencies. © 2025 Elsevier B.V., All rights reserved.",LLM; NLP; Prompt Engineering; Social Prediction; Time Series Analysis,Scopus
10.12785/ijcds/1571026011,10.12785/ijcds/1571026011,"Enhancing Bitcoin Forecast Accuracy by Integrating AI, Sentiment Analysis, and Financial Models","This study explores the enhancement of Bitcoin price prediction by integrating advanced AI models (LSTM, Prophet, SARIMAX) with sentiment analysis from digital platforms like Twitter and Yahoo, processed through Large Language Models (LLMs). The research assesses the impact of incorporating qualitative sentiment data with quantitative financial models. Key findings indicate that sentiment analysis can significantly refine forecasting accuracy. Specifically, the LSTM model demonstrated a reduction in Mean Absolute Percentage Error (MAPE) from 15.59% to 12.75% and an increase in accuracy from 84.41% to 87.25% when sentiment analysis was included. However, the Prophet model showed a decrease in performance, with MAPE increasing to 28.04% and accuracy dropping to 71.96%. The SARIMAX model displayed inconsistent results with sentiment integration. These insights highlight the complexities and potential benefits of combining traditional econometric models with sentiment analysis for improved predictive accuracy in financial forecasting. © 2025 Elsevier B.V., All rights reserved.",Bitcoin forecasting; financial models; investor behavior; Large Language Models; LSTM; market dynamics; predictive accuracy; Prophet model; SARIMAX; sentiment analysis,Scopus
10.12720/jait.16.1.12-20,10.12720/jait.16.1.12-20,Initial Coin Offerings Success Prediction Using Social Media and Large Language Models,"Initial Coin Offering (ICO) is a fundraising method utilized by blockchain startups to raise capital by issuing and selling digital tokens to investors. ICOs have become widely popular for cryptocurrency fundraising, often generating millions of dollars, and surpassing traditional crowdfunding methods like Initial Public Offerings. However, ICO is a risky way of investing and raising capital due to the lack of regulations and standardisation. In this research, we delve into the impact of social media and sentiment analysis on the success of ICOs, employing various machine learning models and Large Language Models. Our analysis is based on data from over 1,000 ICOs gathered from diverse ICO information platforms, coupled with a corpus of 910,478 tweets associated with these ICOs. We extend our investigation to include other social media platforms such as BitcoinTalk, Telegram, Facebook, and Medium. Our analysis revealed that valuable insights regarding the success of ICOs can be derived by examining text sentiment and investigating metadata across these diverse social media channels. © 2025 Elsevier B.V., All rights reserved.",Bidirectional Encoder Representations from Transformers (BERT); sentiment analysis; social media; token sales; web scraping,Scopus
10.1007/s10614-024-10835-7,10.1007/s10614-024-10835-7,"Forecasting Brazilian Stock Market Using Sentiment Indices from Textual Data, Chat-GPT-Based and Technical Indicators","The rapid advancement of artificial intelligence, exemplified by tools such as Chat-GPT, has significantly transformed the landscape of stock market analysis. This paper aims to leverage these technological developments to predict the daily returns of the Ibovespa by utilizing predictors derived from technical indicators and sentiment indices extracted from textual data and Chat-GPT-generated sentiment indices. Our findings reveal that the Chat-GPT-based sentiment index does not enhance the out-of-sample prediction of Ibovespa returns. Conversely, the sentiment index derived from financial news data, utilizing a time-varying dictionary, demonstrates improved out-of-sample predictive accuracy for the Ibovespa. Notably, the predictor based on the technical indicator Accumulation–Distribution (AD) outperforms the historical average benchmark, establishing itself as the superior forecasting model. This study contributes to the ongoing discourse on the integration of artificial intelligence and traditional financial analysis, offering insights into the efficacy of sentiment indices and technical indicators for forecasting stock market returns in the Brazilian context. © 2025 Elsevier B.V., All rights reserved.",Artificial intelligence; Chat-GPT; Ibovespa; Sentiment analysis; Stock market forecasting; Technical indicators,Scopus
10.1016/j.frl.2024.106487,10.1016/j.frl.2024.106487,Intelligent forecasting in bitcoin markets,"This paper examines the effectiveness of Artificial Intelligence (AI) in predicting Bitcoin's price movements. To achieve this, we developed two distinct trading strategies and compared their performance against each other and the traditional Buy and Hold (B&H) strategy. Over the period from January 2018 to September 2023, we found that the strategy optimized by ChatGPT 01-Preview, which integrates multiple technical indicators and sentiment analysis into a weighted composite index, delivered an exceptional total return of 944.85 %. The second strategy, that is using Extreme Gradient Boosting (XGBoost) technique achieved a total return of 189.05 %. The AI strategy's excess return of 755.8 % over the XGBoost strategy highlights the significant advantage of AI particularly in utilizing diverse data sources, such as social media, to predict Bitcoin's price trends more effectively than relying solely on economic data. Both trading strategies significantly outperformed the traditional B&H strategy, which returned 73.08 % over the same period. Furthermore, we found that AI has an advantage during periods of high Bitcoin price volatility. © 2024 Elsevier B.V., All rights reserved.",AI; Bitcoin; Machine learning; Random forest,Scopus
10.1080/1369118X.2024.2420021,10.1080/1369118X.2024.2420021,The supply chain capitalism of AI: a call to (re)think algorithmic harms and resistance through environmental lens,"Artificial Intelligence (AI) is woven into a supply chain of capital, commodities and human labour that has been neglected in critical debates. Given the current surge in generative AI–which is estimated to drive up the extraction of natural resources such as minerals, fossil fuels or water–it is vital to investigate its entire production line from a critical infrastructural perspective. Drawing on the supply chain capitalism, a concept coined by Anna L. Tsing in 2009, this paper contributes to critical AI studies by investigating the structure of AI supply chains, taking into account the mining, electronics, digital and e-waste industry. This paper illustrates how the supply chain capitalism of AI is precipitating geographical asymmetries connected to contested struggles in México by focusing on a key element of these chains: data centres. In times of climate emergency, this paper calls to reconsider algorithmic harms and resistance by investigating the entire capitalist production line of the AI industry from critical and environmental lens. © 2025 Elsevier B.V., All rights reserved.",AI; capitalism; data centre; environment; infrastructure; Supply chain,Scopus
10.1007/978-3-031-72393-3_5,10.1007/978-3-031-72393-3_5,SARF: Stock Market Prediction with Sentiment-Augmented Random Forest,"Stock trend forecasting, a challenging problem in the financial domain, involves extensive data and related indicators. Relying solely on empirical analysis often yields unsustainable and ineffective results. Machine learning researchers have demonstrated that the application of random forest algorithm can enhance predictions in this context, playing a crucial auxiliary role in forecasting stock trends. This study introduces a new approach to stock market prediction by integrating sentiment analysis using FinGPT generative AI model with the traditional Random Forest model. The proposed technique aims to optimize the accuracy of stock price forecasts by leveraging the nuanced understanding of financial sentiments provided by FinGPT. We present a new methodology called “Sentiment-Augmented Random Forest” (SARF), which incorporates sentiment features into the Random Forest framework. Our experiments demonstrate that SARF outperforms conventional Random Forest and LSTM models with an average accuracy improvement of 9.23% and lower prediction errors in predicting stock market movements. © 2024 Elsevier B.V., All rights reserved.",Large Language Model; Machine Learning; Natural Language Processing; Random Forest; Sentiment Analysis; Stock Price Prediction,Scopus
10.1016/j.inffus.2024.102616,10.1016/j.inffus.2024.102616,Data-driven stock forecasting models based on neural networks: A review,"As a core branch of financial forecasting, stock forecasting plays a crucial role for financial analysts, investors, and policymakers in managing risks and optimizing investment strategies, significantly enhancing the efficiency and effectiveness of economic decision-making. With the rapid development of information technology and computer science, data-driven neural network technologies have increasingly become the mainstream method for stock forecasting. Although recent review studies have provided a basic introduction to deep learning methods, they still lack detailed discussion on network architecture design and innovative details. Additionally, the latest research on emerging large language models and neural network structures has yet to be included in existing review literature. In light of this, this paper comprehensively reviews the literature on data-driven neural networks in the field of stock forecasting from 2015 to 2023, discussing various classic and innovative neural network structures, including Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), Transformers, Graph Neural Networks (GNNs), Generative Adversarial Networks (GANs), and Large Language Models (LLMs). It analyzes the application and achievements of these models in stock market forecasting. Moreover, the article also outlines the commonly used datasets and various evaluation metrics in the field of stock forecasting, further exploring unresolved issues and potential future research directions, aiming to provide clear guidance and reference for researchers in stock forecasting. © 2024 Elsevier B.V., All rights reserved.",Deep learning; Finance; Financial market; Neural network; Stock forecast,Scopus
10.1109/ISEC64801.2025.11147253,10.1109/ISEC64801.2025.11147253,,[No abstract available],,Scopus
10.1109/TENSYMP63728.2025.11144933,10.1109/TENSYMP63728.2025.11144933,LLM-Augmented Enhanced Graph Transformer for Stock Movement Prediction,"Predicting stock price movements remains challenging due to the complex interactions and dynamics of financial markets. Recent deep learning advances, particularly integrating numerical data with linguistic analysis via large language models (LLMs), have shown promise. This study proposes an LLM-Augmented Enhanced Graph Transformer that combines LLM-generated financial analyses, FinBERT semantic embeddings, and a Graph Transformer to predict daily stock movements for 260 selected S&P 500 stocks in 2024. We construct a static stock relationship graph based on the cosine similarity of aggregated textual embeddings, capturing long-term semantic dependencies while integrating numerical indicators. Experimental results show our approach outperforms traditional time-series models (e.g., LSTM, Transformer, Informer) and graph-based methods (e.g., GCN, GAT), demonstrating the effectiveness of multimodal fusion and graph-based attention. We also discuss computational constraints and the limitations of static graphs, highlighting future directions such as dynamic graph modeling and optimized text processing. © 2025 Elsevier B.V., All rights reserved.",Graph neural networks; Graph Transformer; Large Language Model; Stock movement prediction,Scopus
10.1049/icp.2025.2498,10.1049/icp.2025.2498,MITIGATING MARKET VOLATILITY IMPACT IN STOCK PREDICTION: A WASSERSTEIN GAN APPROACH WITH GRU AND CNN,"Stock price prediction plays a crucial role in financial decision-making, especially in volatile market conditions. Traditional forecasting methods, including statistical models and deep learning approaches, often struggle to adapt to rapid market fluctuations and unexpected events such as the COVID-19 pandemic. Moreover, many existing models require large datasets and fail to generalize well across different financial conditions. Addressing these challenges, generative models have gained attention for their ability to generate synthetic financial data and improve prediction accuracy. Here, we propose a Wasserstein Generative Adversarial Network (WGAN) with Gated Recurrent Units (GRU) as the generator and Convolutional Neural Networks (CNN) as the discriminator to enhance stock price forecasting robustness. Our model is trained using historical stock prices, trading volume, and technical indicators from four major U.S. companies-Apple, Amazon, Google, and Intel-over a period from 2014 to 2023. The dataset is split into pre- and post-COVID-19 periods to assess the model's adaptability to market anomalies. Experimental results indicate that the proposed WGAN-based model achieves an average Root Mean Square Error (RMSE) of 2.31, outperforming conventional methods such as Linear Regression and Long Short-Term Memory (LSTM) networks. Moreover, the model demonstrates minimal performance degradation when exposed to volatile periods, proving its robustness in handling market uncertainties. These findings suggest that WGAN with GRU and CNN is an effective approach to mitigating the impact of market volatility on stock price prediction. Future research will explore further optimizations, alternative generative architectures, and applications to different financial markets to refine prediction accuracy and generalizability. © 2025 Elsevier B.V., All rights reserved.",Deep Learning; GAN; Market Volatility; Stock Price Prediction; Wasserstein GAN,Scopus
10.1109/ICOCT64433.2025.11118821,10.1109/ICOCT64433.2025.11118821,Applications of Novel Deep Learning Algorithms for Analysing of Cryptocurrency,"With the worldwide spread of cryptocurrencies, data has become richer and more heterogeneous than before and, as a result, poses a new problem related to prediction and decision making. Although there has been recent increase in acceptance of machine learning (ML) and deep learning (DL) technologies, the current analytical models appear to have limited correspondence with cryptocurrency markets. This work directly addresses price forecasting, fraud detection, sentiment analysis, and risk management, thus illustrating the applicability of the current technologies. We implement complex and novel deep learning techniques such as long short-term memory, gated recurrent unit, Bidirectional-LSTM to explore the temporal and spatial behavior of data associated with cryptocurrencies. These models enable accurate predictions of price and market trends along with reinforcement strategies to refine trading strategies and generative models to assess the market and project what the future might require. This is used to help investors and traders spot patterns in the buying and selling of various crypto currencies, these models might have far-reaching effects on the economy. We compared the suggested model's output with that of current setups. This works findings reveal that the proposed model is more accurate than the alternatives since its prediction errors are lower. © 2025 Elsevier B.V., All rights reserved.",Cryptocurrencies; fraud detection; GRU and Bi-LSTM; LSTM; price prediction; risk management,Scopus
10.1109/AITest66680.2025.00018,10.1109/AITest66680.2025.00018,Hybrid LSTM-Transformer Model for Stock Market Prediction: A Deep Learning Approach,"Stock market prediction is a complex and dynamic task due to the volatile nature of financial markets, influenced by economic, social, and geopolitical factors. Traditional machine learning models, including Long Short-Term Memory (LSTM) networks, have shown potential but often fall short in capturing both short-term price fluctuations and long-term dependencies. This paper proposes a novel LSTM-Transformer hybrid model that integrates the sequential modeling capabilities of LSTM with the attention-based long-range pattern recognition of Transformers. To enhance predictive performance, we incorporate key technical indicators-Relative Strength Index (RSI), Moving Average Convergence Divergence (MACD), Bollinger Bands-as well as sentiment features derived from FinBERT, a finance-specific large language model. The model is trained on historical stock data spanning 2015 to 2024 and evaluated using an 80%-20% training-testing split. Performance is assessed using Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), and Sharpe Ratio to capture both prediction accuracy and risk-adjusted returns. A rolling-window backtesting approach is used to simulate real-world trading behavior across varying market conditions. Our hybrid model outperforms standalone LSTM, GRU, and Transformer baselines, achieving an MSE of 0.0021, RMSE of 0.0467, and a directional accuracy of 76.4%. These findings highlight the value of combining deep learning, financial indicators, and sentiment analysis for robust stock market forecasting. A conceptual extension discussing the role of generative models like GPT for unstructured financial data is also presented. © 2025 Elsevier B.V., All rights reserved.",Algorithmic Trading; Backtesting; Deep Learning; Financial Forecasting; LSTM-Transformer Hybrid; Machine Learning; Sentiment Analysis; Stock Market Prediction; Technical Indicators; Time-Series Analysis,Scopus
10.1007/978-981-96-6303-3_29,10.1007/978-981-96-6303-3_29,Stock Price Prediction: Chatbot,"The purpose of this article will be to create a trading bot that can execute trade strategies without human involvement while also keeping user control. It may be challenging to develop a statistical method that accurately captures market behavior due to interdependencies and, in particular, nonlinear trends. By choosing the best model to measure, profitability will guarantee that machine learning stocks are valued accurately. Usual categorization assessment indicators used to evaluate models for stock market forecasting include accuracy rate. Due to advancements in artificial intelligence and computing capacity, programmable prediction algorithms are becoming more accurate at forecasting stock values. Since stock price time series are nonstationary and nonlinear, forecasting future price changes is quite difficult. By training on historical data, machine learning—a new advancement in stock market prediction technology—generates estimates based on the core metrics of the market’s current statistics. Machine learning uses a variety of models to get accurate estimates. © 2025 Elsevier B.V., All rights reserved.",Back testing; Deep reinforcement learning; Generic review; GPT traders,Scopus
10.1109/SIU66497.2025.11112242,10.1109/SIU66497.2025.11112242,Stock Price Prediction with Multimodal Data; Çok Modlu Veri Ile Hisse Senedi Fiyati Tahmini,"In today's financial markets, the influence of dynamic factors is becoming increasingly evident, and markets are affected by real-time data from various sources. In this study, a multimodal machine learning approach is adopted by integrating traditional technical analysis metrics, tweets, and news articles with historical price data. Market sentiment and investor psychology are measured through sentiment analysis of textual data using both the FinBERT and ChatGPT-4o models, and the obtained outputs are combined with financial metrics to construct an LSTM-based stock price prediction model. To enhance the model's stability, LSTM models derived from different training sessions are merged using an ensemble learning method, and the two approaches are compared. The results demonstrate that the ensemble model outperforms the standard LSTM model, and integrating financial indicators with tweet and news data, as opposed to relying solely on price data, leads to increased overall profit. © 2025 Elsevier B.V., All rights reserved.",Deep Learning; Deep Neural Networks; Financial Forecasting; Large Language Models; Multimodal Machine Learning; Stock Market Prediction,Scopus
10.1111/jifm.70004,10.1111/jifm.70004,Carbon Neutrality Uncertainty and the Cross-Section of Stock Returns: Evidence From China,"Climate change impacts future stock returns, though prior literature offers mixed evidence. In this study, we explore how carbon neutrality uncertainty (CNU) affects the cross-section of stock returns in the Chinese market. Our data set includes 3489 stocks from January 2011 to December 2022. Utilizing keywords generated by ChatGPT, we construct a CNU index and estimate the stocks' sensitivity to this uncertainty. Portfolio-level analyzes and cross-sectional regressions indicate a negative cross-sectional relationship between sensitivity to CNU and future stock returns. This relationship remains robust across alternative rolling windows and various measures of the CNU index, and other uncertainty indices cannot account for it. From the perspective of market impediments, arbitrage asymmetry appears to explain this negative relationship. Overall, our results highlight the important role of CNU in determining stock prices. © 2025 Elsevier B.V., All rights reserved.",arbitrage asymmetry; carbon neutrality uncertainty; climate change; stock returns,Scopus
10.3389/frai.2025.1608365,10.3389/frai.2025.1608365,"Large Language Models in equity markets: applications, techniques, and insights","Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector. © 2025 Elsevier B.V., All rights reserved.",algorithmic trading; equity; finance; investing; Large Language Models; LLMS; NLP; stock,Scopus
10.1016/j.procs.2025.08.073,10.1016/j.procs.2025.08.073,Crude oil risk forecasting using time series foundation model,"In this paper, we propose a new Value Risk forecasting model using time series foundation model and historical simulation method. Large Language Model architecture has been introduced into the construction of risk estimation models using time series foundation model. It exploits the time series big data and the advanced transformer architecture to model the complex nonlinear dynamics in risk evolution. It is combined with the historical simulation method to produce more reliable risk estimates. Empirical studies using the crude oil future prices have demonstrated the improved risk forecasting reliability. © 2025 Elsevier B.V., All rights reserved.",Crude oil futures; Large language model; risk forecasting; Time series foundation model; Value at Risk,Scopus
10.1117/12.3071166,10.1117/12.3071166,Modality-aligned fine-tuning of large models for stock prediction,"There is a significant gap between the outstanding performance of Large Language Models (LLMs) in language tasks and their direct application in temporal financial prediction. Traditional fine-tuning methods struggle to overcome challenges such as low signal-to-noise ratio in numerical time-series data and complex dynamic patterns. To address these challenges, we propose an efficient adaptation framework LLaMA-TTPT for frozen LLMs. LLaMA-TTPT addresses the limitations of utilization efficiency and robustness with multi-modal prompt, cross attention and layer-wise hierarchical prompt propagation. The core innovation of this paper is implicitly mapping temporal data into the semantic space of pretrained LLMs. Firstly, we proposed a temporal-text prompt fine-tuning mechanism, which employes trainable numerical encoders and text prompts to convert stock price sequences into LLM-aligned multi-modal inputs. This enhances cross-modal consistency between numerical features and semantic descriptions. Secondly, we adopt cross attention mechanism to fuse dual-modal embeddings. Finally, we propose a temporal-aware hierarchical soft prompt propagation structure. It combines local dynamic prompt with global trend features extracted through LLMs' self-attention, enabling collaborative modeling of long-short term dependencies. Experiments on India Nifty 50 Stock Market dataset demonstrate that LLaMA-TTPT outperforms mainstream temporal models. Ablation analyses further validate the effectiveness of the proposed methods. © 2025 Elsevier B.V., All rights reserved.",Embedded deployment; Illumination robustness; Large Language Models; Multi-scale feature fusion; Stock Prediction,Scopus
10.1109/ICCSP64183.2025.11088423,10.1109/ICCSP64183.2025.11088423,Prophetic markets: Multi-modal deep learning redefines stock market predictions,"Stock market prediction is a vital resource for investors and financial experts looking to reduce risk and maximize profits. In this article, we propose a novel multi-modal deep learning-based method to improve predictions of stock market trends. This study uses an integrated framework of state-of-the-art machine learning techniques, deep learning with LLM, and RAG. We use data retrieval techniques, such as web scraping, to download financial reports containing corporate balance sheets. Further, our method includes real-time sentiment analysis in order to understand the investors' current mentality which can be crucial in determining the market movements. Technical analysis uses deep learning models to interpret important indicators such as RSI, MACD, CCI, and Stochastic oscillators to uncover underlying patterns and correlations in stock trends. Our experiments demonstrate that this integrated strategy performs better than conventional single-dimensional techniques. We are combining data from corporate financial, sentiment analysis, and technical factors as well as active news sentiment analysis to improve the accuracy and reliability of market predictions by demonstrating the performance of a combined set of data sources. This work draws attention to the importance of the multifaceted integration of data by demonstrating RAG benefits for accurate financial data retrieval and multi-modal analysis in the practical applications of stock markets. The results demonstrate how these new approaches can be combined for profit maximization with better decision-making and risk reduction in financial markets. © 2025 Elsevier B.V., All rights reserved.",and technical indicators; financial data; LLM; multi-modal deep learning; news sentiment analysis; RAG; Stock prediction,Scopus
10.3389/fbloc.2025.1627769,10.3389/fbloc.2025.1627769,Short-term cryptocurrency price forecasting based on news headline analysis,"Introduction: This article presents a method for short-term cryptocurrency price forecasting utilizing news headlines. Methods: The study analyzes the impact of news on asset prices within one hour of publication, employing machine learning-based classification with BERT and GPT models, as well as GloVe vector representations. Results: The proposed cascade classifier model enhances prediction accuracy by initially assessing the strength of a news item and subsequently forecasting the direction of price movement. Experimental results demonstrate the effectiveness of the developed classification model. Discussion: The model achieves an accuracy of 79% in predicting price movements, confirming the potential of leveraging news headlines to improve short-term forecasts in cryptocurrency markets. © 2025 Elsevier B.V., All rights reserved.",bidirectional encoder representations from transformers (BERT); Bitcoin (BTC); cryptocurrency; Generative Pre-trained Transformer (GPT); Global Vectors for word representation (GloVe); machine learning; short-term forecasting,Scopus
10.1007/978-981-96-7178-6_2,10.1007/978-981-96-7178-6_2,Stock Trend Prediction Based on Complex Network and Sentiment Analysis,"Stock market is usually characterized by drastic fluctuations, long volatility cycles, and emotional changes. This paper focuses on exploring how to utilize complex networks and sentiment analysis techniques to improve the prediction accuracy of stock movements. We take the semiconductor industry chain stock market as the research object. First, based on complex network theory, we construct a complex network of China’s semiconductor industry chain and extract key network factors. Second, the semantic understanding ability of the large language model is applied to investor comment sentiment analysis, and a multi-dimensional stock sentiment factor is constructed by fine-tuning the GPT large model and combining it with the KNN classifier to recognize investor comment sentiment. Finally, the sentiment factor is combined with the network factors to construct a stock price prediction model using the LSTM algorithm, which is used to predict future stock movements. The experimental results show that the investor sentiment recognition method based on GPT-KNN can obtain an accuracy of 77.59%, which is better than the comparison algorithm, proving the significant advantage of the GPT model in text semantic feature extraction. The average accuracy of the stock trend prediction method integrating multiple factors reaches 69.62%, which is significantly better than the benchmark. Meanwhile, the experimental results of feature combination show that the accuracy is improved by 8.46% and 3.1% by the integration of network factors and sentiment factors, respectively. © 2025 Elsevier B.V., All rights reserved.",Complex Network; Sentiment Analysis; Stock Prediction,Scopus
10.1007/s40745-025-00637-5,10.1007/s40745-025-00637-5,Dynamic Bayesian Networks for Predicting Cryptocurrency Price Directions: Uncovering Causal Relationships,"Cryptocurrencies have gained widespread attention, particularly in finance and investment sectors. Despite their growing popularity, cryptocurrencies can be a high-risk investment due to their price volatility. The inherent volatility in cryptocurrency prices, coupled with the effects of external global economic factors, makes predicting their price movements challenging. To address this challenge, we propose a dynamic Bayesian network (DBN)-based approach to uncover potential causal relationships among various features including social media data, traditional financial market factors, and technical indicators. This study focuses on six major cryptocurrencies, including Bitcoin, Binance Coin, Ethereum, Litecoin, Ripple, and Tether. The proposed model’s performance is compared to five baseline models of auto-regressive integrated moving average, support vector regression, long short-term memory, random forests, support vector machines, and a large language model. Results demonstrate that while DBN performance varies across cryptocurrencies, with some cryptocurrencies exhibiting higher predictive accuracy than others, the DBN significantly outperforms the baseline models. © 2025 Elsevier B.V., All rights reserved.",Causal Feature Engineering; Cryptocurrencies; Dynamic Bayesian Networks; Price Direction Prediction; Social Media,Scopus
10.1007/s10844-025-00971-3,10.1007/s10844-025-00971-3,From news to trends: a financial time series forecasting framework with LLM-driven news sentiment analysis and selective state spaces,"Stock price prediction is inherently challenging due to market volatility and the influence of external factors. Traditional forecasting methods primarily rely on historical price data, limiting their ability to capture market sentiment embedded in financial news. To address this limitation, we propose MambaMoE, a novel model that integrates historical stock prices with sentiment information extracted from financial news. Specifically, we fine-tune a DeepSeek-based large language model (LLM) for financial sentiment classification and incorporate the extracted sentiment information into our predictive framework. At the core of our approach is MambaMoE layer, which leverages the efficiency of state space models (SSMs) to model long-range dependencies while maintaining linear computational complexity, making it well-suited for financial time series forecasting. Additionally, the Mixture of Experts (MoE) mechanism improves the model’s ability to capture diverse market behaviors by dynamically selecting specialized experts based on stock data patterns. Experimental results demonstrate that MambaMoE outperforms LSTM-based models by 23.7% and Transformer-based models by 6.3%, highlighting its superior performance in short-term stock prediction. © 2025 Elsevier B.V., All rights reserved.",LLM; Mamba; Sentiment analysis; Time series forecasting,Scopus
10.1080/15427560.2025.2538879,10.1080/15427560.2025.2538879,Intraday Stock Prediction Using Sentiment Analysis: Evidence from Dividend Announcements,"This study explores whether sentiment extracted from financial news using large language models (LLMs) can predict abnormal intraday stock returns following dividend announcements. Drawing on 4,682 news items linked to 1,258 announcements from 394 S&P 500 companies (January 2023–January 2024), we use ChatGPT to extract sentiment polarity scores and we apply different models to forecast cumulative abnormal returns (CARs) in 30-minute intervals. Our findings reveal that sentiment–especially when captured immediately after news releases–has significant predictive power over intraday price movements. Strategies based on ChatGPT-derived sentiment consistently outperform benchmark models, particularly within the first two hours of trading. These results remain robust across alternative specifications and placebo tests, highlighting the value of LLMs for real-time market prediction. This research advances the literature on sentiment analysis and behavioral finance by linking emotion-driven news interpretation to high-frequency trading performance. © 2025 Elsevier B.V., All rights reserved.",Financial news; intraday trading; investment strategies; market reaction; sentiment analysis,Scopus
10.1109/ICAISISAS64483.2025.11051550,10.1109/ICAISISAS64483.2025.11051550,Machine Learning Approaches to Picking A-Shares Stocks: A Comparative Analysis,"This study explores the integration of advanced machine learning (ML) techniques and large language models (LLMs) in financial modeling, focusing on the Chinese stock market. It introduces the ChatGPT Score, an LLM-driven sentiment analysis factor, and compares the traditional Fama-French five-factor (FF5) model with its augmented version, FF5+ChatGPT Score. The research evaluates linear regression models against ML models, such as Random Forests, Extreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine (LightGBM), and Category Boosting (CatBoost), within five- and six-factor frameworks. Empirical results show that the ChatGPT Score outperforms traditional sentiment tools like SnowNLP and improves the predictive accuracy of the FF5 model. Additionally, CatBoost and Random Forests demonstrate strong portfolio management capabilities. Statistical validation through retrospective analysis confirms the effectiveness of the models, while industry feedback highlights their practical value in investment strategies. However, the study acknowledges the limitations of current models and recommends future research on deep learning techniques to improve financial market analysis and predictive accuracy. © 2025 Elsevier B.V., All rights reserved.",CatBoost; ChatGPT Score; Chinese Stock Market; Fama-French Models; Financial Modeling; Large Language Models; LightGBM; Machine Learning; Random Forests; Sentiment Analysis; XGBoost,Scopus
10.1109/CVC65719.2025.00007,10.1109/CVC65719.2025.00007,AI Oracle: A Blockchain-Powered Oracle for LLMs and AI Agents,"Large Language Models (LLMs) such as GPT and similar architectures have revolutionized artificial intelligence by enabling machines to understand and generate human-like text. However, these models are inherently statistical predictors rather than real-time reasoning systems, leading to fundamental limitations in accessing up-to-date information and verifying factual accuracy. This issue is particularly critical in high-stakes domains such as cryptocurrency markets, decentralized finance (DeFi), and autonomous AI agents, where real-time, verifiable, and tamper-proof information is essential for decision-making. In this paper, we introduce AI Oracle, a novel framework that integrates blockchain-powered oracles with LLMs and autonomous agents to ensure real-time access to cryptographically verified knowledge. We compare AI Oracle with both standalone LLMs and retrieval-based systems using the Model Context Protocol (MCP), highlighting significant advantages in factual reliability, adversarial robustness, and interpretability. AI Oracle combines decentralized consensus, immutable storage, and cryptographic attestation to equip AI agents with enhanced resistance to manipulation, hallucination, and misinformation. Beyond architectural improvements, we explore the broader applicability of AI Oracle across domains that require provable correctness and trust - ranging from real-world asset (RWA) tokenization to autonomous agent coordination and decentralized governance. By positioning AI Oracle as a trust-minimized epistemic infrastructure, we propose a new paradigm in AI systems: the fusion of decentralized trust with autonomous reasoning, enabling agents to operate with resilience, transparency, and embedded verifiability across dynamic environments. © 2025 Elsevier B.V., All rights reserved.",AI Agent; Blockchain Technology; LLM; Price Oracle; RWA,Scopus
10.1109/CNIOT65435.2025.11070984,10.1109/CNIOT65435.2025.11070984,Incorporating related stock and text for stock price movement prediction based on information fusion,"Investors have long been concerned with the analysis of textual information related to target stocks when making stock investments. We collected and extracted stock news headlines from the Chinese stock market and utilized a Large Language Model (LLM) to identify stocks related to the target stock and the relationships among them. Based on these relationships, we constructed a related stock relationship graph. Considering the dynamic changes in the relationship weights between stocks, we employed Graph Attention Networks (GAT) to build a feature fusion model for integrating the features of related stock news. Factors influencing prediction were considered, including different methods of text concatenation, the identification of related stocks, the relationship modeling between related stocks, and the fusion of related stock features. A comparative analysis of the Long Short-Term Memory (LSTM) model, the Bidirectional Long Short-Term Memory (Bi-LSTM) model, and the Long Short-Term Memory with Attention (LSTM-Attention) model revealed that both the news headlines of the target stock and the related stocks, along with their relationships, impact stock price movement prediction. Conversely, ignoring feature fusion and textual feature extraction can negatively affect prediction accuracy. © 2025 Elsevier B.V., All rights reserved.",fusion model; GAT; LLM; LSTM; stock price movement prediction,Scopus
10.1007/978-981-96-3725-6_32,10.1007/978-981-96-3725-6_32,Time Series Demand Prediction Model for Forecasting Bitcoin Prices Using Generative AI,"This paper presents a time series demand prediction model designed to forecast Bitcoin price fluctuations. As cryptocurrency markets are known for their high volatility and speculative nature, accurate predictions are crucial for investors and financial analysts. Utilizing advanced machine learning techniques, this study builds and evaluates multiple models, including ARIMA, LSTM, and Prophet, to predict Bitcoin prices based on historical data. The models are compared for accuracy, computational efficiency, and their ability to capture trends and seasonality. The research demonstrates that incorporating external variables, such as trading volume and market sentiment, can significantly enhance prediction accuracy. This study contributes to the growing field of cryptocurrency forecasting by offering insights into the most effective methodologies for predicting Bitcoin prices, addressing both technical challenges and practical implications for real-world applications. © 2025 Elsevier B.V., All rights reserved.",ARIMA; Bitcoin price forecasting; Cryptocurrency market; Financial modeling; LSTM; Machine learning; Market volatility; Prophet model; Time series prediction; Trading volume,Scopus
10.1109/CAI64502.2025.00032,10.1109/CAI64502.2025.00032,Graph LLM-Based Portfolio Management Algorithm,"This paper explores the integration of large language models (LLMs) with graph-based financial networks for quantitative trading. By leveraging GPT-3 for stock network return predictions, we develop a Graph-LLM trading strategy. Experimental results demonstrate that the proposed strategy achieves lower volatility and more stable performance than traditional baselines. Our findings highlight the potential of combining LLMs with financial complex networks to enhance quantitative trading strategies. © 2025 Elsevier B.V., All rights reserved.",Financial complex networks; Graph-based trading strategies; Large language models; Quantitative trading,Scopus
10.1007/978-3-031-97564-6_24,10.1007/978-3-031-97564-6_24,Predicting Stock Prices with ChatGPT-Annotated Reddit Sentiment: Hype or Reality?,"The surge of retail investor activity on social media, exemplified by the 2021 GameStop short squeeze, raised questions about the influence of online sentiment on stock prices. This paper explores whether sentiment derived from social media discussions can meaningfully predict stock market movements. We focus on Reddit’s r/wallstreetbets and analyze sentiment related to two companies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment’s role, we employ two existing text-based sentiment analysis methods and introduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model designed to better interpret the informal language and emojis prevalent in social media discussions. We use correlation and causality metrics to determine these models’ predictive power. Surprisingly, our findings suggest that social media sentiment has only a weak correlation with stock prices. At the same time, simpler metrics, such as the volume of comments and Google search trends, exhibit stronger predictive signals. These results highlight the complexity of retail investor behavior and suggest that traditional sentiment analysis may not fully capture the nuances of market-moving online discussions. © 2025 Elsevier B.V., All rights reserved.",ChatGPT; Sentiment; Social media; Stock market,Scopus
10.54364/AAIML.2025.52216,10.54364/AAIML.2025.52216,Assessing Lag-Llama in Probabilistic Time Series Forecasting for the Indonesian Stock Market,"Accurately predicting stock prices is crucial for investors and policymakers. This paper presents the first empirical evaluation of Lag-Llama, a novel probabilistic time series forecasting model, for predicting stock prices on the Indonesian Stock Exchange (IDX). By applying Lag-Llama to both univariate and multi-time series forecasts of key IDX stocks, we assess its ability to capture temporal patterns and market volatility, particularly in comparison to state-of-the-art models like DeepAR (RNN) and Temporal Fusion Transformer (TFT). Our results show that in fine-tuning scenarios Lag-Llama achieves a Continuous Ranked Proba-bility Score (CRPS) of 0.0195 on a combined dataset of three major stocks (BBCA, BMRI, and AMRT), closely matching TFT (CRPS 0.0179) and outperforming DeepAR (CRPS 0.0270). However, forecasting across broader stock groups (Top 1–9 and Top 10–18 by market cap-italization) proves more challenging, with CRPS values rising (e.g. 0.0517 for the Top 1– 9 stocks). This study demonstrates Lag-Llama’s potential as a robust tool for stock price prediction—particularly for select, closely-related stock groupings—offering improved precision and reliability compared to traditional methods. © 2025 Elsevier B.V., All rights reserved.",Lag-Llama; Large Language Models; Probabilistic Time Series Forecasting; Stock Market Analysis,Scopus
10.1007/s11156-025-01437-x,10.1007/s11156-025-01437-x,Using Generative AI to predict the weather impact on future stock returns,"This study explores the use of Generative AI, specifically OpenAI’s ChatGPT, for forecasting the impacts of severe weather events on stock returns. Employing prompts that assess textual weather descriptions, ChatGPT, a powerful generative AI large language model (LLM), provides predictions incorporated into econometric models. Results show that when ChatGPT forecasts negative stock impacts from storms, larger, more profitable firms with lower leverage and higher liquidity experience lower subsequent returns, suggesting investor underreaction to weather risk. ChatGPT’s predictive abilities are stronger during favorable economic conditions like uptrends, low volatility, and robust employment growth, implying investor underreaction amid bullish sentiment. © 2025 Elsevier B.V., All rights reserved.",ChatGPT; Generative AI; Large language model (LLM); Stock returns; Weather risk,Scopus
2-s2.0-105010263013,,A TRAINING-FREE SUB-QUADRATIC COST TRANSFORMER MODEL SERVING FRAMEWORK WITH HIERARCHICALLY PRUNED ATTENTION,"In modern large language models (LLMs), increasing the context length is crucial for improving comprehension and coherence in long-context, multi-modal, and retrieval-augmented language generation. While many recent transformer models attempt to extend their context length over a million tokens, they remain impractical due to the quadratic time and space complexities. Although recent works on linear and sparse attention mechanisms can achieve this goal, their real-world applicability is often limited by the need to re-train from scratch and significantly worse performance. In response, we propose a novel approach, Hierarchically Pruned Attention (HiP), which reduces the time complexity of the attention mechanism to O(T log T) and the space complexity to O(T), where T is the sequence length. We notice a pattern in the attention scores of pretrained LLMs where tokens close together tend to have similar scores, which we call “attention locality”. Based on this observation, we utilize a novel tree-search-like algorithm that estimates the top-k key tokens for a given query on the fly, which is mathematically guaranteed to have better performance than random attention pruning. In addition to improving the time complexity of the attention mechanism, we further optimize GPU memory usage by implementing KV cache offloading, which stores only O(log T) tokens on the GPU while maintaining similar decoding throughput. Experiments on benchmarks show that HiP, with its training-free nature, significantly reduces both prefill and decoding latencies, as well as memory usage, while maintaining high-quality generation with minimal degradation. HiP enables pretrained LLMs to scale up to millions of tokens on commodity GPUs, potentially unlocking long-context LLM applications previously deemed infeasible. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.1109/IDS66066.2025.00016,10.1109/IDS66066.2025.00016,Enhancing FinRL Trading Agents with Advance LLM-Processed Financial News: An Improved Approach Using DeepSeek-V3,"The use of AI techniques to improve stock market related operations has been benefiting traders in the stock market. FinRL is a framework that has been shown to be effective in building Reinforcement Learning (RL) based Trading Agents. Use of LLMs for performance improvement of the Agents is one of the recent initiatives. LLMs are being used to generate signals that could be combined with historical stock prices for better prediction of stock price movement trends leading to profitable trading. This paper aims to develop efficiently engineered prompts to generate DeepSeek-V3-based sentiment signals, integrate them into the FinRL environment, and improve the performance of reinforcement learning trading agents. The code, data, and trading agents are at: https://github.com/SatishChandraPhD/FinRL2025. © 2025 Elsevier B.V., All rights reserved.",DeepSeek; financial news; Financial Reinforcement Learning; FinRL; large language model; prompt; stock market; stock price trend; trading agent,Scopus
10.1007/978-3-031-96235-6_21,10.1007/978-3-031-96235-6_21,Comparative Analysis and Evaluation of SLMs and LLMs for Stock Price Movement Prediction,"This paper investigates the performance disparities between Small Language Models (SLMs) and Large Language Models (LLMs) in predicting stock price movements using data from two different datasets containing news articles and tweets. The study emphasizes the potential of SLMs as a more accessible and resource-efficient alternative to LLMs, enabling local and in-house deployment. Critical gaps are addressed, including the lack of direct price movement predictions, the utilization and comparison of State-of-the-Art (SotA) models, and the integration of diverse data sources. The research employed a fundamental trading strategy based on predicted stock price movement as the sole trading signal. The Phi-2 model, fine-tuned with Quantized Low-Rank Adaptation (QLoRA) on consumer-grade hardware, was compared with GPT-4, serving as a SotA benchmark. Performance was evaluated using accuracy, precision, recall, and F1-score. The results indicate that the fine-tuned SML (Phi-2) outperformed the LLM (GPT-4), albeit by a small margin, demonstrating the potential of a trained SML over a general LLM. © 2025 Elsevier B.V., All rights reserved.",Algorithmic Trading; Artificial Intelligence; Large Language Models; Small Language Models; Stock Price Prediction,Scopus
10.1007/978-3-031-96235-6_23,10.1007/978-3-031-96235-6_23,Enhancing Cryptocurrency Sentiment Analysis with GPT-4: A Comparative Study,"Attracting investors seeking distributed investing possibilities, cryptocurrencies are gradually taking front stage on financial markets. But sentiment analysis is essential for understanding market dynamics with considerable volatility molded by news, social media trends, and investor mood. This paper investigates the relevance of Large Language Models (LLMs), particularly fine-tuned GPT-4, in cryptocurrency sentiment analysis. By fine-tuning GPT-4 using a cryptocurrency news dataset, this paper compares its sentiment classification performance against other models, including FinBERT, BERT, Flan-T5, and Gemma-7B. The results indicate higher accuracy since finely tuned LLMs show better in classifying sentiments as positive, neutral, or negative. These results highlight the need of optimizing to raise sentiment analysis capability. This paper contributes to both academic research and financial applications, offering insights into how LLMs can be leveraged for market trend predictions and risk management strategies. © 2025 Elsevier B.V., All rights reserved.",Comparative Study; Cryptocurrency; Fine-Tuning; GPT-4; Large Language Model; Sentiment Analysis,Scopus
10.1007/978-981-96-1758-6_20,10.1007/978-981-96-1758-6_20,"Forex Price Prediction: A Multi-model Approach Integrating Sentiment Analysis Using LLMs with LSTM, XGBoost, Transformer Models","Accurate forex price prediction is challenging due to the market’s inherent volatility and the complex interactions among various economic factors and market sentiment. This study addresses these challenges by integrating sentiment analysis with advanced deep learning and machine learning architectures within a multi-model framework. Over two thousand financial news headlines were collected from leading economic websites using web scraping tools such as Selenium and BeautifulSoup, forming the basis for sentiment analysis. The sentiment data was processed using cutting edge natural language processing techniques, including Zero-Shot learning with GPT-4 and GEMINI Advanced models, selected for their proficiency in handling unlabeled financial sentiment data. The proposed solution combines sentiment scores with technical and fundamental market indicators, feeding these into diverse predictive models, including Long Short-Term Memory networks, eXtreme Gradient Boosting, and Transformer architectures in encoder-decoder and decoder-only configurations. This approach captures the nuanced effects of market sentiment within a four-hour trading window, aligning closely with real-time market dynamics. The key findings indicate that integrating sentiment analysis significantly improves prediction accuracy, with the XGBoost model demonstrating superior performance when combined with technical, fundamental, and sentiment data. The study reveals that while this multi-model approach offers improved predictive capabilities, it also faces limitations such as dependency on high-quality sentiment data and the computational intensity of training complex models. These results suggest that the integration of sentiment analysis provides a competitive edge in forex forecasting, though further research is needed to refine these methods and address their limitations. © 2025 Elsevier B.V., All rights reserved.",Forex prediction; LSTM; Sentiment analysis; Transformer; XGBoost,Scopus
10.1142/S1469026825500075,10.1142/S1469026825500075,RMHAN: Random Multi-Hierarchical Attention Network with RAG-LLM-Based Sentiment Analysis Using Text Reviews,"Currently, social media networks produce a large quantity of social data from users. To understand the views of people and sentimental tendencies on a commodity or an event in a timely manner, it is essential to conduct sentiment analysis (SA) on the views that are expressed by users. For longer text data, it comprises various contents and the correlation among words is more complicated than the short text. To bridge this gap, a random multi-hierarchical attention network (RMHAN) is introduced for SA using text reviews. First, the input review is passed to bidirectional encoder representation from transformers (BERTs) tokenization, which breaks the text into individual tokens, and the output-1 is obtained. Likewise, input review is passed to the retrieval-augmented generation-large language model (RAG-LLM) for recognizing, translating, predicting, or generating text or additional content, and thus, output-2 is accomplished. Thereafter, the tokenized word is passed to the feature extraction phase for extracting the features. Then, SA is conducted employing RMHAN. Here, RMHAN is the combination of random multimodel deep learning (RMDL) and hierarchical attention network (HAN), where layers are modified employing the Taylor network with some forward methodology. It can be noticed that RMHAN accomplished a better accuracy of 91.90%, a precision of 91.70%, and an F1-score of 89.10%. © 2025 Elsevier B.V., All rights reserved.",hierarchical attention network; random multimodel deep learning; retrieval-augmented generation; Sentiment analysis; term frequency-inverse document frequency,Scopus
10.1007/s10614-025-11024-w,10.1007/s10614-025-11024-w,Stock Market Forecasting: From Traditional Predictive Models to Large Language Models,"Stock market forecasting is a complex research problem due to the complexity of the factors influencing stock market trends. This survey provides a comprehensive overview of recent advancements in stock market forecasting, focusing on the impact of large language models (LLMs) in financial analytics. The survey explores the strengths and challenges of feature engineering, ensemble methods, hybrid models, text-based prediction and reinforcement learning. It then presents the transformative impact of LLMs, highlighting their capabilities in utilizing transfer learning and few-shot learning to understand complex financial information, enhancing sentiment analysis, improving portfolio management, and stock forecasting accuracy. A key novelty of this survey lies in presenting comprehensive analysis of the strengths and weaknesses of LLMs for different financial tasks in addition to exploring how LLMs can be combined with machine learning and reinforcement learning approaches to overcome their limitations in handling unstructured data, improving model explainability, and enhancing generalizability. Finally, this survey identifies existing research gaps and limitations, proposing future research directions aimed at improving prediction accuracy and utilizing both LLMs and predictive models’ capabilities in stock market forecasting. © 2025 Elsevier B.V., All rights reserved.",Feature engineering; Large language models; LLM-based financial agents; Machine learning; Reinforcement learning; Stock market forecasting,Scopus
10.1080/14697688.2025.2511115,10.1080/14697688.2025.2511115,Stock market simulator using hidden Markov generative model and its application in risk measurement,"We propose a novel data-driven framework, called hidden Markov generative model, which combines the hidden Markov model (HMM) and a generative model for simulating a sequence of data. Specifically, we use the Wasserstein generative adversarial network (WGAN) as the generative model and use the resulting setup, HMM-WGAN, for simulating multivariate stock returns. In line with the original GAN model for images, we depict the invisible hands in financial markets as market painters and the different market regimes as distinct observable painting styles. The framework comprises of two phases. In Phase I, we train a time-homogeneous HMM to identify market painters for each trading day using a set of realized exogenous features. In Phase II, the painting style for each market painter is learned adversarially from a set of realized stock returns using WGAN. Subsequently, the market painter for the next trading day is simulated with the current regime and the trained HMM's transition matrix, and the consequent painting, i.e. multivariate stock returns, is then generated using the market painter's trained WGAN generator. Our empirical results demonstrate that the simulated multivariate stock returns not only replicate a comprehensive set of well-documented stylized facts—including heavy-tailed distributions, volatility clustering, and leverage effects—but also yield a more robust value-at-risk estimates compared to traditional approaches. As such, our framework provides a flexible, data-driven alternative to conventional parametric models without imposing restrictive assumptions. © 2025 Elsevier B.V., All rights reserved.",Deep learning; Generative models; Hidden Markov models; Risk measurement; Stock market simulation; Stylized facts,Scopus
10.22495/rgcv15i2p13,10.22495/rgcv15i2p13,CAN CHATGPT PREDICT STOCK PRICES? EVALUATING ARTIFICIAL INTELLIGENCE-DRIVEN FINANCIAL FORECASTING AND RISK MANAGEMENT,"The use of artificial intelligence (AI) in financial forecasting has become increasingly significant in finance and accounting, offering improved precision in predicting key financial indicators such as revenue and net income. The purpose of this study is to explore the relationship between AI models’ benchmark scores and their predictive accuracy, addressing a gap in the literature regarding comprehensive evaluations of AI performance across financial metrics. Recent research highlights AI’s potential to outperform traditional statistical methods, with deep learning and ensemble models demonstrating notable accuracy in predicting stock prices and financial ratios (Khattak et al., 2023; Cao, 2021). By analyzing the 2020–2022 financial records of ten publicly listed corporations this research implements zero-shot prompt approaches for forecasting 2023 revenue and net income. Research findings demonstrate AI models can effectively boost financial prediction accuracy and such accuracy remains essential for business choices and risk protocols. Practical steps for AI reliability enhancement focus on using top-quality data with transparency and methods to control algorithmic biases. The research is relevant because it adds to AI finance understanding in academia while generating practical applications that guide industry professionals toward future exploration of financial AI applications. © 2025 Elsevier B.V., All rights reserved.",Artificial Intelligence; Benchmarking; Financial Forecasting; Net Income Prediction; Predictive Analytics; Revenue Prediction,Scopus
10.1109/ICASSPW65056.2025.11011079,10.1109/ICASSPW65056.2025.11011079,Hybrid Encoding-based Quantum Self Attention for Financial Time Series Analysis,"Self-attention mechanisms, central to Transformer architectures, have become foundational in the development of large language models (LLMs) and various advanced machine learning systems. These mechanisms are pivotal for effectively capturing complex data dependencies and relationships, which is crucial for tasks such as natural language understanding and generation. However, as dimensionality increases, self-attention mechanisms face significant challenges related to computational efficiency and scalability. This paper introduces an encoding-based quantum self-attention mechanism designed to address these issues by embedding classical data into quantum states. This approach facilitates more efficient computation and reduces model complexity. To further enhance performance for real-world applications, particularly in financial time series forecasting, we propose a hybrid model that integrates Long Short-Term Memory (LSTM) networks with quantum self-attention mechanism. Given the constraints of the Noisy Intermediate-Scale Quantum (NISQ) era, this hybrid approach represents a plausible solution, leveraging the strengths of both classical and quantum methods and focusing on achieving faster convergence. Experimental results demonstrate that our approach converges significantly quicker than traditional models, showcasing the advantages of integrating quantum techniques with classical machine learning for practical applications. © 2025 Elsevier B.V., All rights reserved.",LSTM; Quantum Neural Networks; Quantum Self-Attention; Self-Attention; Transformers,Scopus
10.1007/978-3-031-84371-6_3,10.1007/978-3-031-84371-6_3,Advancing Interpretability in Sequential Models Through Generative AI Rationalization Using GPT-4,"In this study, we investigate the role of Generative Pre-trained Transformer 4 (GPT-4) in enhancing interpretability of sequential predictions in Natural Language Processing (NLP). Our study introduces a hybrid model that integrates traditional sequential prediction models with GPT-4, aiming to generate detailed, context-sensitive explanations for model outputs. This approach is rooted in the use of advanced transformer architectures and a specialized tokenization method that maintains semantic coherence, allowing for deep contextual analysis by GPT-4. Additionally, we devise a rationale generation algorithm that achieves a balance between succinctness and informativeness. Our experimental validation spans across various high-dimensional datasets, including financial time-series and multilingual texts, employing both qualitative and quantitative metrics to evaluate the model’s performance. These metrics focus on the plausibility and consistency of the rationales, as well as the model’s predictive accuracy. Preliminary results demonstrate that our approach not only enhances the accuracy of sequential predictions but also significantly improves their interpretability. This finding highlights the potential of generative AI to bridge the gap between complex AI decision-making processes. This research underscores the viability of employing generative AI to elucidate the underlying mechanisms of sequential prediction models, paving the way for more transparent AI systems. © 2025 Elsevier B.V., All rights reserved.",Explainable AI (XAI); Generative AI; Sequential predictions,Scopus
10.1007/978-3-031-84460-7_33,10.1007/978-3-031-84460-7_33,Transformer for Time Series: An Application to the S&P500,"The transformer models have been extensively used with good results in a wide area of machine learning applications including Large Language Models and image generation. Here, we inquire on the applicability of this approach to financial time series. We first describe the dataset construction for two prototypical situations: a mean reverting synthetic Ornstein-Uhlenbeck process on one hand and real S&P500 data on the other hand. Then, we present in detail the proposed Transformer architecture and finally we discuss some encouraging results. For the synthetic data we predict rather accurately the next move, and for the S&P500 we get some interesting results related to quadratic variation and volatility prediction. © 2025 Elsevier B.V., All rights reserved.",LLM for time series; S&P500; Time series; Transformer,Scopus
10.1109/CSICC65765.2025.10967454,10.1109/CSICC65765.2025.10967454,LoopGAN: A Novel Multi-Step Generative Architecture for Sequential Stock Forecasting,"This paper introduces ""LoopGAN,"" an advanced generative model architecture designed for sequential stock forecasting, leveraging the strengths of Conditional GAN (CGAN) and Least Squares GAN (LSGAN) to enhance prediction accuracy in highly volatile financial time series. LoopGAN's unique recursive prediction mechanism allows each output to feed back as input, creating dynamic, extended forecasts across multiple time steps. Extensive evaluation of the Dow Jones Industrial Average (DJIA) dataset, highlights LoopGAN's superior performance, achieving a Mean Absolute Percentage Error (MAPE) of 0.005739. This result surpasses traditional models, with LoopGAN outperforming LSTM and RNN models, which registered MAPE scores of 0.006803 and 0.008023, respectively. These findings underscore LoopGAN's robustness, offering a marked improvement in prediction accuracy and confirming its reliability for complex financial forecasting tasks. © 2025 Elsevier B.V., All rights reserved.",architecture; CGAN; GAN; LSGAN; stock forecasting,Scopus
10.1109/ACCESS.2025.3568028,10.1109/ACCESS.2025.3568028,Agora: A Distributed Language Model Framework with API-Call Support for Integrated Climate Forecasting,"We introduce Agora, a Generative AI-driven system that delivers expert answers and recommendations on climate and agriculture, transforming complex data into clear, natural language explanations. While built for the rural domain, Agora is highly adaptable and can be deployed across various domain applications. It operates as a ""mixture-of-experts"" language model system, selectively utilizing multiple fine-tuned large language models for inference. By dynamically integrating external data through API calls, Agora ensures real-time, contextually relevant responses. Agora is built for extensibility - it seamlessly integrates new APIs and domains without requiring a full system retrain. Developed entirely with open-source large language models from the LLaMA family, Agora remains open and adaptable, allowing anyone to extend and enhance its capabilities. Optimized for accessibility, Agora runs efficiently on commodity GPUs without compromising performance. By eliminating the need for expensive hardware like NVIDIA's A100, it makes text generation more affordable and widely accessible. Agora outperforms closed-source models, achieving 78% accuracy on our question-answering benchmark. This result is achieved via dynamic API integration, which pulls in real-time external data, making responses more adaptive, precise, and context-aware. © 2025 Elsevier B.V., All rights reserved.",API-call orchestration; API-call support; forecast generation; large language model; model fine-tuning; natural language processing,Scopus
10.1109/CiFer64978.2025.10975739,10.1109/CiFer64978.2025.10975739,Leveraging Large Language Models and Retrieval-Augmented Generation for Enhanced Multi-Asset Portfolio Construction,"This study assesses the Large Language Models (LLMs) in creating investment portfolios. We implement a few-shot learning technique, followed by Retrieval Augmented Generation (RAG) enhanced with comprehensive up-to-date financial data, using Meta's latest LLM, Llama 3.1-8b. In the first phase, We assess the models' efficacy using key financial indicators, including total returns, annualized volatility, riskadjusted performance (Sharpe ratio), potential loss estimates (value-at-risk), and their pre-training knowledge with the S&P 500 Index performance baseline. In the second phase, we enhance the LLM's knowledge base by RAG and the latest historical and statistical metrics (such as earnings per share (EPS), dividends per share (DPS), profit margin, and many more) for each asset from different classes. The study constrains model inputs to specific sets of financial assets, such as equities, exchangetraded funds (ETFs), commodities, cryptocurrencies, and bonds. To evaluate model performance and adaptability, we analyzed across two distinct time frames: (1) within the models' training data cutoff, and (2) from the cutoff date to the present. This approach enables the assessment of model generalization to past and present market conditions. The research quantifies LLMs' capabilities in financial asset allocation, comparing baseline performance against RAG-augmented strategies. Our results demonstrate that RAG-enhanced LLM significantly outperforms vanilla LLM in portfolio construction across various asset classes. We contemplate that these results could influence AI-driven financial decision-making processes such as automated trading, real-time sentiment analysis, and investment management. © 2025 Elsevier B.V., All rights reserved.",Asset Allocation; Computational Finance; Generative AI; Large Language Models; Llama; Portfolio management,Scopus
10.1109/CSNT64827.2025.10967744,10.1109/CSNT64827.2025.10967744,Recommender Systems for Sector-Specific Stock Analysis,"Recommender systems are essential tools that assist users in making informed decisions by providing suggestions based on their previous actions and preferences. Traditional methods like content based and collaborative filtering work well for smaller datasets but often fail to extract information from large datasets due to their limited ability to capture complex patterns. This paper introduces a novel approach for stock recommendation that leverages a large language model, Llama 3.1, fine-tuned on financial news data. Financial news headlines and summaries were collected using the FinnHub API which served as the primary dataset. The system integrates stock price forecasting, sentiment analysis, and performance indicators to generate an effective analysis for decision making. The forecasting algorithm generates the stock price predictions which were integrated with sentiment analysis and stock performance indicators to create an informative prompt-response dataset for fine-tuning. The proposed system ranks stocks based on positive developments, potential concerns, and forecasted closing prices, providing Buy or Sell recommendations. Experimental results demonstrated moderate performance for predicting Buy recommendations, while Sell predictions exhibited lower accuracy comparatively. Analysis based on sectors revealed that the consumer cyclical and healthcare sectors yielded the best performance for Buy and Sell recommendations, respectively. © 2025 Elsevier B.V., All rights reserved.",Large Language Models; Ranking Algorithm; Recommender Systems,Scopus
10.3905/jpm.2025.1.710,10.3905/jpm.2025.1.710,Using Large Language Models to Estimate Novel Risk: Impact on Volatility,"This article presents an integrated framework to estimate hard to measure (novel) financial risk for volatility forecasting. Recognizing the limitations of traditional models—which often overlook emerging “novel risks”—the article leverages advanced large language models (LLMs) to extract and quantify key risk factors, including ESG, geopolitical, and supply chain disruption risks, from corporate disclosures. These LLM-derived risk scores are then combined with conventional financial indicators such as leverage, beta, and short interest, and incorporated into a long short-term memory (LSTM) neural network to predict firm-specific (idiosyncratic) volatility. Empirical analysis, conducted on over 18,000 regulatory filings spanning 2015 to 2024, demonstrates that the integrated model significantly improves volatility forecasting, as evidenced by enhanced R2 values and reduced mean squared error. Additionally, feature importance analyses confirm the pivotal role of novel risk measures. Overall, the findings underscore the benefits of merging unstructured and hard to quantify data with quantitative models to offer a more nuanced approach to estimation of novel financial risk. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.14569/IJACSA.2025.0160402,10.14569/IJACSA.2025.0160402,"Comparing Vision-Instruct LLMs, Vision-Based Deep Learning, and Numeric Models for Stock Movement Prediction","This research conducts a comparative study of several stock movement prediction approaches, evaluating large language models (LLMs) and vision-based deep learning models with stock image as input, as well as models that utilize numerical data. Specifically, the study investigates a prompt-based LLM framework that processes candlestick charts, comparing its performance with image-based models such as MobileNetV2, Vision Transformer, and Convolutional Neural Network (CNN), as well as models with numerical inputs including Support Vector Machine (SVM), Random Forest, LSTM, and CNN-LSTM. Although LLMs have demonstrated promising results in stock prediction, directly applying them to stock images poses challenges compared to numerical approaches. To address this, this study further improves LLM performance with post-hoc calibration, reducing prediction biases. Experimental results demonstrate that post-hoc calibrated LLMs with visual input achieve competitive performance compared to other models, highlighting their potential as a viable alternative to traditional stock prediction methods while simplifying the prediction process. © 2025 Elsevier B.V., All rights reserved.",Convolutional Neural Network (CNN); Large Language Model (LLM); MobileNetV2; stock price prediction; time series forecasting; vision transformer,Scopus
10.1007/978-981-96-4589-3_9,10.1007/978-981-96-4589-3_9,Rationale-Driven Predictions for Stock Movements: A Multi-model Integration and Stack Generalization Approach,"With the advancement of computational power, large language models (LLMs) have rapidly developed in various fields. However, predicting stock price fluctuations remains a significant challenge, mainly due to the following two aspects: Lack Interpretability: Traditional methods usually lack interpretability, making it difficult for people to understand why the model predicts a rise or fall in stock prices. In the highly volatile financial market, since people often need to rely on professional judgment when making decisions, the quality of the reasoning provided by the model can sometimes be even more important than the accuracy of the model’s predictions.Model prediction bias: When generating rationales, models tend to favor a certain label, causing the final output of the model to lack reference significance. Lack Interpretability: Traditional methods usually lack interpretability, making it difficult for people to understand why the model predicts a rise or fall in stock prices. In the highly volatile financial market, since people often need to rely on professional judgment when making decisions, the quality of the reasoning provided by the model can sometimes be even more important than the accuracy of the model’s predictions. Model prediction bias: When generating rationales, models tend to favor a certain label, causing the final output of the model to lack reference significance. To address these challenges, we propose a new framework. We independently trained two models, TechGPT and SentiGPT, to analyze stock price data and text data from community platforms, respectively. By combining the outputs of TechGPT and SentiGPT, we developed a comprehensive model named IntegraGPT. During the training data collection process, we used In-Context Learning to require multiple large language models to generate reasoning rationales, avoiding reliance on a single large language model for reasoning. This approach addresses the issues of insufficient interpretability and model prediction bias. © 2025 Elsevier B.V., All rights reserved.",Large Languange Model; Natural Language Processing; Stock Movement Prediction,Scopus
10.1109/HPCA61900.2025.00129,10.1109/HPCA61900.2025.00129,Make LLM Inference Affordable to Everyone: Augmenting GPU Memory with NDP-DIMM,"The billion-scale Large Language Models (LLMs) necessitate deployment on expensive server-grade GPUs with large-storage HBMs and abundant computation capability. As LLM-assisted services become popular, achieving cost-effective LLM inference on budget-friendly hardware becomes the current trend. This has sparked extensive research into relocating LLM parameters from expensive GPUs to external host memory. However, the restricted bandwidth between the host and GPU memory limits the inference performance of existing solutions. This work introduces Hermes, a budget-friendly system that leverages the near-data processing units (NDP) within commodity DRAM DIMMs to enhance the performance of a single consumer-grade GPU, achieving efficient LLM inference. We recognize that the inherent activation sparsity in LLMs naturally divides weight parameters into two categories, termed 'hot' and 'cold' neurons, respectively. Hot neurons, which consist of only approximately 20% of all weight parameters, account for 80% of the total computational load. In contrast, cold neurons make up the other 80% of parameters but are responsible for just 20% of the computational workload. Leveraging this observation, we propose a heterogeneous computing strategy: mapping hot neurons to a single computation-efficient GPU without large-capacity HBMs, while offloading cold neurons to NDP-DIMMs, which offer large memory size but limited computation capabilities. In addition, the dynamic nature of activation sparsity necessitates a real-time partition of hot and cold neurons and adaptive remapping of cold neurons across multiple NDP-DIMM modules. To tackle these issues, we introduce a lightweight predictor that ensures optimal real-time neuron partition and adjustment between GPU and NDP-DIMMs. Furthermore, we utilize a window-based online scheduling mechanism to maintain load balance among multiple NDP-DIMM modules. In summary, Hermes facilitates the deployment of LLaMA2-70B on consumer-grade hardware at a rate of 13.75 tokens/s and realizes an average 75.24 × speedup over the state-of-the-art offloading-based inference system on popular LLMs. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.1109/TCSS.2025.3557911,10.1109/TCSS.2025.3557911,Enhancing Hybrid Bike-Sharing Systems Through Long-Term Inventory Management: A Generative-Model-Informed Reinforcement Learning Approach,"Hybrid bike-sharing systems (operating both bikes and ebikes) are emerging worldwide for flexibility and sustainability. Excessive rebalancing, while addressing supply-demand imbalances, causes financial burdens and resource waste. Hence, long-term daily operations (e.g., rebalancing at midnights for upcoming days) have practical economic significance, but they remain underexplored due to difficulties in tracking high within-day and between-day demand variability and the interplay between demand and daily inventory management strategies. Besides, cooperative operation of bikes and ebikes expands solution space, given their inherent demand coupling. This study is the first to explore long-term daily inventory strategies for the hybrid system (ebikes get charged at stations), determining spatial-heterogeneous inventory at midnight to maximize profits. To address the demand variability perception issue, we develop a recurrent-attentive neural process (RANP) model to predict hour-to-hour demand of the upcoming day. The RANP is integrated into a long-term optimization model, referred to as the generative-models-informed Markov decision process (GMI-MDP), where two cooperative intelligent agents determine the bike–ebike allocation based on demand perception and system rewards. A suite of numerical experiments utilizing a real-world dataset from New York is carried out, and various strategies are compared. The proposed method, through online and offline tests, demonstrates superiority over other MDP-based and rule-based methods, achieving a faster solution-seeking process and more stable rewards than MDP with exact upcoming demand. By comparing inventory volatility, we offer insights into managerial operations. © 2025 Elsevier B.V., All rights reserved.",Bike–ebike allocation; generative models; long-term management; Markov decision process (MDP),Scopus
10.24425/ijet.2025.153538,10.24425/ijet.2025.153538,LLM-Based multi-agent system for individual investment in energy and natural resources,"Recent advancements in large language models and multiagent large language model based systems show that these technologies can be applied to a large number of problems. They can automate complex tasks and perform advanced analyses that would take an expert a significant amount of time. This article describes a multiagent large language model (LLM) based platform for investment advisory in the energy natural resources sector. The system integrates multiple types of investment analyses e.g. technical analysis, fundamental analysis, sentiment analysis and stock price prediction. The approach of integrating multiple types of analyses in one system allows the investor to save significant amount of time on analyzing potential investments. © 2025 Elsevier B.V., All rights reserved.",Autonomous LLM Agents; Energy Minerals Market; Investment Advisory System; LangGraph; Multiagent systems,Scopus
10.1109/ICADEIS65852.2025.10933431,10.1109/ICADEIS65852.2025.10933431,The Effect of News Sentiment on Jakarta Composite Index Prediction Using Support Vector Regression Method,"This research investigates the impact of news sentiment on predicting the Jakarta Composite Index (JCI) using the Support Vector Regression (SVR) method. Market sentiment, derived from news articles, has been analyzed to understand its influence on stock price movements. A dual dataset approach was employed, consisting of financial news articles from Kompas.com and historical JCI stock data. The research incorporates sentiment analysis using ChatGPT large language models (LLMs), which are then integrated as features into the prediction model. Five scenarios of sentiment integration were evaluated to identify the most effective approach. The results indicate that Scenario 4 consistently delivers the highest prediction accuracy across different evaluation metrics, with Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) values of 0.009555 and 0.007298 in the log metric evaluation, 47.616867 and 36.52605 in the absolute metric evaluation, and 85.146387 and 70.34775 in the stock closing price evaluation. While sentiment integration shows potential, its success is scenario-dependent and influenced by hyperparameter tuning. This research underscores the utility of sentiment analysis in enhancing stock price predictions and provides a foundation for further exploration of sentiment based predictive models in financial markets. © 2025 Elsevier B.V., All rights reserved.",sentiment analysis; stock price prediction; support vector regression,Scopus
10.1109/ICADEIS65852.2025.10933440,10.1109/ICADEIS65852.2025.10933440,A Sentiment-Augmented Machine Learning Approach to Forecasting IHSG Prices Using XGBoost,"Stocks are a commonly used investment instrument, representing ownership in a company, and offering opportunities for investors to gain profits through the appreciation of stock value as well as dividend distribution. As one of the main financial assets, stocks are also influenced by various external factors, such as economic conditions, government policies, and market sentiment. All of these factors play a crucial role in determining stock price movements. This study integrates sentiment analysis with the XGBoost algorithm to predict IHSG stock prices. By utilizing historical stock data and sentiment derived from financial news, the study evaluates the impact of sentiment data integration on prediction accuracy. Three types of returns (absolute, relative, and logarithmic) and five sentiment scenarios were employed to assess the contribution of sentiment features to the prediction model. The results indicate that sentiment integration consistently improves the predictive performance of the model compared to using historical data alone. Among the tested scenarios, Scenario 2, 4, and 5 demonstrated the best performance, with an RMSE value of 0.009163 and an MAE value of 0.007432, using the logarithmic return type. These findings suggest that incorporating sentiment features into predictive models can enhance the accuracy of stock price predictions and highlight the potential of Natural Language Processing (NLP) and Large Language Models (LLMs) in stock market analysis. © 2025 Elsevier B.V., All rights reserved.",large language models; sentiment analysis; stock prediction; XGBoost algorithm,Scopus
10.5220/0013174500003890,10.5220/0013174500003890,Multimodal Stock Price Prediction,"In an era where financial markets are heavily influenced by many static and dynamic factors, it has become increasingly critical to carefully integrate diverse data sources with machine learning for accurate stock price prediction. This paper explores a multimodal machine learning approach for stock price prediction by combining data from diverse sources, including traditional financial metrics, tweets, and news articles. We capture real-time market dynamics and investor mood through sentiment analysis on these textual data using both ChatGPT-4o and FinBERT models. We look at how these integrated data streams augment predictions made with a standard Long Short-Term Memory (LSTM model) to illustrate the extent of performance gains. Our study's results indicate that incorporating the mentioned data sources considerably increases the forecast effectiveness of the reference model by up to 5%. We also provide insights into the individual and combined predictive capacities of these modalities, highlighting the substantial impact of incorporating sentiment analysis from tweets and news articles. This research offers a systematic and effective framework for applying multimodal data analytics techniques in financial time series forecasting that provides a new perspective for investors to leverage data for decision-making. © 2025 Elsevier B.V., All rights reserved.",Deep Learning; Deep Neural Networks; Financial Forecasting; Large Language Models; Multimodal Machine Learning; Stock Market Prediction,Scopus
10.5220/0013191200003890,10.5220/0013191200003890,Integrating Traditional Technical Analysis with AI: A Multi-Agent LLM-Based Approach to Stock Market Forecasting,"Traditional technical analysis methods face limitations in accurately predicting trends in today’s complex f inancial markets. This paper introduces ElliottAgents, an multi-agent system that integrates the Elliott Wave Principle with AI for stock market forecasting. The inherent complexity of financial markets, characterized by non-linear dynamics, noise, and susceptibility to unpredictable external factors, poses significant challenges for accurate prediction. To address these challenges, the system employs LLMs to enhance natural language understanding and decision-making capabilities within a multi-agent framework. By leveraging technologies such as Retrieval-Augmented Generation (RAG) and Deep Reinforcement Learning (DRL), ElliottAgents performs continuous, multi-faceted analysis of market data to identify wave patterns and predict future price movements. The research explores the system’s ability to process historical stock data, recognize Elliott wave patterns, and generate actionable insights for traders. Experimental results, conducted on historical data from major U.S. companies, validate the system’s effectiveness in pattern recognition and trend forecasting across various time frames. This paper contributes to the field of AI-driven financial analysis by demonstrating how traditional technical analysis methods can be effectively combined with modern AI approaches to create more reliable and interpretable market prediction systems. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.1109/IDCIOT64235.2025.10914764,10.1109/IDCIOT64235.2025.10914764,"Comparative Advances in Financial Sentiment Analysis:A Review of BERT,FinBert, and Large Language Models","Capturing market sentiments and supporting well-informed financial decision-making depend on the developing field of Financial Sentiment Analysis (FSA). Natural language processing (NLP) has made significant strides in comprehending and categorizing sentiment in intricate financial texts, especially with the use of Large Language Models (LLMs). The application of various LLMs, such as Bidirectional Encoder Representations form Transformers(BERT) and Financial BERT (FinBERT), as well as distilled models, such as DistilBERT and DistilRoBERTa, on a variety of financial datasets, including Financial Phrase Bank and LexisNexis news articles, was the main focus of this review article. highlighting different approaches such as model fine-tuning, zero-shot and few-shot learning, and prompt engineering. The study focuses on practical model predictions through a case study of sentimental analysis of cryptocurrencies. While FinBERT, a financial variant of BERT, exhibits high accuracy and robustness, other LLMs exhibit varying degrees of success based on the dataset and domain requirements. The analysis concentrates on the difficulties, compromises, and potential paths for improving LLMs for financial sentiment analysis. © 2025 Elsevier B.V., All rights reserved.",BERT; Data preprocessing; Fin Bert; Financial Datasets; Financial Sentimental Analysis; FSA; LLMs,Scopus
10.1109/TEM.2025.3554567,10.1109/TEM.2025.3554567,Being an Emotionally Unaffected Investor: Evidence From Bitcoin,"As one of the most prominent cryptocurrencies, Bitcoin has been at the forefront of a major revolution in the financial and technological sectors. This study utilizes data from social media to extract the emotional tendencies of investors in the Bitcoin market and analyze differences in investor behavior under various emotional features. We find that when investors exhibit reluctance (such as Sadness and Fear) to buy Bitcoin, it is the opportune moment to invest and achieve returns higher than expected. Conversely, when the emotional tone of investors becomes positive (such as Joy and Love), indicating a tendency to invest, we choose to avoid investing. Our research has also revealed that such emotional cues can assist in better predicting returns in the Bitcoin market. Analyzing market emotions contributes to a deeper understanding of market fluctuations and investor behavior. Our findings help stakeholders recognize the role of subjective emotions in the market and provide them with prudent investment advice: avoid relying excessively on the feelings of others, as this may trigger investment losses. © 2025 Elsevier B.V., All rights reserved.",BERT; bitcoin; investor behavior; large language models; machine learning; return prediction; textual analysis,Scopus
10.1080/23322039.2025.2468387,10.1080/23322039.2025.2468387,A systematic approach to predicting NFT prices using time series forecasting and macroeconomic factors in digital assets,"Non-fungible tokens (NFTs) have gained mainstream attention in the fintech community, but there is little research on their statistical properties. This study investigates the long-memory characteristics of NFT returns and volatility, focusing on their potential for predicting price movements. As NFTs do not conform to traditional models, understanding their unique features is crucial for comprehending complex market dynamics. This study aims to reveal the impact of macroeconomic factors on NFT prices, understand their correlation and develop predictive models using autoregression and artificial intelligence (AI) technology. This research utilized datasets from the Centers for Disease Control and Prevention (CDC), U.S. Bureau of Labor Statistics, Bureau of Economic Analysis, Christie’s, Dune, and Google Trends. Correlation and p value tests revealed strong relationships between NFT prices and variables such as weekly volume, pandemics, inflation and security. The Baseline Model using autoregression with NFT volume, security and technology factors outperformed all other models demonstrating the speculative volatility of NFTs. The Transformer Model using transformers, an architecture used by ChatGPT, Gemini and Stable Diffusion, showed high accuracy with less feature selection and preprocessing efforts. This study provides a novelty using a systematic approach for researchers to perform financial forecasting and contributes to the scarce literature on NFTs. This research offers valuable insights to investors and private agents regarding the right economic conditions for NFT investments by reducing portfolio risks and making informed decisions. To the authors’ best knowledge, this is the first study to utilize time-series transformers for forecasting NFTs based on macroeconomic factors. © 2025 Elsevier B.V., All rights reserved.",Artificial Intelligence; artificial intelligence; Econometrics; Finance; Financial Management; fintech; Macroeconomics; macroeconomics; NFTs; prediction; Risk Management; Technology; time series; transformer,Scopus
10.24136/oc.3109,10.24136/oc.3109,"Enterprise generative artificial intelligence technologies, internet of things and blockchain-based fintech management, and digital twin industrial metaverse in the cognitive algorithmic economy","Research background: Enterprise generative AI system-based worker behavior tracking and monitoring, socially responsible organizational practices, employee performance management satisfaction, and human resource management procedures, relationships, and outcomes develop on hiring and objective performance assessment algorithms in terms of human resource management activities, functions, processes, practices, policies, and productivity. Deep reinforcement and machine learning techniques, operational and analytical generative AI and cloud capabilities, and real-time anomalous behavior recognition systems further fintech development for credit and lending services, payment analytics processes, and risk assessment, monitoring, and mitigation. Generative AI tools can bolster predictive analytics by collaborative and interconnected sensor and machine data for tailored, seamless, and finetuned product, operational process, and organizational workflow development, efficiency, and innovation, driving agile transformative changes in digital twin industrial metaverse. Purpose of the article: We show that enterprise generative AI-driven schedule prediction tools, job search and algorithmic hiring systems, and synthetic training data can improve team selection, job performance and firing decisions, hiring decision processes, and workforce productivity in terms of prediction and decision-making by use of algorithmic management, system performance, and production process tracking tools. Blockchain-based fintech operations can shape cloud-based financial and digital banking services, quote-to-cash process automation, cash-settled crypto futures, digital loan decisioning, asset tokenization simulated transactions, transaction switching and routing operations, tailored peer-to-peer lending, and proactive credit line management. Collaborative unstructured enterprise data processing, infrastructure, and governance can develop on AI decision and behavior automation technology, retrieval augmented generation and development management systems, and real-time data descriptive and predictive analytics, driving productivity surges and competitive advantage in digital twin industrial metaverse. Methods: Reference and review management tools, together with evidence synthesis screening software, harnessed were Abstrackr, AMSTAR, ASReview Lab, CASP, Catchii, Citationchaser, DistillerSR, JBI SUMARI, Litstream, PICO Portal, and Rayyan. Findings & value added: The current state of the art is improved for theory on organizational issues and for policy making as deep learning-based generative AI tools and workplace monitoring systems can augment performance and productivity, gauge employee effectiveness, build resilient, satisfied, and engaged workforce, assess human capital, skill, and career development, drive employee and productivity expectations in relation to flexibility and stability, and shape turnover, retention, and loyalty. Cloud and account servicing technologies can be deployed in generative AI fintechs for embedded cryptocurrency trading, transaction monitoring and processing, digital asset transfers, payment screening, corporate and retail banking operations, and fraud prevention. Generative AI technologies can reshape jobs and reimagine meaningful work, involving creativity and innovation and adaptable and resilient sustained performance, providing valuable constructive feedback, optimizing workplace flexibility and psychological safety, and measuring and supporting autonomy and flexibility-based efficiency, performance, and productivity, while configuring demanding, engaging, and rewarding experiences by cloud and edge computing devices in digital twin industrial metaverse. © 2025 Elsevier B.V., All rights reserved.",blockchain; cognitive algorithmic economy; digital twin industrial metaverse; enterprise generative artificial intelligence; fintech; internet of Thing,Scopus
10.24136/oc.3283,10.24136/oc.3283,Generative artificial intelligence algorithms in Internet of Things blockchain-based fintech management,"Research background:Big data-driven artificial Internet of Things (IoT) fintech algorithms can provide real-time personalized financial service access, strengthen risk management, and manage, monitor, and mitigate transaction operational risks by operational credit risk man-agement, suspicious financial transaction abnormal pattern detection, and synthetic financial data-based fraud simulation. Blockchain technologies, automated financial planning and investment advice services, and risk scoring and fraud detection tools can be leveraged in financial trading forecasting and planning, cryptocurrency transactions, and financial work-flow automation and fraud detection. Algorithmic trading and fraud detection tools, distributed ledger and cryptocurrency technologies, and ensemble learning and support vector machine algorithms are pivotal in predictive analytics-based risk mitigation, customer behavior and preference-based financial product and service personalization, and financial transaction and fraud detection automation. Credit scoring and risk management tools can offer financial personalized recommendations based on customer data, behavior, and preferences, in addition to transaction history, by generative adversarial and deep learning recurrent neu-ral networks. Purpose of the article: We show that blockchain and edge computing technologies, generative artificial IoT-based fintech algorithms, and transaction monitoring and credit scoring tools can be harnessed in financial decision-making processes and loan default rate mitigation for transaction, payment, and credit process efficiency. Generative and predictive artificial intelligence (AI) algorithmic trading systems can drive coherent customer service operations, provide tailored financial and investment advice, and influence financial decision processing, while performing real-time risk assessment and financial and trading risk scenario simulation across fluctuating market conditions. Fraud and money laundering prevention tools, block-chain and financial transaction technologies, and federated and decentralized machine learning algorithms can articulate algorithmic profiling-based transaction data patterns and structures, credit assessment, loan repaying likelihood prediction, and interest rate and credit lending risk management by real-time financial pattern and economic forecast-based credit analysis across investment payment and transaction record infrastructures. Methods: Research published between 2023 and 2024 was identified and analyzed across ProQuest, Scopus, and the Web of Science databases by use of screening and quality assessment software systems such as Abstrackr, AMSTAR, AXIS, CADIMA, CASP, Catchii, Distill-erSR, Eppi-Reviewer, MMAT, Nested Knowledge, PICO Portal, Rayyan, ROBIS, and SRDR+. Findings & value added: The main value added derived from the systematic literature review is that generative AI-based operational risk management, fraud detection, and transaction monitoring tools can provide personalized financial support and services and clarify financial and credit decisions and operations by financial decision-making process automation in dynamic business environments based on fraud detection capabilities and transaction data analysis and assessment. The benefits for theory and current state of the art are that credit risk and financial forecasting tools, artificial IoT-based fintech and generative AI algorithms, and algorithmic trading and distributed ledger technologies can be deployed in financial decision-making and customer behavior pattern optimization, credit score assessment, and money laundering and fraudulent payment detection. Policy implications reveal that investment management and algorithmic credit scoring tools can streamline financial activity operational efficiency, design financial planning analysis and forecasting, and carry out financial service and transaction data analysis for informed transaction decision-making and fraudulent behavior pattern and incident detection, taking into account credit history and risk evaluation and improving personalized experiences. © 2025 Elsevier B.V., All rights reserved.",algorithmic trading; blockchain; fintech; fraud detection; generative artificial intelligence; Internet of Things,Scopus
10.3390/jrfm17120537,10.3390/jrfm17120537,Fin-ALICE: Artificial Linguistic Intelligence Causal Econometrics,"This study introduces Fin-ALICE (Artificial Linguistic Intelligence Causal Econometrics), a framework designed to forecast financial time series by integrating multiple analytical approaches including co-occurrence networks, supply chain analysis, and emotional sentiment analysis to provide a comprehensive understanding of market dynamics. In our co-occurrence analysis, we focus on companies that share the same emotion on the same day, using a much shorter horizon than our previous study of one month. This approach allows us to uncover short-term, emotion-driven correlations that traditional models might overlook. By analyzing these co-occurrence networks, Fin-ALICE identifies hidden connections between companies, sectors, and events. Supply chain analysis within Fin-ALICE will evaluate significant events in commodity-producing countries that impact their ability to supply key resources. This analysis captures the ripple effects of disruptions across industries and regions, offering a more nuanced prediction of market movements. Emotional sentiment analysis, powered by the Fin-Emotion library developed in our prior research, quantifies the emotional undertones in financial news through metrics like “emotion magnitude” and “emotion interaction”. These insights, when integrated with Temporal Convolutional Networks (TCNs), significantly enhance the accuracy of financial forecasts by capturing the emotional drivers of market sentiment. Key contributions of Fin-ALICE include its ability to perform month-by-month company correlation analysis, capturing short-term market fluctuations and seasonal patterns. We compare the performance of TCNs against advanced models such as LLMs and LSTMs, demonstrating that the Fin-ALICE model outperforms these models, particularly in sectors where emotional sentiment and supply chain dynamics are critical. Fin-ALICE provides decision-makers with predictive insights and a deeper understanding of the underlying emotional and supply chain factors that drive market behaviors. © 2024 Elsevier B.V., All rights reserved.",emotion interaction; financial market analysis; large language models; sentiment analysis; supply chain; temporal convolutional networks; time series forecasting,Scopus
10.3390/app142411897,10.3390/app142411897,Large Language Models and the Elliott Wave Principle: A Multi-Agent Deep Learning Approach to Big Data Analysis in Financial Markets,"Traditional technical analysis methods face limitations in accurately predicting trends in today’s complex financial markets. Meanwhile, existing AI-driven approaches, while powerful in processing large datasets, often lack interpretability due to their black-box nature. This paper presents ElliottAgents, a multi-agent system that combines the Elliott wave principle with LLMs, showcasing the application of deep reinforcement learning (DRL) and natural language processing (NLP) in financial analysis. By integrating retrieval-augmented generation (RAG) and deep reinforcement learning (DRL), the system processes vast amounts of market data to identify Elliott wave patterns and generate actionable insights. The system employs a coordinated team of specialized agents, each responsible for specific aspects of analysis, from pattern recognition to investment strategy formulation. We tested ElliottAgents on both stock and cryptocurrency markets, evaluating its effectiveness in pattern identification and trend prediction across different time scales. Our experimental results demonstrate improvements in prediction accuracy when combining classical technical analysis with AI-driven approaches, particularly when enhanced by DRL-based backtesting process. This research contributes to the advancement of financial technology by introducing a scalable, interpretable framework that enhances market analysis capabilities, offering a promising new methodology for both practitioners and researchers. © 2024 Elsevier B.V., All rights reserved.",deep reinforcement learning (DRL); Elliott wave principle; financial markets; investment strategies; large language models (LLMs); multi-agent systems,Scopus
10.1038/s41598-024-68959-7,10.1038/s41598-024-68959-7,Meta graphical lasso: uncovering hidden interactions among latent mechanisms,"In complex systems, it’s crucial to uncover latent mechanisms and their context-dependent relationships. This is especially true in medical research, where identifying unknown cancer mechanisms and their impact on phenomena like drug resistance is vital. Directly observing these mechanisms is challenging due to measurement complexities, leading to an approach that infers latent mechanisms from observed variable distributions. Despite machine learning advancements enabling sophisticated generative models, their black-box nature complicates the interpretation of complex latent mechanisms. A promising method for understanding these mechanisms involves estimating latent factors through linear projection, though there’s no assurance that inferences made under specific conditions will remain valid across contexts. We propose a novel solution, suggesting data, even from systems appearing complex, can often be explained by sparse dependencies among a few common latent factors, regardless of the situation. This simplification allows for modeling that yields significant insights across diverse fields. We demonstrate this with datasets from finance, where we capture societal trends from stock price movements, and medicine, where we uncover new insights into cancer drug resistance through gene expression analysis. © 2024 Elsevier B.V., All rights reserved.",Graphical lasso; Graphical model; Latent factor; Stiefel manifolds,Scopus
10.3905/jfds.2023.1.143,10.3905/jfds.2023.1.143,Assessing Look-Ahead Bias in Stock Return Predictions Generated by GPT Sentiment Analysis,"Large language models (LLMs), including ChatGPT, can extract profitable trading signals from the sentiment in news text. However, backtesting such strategies poses a challenge because LLMs are trained on many years of data, and backtesting produces biased results if the training and backtesting periods overlap. This bias can take two forms: a look-ahead bias, in which the LLM may have specific knowledge of the stock returns that followed a news article, and a distraction effect, in which general knowledge of the companies named interferes with the measurement of a text’s sentiment. The authors investigate these sources of bias through trading strategies driven by the sentiment of financial news headlines. They compare trading performance based on the original headlines with debiased strategies in which they remove the relevant company’s identifiers from the text. In-sample (within the LLM training window), the authors find, surprisingly, that the anonymized headlines outperform, indicating that the distraction effect has a greater impact than look-ahead bias. This tendency is particularly strong for larger companies—companies about which the authors expect an LLM to have greater general knowledge. Out-of-sample, look-ahead bias is not a concern but distraction remains possible. The authors’ proposed anonymization procedure is therefore potentially useful in out-of-sample implementation, as well as for debiased backtesting. © 2024 Elsevier B.V., All rights reserved.",,Scopus
10.1145/3677052.3698649,10.1145/3677052.3698649,A Financial Time Series Denoiser Based on Diffusion Models,"Financial time series often exhibit low signal-to-noise ratio, posing significant challenges for accurate data interpretation and prediction and ultimately decision making. Generative models have gained attention as powerful tools for simulating and predicting intricate data patterns, with diffusion models emerging as particularly effective methods. This paper introduces a novel approach utilizing a diffusion model as a denoiser for financial time series in order to improve data predictability and trading performance. By leveraging the forward and reverse processes of a conditional diffusion model to add and remove noise progressively, we reconstruct original data from noisy inputs. Our extensive experiments demonstrate that diffusion model-based denoised time series significantly enhance the performance on downstream future return classification tasks. Moreover, trading signals derived from the denoised data yield more profitable trades with fewer transactions, thereby minimizing transaction costs and increasing overall trading efficiency. Finally, we show that by using classifiers trained on denoised time series, we can recognize how noisy the market is and obtain excess returns. © 2025 Elsevier B.V., All rights reserved.",Denoising; Diffusion Model; Financial Time Series; Trading,Scopus
10.1145/3677052.3698689,10.1145/3677052.3698689,ECC Analyzer: Extracting Trading Signal from Earnings Conference Calls using Large Language Model for Stock Volatility Prediction,"In the realm of financial analytics, leveraging unstructured data, such as earnings conference calls (ECCs), to forecast stock volatility is a critical challenge that has attracted both academics and investors. While previous studies have used multimodal deep learning-based models to obtain a general view of ECCs for volatility predicting, they often fail to capture detailed, complex information. Our research introduces a novel framework: ECC Analyzer, which utilizes large language models (LLMs) to extract richer, more predictive content from ECCs to aid the model's prediction performance. We use the pre-trained large models to extract textual and audio features from ECCs and implement a hierarchical information extraction strategy to extract more fine-grained information. This strategy first extracts paragraph-level general information by summarizing the text and then extracts fine-grained focus sentences using Retrieval-Augmented Generation (RAG). These features are then fused through multimodal feature fusion to perform volatility prediction. Experimental results demonstrate that our model outperforms traditional analytical benchmarks, confirming the effectiveness of advanced LLM techniques in financial analysis. © 2025 Elsevier B.V., All rights reserved.",Earnings Conference Call Analysis; Large Language Model; Retrieval-Augmented Generation; Volatility forecasting,Scopus
10.1145/3677052.3698688,10.1145/3677052.3698688,FinVision: A Multi-Agent Framework for Stock Market Prediction,"Financial trading has been a challenging task, as it requires the integration of vast amounts of data from various modalities. Traditional deep learning and reinforcement learning methods require large training data and often involve encoding various data types into numerical formats for model input, which limits the explainability of model behavior. Recently, LLM-based agents have demonstrated remarkable advancements in handling multi-modal data, enabling them to execute complex, multi-step decision-making tasks while providing insights into their thought processes. This research introduces a multi-modal multi-agent system designed specifically for financial trading tasks. Our framework employs a team of specialized LLM-based agents, each adept at processing and interpreting various forms of financial data, such as textual news reports, candlestick charts, and trading signal charts. A key feature of our approach is the integration of a reflection module, which conducts analyses of historical trading signals and their outcomes. This reflective process is instrumental in enhancing the decision-making capabilities of the system for future trading scenarios. Furthermore, the ablation studies indicate that the visual reflection module plays a crucial role in enhancing the decision-making capabilities of our framework. © 2025 Elsevier B.V., All rights reserved.",Large Language Models; Multi-Agent Framework,Scopus
10.1145/3677052.3698684,10.1145/3677052.3698684,Transformers and attention-based networks in quantitative trading: a comprehensive survey,"Since the advent of the transformer neural network architecture, there has been a rapid adoption and investigation of its applicability in various domains, such as computer vision, speech processing, and natural language processing, with the latter most notably exemplified by the rise of Large Language Models. These accomplishments have also led to increased interest in other network architectures that rely on attention mechanisms, one of the building blocks of transformers. Transformers and other attention-based networks are being applied to the quantitative analysis, management, and trading of financial assets, be it for price movement prediction, discovery of trading strategies, portfolio optimization, and risk management. The applications range across different asset categories, including equity markets, foreign exchange pairs, cryptocurrencies, and futures markets. This survey aims to provide a comprehensive overview of the applications of attention-based networks within the field of quantitative analysis, management, and trading of financial assets. After a brief overview of transformers and attention mechanisms, we analyze the existing applications of these architectures for quantitative finance in a taxonomy of four specializations: Alpha Seeking, Risk Management, Portfolio Construction, and Execution. After comparing the literature in light of the research problems, modeling approaches, and complementary results, we discuss current challenges and research opportunities. © 2025 Elsevier B.V., All rights reserved.",Machine Learning; Quantitative trading; Transformers,Scopus
10.1145/3677052.3698647,10.1145/3677052.3698647,NeuralFactors: A Novel Factor Learning Approach to Generative Modeling of Equities,"The use of machine learning for statistical modeling (and thus, generative modeling) has grown in popularity with the proliferation of time series models, text-to-image models, and especially large language models. Fundamentally, the goal of classical factor modeling is statistical modeling of stock returns, and in this work, we explore using deep generative modeling to enhance classical factor models. Prior work has explored the use of deep generative models in order to model hundreds of stocks, leading to accurate risk forecasting and alpha portfolio construction; however, that specific model does not allow for easy factor modeling interpretation in that the factor exposures cannot be deduced. In this work, we introduce NeuralFactors, a novel machine-learning based approach to factor analysis where a neural network outputs factor exposures and factor returns, trained using the same methodology as variational autoencoders. We show that this model outperforms prior approaches both in terms of log-likelihood performance and computational efficiency. Further, we show that this method is competitive to prior work in generating realistic synthetic data, covariance estimation, risk analysis (e.g., value at risk, or VaR, of portfolios), and portfolio optimization. Finally, due to the connection to classical factor analysis, we analyze how the factors our model learns cluster together and show that the factor exposures could be used for embedding stocks. © 2025 Elsevier B.V., All rights reserved.",Generative Modeling; Portfolio Optimization; Risk Forecasting; Statistical Factors; Stock Returns; Variational Autoencoders,Scopus
10.1287/ijoc.2022.0055,10.1287/ijoc.2022.0055,Let the Laser Beam Connect the Dots: Forecasting and Narrating Stock Market Volatility,"Forecasting market volatility, especially high-volatility incidents, is a critical issue in financial market research and practice. Business news as an important source of market information is often exploited by artificial intelligence–based volatility forecasting models. Computationally, deep learning architectures, such as recurrent neural networks, on extremely long input sequences remain infeasible because of time complexity and memory limitations. Meanwhile, understanding the inner workings of deep neural networks is challenging because of the largely black box nature of large neural networks. In this work, we address the first challenge by proposing a long- and short-term memory retrieval (LASER) architecture with flexible memory and horizon configurations to forecast market volatility. Then, we tackle the interpretability issue by devising a BEAM algorithm that leverages a large pretrained language model (GPT-2). It generates human-readable narratives verbalizing the evidence leading to the model prediction. Experiments on a Wall Street Journal news data set demonstrate the superior performance of our proposed LASER-BEAM pipeline in predicting high-volatility market scenarios and generating high-quality narratives compared with existing methods in the literature. © 2024 Elsevier B.V., All rights reserved.",forecasting; memory retrieval; mode interpretability; narrative generation,Scopus
10.3390/bdcc8110143,10.3390/bdcc8110143,"Innovative Sentiment Analysis and Prediction of Stock Price Using FinBERT, GPT-4 and Logistic Regression: A Data-Driven Approach","This study explores the comparative performance of cutting-edge AI models, i.e., Finaance Bidirectional Encoder representations from Transsformers (FinBERT), Generatice Pre-trained Transformer GPT-4, and Logistic Regression, for sentiment analysis and stock index prediction using financial news and the NGX All-Share Index data label. By leveraging advanced natural language processing models like GPT-4 and FinBERT, alongside a traditional machine learning model, Logistic Regression, we aim to classify market sentiment, generate sentiment scores, and predict market price movements. This research highlights global AI advancements in stock markets, showcasing how state-of-the-art language models can contribute to understanding complex financial data. The models were assessed using metrics such as accuracy, precision, recall, F1 score, and ROC AUC. Results indicate that Logistic Regression outperformed the more computationally intensive FinBERT and predefined approach of versatile GPT-4, with an accuracy of 81.83% and a ROC AUC of 89.76%. The GPT-4 predefined approach exhibited a lower accuracy of 54.19% but demonstrated strong potential in handling complex data. FinBERT, while offering more sophisticated analysis, was resource-demanding and yielded a moderate performance. Hyperparameter optimization using Optuna and cross-validation techniques ensured the robustness of the models. This study highlights the strengths and limitations of the practical applications of AI approaches in stock market prediction and presents Logistic Regression as the most efficient model for this task, with FinBERT and GPT-4 representing emerging tools with potential for future exploration and innovation in AI-driven financial analytics. © 2024 Elsevier B.V., All rights reserved.",FinBERT; FinBERT model; logistic regression; Optuna; time series cross-validation,Scopus
2-s2.0-85204009784,,"COMPARISON OF LEXICON-BASED METHOD, MACHINE LEARNING AND CHATGPT ON SENTIMENT ANALYSIS OF BIG CAP AND SMALL CAP COMPANIES IN UNITED STATE INDEXES","Sentiment analysis is a natural language processing (NLP) method that identifies the sentiment contained in a body of text. It has gained significant attention due to its potential applications in various domains, including finance, marketing, and public opinion monitoring. In the financial sector, sentiment analysis is essential for analyzing market trends, forecasting stock prices, and guiding investment choices. This research paper compares the performance of lexicon-based method, machine learning technique, and ChatGPT in sentiment analysis of big cap and small cap companies in United States indexes using Twitter data. The purpose of implementing ChatGPT is to identify the usefulness of this well-known tool that is currently flooding the social media scene. The results show that Random Forest achieved the highest accuracy overall with 83.6% on big cap and 78.8% on small cap. ChatGPT sentiment has an accuracy of 77.44% on big cap and 72.43% on small cap. Meanwhile the lowest performing method is the TextBlob which has an accuracy of 46.52% on big cap and 43.57% on small cap. Random Forest is able to understand the context of tweets and handle slang terms and phrases, while ChatGPT is still under development but has the potential to perform better in the future. There are many slang terms and phrases that are used in the stock market that are not included in the TextBlob dictionary. Therefore, the performance of TextBlob is the least performing method. © 2024 Elsevier B.V., All rights reserved.",Chatgpt; Lexicon; Machine Learning; Random Forest; Sentiment Analysis; Textblob,Scopus
10.1145/3637528.3671629,10.1145/3637528.3671629,FNSPID: A Comprehensive Financial News Dataset in Time Series,"Financial market predictions utilize historical data to anticipate future stock prices and market trends. Traditionally, these predictions have focused on the statistical analysis of quantitative factors, such as stock prices, trading volumes, inflation rates, and changes in industrial production. Recent advancements in large language models motivate the integrated financial analysis of both sentiment data, particularly market news, and numerical factors. Nonetheless, this methodology frequently encounters constraints due to the paucity of extensive datasets that amalgamate both quantitative and qualitative sentiment analyses. To address this challenge, we introduce a large-scale financial dataset, namely, Financial News and Stock Price Integration Dataset (FNSPID). It comprises 29.7 million stock prices and 15.7 million time-aligned financial news records for 4,775 S&P500 companies, covering the period from 1999 to 2023, sourced from 4 stock market news websites. We demonstrate that FNSPID excels existing stock market datasets in scale and diversity while uniquely incorporating sentiment information. Through financial analysis experiments on FNSPID, we propose: (1) the dataset's size and quality significantly boost market prediction accuracy; (2) adding sentiment scores modestly enhances performance on the transformer-based model; (3) a reproducible procedure that can update the dataset. Completed work, code, documentation, and examples are available at this http URL. FNSPID offers unprecedented opportunities for the financial research community to advance predictive modeling and analysis. © 2025 Elsevier B.V., All rights reserved.",financial dataset; financial market prediction; machine learning; sentiment analysis; time series,Scopus
2-s2.0-85205525479,,"EVALUATING TEXTBLOB, LEXICON, SUPPORT VECTOR MACHINE, NAIVE BAYES, AND CHATGPT APPROACHES FOR SENTIMENT ANALYSIS OF NASDAQ LISTED COMPANIES","Sentiment analysis is a type of contextual text mining that finds and extracts subjective information from the source material in order to assist companies in understanding the social sentiment of their brand, product, or service while monitoring online conversations, especially Twitter has become a popular medium for individuals to express their opinions, share news, and discuss various topics, including stocks and companies. Stock market sentiment analysis is useful for understanding investor sentiments and forecasting market moves. Market players can use sentiment analysis tools to evaluate market sentiment and make educated investing decisions. The previous study examined data with fewer than ten thousand rows; however, this research will work with very huge data sets of more than one hundred thousand Nasdaq companies acquired from @Nasdaq and @AppleSupport Twitter accounts and @nasdaq and @apple from subreddit in Reddit social media. This study will compare the classification accuracy of Naive Bayes and SVM, as well as the time consumption of each strategy while classifying vast quantities of data. The TextBlob NLTK (Natural Language Toolkit) will be used in this study to label each phrase in the data using a lexicon-based method; also, this effort will employ ChatGPT, an OpenAI chatbot, to label each row of data received. As a consequence, it was discovered that SVM is the most superior approach in its classification, both in terms of Precision, Recall, and F1-Score metrics, as well as total accuracy, which reaches 93.5%, while Naive Bayes is at 61.5% and ChatGPT is at 42.2%. © 2024 Elsevier B.V., All rights reserved.",Big Data; ChatGPT; Nasdaq; Naïve Bayes; Sentiment Analysis; SVM (Support Vector Machine); TextBlob,Scopus
10.1007/s10115-024-02085-8,10.1007/s10115-024-02085-8,Multi-factor stock price prediction based on GAN-TrellisNet,"Applying deep learning, especially time series neural networks, to predict stock price, has become one of the important applications in quantitative finance. Recently, some GAN-based stock prediction models are proposed, where LSTM or GRU is used as the generator. However, these generators lack the function of feature extraction, and the prediction accuracies are slightly low. Meanwhile, these models choose some simple volume-price factors (such as OCHLV and OCHLVC) as inputs, without considering the impact of other factors on stock prices. In order to solve these problems, a stock prediction method based on multiple factors and GAN-TrellisNet is proposed. Instead of “OCHLV” or ”OCHLVC,” a multi-factor strategy with ”alpha158+OCHLVC” is introduced to enrich the stock data of inputs. The proposed generative adversarial network (GAN) is a combination of two neural networks which are TrellisNet as generative model and convolutional neural network (CNN) as discriminative model for adversarial training to forecast the stock market. TrellisNet, which integrates the feature extraction capabilities of CNN and the temporal processing capabilities of recurrent neural network (RNN), will generate new predicted results based on historical data, and then CNN will distinguish between predicted results and real stock prices. In order to demonstrate the performance of our method, we selected the decade data of different stocks from four markets (A-shares, U.S. stocks, U.K. stocks and Hong Kong stocks) as dataset and conducted two groups of comparative experiments. Compared with the state-of-the-art methods based on GAN, our method has better performance in terms of MSE, MAE, RMSE and MAPE. In addition, the multi-factor strategy with “alpha158+OCHLVC” is more effective than the original strategy with OCHLVC factors. © 2024 Elsevier B.V., All rights reserved.",Alpha158; CNN; GAN; Multi-factor strategy; OCHLVC; Stock price prediction; TrellisNet,Scopus
10.1145/3652037.3652047,10.1145/3652037.3652047,Assessment of the Applicability of Large Language Models for Quantitative Stock Price Prediction,"In accordance with the findings presented in [34], this study examines the applicability of Machine Learning (ML) models and training strategies from the Natural Language Processing (NLP) domain in addressing time series problems, emphasizing the structural and operational aspects of these models and strategies. Recognizing the structural congruence within the data, we opt for Stock Price Prediction (SPP) as the designated domain to assess the transferability of NLP models and strategies. Building upon initial positive outcomes derived from quantitative SPP models in our ongoing research endeavors, we provide a rationale for exploring a range of additional methods and conducting subsequent research experiments. The outlined research aims to elucidate the efficacy of leveraging NLP models and techniques for addressing time series problems exemplified as SPP. © 2024 Elsevier B.V., All rights reserved.",big data; large language models; natural language processing; quantitative analysis; stock embeddings; stock price prediction,Scopus
10.1145/3652037.3652076,10.1145/3652037.3652076,Stock Price Trend Prediction using Emotion Analysis of Financial Headlines with Distilled LLM Model,"Capturing the volatility of stock prices helps individual traders, stock analysts, and institutions alike increase their returns in the stock market. Financial news headlines have been shown to have a significant effect on stock price mobility. Lately, many financial portals have restricted web scraping of stock prices and other related financial data of companies from their websites. In this study we demonstrate that emotion analysis of financial news headlines alone can be sufficient in predicting stock price movement, even in the absence of any financial data. We propose an approach that eliminates the need for web scraping of financial data. We use API based mechanism to retrieve financial news headlines. In this study we train and subsequently leverage light and computationally fast Distilled LLM Model to gather emotional tone and strength of financial news headlines for companies. We then use this information with several machine learning-based classification algorithms to predict the stock price direction based solely on the emotion analysis of news. We demonstrate that emotion analysis-based attributes of financial news headlines are as accurate in predicting the price direction as running the algorithms with the financial data alone. © 2024 Elsevier B.V., All rights reserved.",Artifical Neural Network; Artificial intelligence; Distilled LLM.; emotion analysis; LLM; logistic regression; machine learning; neural networks; Random Forest; sentiment analysis; stock price direction prediction; trend prediction,Scopus
10.1016/j.eswa.2023.122952,10.1016/j.eswa.2023.122952,Stock market forecasting using DRAGAN and feature matching,"Applying machine learning methods to forecast stock prices has been a topic of interest in recent years. However, a few studies have been reported based on generative adversarial networks (GANs) in this area, but their results are promising. While GANs are powerful generative models successfully applied in different areas, they suffer from inherent challenges such as training instability and mode collapse. Another primary concern is capturing correlations in stock prices. Therefore, the main challenges fall into two categories: capturing correlations and addressing the inherent problems of GANs. In this paper, we introduce a novel framework based on DRAGAN and feature matching for stock price forecasting, which improves training stability and alleviates mode collapse. We employ windowing to acquire temporal correlations by the generator and exploit conditioning on discriminator inputs to capture temporal correlations and correlations between prices and features. Experimental results on data from several stocks indicate that proposed method outperforms long short-term memory (LSTM) as a baseline method, as well as basic GANs and WGAN-GP as two different variants of GANs. © 2023 Elsevier B.V., All rights reserved.",Feature matching; Generative Adversarial Networks; Stock price prediction; Time series forecasting,Scopus
10.2478/mmcks-2024-0008,10.2478/mmcks-2024-0008,Emoji driven crypto assets market reactions,"In the burgeoning realm of cryptocurrency, social media platforms like Twitter have become pivotal in influencing market trends and investor sentiments. In our study, we leverage GPT-4 and a fine-tuned transformer-based BERT model for a multimodal sentiment analysis, focusing on the impact of emoji sentiment on cryptocurrency markets. By translating emojis into quantifiable sentiment data, we correlate these insights with key market indicators such as BTC Price and the VCRIX index. Our architecture's analysis of emoji sentiment demonstrated a distinct advantage over FinBERT's pure text sentiment analysis in such predicting power. This approach may be fed into the development of trading strategies aimed at utilizing social media elements to identify and forecast market trends. Crucially, our findings suggest that strategies based on emoji sentiment can facilitate the avoidance of significant market downturns and contribute to the stabilization of returns. This research underscores the practical benefits of integrating advanced AI-driven analyzes into financial strategies, offering a nuanced perspective on the interaction between digital communication and market dynamics in an academic context. © 2024 Elsevier B.V., All rights reserved.",bitcoin; crypto; emoji; LLM; VCRIX,Scopus
10.1145/3589334.3645611,10.1145/3589334.3645611,Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models,"Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale. To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a verbal self-reflective agent and Proximal Policy Optimization (PPO) that allow a LLM teach itself how to generate explainable stock predictions, in a fully autonomous manner. The reflective agent learns how to explain past stock movements through a self-reasoning process, while the PPO trainer trains the model to generate the most likely explanations given the input texts at test-time. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a specialized LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient, for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics. Our code can be accessed through https://github.com/koa-fin/sep. © 2024 Elsevier B.V., All rights reserved.",explainable ai; large language models; stock prediction,Scopus
10.1145/3629527.3651419,10.1145/3629527.3651419,FootPrinter: Quantifying Data Center Carbon Footprint,"Data centers have become an increasingly significant contributor to the global carbon footprint. In 2021, the global data center industry was responsible for around 1% of the worldwide greenhouse gas emissions. With more resource-intensive workloads, such as Large Language Models, gaining popularity, this percentage is expected to increase further. Therefore, it is crucial for data center service providers to become aware of and accountable for the sustainability impact of their design and operational choices. However, reducing the carbon footprint of data centers has been a challenging process due to the lack of comprehensive metrics, carbon-aware design tools, and guidelines for carbon-aware optimization. In this work, we propose FootPrinter, a first-of-its-kind tool that supports data center designers and operators in assessing the environmental impact of their data center. FootPrinter uses coarse-grained operational data, grid energy mix information, and discrete event simulation to determine the data center's operational carbon footprint and evaluate the impact of infrastructural or operational changes. FootPrinter can simulate days of operations of a regional data center on a commodity laptop in a few seconds, returning the estimated footprint with marginal error. By making this project open source, we hope to engage the community in the development of methodologies and tools for systematically assessing and exploring the sustainability of data centers. © 2024 Elsevier B.V., All rights reserved.",carbon emission; carbon footprint; data center; simulation,Scopus
10.1109/MSEC.2024.3385549,10.1109/MSEC.2024.3385549,Degenerative AI?,"It is not secret that generative AI, especially in the form of large language models (LLMs), is extremely popular today. One might go so far as to say that it's eaten the world. It may be a bubble, or it may last though the death of cryptocurrencies has long been predicted, as I write this Bitcoin has just reached an all-time high value against the American dollar but for now and at least the next few years, generative AI will be with us. As people who care about security and privacy, we need to understand the implications of it: is it good or bad for our field, and if the latter, what should we do about it? Ignoring it is not an option. © 2024 Elsevier B.V., All rights reserved.",,Scopus
10.1016/j.frl.2024.105227,10.1016/j.frl.2024.105227,Sentiment trading with large language models,"We analyse the performance of the large language models (LLMs) OPT, BERT, and FinBERT, alongside the traditional Loughran-McDonald dictionary, in the sentiment analysis of 965,375 U.S. financial news articles from 2010 to 2023. Our findings reveal that the GPT-3-based OPT model significantly outperforms the others, predicting stock market returns with an accuracy of 74.4%. A long-short strategy based on OPT, accounting for 10 basis points (bps) in transaction costs, yields an exceptional Sharpe ratio of 3.05. From August 2021 to July 2023, this strategy produces an impressive 355% gain, outperforming other strategies and traditional market portfolios. This underscores the transformative potential of LLMs in financial market prediction and portfolio management and the necessity of employing sophisticated language models to develop effective investment strategies based on news sentiment. © 2024 Elsevier B.V., All rights reserved.",Artificial intelligence investment strategies; Generative pre-trained transformer (GPT); Large language models; Machine learning in stock return prediction; Natural language processing (NLP),Scopus
10.3390/jtaer19010029,10.3390/jtaer19010029,The Impact of Academic Publications over the Last Decade on Historical Bitcoin Prices Using Generative Models,"Since 2012, researchers have explored various factors influencing Bitcoin prices. Up until the end of July 2023, more than 9100 research papers on cryptocurrencies were published and indexed in the Web of Science Clarivate platform. The objective of this paper is to analyze the impact of publications on Bitcoin prices. This study aims to uncover significant themes within these research articles, focusing on cryptocurrencies in general and Bitcoin specifically. The research employs latent Dirichlet allocation to identify key topics from the unstructured abstracts. To determine the optimal number of topics, perplexity and topic coherence metrics are calculated. Additionally, the abstracts are processed using BERT-transformers and Word2Vec and their potential to predict Bitcoin prices is assessed. Based on the results, while the research helps in understanding cryptocurrencies, the potential of academic publications to influence Bitcoin prices is not significant, demonstrating a weak connection. In other words, the movements of Bitcoin prices are not influenced by the scientific writing in this specific field. The primary topics emerging from the analysis are the blockchain, market dynamics, transactions, pricing trends, network security, and the mining process. These findings suggest that future research should pay closer attention to issues like the energy demands and environmental impacts of mining, anti-money laundering measures, and behavioral aspects related to cryptocurrencies. © 2025 Elsevier B.V., All rights reserved.",Bitcoin prices; cryptocurrency; latent Dirichlet allocation; research publication; sentiment analysis; topic modelling,Scopus
10.1016/j.jedc.2024.104821,10.1016/j.jedc.2024.104821,Dynamic CVaR portfolio construction with attention-powered generative factor learning,"The dynamic portfolio construction problem requires dynamic modeling of the joint distribution of multivariate stock returns. To achieve this, we propose a dynamic generative factor model which uses random variable transformation as an implicit way of distribution modeling and relies on the Attention-GRU network for dynamic learning and forecasting. The proposed model captures the dynamic dependence among multivariate stock returns, especially focusing on the tail-side properties. We also propose a two-step iterative algorithm to train the model and then predict the time-varying model parameters, including the time-invariant tail parameters. At each investment date, we can easily simulate new samples from the learned generative model, and we further perform CVaR portfolio optimization with the simulated samples to form a dynamic portfolio strategy. The numerical experiment on stock data shows that our model leads to wiser investments that promise higher reward-risk ratios and present lower tail risks. © 2024 Elsevier B.V., All rights reserved.",Attention-GRU network; CVaR portfolio optimization; Dynamic portfolio construction; Generative factor model; Tail properties,Scopus
10.1016/j.techsoc.2024.102454,10.1016/j.techsoc.2024.102454,Nexus between Chat GPT usage dimensions and investment decisions making in Pakistan: Moderating role of financial literacy,"This study's primary goal is to investigate and gain better knowledge of the relationship between ChatGPT usage dimensions such as analyzing data, managing risk, optimizing portfolios, forecasting market trends, and conducting sentiment analysis and investment decisions of investors in the Pakistan stock market, as well as the moderating role of financial literacy. The sample for this study included individual stock market investors in Pakistan. Using a self-administered questionnaire and a cross-sectional design, a non-probability convenience sampling technique followed by snowball techniques was used to collect data from 388 active and potential individual investors. The study's findings showed that ChatGPT usage dimensions have a positive and significant impact on investment decision making. Furthermore, financial literacy is found to moderate the relationship between optimizing portfolios, forecasting market trends, and investment decision making. The study's findings outlined practical implications for the researcher, financial advisors, individual investors, governmental decision-makers, policymakers, and stock market authorities who are interested in leveraging the benefits of artificial intelligence and machine learning in investment decision making in the context of emerging economies like Pakistan. © 2024 Elsevier B.V., All rights reserved.",Analyzing data; ChatGPT; Conducting sentiment analysis; Financial literacy and investment decision making; Forecasting market trends; Managing risk; Optimizing portfolios,Scopus
10.1109/DSIT61374.2024.10881129,10.1109/DSIT61374.2024.10881129,Transformer-Based Models for Commodity Trading Price Forecasting,"Transformer-based models have gained significant traction across various fields such as natural language processing (NLP), large language models (LLM), smart transportation, and finance due to their ability to capture long-term dependencies and sequence patterns. However, their application in forecasting stock or commodity trading returns remains underexplored. In this study, we aim to compare the performance of three transformer-based models - Informer, Autoformer, and Transformer with Positional Encoder unit - alongside an LSTM for forecasting commodity returns. Specifically, the two datasets used will consist of historical commodity prices, including six types of metals. These models, known for their capacity to handle long sequence data, have shown promise in financial forecasting, particularly. Still, their potential in commodity trading price forecasting has been less studied. By evaluating these models based on historical metal prices, this research seeks to determine the most accurate model for predicting commodity returns, providing valuable insights for the commodity trading and financial sectors. © 2025 Elsevier B.V., All rights reserved.",Autoformer; Commodity Trading; Encoder; Informer; Positional Embedding; Time series; Transformer,Scopus
10.1109/FMLDS63805.2024.00071,10.1109/FMLDS63805.2024.00071,Can GPT Price Options?,"Options are financial instruments that grant the holder the right, but not the obligation, to buy or sell an underlying asset at a predetermined price within a specified time frame. Traditional option pricing models, such as the Black-Scholes equation, depend on simplifying assumptions and struggle to effectively capture complex market dynamics. The study investigates the viability of using the Generative Pretrained Transformer (GPT) model to assess the value of stock options. We fine-tune the state-of-the-art GPT-3.5-turbo model by utilizing past option chain data and evaluate its precision in predicting option prices for well-known technology stocks including Apple (AAPL), Google (GOOG), and Microsoft (MSFT). Our model employs many features, including strike price, underlying price, days to expiry, and volatility index (VIX), to precisely predict option prices. Extensive examination undertaken at various degrees of moneyness and time horizons demonstrates that GPT models consistently surpass Black-Scholes in terms of both mean absolute error and root mean squared error. Out of all the models that were assessed, the 5-year data models exhibit the greatest overall accuracy. An error study suggests that pricing for options at the money has improved, but there are issues in appropriately pricing options that are highly in the money or out of the money. The GPT technique shows promise in leveraging transformers for computational finance applications. © 2025 Elsevier B.V., All rights reserved.",Black-Scholes Model; Finance Applications; Generative Pre-trained Transformer; Machine Learning; Options; Pricing; Stocks; Volatility,Scopus
10.1109/ICCCMLA63077.2024.10871633,10.1109/ICCCMLA63077.2024.10871633,Adapting Speech Models for Stock Price Prediction,"Large language models (LLMs) have demonstrated remarkable success in the field of natural language processing (NLP). Despite their origins in NLP, these algorithms possess the theoretical capability to process any data type represented in an NLP-like format. In this study, we use stock data to illustrate three methodologies for processing regression data with LLMs, employing tokenization and contextualized embeddings. By leveraging the well-known LLM algorithm Bidirectional Encoder Representations from Transformers (BERT) [1], we apply quantitative stock price prediction methodologies to predict stock prices and stock price movements, showcasing the versatility and potential of LLMs in financial data analysis. © 2025 Elsevier B.V., All rights reserved.",finance; fintech; large language models; machine learning; natural language processing; quantitative stock price prediction; stock movement prediction,Scopus
10.1109/BigDIA63733.2024.10808510,10.1109/BigDIA63733.2024.10808510,A Novel Wavelet Based Generative Model for Time Series Prediction,"Generative models have become an exciting area of research in recent years. Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs) have been utilized in various data augmentation applications. However, generative models can learn high-dimensional features of data through adversarial learning, making them suitable for nonlinear and nonstationary time series analysis, such as stock market prediction, high-frequency trading, and ocean current forecasting. In this paper, the researchers focus on using a wavelet-based GAN to predict stock market prices by generating synthetic stock market price trends. Historical stock price data from 2014 to 2024 is used for our experiments, and the results show that the wavelet-based GAN outperforms deep learning baseline models.. © 2025 Elsevier B.V., All rights reserved.",Data Augmentation; Generative Adversarial Network; Stock Market Prediction; Wavelet Transform,Scopus
10.1109/InCoWoCo64194.2024.10863422,10.1109/InCoWoCo64194.2024.10863422,Comparing the Best-Fit and Integrating Generative Deep Learning with Time Series Models for Metal Price Forecasting: A Predictive Analysis,"Forecasting metal prices in volatile financial markets is a challenging task due to the non-linear and stochastic nature of price movements. This research integrates deep learning techniques with time series models to predict metal prices, focusing on the MCX Index. A novel Generative Adversarial Network (GAN) framework, coupled with a Convolutional Neural Network (CNN) as a discriminator and Gated Recurrent Units (GRU) as a generator, is proposed. Historical NSE metal spot price data, specifically gold and silver, were used for model training and evaluation. The empirical results demonstrated that the proposed GAN-based architecture outperformed other deep learning models, including LSTM and Bi-LSTM, in terms of forecasting accuracy. The study provides valuable insights into the application of deep generative models for financial forecasting, addressing key challenges associated with modeling non-stationary and noisy financial data. © 2025 Elsevier B.V., All rights reserved.",commodity spot price; gated recurrent unit (GRU); generative adversarial network (GAN); metal price prediction; time-reries forecasting,Scopus
10.1109/ASIANCON62057.2024.10838194,10.1109/ASIANCON62057.2024.10838194,Future Finance: Predictive Insights and Chatbot Consultation,"The framework has four pillars on which the rest of it is built. Initially, the Stock Analysis sector is a data-driven approach where historical data is broken down into key components to reduce the amount of hidden information. This is as from there onwards the Stock Prediction module is run which applies predictive modeling methodologies to gain market revelations about future market trends and movements with precision which is informed to investors to help them not only to acquire profits but also maintain stability and to gain knowledge on what to expect. The Assystem, complementing smart wearables, utilizes AI Assistance, with forward facing conversational chatbot interface thus creating a natural environment for the users. This AI-enabled assistant provides customized suggestions, up-to-the-minute details, and impeccable representative behavior as it syncs to investors' expectations. Finally, the Market Guider feature offers users the news and updates from the stock market which were curated, enabling them to stay updated with the involved changes. For predictive analysis, we've opted for the LSTM model due to its superior performance compared to other models tested. It achieved an R-squared score of 0.89, indicating strong predictive power, and demonstrated robustness with a cross-validation score of 0.84 on both training and testing datasets. The model was serialized into a Hierarchical Data Format (HDF) file to save runtime operations and facilitate deployment in Streamlit. Through a Streamlit interface, users can input a stock ticker and receive predicted prices generated by the trained LSTM model. © 2025 Elsevier B.V., All rights reserved.",AI assistance; chatbot consultation; Future Finance; LLM; LSTM; Machine Learning; market guider; Mean Squared Error (MSE); predictive insights; predictive modeling; proactive decision-making; real-time updates; stock analysis,Scopus
10.1109/BigData62323.2024.10824953,10.1109/BigData62323.2024.10824953,Large Language Models for Financial Aid in Financial Time-series Forecasting,"Considering the difficulty of financial time series forecasting in financial aid, much of the current research focuses on leveraging big data analytics in financial services. One modern approach is to utilize ""predictive analysis"", analogous to forecasting financial trends. However, many of these time series data in Financial Aid (FA) pose unique challenges due to limited historical datasets and high dimensional financial information, which hinder the development of effective predictive models that balance accuracy with efficient runtime and memory usage. Pre-trained foundation models are employed to address these challenging tasks. We use state-of-the-art time series models including pre-trained LLMs (GPT-2 as backbone), transformers, and linear models to demonstrate their ability to outperform traditional approaches, even with minimal (""few-shot"") or no fine-tuning (""zero-shot""). Our benchmark study, which includes financial aid with seven other time series tasks, shows the potential of using LLMs for scarce financial datasets. © 2025 Elsevier B.V., All rights reserved.",Deep Learning; Financial Aid; Foundation Models; Large Language Models; Time Series Forecast,Scopus
10.1109/BigData62323.2024.10825946,10.1109/BigData62323.2024.10825946,Stock Price Prediction Using LLM-Based Sentiment Analysis,"This paper examines the effectiveness of recent large language model-based news sentiment estimation for stock price forecasting with the combination of latest transformer-based prediction models. To achieve a better accuracy in sentiment classification, experiments are designed to compare six different models (GPT 4, Llama 3, Gemma 2, Mistral 7b, FinBERT, VADER) in financial news sentiment classification, and it was found that recent large language models can outperform FinBERT and VADER, which are the most commonly used models in financial sentiment analysis. Based on the experiment results, Llama 3, with relatively stable performance, is chosen to classify the news sentiments of the selected companies. Informer, Transformer, TCN, LSTM, SVR, Random Forest and Naive Forecast are used to predict the stock prices with different sliding window sizes. Experiments with different scenarios are designed to evaluate the prediction ability of news sentiment. Results show that adding news sentiment data can indeed improve the stock price prediction. Informer, one of the state-of-the-art transformer models for long-term prediction tasks, yields the best performances in most cases. Ablation study of Informer suggests that the generative style decoder plays an important role in performance improvement. © 2025 Elsevier B.V., All rights reserved.",Informer; LLM; sentiment analysis; time series forecasting; Transformer,Scopus
10.1109/BigData62323.2024.10825449,10.1109/BigData62323.2024.10825449,Combining Financial Data and News Articles for Stock Price Movement Prediction Using Large Language Models,"Predicting financial markets and stock price movements requires analyzing a company's performance, historic price movements, industry-specific events alongside the influence of human factors such as social media and press coverage. We assume that financial reports (such as income statements, balance sheets, and cash flow statements), historical price data, and recent news articles can collectively represent aforementioned factors.We combine financial data in tabular format with textual news articles and employ pre-trained Large Language Models (LLMs) to predict market movements. Recent research in LLMs has demonstrated that they are able to perform both tabular and text classification tasks, making them our primary model to classify the multi-modal data. We utilize retrieval augmentation techniques to retrieve and attach relevant chunks of news articles to financial metrics related to a company and prompt the LLMs in zero, two, and four-shot settings. Our dataset contains news articles collected from different sources, historic stock price, and financial report data for 20 companies with the highest trading volume across different industries in the stock market. We utilized recently released language models for our LLM-based classifier, including GPT- 3 and 4, and LLaMA- 2 and 3 models.We introduce an LLM-based classifier capable of performing classification tasks using combination of tabular (structured) and textual (unstructured) data. By using this model, we predicted the movement of a given stock's price in our dataset with a weighted F1-score of 58.5% and 59.1% and Matthews Correlation Coefficient of 0.175 for both 3-month and 6-month periods.The dataset and codes for this paper can be found on Github. https://github.com/aliielahi/FinedFMP 1 © 2025 Elsevier B.V., All rights reserved.",Financial Stock Price Movement Prediction; Information Retrieval; Large Language Models; Retrieval Augmented Generation,Scopus
10.18653/v1/2024.findings-emnlp.226,10.18653/v1/2024.findings-emnlp.226,QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware,"Extreme multi-label text classification (EMTC) involves predicting multiple labels from a vast pool of candidates based on a user's textual query. While traditional BERT-based methods have shown limited success, large language models (LLMs) have brought new possibilities. It is promising to leverage their remarkable comprehension ability to understand textual queries. However, implementing LLMs is non-trivial for two main reasons. Firstly, real-world EMTC datasets can be extremely large, with candidate product pairs reaching up to ten million in real-world scenarios, which poses significant challenges in data ingestion. Secondly, the large size of LLMs makes computation and memory demands prohibitive for EMTC applications. To this end, we propose QUEST, a Quantized and Efficient Learning with Sampling Technique. QUEST includes a tailored hash sampling module that reduces the data volume to one-fourth of its original size. Additionally, we perform compressive fine-tuning LLMs with only twenty thousand trainable parameters, largely reducing computational requirements. Extensive experiments demonstrate that QUEST outperforms existing methods while requiring fewer computational resources, unlocking efficient EMTC on commodity hardware such as a single Nvidia RTX 3090 GPU with 24 GB of memory. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.18653/v1/2024.emnlp-industry.77,10.18653/v1/2024.emnlp-industry.77,Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow,"Large language models (LLMs) and their fine-tuning techniques have demonstrated superior performance in various language understanding and generation tasks. This paper explores fine-tuning LLMs for predicting stock returns with financial newsflow. Return prediction is fundamental for quantitative investing tasks like portfolio construction and optimization. We formulate the model to include a text representation and forecasting modules. We propose to compare the encoder-only and decoder-only LLMs, considering they generate text representations in distinct ways. The impact of these different representations on return forecasting remains an open question. Meanwhile, we compare two simple methods of integrating LLMs’ token-level representations into the forecasting module. The experiments on real investment universes reveal that: (1) aggregated representations from LLMs’ token-level embeddings generally produce return predictions that enhance the performance of long-only and long-short portfolios; (2) in the relatively large investment universe, the decoder LLMs-based prediction model leads to stronger portfolios, whereas in the small universes, there are no consistent winners; (3) return predictions derived from LLMs’ text representations are a strong signal for portfolio construction, outperforming conventional sentiment scores. These findings suggest the potential of LLM fine-tuning for enhancing return prediction-based portfolio construction. © 2025 Elsevier B.V., All rights reserved.",,Scopus
2-s2.0-85216409938,,Prediction of Foreign Exchange Rates by a Large Language Model,"This paper proposes a prompt-based method utilizing a large language model (LLM) to predict changes in foreign exchange rates based on limit order information. While traditional deep learning models for prediction utilize numerical values as input and output, LLMs use sentences and prompts. To address this, we design prompts that incorporate the numerical values. GPT-2, a widely adopted LLM, is employed and fine-tuned using a training dataset. The effectiveness of our proposed method is demonstrated through empirical analysis using actual time series data. © 2025 Elsevier B.V., All rights reserved.",Finance; Foreign exchange rate; Large language model; Machine learning; Time series,Scopus
10.1109/CIFER62890.2024.10772910,10.1109/CIFER62890.2024.10772910,Semantic Graph Learning for Trend Prediction from Long Financial Documents,"The advent of large language models (LLMs) has initiated much research into their various financial applications. However, in applying LLMs on long documents, semantic relations are not explicitly incorporated, and a full or arbitrarily sparse attention operation is employed. In recent years, progress has been made in Abstract Meaning Representation (AMR), which is a graph-based representation of text to preserve its semantic relations. Since AMR can represent semantic relationships at a deeper level, it can be beneficially utilized by graph neural networks (GNNs) for constructing effective document-level graph representations built upon LLM embeddings to predict target metrics in the financial domain. We propose FLAG: Financial Long document classification via AMR-based GNN, an AMR graph based framework to generate document-level embeddings for long financial document classification. We construct document-level graphs from sentence-level AMR graphs, endow them with specialized LLM word embeddings in the financial domain, apply a deep learning mechanism that utilizes a GNN, and examine the efficacy of our AMR-based approach in predicting labeled target data from long financial documents. Extensive experiments are conducted on a dataset of quarterly earnings calls transcripts of companies in various sectors of the economy, as well as on a corpus of more recent earnings calls of companies in the S&P 1500 Composite Index. We find that our AMR-based approach outperforms fine-tuning LLMs directly on text in predicting stock price movement trends at different time horizons in both datasets. Our work also outperforms previous work utilizing document graphs and GNNs for text classification. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.1111/1475-679X.12593,10.1111/1475-679X.12593,Context-Based Interpretation of Financial Information,"To what extent does the narrative context surrounding the numbers in financial statements alter the informativeness of these numbers, that is, contextualize them? Answering this question empirically presents a methodological challenge. Leveraging recent advances in deep learning, we propose a method to uncover the value of contextual information learned from the (deep) interactions between numeric and narrative disclosures. We show that the contextualization of accounting numbers makes them substantially more informative in shaping beliefs about a firm's future, especially when numeric data are less reliable. In fact, the informational value of interactions dominates the direct informational value of the narrative context. We corroborate this finding by showing that stock markets and financial analysts incorporate the interactions between narrative and numeric information when making forecasts. We also demonstrate the value of our approach by identifying rich firm-year–specific heterogeneity in earnings persistence. We discuss a number of avenues for future research. © 2024 Elsevier B.V., All rights reserved.",cash flows; deep learning; earnings; earnings persistence; heterogeneity; LLMs; MD&A; narrative context; neural networks,Scopus
10.1007/s10614-024-10811-1,10.1007/s10614-024-10811-1,MoF: A Background-Aware Multi-source Fusion Financial Trend Forecasting Mechanism,"With the rapid growth of economic globalization and digital economics, accurately predicting stock price fluctuations has become crucial yet challenging due to high volatility and market noise. Existing forecasting methods, relying primarily on time-series data, technical indicators, and sentiment analysis, often fail to capture the semantic depth of background knowledge, particularly the influence of real-time events. To address this limitation, we propose MoF, a background-aware multi-source fusion mechanism for financial trend forecasting. MoF integrates stock price data with background knowledge on the impact of real-time events on stock trends, which includes key information from policy documents and stock commentaries, and subsequently leverages the MacBERT model to generate feature vectors for stock prediction. Our results show that MoF, by incorporating the influence of real-time events, improves accuracy and interpretability in stock trend forecasting, surpassing LSTM-based models with over 90% accuracy in predicting market fluctuations and providing reliable directional predictions. © 2024 Elsevier B.V., All rights reserved.",Background-aware; Financial trend; LLM; Macbert,Scopus
10.3905/jpm.2024.1.645,10.3905/jpm.2024.1.645,Large Language Models for Financial and Investment Management: Applications and Benchmarks,"The rapid evolution and unprecedented advancements in large language models (LLMs) have ushered in a new era of innovation in the realm of machine learning, with far-reaching implications for the finance and investment management sectors. These models have exhibited remarkable prowess in contextual understanding, processing vast and complex datasets, and generating content that aligns closely with human preferences. The transformative potential of LLMs in finance has catalyzed a surge of research and applications. As the integration of LLMs into financial practices continues to accelerate, there is an urgent need for a systematic examination of their diverse applications, methodologies, and impact, which necessitates a comprehensive review and synthesis of recent developments in this rapidly evolving field. This article aims to bridge the gap between cutting-edge artificial intelligence technology and its practical implementation in finance, providing a robust framework for understanding and leveraging LLMs in financial contexts. The authors explore the application of LLMs on various financial tasks, focusing on their potential to transform traditional practices and drive innovation. The article is highlighted for categorizing the existing literature into key application areas, including linguistic tasks, sentiment analysis, financial time series, financial reasoning, and agent-based modeling. For each application area, the authors delve into specific methodologies, such as textual analysis, knowledge-based analysis, forecasting, data augmentation, planning, decision support, and simulations. Furthermore, the article provides a comprehensive collection of datasets, benchmarks, and useful code associated with mainstream applications, offering valuable resources for researchers and practitioners. The authors hope their work can help facilitate the adoption and further development of LLMs in finance and investment management. © 2024 Elsevier B.V., All rights reserved.",,Scopus
2-s2.0-85209671545,,LLM-Driven Knowledge Enhancement for Securities Index Prediction,"The securities market carries complex financial interactions, providing challenges to its prediction. To represent this complexity, researchers have utilized multi-source data, such as financial news and macro market indicators, for better performance. However, these efforts often ignore the internal knowledge among these data or suffer from the high cost of acquiring diverse knowledge. Thus, we propose a LLM-driven knowledge enhancement method for securities index prediction. Specifically, we collect the daily data of Shanghai Stock Exchange indexes and their related market indicators and model the internal knowledge among them as triplets. Then we leverage LLM as a knowledge base to acquire diverse knowledge efficiently. Finally, we integrate the knowledge and numeric multi-source data as a heterogeneous graph and apply a GNN model to predict the trend of securities indexes. Experiments demonstrate the effectiveness of our method in prediction and real-world backtest. © 2024 Elsevier B.V., All rights reserved.",Knowledge Enhancement; Large Language Models; Stock Market Prediction,Scopus
10.1109/AiDAS63860.2024.10730589,10.1109/AiDAS63860.2024.10730589,GPT-4 Powered Virtual Analyst for Fundamental Stock Investment by Leveraging Qualitative Data,"This paper introduces an advanced AI-assisted tool, powered by GPT-4, for fundamental stock investment, offering human-like investment advice accompanied by supporting information to validate recommendations for users. While traditional stock market prediction tools rely heavily on quantitative data such as stock prices, volume, earnings, and dividends, the use of qualitative data for stock market analysis is an emerging trend. Recent advancements in AI, particularly with Generative AI like ChatGPT, have significantly influenced user interactions and decision-making processes. Recognizing the potential of AI across various industries, we have customized GPT-4 to perform fundamental analysis based on news, financial and annual reports of companies, government policies, and more. Our tool analyzes the above qualitative data and provide numerical scores along with logical and fact-based justifications for the short, medium, and long-term investment prospects of companies. The system delivers reliable recommendations for up to ten months without continuous monitoring, making it valuable to a wide range of users, from value investors to everyday traders. The benefits of using our tool are substantial, including significant time and cost savings. © 2024 Elsevier B.V., All rights reserved.",Fundamental Analysis; Generative AI; Qualitative Data; Stock Market Investment; Virtual Analyst,Scopus
10.1080/14697688.2024.2399285,10.1080/14697688.2024.2399285,Path shadowing Monte Carlo,"We introduce a Path Shadowing Monte Carlo method, which provides the prediction of future paths, given any generative model. At any given date, it averages future quantities over generated price paths whose past history matches, or ‘shadows’, the actual (observed) history. We test our approach using paths generated from a maximum entropy model of financial prices, based on a recently proposed multi-scale analogue of the standard skewness and kurtosis called ‘Scattering Spectra’. This model promotes the diversity of generated paths while reproducing main statistical properties of financial prices, including stylized facts such as volatility roughness. Our method yields state-of-the-art predictions for future realized volatility and allows one to determine conditional option smiles for the S&P500 that outperform both the most recent low-parametric models and the option market itself. The code is available at https://github.com/RudyMorel/shadowing (This work is supported by the PRAIRIE 3IA Institute of the French ANR-19-P3IA-0001 program and the ENS-CFM models and data science chair.). © 2024 Elsevier B.V., All rights reserved.",Option pricing; Volatility prediction; Wavelets,Scopus
10.1016/j.bar.2024.101513,10.1016/j.bar.2024.101513,The information content of delayed block trades in cryptocurrency markets,"This paper examines the price impact of large block trades in cryptocurrency markets by using a natural experiment in Bitcoin provided by the Gemini exchange. The exchange introduced a block trading facility in 2018, but in December 2019, it changed the minimum size threshold that allows market participants to trade a block and report it with a delay. Consistent with theoretical predictions and earlier empirical findings, we largely confirm that the information content of large trades is significantly lower in the upstairs market than in the downstairs. In contrast with prior research in traditional markets, we find that delaying the reporting of a block traded away from the continuous book discourages informed trading and potentially decreases the informativeness of trading and, therefore, information efficiency. Further, we find that the newly implemented size requirement for upstairs trades increases the total market impact, thereby not working as the intended introduction of a block trading facility. © 2024 Elsevier B.V., All rights reserved.",Block trading; Cryptocurrency markets; Information efficiency; Informed trading; Market microstructure; Price impact,Scopus
10.1109/DOCS63458.2024.10704454,10.1109/DOCS63458.2024.10704454,Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach,"Accurate stock market predictions following earnings reports are crucial for investors. Traditional methods, particularly classical machine learning models, struggle with these predictions because they cannot effectively process and interpret extensive textual data contained in earnings reports and often overlook nuances that influence market movements. This paper introduces an advanced approach by employing Large Language Models (LLMs) instruction fine-tuned with a novel combination of instruction-based techniques and quantized low-rank adaptation (QLoRA) compression. Our methodology integrates 'base factors', such as financial metric growth and earnings transcripts, with 'external factors', including recent market indices performances and analyst grades, to create a rich, supervised dataset. This comprehensive dataset enables our models to achieve superior predictive performance in terms of accuracy, weighted Fl, and Matthews correlation coefficient (M CC), especially evident in the comparison with benchmarks such as GPT-4. We specifically highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases significant improvements over baseline models. The paper also discusses the potential of expanding the output capabilities to include a 'Hold''''' option and extending the prediction horizon, aiming to accommodate various investment styles and time frames. This study not only demonstrates the power of integrating cutting-edge AI with fine-tuned financial data but also paves the way for future research in enhancing AI -driven financial analysis tools. © 2024 Elsevier B.V., All rights reserved.",Instruction Fine Tuning; Large Language Model; Quantized Low-Rank Adaptation,Scopus
10.1007/978-3-031-69982-5_14,10.1007/978-3-031-69982-5_14,Sentiment Analysis for Stock Prediction Using Mass Media Sources,"“Sentiment Analysis for Stock Prediction Using Mass Media Sources” introduces a groundbreaking approach to forecasting stock movements by harnessing sentiment analysis applied to economic news gathered from a diverse range of mass media sources. The project encompasses the creation of a comprehensive system that systematically scrapes economic news websites to gather information relevant to specific companies. This data is then meticulously analyzed to discern the sentiments expressed in the news articles. Subsequently, cutting-edge Machine learning techniques are put to use to anticipate potential fluctuations in the stock prices of the target companies. This holistic approach capitalizes on the amalgamation of Natural language processing which combined with machine learning techniques, and real-time news data, delivering invaluable insights for both investors and traders. © 2024 Elsevier B.V., All rights reserved.",GPT models; OpenAI; Reliance; Sentiment Analysis; Stock Prediction,Scopus
10.1109/CIBCB58642.2024.10702147,10.1109/CIBCB58642.2024.10702147,The Development of CanPrompt Strategy in Large Language Models for Cancer Care,"Background: The recent revolution in Large Language Models (LLMs) is transforming industries, enhancing communication, and reshaping research methodologies. LLMs have found significant applications across various sectors, notably in finance for stock market predictions, and in healthcare, where complex medical data is analyzed for diagnosis at an early stage, improving diagnostic procedures, and personalized treatment planning. In healthcare, where complex medical data is analyzed for diagnosis at an early stage. Despite the immense potential, challenges such as overwhelming Big Data, model hallucinations, and ethical concerns about patient privacy and bias persist. Method: We implemented novel strategies like CanPrompt to mitigate the accuracy and hallucination concerns to ensure responsible deployment. The CanPrompt strategy utilizes prompt engineering combined with few-shot and in-context learning to significantly enhance model accuracy by generating more relevant answers. The models were tested against a specialized dataset from MedQuAD, focusing on cancer, and evaluated using metrics like ROUGE and BERTScore to assess the semantic and syntactic accuracy of generated responses against validated ""Gold Answers"". Through this approach, the study seeks to outline the potential and limitations of LLMs in improving cancer care. Result: After applying CanPrompt with models Mistral 7x8b, Falcon 40b, and Llama 3-8b, BERTScore results showed Mistral leading with an accuracy around 84%, Falcon slightly lower, and Llama the least, with respective precision scores also reflecting a similar trend. Conclusion: The study demonstrates the promise of LLMs in cancer care through the introduction of CanPrompt. © 2024 Elsevier B.V., All rights reserved.",and Llama 3-8b; BERTScore; Cancer; Falcon 40b; Large Language Model (LLM); Mistral 7x8B; prompt; ROGUE score,Scopus
10.1109/ICCIMS61672.2024.10690672,10.1109/ICCIMS61672.2024.10690672,Self-Evolving Programs: A Novel Approach Leveraging LLMs and Quine Programs,"In an era where software systems undergo rapid evolution, the demand for self-evolving programs has received much attention. This paper introduces a groundbreaking methodology that amalgamates the predictive power of Large Language Model-Based Methods with the self-replicating nature of Quine Programs to organize self-evolving software. This innovative integration not only facilitates dynamic code adaptation to fluctuating runtime conditions but also pioneers a shift from traditional static coding paradigms. Through this approach, we aim to revolutionize software development, particularly enhancing security and performance with a focus on countering selfish mining attacks in Bitcoin. It should be noted that the suggested approach has not yet been considered in the field of software engineering, and its applications are not limited to software security. It has high potential to be used in every domain that requires adaptive programs. Since the suggested approach is novel, the proposed solution in Bitcoin is also novel. The results of simulation show the efficiency of the proposed solution. © 2024 Elsevier B.V., All rights reserved.",Dynamic Code Optimization; Language Model-based Methods; Quine Programs; Self-Evolving Programs; Selfish Mining Defense,Scopus
10.18653/v1/2024.findings-acl.185,10.18653/v1/2024.findings-acl.185,LLMFactor: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction,"Recently, Large Language Models (LLMs) have attracted significant attention for their exceptional performance across a broad range of tasks, particularly in text analysis. However, the finance sector presents a distinct challenge due to its dependence on time-series data for complex forecasting tasks. In this study, we introduce a novel framework called LLMFactor, which employs Sequential Knowledge-Guided Prompting (SKGP) to identify factors that influence stock movements using LLMs. Unlike previous methods that relied on keyphrases or sentiment analysis, this approach focuses on extracting factors more directly related to stock market dynamics, providing clear explanations for complex temporal changes. Our framework directs the LLMs to create background knowledge through a fill-in-the-blank strategy and then discerns potential factors affecting stock prices from related news. Guided by background knowledge and identified factors, we leverage historical stock prices in textual format to predict stock movement. An extensive evaluation of the LLMFactor framework across four benchmark datasets from both the U.S. and Chinese stock markets demonstrates its superiority over existing state-of-the-art methods and its effectiveness in financial time-series forecasting. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.18653/v1/2024.findings-acl.233,10.18653/v1/2024.findings-acl.233,Can Large Language Models Mine Interpretable Financial Factors More Effectively? A Neural-Symbolic Factor Mining Agent Model,"Finding interpretable factors for stock returns is the most vital issue in the empirical asset pricing domain. As data-driven methods, existing factor mining models can be categorized into symbol-based and neural-based models. Symbol-based models are interpretable but inefficient, while neural-based approaches are efficient but lack interpretability. Hence, mining interpretable factors effectively presents a significant challenge. Inspired by the success of Large Language Models (LLMs) in various tasks, we propose a FActor Mining Agent (FAMA) model that enables LLMs to integrate the strengths of both neural and symbolic models for factor mining. In this paper, FAMA consists of two main components: Cross-Sample Selection (CSS) and Chain-of-Experience (CoE). CSS addresses the homogeneity challenges in LLMs during factor mining by assimilating diverse factors as in-context samples, whereas CoE enables LLMs to leverage past successful mining experiences, expediting the mining of effective factors. Experimental evaluations on real-world stock market data demonstrate the effectiveness of our approach by surpassing the SOTA RankIC by 0.006 and RankICIR by 0.105 in predicting S&P 500 returns. Furthermore, the investment simulation shows that our model can achieve superior performance with an annualized return of 38.4% and a Sharpe ratio of 667.2%. © 2025 Elsevier B.V., All rights reserved.",,Scopus
2-s2.0-85204874765,,Enhanced Financial Sentiment Analysis and Trading Strategy Development Using Large Language Models,"This study proposes a novel methodology for enhanced financial sentiment analysis and trading strategy development using large language models (LLMs) such as OPT, BERT, FinBERT, LLAMA 3 and RoBERTa. Utilizing a dataset of 965,375 U.S. financial news articles from 2010 to 2023, our research demonstrates that the GPT-3-based OPT model significantly outperforms other models, achieving a prediction accuracy of 74.4% for stock market returns. Our findings reveal that the advanced capabilities of LLMs, particularly OPT, surpass traditional sentiment analysis methods, such as the Loughran-McDonald dictionary model, in predicting and explaining stock returns. For instance, a self-financing strategy based on OPT scores achieves a Sharpe ratio of 3.05 over our sample period, compared to a Sharpe ratio of 1.23 for the strategy based on the dictionary model. This study highlights the superior performance of LLMs in financial sentiment analysis, encouraging further research into integrating artificial intelligence and LLMs in financial markets. © 2024 Elsevier B.V., All rights reserved.",,Scopus
10.1109/ICoDSA62899.2024.10652178,10.1109/ICoDSA62899.2024.10652178,Estimating Value at Risk for Central Counterparties: A Generative AI Approach,"Central counterparties (CCPs) play an important role in the stability of financial markets by helping to mitigate systemic risk. It is important that CCPs have robust risk management tools in order to protect themselves from failing due to a defaulting member. In this paper a new model using a Bidirectional Generative Adversarial Network (BiGAN), a type of generative AI model, is proposed to estimate Value at Risk (VaR), a common metric used to compute initial margin for CCPs. Fifteen years of closing prices from the S&P 500 index was used as the dataset. The model was backtested for a period of four years. The results were evaluated using the number of breaches, Kupiec test, excess margin as well as two procyclicality measures: the standard deviation and peak to trough ratio of margin. The results were compared against three widely used models: filtered historical simulation method, historical VaR and parametric VaR. The results from this study showed that VaR computed using the BiGAN model produced 19 breaches on average for the four-year test period. While the experimental results show the proposed model is comparable with other models in terms of accuracy, its standard deviation for margin calls is lower which results in more short-term stability and a lower excess margin compared to the traditional models. The results of this research encourage further research on using BiGAN to estimate VAR. © 2024 Elsevier B.V., All rights reserved.",Bidirectional Generative Adversarial Networks; Central Counterparty; Financial Risk Management; Generative AI; Value-at-Risk,Scopus
10.1016/j.procs.2024.08.258,10.1016/j.procs.2024.08.258,ChatGPT-based Sentiment Analysis and Risk Prediction in the Bitcoin Market,"The risk prediction of financial markets is of paramount importance, with investor sentiment playing a critical role. However, current research appears to be lacking in-depth exploration of this particular aspect within the Bitcoin market. This study aims to explore the impact of market participants' sentiment on risk prediction in the bitcoin market. We first applied ChatGPT to analyze the sentiment of crawled Bitcoin-related news headlines. Meanwhile, Monte Carlo simulation was employed to calculate value at risk (VaR). And we selected five conventional factors, including Bitcoin price, transaction volume, market share, hash rate, and average difficulty of mining. Finally, K-Nearest Neighbors (KNN) regression model was used to construct the model for predicting the risk of bitcoin market. We made a comparison between the accuracy outcomes when considering and not considering sentiment as factors. The results show that market participant's sentiment is significantly associated with market risk, and the inclusion of sentiment can significantly improve the accuracy of the risk prediction model. © 2024 Elsevier B.V., All rights reserved.",Bitcoin market; ChatGPT; Investor sentiment; Risk prediction; Text mining,Scopus
10.1007/978-981-97-5934-7_19,10.1007/978-981-97-5934-7_19,News that Moves the Market: DSEX-News Dataset for Forecasting DSE Using BERT,"Stock market is a complex and dynamic industry that has always presented challenges for stakeholders and investors due to its unpredictable nature. This unpredictability motivates the need for more accurate prediction models. Traditional prediction models have limitations in handling the dynamic nature of the stock market. Additionally, previous methods have used less relevant data, leading to suboptimal performance. This study proposes the use of Bidirectional Encoder Representations from Transformers (BERT), a pre-trained Large Language Model (LLM), to predict Dhaka Stock Exchange (DSE) market movements. We also introduce a new dataset designed specifically for this problem, capturing important characteristics and patterns that were missing in other datasets. We test our new dataset of headlines and stock market indexes on various machine learning techniques, including Decision Tree (DT), Logistic Regression (LR), K-Nearest Neighbors (KNN), Random Forest (RF), Linear Support Vector Machine (LSVM), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs), Bidirectional Long Short-Term Memory (Bi-LSTM), BERT, Financial Bidirectional Encoder Representations from Transformers (FinBERT), and RoBERTa, which are compared to assess their predictive capabilities. Our proposed model achieves 99.83% accuracy on the training set and 99.78% accuracy on the test set, outperforming previous methods. © 2024 Elsevier B.V., All rights reserved.",Deep Learning; Large Language Model; Machine Learning; Natural Language Processing; Sentiment Analysis; Stock Exchange,Scopus
10.1109/ACCESS.2024.3445413,10.1109/ACCESS.2024.3445413,"Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study","This paper comprehensively examines Large Language Models (LLMs) in sentiment analysis, specifically focusing on financial markets and exploring the correlation between news sentiment and Bitcoin prices. We systematically categorize various LLMs used in financial sentiment analysis, highlighting their unique applications and features. We also investigate the methodologies for effective data collection and categorization, underscoring the need for diverse and comprehensive datasets. Our research features a case study investigating the correlation between news sentiment and Bitcoin prices, utilizing advanced sentiment analysis and financial analysis methods to demonstrate the practical application of LLMs. The findings reveal a modest but discernible correlation between news sentiment and Bitcoin price fluctuations, with historical news patterns showing a more substantial impact on Bitcoin's longer-term price than immediate news events. This highlights LLMs' potential in market trend prediction and informed investment decision-making. © 2024 Elsevier B.V., All rights reserved.",Bitcoin price; Large language model; machine learning; market dynamics; sentiment analysis,Scopus
10.1109/ISCA59077.2024.00082,10.1109/ISCA59077.2024.00082,LLMCompass: Enabling Efficient Hardware Design for Large Language Model Inference,"The past year has witnessed the increasing popularity of Large Language Models (LLMs). Their unprecedented scale and associated high hardware cost have impeded their broader adoption, calling for efficient hardware designs. With the large hardware needed to simply run LLM inference, evaluating different hardware designs becomes a new bottleneck. This work introduces LLMCompass1, a hardware evaluation framework for LLM inference workloads. LLMCompass is fast, accurate, versatile, and able to describe and evaluate different hardware designs. LLMCompass includes a mapper to automatically find performance-optimal mapping and scheduling. It also incorporates an area-based cost model to help architects reason about their design choices. Compared to real-world hardware, LLMCompass' estimated latency achieves an average 10.9% error rate across various operators with various input sizes and an average 4.1% error rate for LLM inference. With LLMCompass, simulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done within 16 minutes on commodity hardware, including 26,400 rounds of the mapper's parameter search. With the aid of LLMCompass, this work draws architectural implications and explores new cost-effective hardware designs. By reducing the compute capability or replacing High Bandwidth Memory (HBM) with traditional DRAM, these new designs can achieve as much as 3.41x improvement in performance/cost compared to an NVIDIA A100, making them promising choices for democratizing LLMs.1Available at https://github.com/PrincetonUniversity/LLMCompass. © 2025 Elsevier B.V., All rights reserved.",accelerator; area model; cost model; Large language model; performance model,Scopus
10.1007/978-3-031-66336-9_31,10.1007/978-3-031-66336-9_31,Language as a Lens: A Hybrid Text Summarization and Sentiment Analysis Approach for Multiclass Stock Return Prediction,"This research explores the application of text summarization and sentiment analysis techniques in the multiclass classification of hourly stock price returns, studying six companies from the Dow Jones Index between 2017 and the first quarter of 2020. The study employs three distinct text summarization methods to efficiently process a substantial volume of financial news. This approach enhances the depth and accuracy of subsequent sentiment analysis. Sentiment is assessed through a combination of lexicon-based and deep learning methods. These insights, along with technical market data, are integrated into a Light Gradient Boosting Machine (LGBM) model, which is refined through Bayesian hyperparameter optimization and assessed via cross-validation. The results demonstrate that the model’s performance peaks at a standard deviation coefficient of 0.25, indicating an optimal balance for the three-class classification problem. Furthermore, the feature importance analysis reveals that while temporal and market-related factors play a significant role, sentiment features captured by FinBERT and VADER substantially contribute to the model’s predictive power. A notable finding of this research is the superior performance of FinBERT over GPT-3.5 in feature importance analysis, underscoring the efficacy of specialized language models in financial contexts. By marrying natural language processing techniques with machine learning, the study presents a novel approach to understanding the predictive power of news sentiment in financial markets. © 2024 Elsevier B.V., All rights reserved.",Feature importance; Financial forecasting; LGBM; Sentiment analysis; Text summarization,Scopus
10.1080/12460125.2024.2371670,10.1080/12460125.2024.2371670,ChatGPT’s crystal ring: simulating auditors’ use of machine learning in stock price prediction,"This study investigates the influence of technological factors on the intent to use Machine Learning (ML) tools such as Python for the purpose of predicting stock prices. Further, it investigates the moderate impact of Artificial Intelligence (AI) models usage, in particular ChatGPT, on these associations. The outcomes of a simulation involving 400 auditors, accounting for the heterogeneity of their competencies, were obtained through code utilisation based on the Python programming language. The technological factors drawn from diffusion of innovation theory (DOI), including relative advantages, Complexity, compatibility, observability, and triability, all showed positive associations with behavioural intent. The use of ChatGPT significantly fortified these connections. These results suggest a fruitful symbiotic outcome may be achieved by combining AI capabilities with these variables. The findings underscore the significance of planning for the adoption of AI in financial decision-making and auditing and also illustrate the potential of AI in these areas. © 2024 Elsevier B.V., All rights reserved.",auditor; ChatGPT; DOI; Python; simulation; stock prices,Scopus
2-s2.0-85195934691,,AlphaFin: Benchmarking Financial Analysis with Retrieval-Augmented Stock-Chain Framework,"The task of financial analysis primarily encompasses two key areas: stock trend prediction and the corresponding financial question answering. Currently, machine learning and deep learning algorithms (ML&DL) have been widely applied for stock trend predictions, leading to significant progress. However, these methods fail to provide reasons for predictions, lacking interpretability and reasoning processes. Also, they can not integrate textual information such as financial news or reports. Meanwhile, large language models (LLMs) have remarkable textual understanding and generation ability. But due to the scarcity of financial training datasets and limited integration with real-time knowledge, LLMs still suffer from hallucinations and are unable to keep up with the latest information. To tackle these challenges, we first release AlphaFin datasets, combining traditional research datasets, real-time financial data, and handwritten chain-of-thought (CoT) data. It has a positive impact on training LLMs for completing financial analysis. We then use AlphaFin datasets to benchmark a state-of-the-art method, called Stock-Chain, for effectively tackling the financial analysis task, which integrates retrieval-augmented generation (RAG) techniques. Extensive experiments are conducted to demonstrate the effectiveness of our framework on financial analysis. © 2024 Elsevier B.V., All rights reserved.",Chain-of-Thoughts; Finance; Financial Question Answering; Large Language Models; Retrieval-Augmented Generation; Stock Trend Prediction,Scopus
2-s2.0-85195171155,,Modal-adaptive Knowledge-enhanced Graph-based Financial Prediction from Monetary Policy Conference Calls with LLM,"Financial prediction from Monetary Policy Conference (MPC) calls is a new yet challenging task, which targets at predicting the price movement and volatility for specific financial assets by analyzing multimodal information including text, video, and audio. Although the existing work has achieved great success using cross-modal transformer blocks, it overlooks the potential external financial knowledge, the varying contributions of different modalities to financial prediction, as well as the innate relations among different financial assets. To tackle these limitations, we propose a novel Modal-Adaptive kNowledge-enhAnced Graph-basEd financial pRediction scheme, named MANAGER. Specifically, MANAGER resorts to FinDKG to obtain the external related knowledge for the input text. Meanwhile, MANAGER adopts BEiT-3 and Hidden-unit BERT (HuBERT) to extract the video and audio features, respectively. Thereafter, MANAGER introduces a novel knowledge-enhanced cross-modal graph that fully characterizes the semantic relations among text, external knowledge, video and audio, to adaptively utilize the information in different modalities, with ChatGLM2 as the backbone. Extensive experiments on a publicly available dataset Monopoly verify the superiority of our model over cutting-edge methods. © 2024 Elsevier B.V., All rights reserved.",Financial Prediction; LLM; Multimodal Learning,Scopus
10.1016/j.procs.2024.03.246,10.1016/j.procs.2024.03.246,Checking Counterfeit Critiques on Commodities using Ensemble Classifiers Enhancing Information Credibility,"The conundrum of the ubiquitous deceptive reviews has overruled the online ontology with the obsession of obscure but obligatory posting of product reviews for the customers to believe, behold and beget the online product marketing. This mandates contemporary research in the direction to delve deeper on the application and analysis of deceiving online reviews with matured and advanced AI models functional on large scale datasets to effectively and efficiently demarcate between the genuine and the sham. The research counteracts the counterfeiting product reviews via the applications, assessment and analysis of the befitting AI models - Elastic-net Classifier model based on block coordinate descent with Wordcloud and its further performance enhancement through LightGBM Trees Classifier with Grid Search and Early Stopping support, with Log-Loss as performance metric for experimentation to gain insight into the intricacies of detection, diagnosis and diminution of fake product reviews. The paper also delineates discriminative and affirmative aspects of the dataset quality, statistics, stability and standards inherent and coherent to the creation of the dataset using Large Language Models (LLMs) intrinsic to the zeitgeist juncture of recent times promoting machines to produce large scale, cost effective bogus reviews in lieu of the Amazon Mechanical Turks. The results obtained with the Log-Loss holdout score of 0.1462 conforming the LightGBM classifier proves its performance better than the Elastic-Net classifier, conforming it as better than the ROC-AUC in terms of its proximity to the prediction probability for the matching actual/true value. © 2024 Elsevier B.V., All rights reserved.",Amazon Mechanical Turks; Elastic-net Classifier; Information credibility; Large Language Models; LightGBM Trees Classifier,Scopus
10.1007/978-981-97-0837-6_4,10.1007/978-981-97-0837-6_4,Forecasting Chinese Overnight Stock Index Movement Using Large Language Models with Market Summary,"Forecasting financial market movement constitutes a complex and pivotal research area within the realm of Financial Technology (Fintech). In this work, we investigate the ability of large language models to predict Chinese overnight stock index movement, utilizing market summary gleaned from news media sources. We fine-tune various pre-trained models to compare the performance with that of Generative Pre-training Transformer (GPT) models, specifically GPT-3.5 and GPT-4, as provided by OpenAI. The empirical findings underscore that the fine-tuned pre-trained models, characterized by fewer parameters and more straightforward architectures, surpass the esteemed GPT-3.5 and GPT-4 models in predictive metrics of accuracy and f1. All fine-tuned models are publicly available on the huggingface platform (https://huggingface.co/hw2942). © 2024 Elsevier B.V., All rights reserved.",BERT; Forecasting overnight stock index movement; GPT; Large language models,Scopus
10.1007/978-3-031-50381-8_72,10.1007/978-3-031-50381-8_72,Application and Modeling of LLM in Quantitative Trading Using Deep Learning Strategies,"After more than 100 years of development, with the breakthrough of computer technology, deep learning and big data industry, the quantitative trading market has gradually matured, and more and more investors have begun to use quantitative trading to invest. Quantitative trading automatically executes transactions through written programs, eliminating the interference of human subjective factors on transaction execution. But the threshold for quantitative trading is high, requiring researchers to have a deep understanding of mathematics, statistics, finance, and computer technology. The newly emerged Large Language Model (LLM) can help users get started to a certain extent, by giving the general framework of the code, so that users can have a preliminary understanding of the countermeasures faster and more accurately. In terms of model training and testing, this paper adopts the CSI 300 index obtained from tushare platform to study the results of daily data, weekly data and monthly data after training. This project trained a stock price prediction model using long short-term memory (LSTM) methods. Then, the backtest model was established with the classic double moving average strategy in quantitative trading, and the backtrader platform was used to visualize the return results simulated by the backtest. Finally, we discussed the risks of using LLM codes to execute quantitative trading. © 2024 Elsevier B.V., All rights reserved.",Deep learning; LLM; Quantitative trading,Scopus
10.1080/23270012.2024.2306929,10.1080/23270012.2024.2306929,Dividend announcement and the value of sentiment analysis,"Payout policy constitutes one of the most important corporate financial decisions since dividends are essential factors in determining a firm’s value. A dividend announcement generates a market signal which translates into changes in stock returns, impacting short-term price fluctuations and producing abnormal returns. The sample consists of 394 companies listed on the S&P500 index, from which 1574 dividend announcements and 7222 news items are derived during the years 2022–2023. News pieces are obtained from 58 specialized sources, and ChatGPT is used to automate the sentiment extracted from them. Using sentiment analysis, this paper shows the key role played by sentiments derived from financial news posted just after dividend announcements in predicting market reaction and helping investors to select optimal investment strategies. This paper contributes to the current literature, highlighting the influence that sentiments have on determining stock market returns. © 2024 Elsevier B.V., All rights reserved.",dividend announcement; financial news; investment strategies; market reaction; payout policy; sentiment analysis,Scopus
10.1109/ACCESS.2024.3350638,10.1109/ACCESS.2024.3350638,Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering,"Blockchain technology has revolutionized the financial landscape, witnessing widespread adoption of cryptocurrencies due to their decentralized and transparent nature. As sentiments expressed on social media platforms wield substantial influence over cryptocurrency market dynamics, sentiment analysis has emerged as a crucial tool for gauging public opinion and predicting market trends. This paper explores fine-tuning techniques for large language models to enhance sentiment analysis performance. Experimental results demonstrate a significant average zero-shot performance gain of 40% on unseen tasks after fine-tuning, highlighting its potential. Additionally, the impact of instruction-based fine-tuning on models of varying scales is examined, revealing that larger models benefit from instruction tuning, achieving the highest average accuracy score of 75.16%. In contrast, smaller-scale models may experience reduced generalization due to complete model capacity utilization. To gain deeper insight into instruction effectiveness, the paper presents experimental investigations under different instruction tuning setups. Results show the model achieves an average accuracy score of 72.38% for short and simple instructions, outperforming long and complex instructions by over 12%. Finally, the paper explores the relationship between fine-tuning corpus size and model performance, identifying an optimal corpus size of 6,000 data points for the highest performance across different models. Microsoft's MiniLM, a distilled version of BERT, excels in efficient data use and performance optimization, while Google's FLAN-T5 demonstrates consistent and reliable performance across diverse datasets. © 2024 Elsevier B.V., All rights reserved.",in-context learning; instruction tuned; prompt engineering; supervised fine-tuning; Zero-shot learning,Scopus
10.1109/3DV62453.2024.00058,10.1109/3DV62453.2024.00058,GAN-Avatar: Controllable Personalized GAN-based Human Head Avatar,"Digital humans and, especially, 3D facial avatars have raised a lot of attention in the past years, as they are the backbone of several applications like immersive telepresence in AR or VR. Despite the progress, facial avatars reconstructed from commodity hardware are incomplete and miss out on parts of the side and back of the head, severely limiting the usability of the avatar. This limitation in prior work stems from their requirement of face tracking, which fails for profile and back views. To address this issue, we propose to learn person-specific animatable avatars from images without assuming to have access to precise facial expression tracking. At the core of our method, we leverage a 3D-aware generative model that is trained to reproduce the distribution of facial expressions from the training data. To train this appearance model, we only assume to have a collection of 2D images with the corresponding camera parameters. For controlling the model, we learn a mapping from 3DMM facial expression parameters to the latent space of the generative model. This mapping can be learned by sampling the latent space of the appearance model and reconstructing the facial parameters from a normalized frontal view, where facial expression estimation performs well. With this scheme, we decouple 3D appearance reconstruction and animation control to achieve high fidelity in image synthesis. In a series of experiments, we compare our proposed technique to state-of-the-art monocular methods and show superior quality while not requiring expression tracking of the training data. © 2024 Elsevier B.V., All rights reserved.",3D facial avatar; facial reenactment; personalized GAN,Scopus
10.1109/CISCT62494.2024.11134255,10.1109/CISCT62494.2024.11134255,Transforming Financial Market Prediction Through Generative AI-Powered Data Management,"Predicting financial markets remains essential for decision-making in trading and investment. However, traditional models often fall short due to low-quality data, market volatility, and the complexity of global economic trends. Generative AI offers a transformative approach by improving data management processes, enhancing prediction accuracy, and overcoming the limitations of current forecasting models. This research explores the potential of Generative AI to enrich financial data through techniques like data augmentation, synthetic data generation, and anomaly detection. Specifically, the study investigates how integrating Generative AI into data preprocessing can enhance predictive modeling using Long Short-Term Memory (LSTM) networks for time series forecasting, particularly in stock prices. The research also explores feature engineering techniques such as moving averages, Relative Strength Index (RSI), and volatility metrics, which are crucial for capturing market trends. Generative Adversarial Networks (GANs) are employed to create additional realistic trading scenarios, boosting model robustness. Implemented using Python, the findings reveal that the combined LSTM and GAN model improved prediction accuracy over traditional methods, achieving an RMSE of 0.096 and R-squared (R ) 0.85 in stock price forecasts. The incorporation of synthetic data with traditional financial metrics leads to an improvement in the model's ability to predict short-term market trends. These findings suggest that the use of Generative AI can provide a more resilient and adaptive approach to financial market prediction, opening new avenues for research in the domain. Future research could focus on expanding the scope to include multi-market scenarios and incorporating real-time data streams. © 2025 Elsevier B.V., All rights reserved.",data augmentation; financial market prediction; GAN; generative AI; LSTM; synthetic data,Scopus
10.22059/jcountst.2024.377065.1130,10.22059/jcountst.2024.377065.1130,The impact of the expansion of artificial intelligence on modern diplomacy in countries worldwide,"This article examines artificial intelligence technology as a modern and challenging phenomenon over the past decade. This technology has had a significant impact on the economic, political, and socio-cultural life in many countries. In this review article by using the descriptive-analytical method, the authors strive to define artificial intelligence within modern scientific discourse and introduce two practical applications of AI technologies. They discuss the ""practical mode"", which is used for effective management and accident prevention in industrial machinery, medicine, transportation, construction, oil and gas industries, mining, the nuclear sector, and more. Additionally, they introduce ""generative AI"", which is used for translating large texts, predicting business processes, evaluating financial and commodity markets, assessing societal feedback to any economic, political, and social changes, mastering risk management, and more. The article also explores the main challenges and risks of AI for modern society, including the creation of fake narratives, information bubbles, saturation, and other manipulation tools employed by technocratic elites in their quest for dominance. The concentration and distribution of AI development centers in specific areas could lead to increased inequality and tension between the North and South regions. Controlling the AI domain to protect national interests and maintain modern international relations poses a fundamental challenge for political and economic groups, institutions, and society. Researchers attempt to make predictions about the impact on energy, which will intensify with increased energy consumption and competition over rare elements. This rapidly growing demand cannot be met by ""clean energy"", so the energy transition might be slowed down by AI. This research proposes international actions for control, risk assessment, and an in-depth analysis of AI's impact on the development of other sectors. © 2025 Elsevier B.V., All rights reserved.",AI; globalization; regional policy; regionalization; security,Scopus
10.1109/ICCA62237.2024.10927923,10.1109/ICCA62237.2024.10927923,Enhancing Stock Price Prediction: A Hybrid Approach Leveraging Large Language Models and Deep Learning,"Accurate stock price prediction is a challenging yet crucial goal in finance, with significant implications for investment decisions and risk management. This paper presents a comprehensive review of machine learning techniques for stock price prediction, examining traditional methods such as regression and ensemble models, as well as advanced approaches that integrate sentiment analysis and textual data sources. With the emergence of powerful Large Language Models (LLMs) such as ChatGPT, Llama and Gemini, we explore their potential for enhancing predictive accuracy using historical stock data. Key challenges are discussed, including data quality, model interpretability, and adapting to dynamic market conditions. Additionally, this paper proposes a trustworthy stock price prediction model based on LLMs enabling informed investment decision-making. Experimental results demonstrate that ChatGPT-4o model achieved a prediction accuracy of approximately 97%, which can be improved by tuning model parameters. Consequently, the paper highlights the potential of LLMs in improving stock price forecasting. © 2025 Elsevier B.V., All rights reserved.",Large Language Models (LLMs); Machine Learning; Stock Price Prediction,Scopus
10.1109/ICCA62237.2024.10927897,10.1109/ICCA62237.2024.10927897,Assessing the Correlation Between News Sentiment and Stock Price Movements: A Case Study of 'WeWork' Using Advanced NLP Techniques,"This research explores the intricate relationship between news article sentiment and stock price movements, with the company 'WeWork' serving as a case study. Leveraging advanced Natural Language Processing (NLP) techniques and Large Language Models (LLMs) such as Open AI, this study aims to transform unstructured textual data into actionable financial insights. Through rigorous data collection and preprocessing, sentiment scores were derived from a wide range of news sources and correlated with historical stock prices. Statistical analyses, including linear regression and correlation metrics, revealed a weak positive correlation of 16.47% between sentiment and stock prices. Although the correlation suggests that sentiment analysis can offer valuable insights into market trends, it is insufficient as a standalone predictor for investment decisions. The findings underscore the importance of integrating sentiment analysis with traditional financial metrics, and call for the development of more robust models incorporating diverse data sources in future research. © 2025 Elsevier B.V., All rights reserved.",Large Language Models (LLMs); Natural Language Processing (NLP); Sentiment Analysis; Stock Price Prediction,Scopus
10.1109/ICCIRT59484.2024.10921844,10.1109/ICCIRT59484.2024.10921844,StockAI - Stock Analysis Tool Agent,"StockAI is a stock market analysis tool that integrates machine learning, traditional trading indicators, and intelligent agents to analyze live data and projections for stock investors. It does this by carrying out an analysis of the historical price trend of a stock and the ongoing stock markets from the use of mathematical indicators such as moving averages, relative strength index, and candlestick patterns. As a result, it aids in decision-making for both new and old traders. The system also leverages machine learning algorithms like random forests to generate price predictions with improved accuracy. StockAI's interactive interface allows users to engage with the tool through natural language queries. However, challenges remain in evaluating the outputs of large language models, as current methods rely heavily on human evaluation. The ultimate goal of StockAI is to help investors make informed decisions, optimize market opportunities and mitigate risks through a combination of AI-driven analysis and traditional financial indicators. © 2025 Elsevier B.V., All rights reserved.",agents; large language models; price prediction; stock market analysis,Scopus
10.1109/ICICYTA64807.2024.10913442,10.1109/ICICYTA64807.2024.10913442,The Role of News Sentiment in Predicting the Jakarta Composite Index Using Long Short-Term Memory,"This paper investigates the integration of sentiment analysis and historical data to enhance the accuracy of Jakarta Composite Index (JCI) stock return predictions using a Long Short-Term Memory (LSTM) model. The dataset spans January 3, 2014, to August 6, 2024, consisting of 2,647 daily observations enriched with sentiment scores derived from over 10,000 Kompas.com news articles. Sentiment analysis, performed using a Large Language Model (LLM)-based ChatGPT model, classified sentiment into Positive, Neutral, and Negative categories, which were then integrated as predictive features. Five scenarios for incorporating sentiment data were evaluated, with Scenario 2 (sequence of past sentiment scores) yielding the best performance. Specifically, it achieved the lowest Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) across various metrics: 36.4570 and 47.5527 for Absolute Return prediction, 0.005209 and 0.006804 for Relative Return prediction, and 50,725 and 65,653 for Close Price prediction. These findings underscore the significant role of sequential sentiment data in improving prediction accuracy, offering practical recommendations for investors to leverage sentiment analysis in making more informed decisions in the JCI market. © 2025 Elsevier B.V., All rights reserved.",JCI; LSTM; sentiment analysis; stock prediction,Scopus
10.1109/ISCMI63661.2024.10851549,10.1109/ISCMI63661.2024.10851549,Foreign Exchange Rate Forecast by a Large Language Model Integrated with Trend Description,"In this paper, we propose a large language model to forecast the direction of change in a foreign exchange rate. The input of the proposed model is textual information as a prompt, whereas that of conventional forecast models is numerical information. A recent trend in the exchange rate is added to input textual information to enhance forecast accuracy. GPT-2 is adopted as our large language model and is fine-tuned using training data. The effectiveness of the proposed model is empirically examined using actual data. © 2025 Elsevier B.V., All rights reserved.",deep learning; finance; large language model; machine learning; time series,Scopus
10.1109/ISCMI63661.2024.10851487,10.1109/ISCMI63661.2024.10851487,A Comparative Study of Sequential Deep Learning Models in Financial Time Series Forecasting,"Time series analysis of daily stock prices is challenging due to the inherent complexity, nonlinearity, and nonstationarity of financial data. In this paper, we compare three sequential deep learning models - LSTM, Transformer, and Large Language Models (LLMs) - for stock price prediction. By transforming the regression problem of predicting daily log returns into a classification task, we evaluate the models' classification accuracies, with the Transformer achieving the highest accuracy of 22%, followed by LSTM (15.6%) and LLM (15.3%). Regression metrics showed LSTM initially performing better, with a lower RMSE (180.92) than LLM (1739.61). However, outlier predictions in the LLM, caused by incomplete number outputs, inflated its error. After removing these outliers, LLM's RMSE improved significantly to 33.85, surpassing LSTM. These results demonstrate the potential of Transformer and LLM models for financial time series prediction. Future work will explore incorporating self-reflection mechanisms in LLM predictions and extending the comparison to multivariate financial time series incorporating textual data and other features. © 2025 Elsevier B.V., All rights reserved.",Deep Learning; Finance; Large Language Model; Survey; Time Series Forecasting,Scopus
10.1109/ISCMI63661.2024.10851691,10.1109/ISCMI63661.2024.10851691,Gold Price Forecasting in Uncertain Times: Integrating Sentiment Analysis and External Indices,"Since 2020, financial markets have experienced unprecedented volatility, making the traditional models for predicting gold prices significantly challenging. These models often overlook the nuanced impacts of real-time sentiment, economic indicators, and related metals like silver. This study proposes a novel framework to combine gold prices with other relevant features to improve predictive performance in the precious metal market. Further, we employ three advanced recent deep learning models, LSTM, N-HiTS, and TSMixer, and evaluate their performance with various metrics using the different combinations of the proposed features. The results demonstrate that incorporating the proposed additional features, such as silver prices and sentiment analysis, significantly improves forecasting accuracy, amidst the volatile and uncertain market conditions spanning from 2020 to 2024. The best-performing models outperform traditional models, such as ARIMA. Our findings highlight the importance of feature selection and combination in predictive modeling and demonstrate the potential of multi-feature models in capturing complex market dynamics. The insights from this study can inform investment decisions and risk management strategies in the precious metal market, and future research can build on our approach to explore additional features and models. © 2025 Elsevier B.V., All rights reserved.",Deep learning; Financial volatility; Gold prices; LLMs; Sentiment analysis,Scopus
10.1109/ICDMW65004.2024.00019,10.1109/ICDMW65004.2024.00019,Leveraging Large Language Models for Predicting Stock Option Valuation and Financial Risk Mitigation,"The prediction of short-term stock options with near-future expiration dates is a challenging task due to high volatility, limited information, market noise and the risk of time decay. This work focuses on the new approach to the stock options valuation by leveraging Large Language Models (LLMs) through the integration of quantitative (i.e. financial features-lagged prices, moving averages, and volatility indicators) and qualitative data (i.e. news data, including article titles, full textual content, and publication dates). More specifically, our approach fuses sentiment analysis from LLMs applied to financial news from two reputable outlets (i.e. Economic Times and Yahoo Finance India) with quantitative data on stock options, which includes stock option closing price. By conducting experiments on companies from the NIFTY 50 index using ChatGPT-3.5, ChatGPT-4, and LLaMA 3.1, we show that our method achieves superior prediction accuracy compared to other similar approaches. The paper develops a new framework to improve the valuation of short-term stock options using advanced natural language processing behaviors afforded by LLMs to achieve a more holistic capture of market dynamics and sentiment in option pricing. © 2025 Elsevier B.V., All rights reserved.",Bearish Prediction; Bullish Prediction; ChatGPT-3.5; ChatGPT-4; Financial Markets; Large Language Models; LLaMA 3.1; NIFTY50; Option Valuation; Risk Management; Sentiment Analysis; Short-term Options,Scopus
10.1109/ICDMW65004.2024.00021,10.1109/ICDMW65004.2024.00021,Sentiment Score of Bloomberg Market Wraps with ChatGPT,"In this paper, we used a large dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines affect stock market movements. To make this analysis more effective, we employed ChatGPT. First, from the summary of daily financial updates, we identify top global news headlines that could have a significant influence on stock markets. Second, for each headline, we questioned ChatGPT to answer whether the news might lead to a rise, a fall in stock prices or an indecisive future. This two-stage method proves more effective than a direct question on the entire text. By gathering ChatGPT's predictions day by day, we formed an overall market sentiment score and transform this score into a practical investment strategy in the NASDAQ index, demonstrating the significance of minimizing noise in sentiment scores by initially accumulating and then detrending them. This approach showcases that ChatGPT's analysis of news headlines can provide valuable insights into future stock market behaviours and be a valuable tool to develop intuitive NLP-driven investment strategies leveraging news predictive power. © 2025 Elsevier B.V., All rights reserved.",Bloomberg News; ChatGPT; NLP; SentimentScore,Scopus
2-s2.0-105000488263,,Thinking Forward: Memory-Efficient Federated Finetuning of Language Models,"Finetuning large language models (LLMs) in federated learning (FL) settings has become increasingly important as it allows resource-constrained devices to finetune a model using private data. However, finetuning LLMs using backpropagation requires excessive memory (especially from intermediate activations) for resource-constrained devices. While Forward-mode Auto-Differentiation (AD) can significantly reduce memory footprint from activations, we observe that directly applying it to LLM finetuning results in slow convergence and poor accuracy. In this paper, we introduce SPRY, an FL algorithm that splits trainable weights of an LLM among participating clients, such that each client computes gradients using Forward-mode AD that are closer estimations of the true gradients. SPRY achieves a low memory footprint, high accuracy, and fast convergence. We formally prove that the global gradients in SPRY are unbiased estimators of true global gradients for homogeneous data distributions across clients, while heterogeneity increases bias of the estimates. We also derive SPRY's convergence rate, showing that the gradients decrease inversely proportional to the number of FL rounds, indicating the convergence up to the limits of heterogeneity. Empirically, SPRY reduces the memory footprint during training by 1.4-7.1× in contrast to backpropagation, while reaching comparable accuracy, across a wide range of language tasks, models, and FL settings. SPRY reduces the convergence time by 1.2-20.3× and achieves 5.2-13.5% higher accuracy against state-of-the-art zero-order methods. When finetuning Llama2-7B with LoRA, compared to the peak memory consumption of 33.9GB of backpropagation, SPRY only consumes 6.2GB of peak memory. For OPT13B, the reduction is from 76.5GB to 10.8GB. SPRY makes feasible previously impossible FL deployments on commodity mobile and edge devices. Our source code is available for replication at https://github.com/Astuary/Spry. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.1109/IKT65497.2024.10892779,10.1109/IKT65497.2024.10892779,LLM-Driven Feature Extraction for Stock Market Prediction: A case study of Tehran Stock Exchange,"Stock market prediction is one of the most challenging research areas in recent years. With the emergence of deep learning and artificial intelligence, researchers have proposed various methods to predict stock market directions, considering different financial variables. One of the most significant variables influencing stock movement is user opinions and social media, which has attracted much attention from researchers in recent years. Although existing studies have introduced various methods to combine stock price and textual features, a reliable and comprehensive method has not yet been established, and there is still room for improvement. In this research, a novel method based on large language models is introduced for feature extraction from financial texts, and a self-attention mechanism is proposed to capture the internal relationships between textual and financial features. The results of the model presented in this study show a 3.10% improvement in accuracy compared to the latest competing models on a newly collected dataset. © 2025 Elsevier B.V., All rights reserved.",Graph Neural Networks; Information Fusion; Large Language Models; Self-Attention Mechanism; Stock Market Prediction,Scopus
10.1007/s44196-023-00212-x,10.1007/s44196-023-00212-x,An Efficient GAN-Based Multi-classification Approach for Financial Time Series Volatility Trend Prediction,"Deep learning has achieved tremendous success in various applications owing to its robust feature representations of complex high-dimensional nonlinear data. Financial time-series prediction is no exception. Hence, the volatility trend prediction in financial time series (FTS) has been an active topic for several decades. Inspired by generative adversarial networks (GAN), which have been studied extensively in image processing and have achieved excellent results, we present the ordinal regression GAN for financial volatility trends (ORGAN-FVT) method for the end-to-end multi-classification task of FTS. An improved generative model based on convolutional long short-term memory (ConvLSTM) and multilayer perceptron (MLP) is proposed to capture temporal features effectively and mine the data distribution of volatility trends (short, neutral, and long) from given FTS data. Meanwhile, ordinal regression is leveraged for the discriminator to improve the multi-classification performance, making the model more practical. Finally, we empirically compare ORGAN-FVT with several state-of-the-art approaches on three real-world stock datasets: MICROSOFT(MSFT), Tesla(TSLA), and The People’s Insurance Company of China(PAICC). ORGAN-FVT demonstrated significantly better AUC and F1 scores, at most 20.81% higher than its competitors. © 2023 Elsevier B.V., All rights reserved.",Classification; Convolutional LSTM; Financial time series; Generative adversarial nets,Scopus
10.1145/3604237.3626884,10.1145/3604237.3626884,Generative Machine Learning for Multivariate Equity Returns,"The use of machine learning to generate synthetic data has grown in popularity with the proliferation of text-to-image models and especially large language models. The core methodology these models use is to learn the distribution of the underlying data, similar to the classical methods common in finance of fitting statistical models to data. In this work, we explore the efficacy of using modern machine learning methods, specifically conditional importance weighted autoencoders (a variant of variational autoencoders) and conditional normalizing flows, for the task of modeling the returns of equities. The main problem we work to address is modeling the joint distribution of all the members of the S&P 500, or, in other words, learning a 500-dimensional joint distribution. We show that this generative model has a broad range of applications in finance, including generating realistic synthetic data, volatility and correlation estimation, risk analysis (e.g., value at risk, or VaR, of portfolios), and portfolio optimization. © 2023 Elsevier B.V., All rights reserved.",Generative Modeling; Normalizing Flows; Portfolio Optimization; Risk Forecasting; Stock Returns; Variational Autoencoders,Scopus
10.1145/3604237.3626861,10.1145/3604237.3626861,Predictability of Post-Earnings Announcement Drift with Textual and Contextual Factors of Earnings Calls,"Post-Earnings Announcement Drift (PEAD), a well-known anomaly in financial markets, describes the tendency of cumulative stock returns to drift in the direction of an earnings surprise for a prolonged period following an earnings announcement. Numerous studies have used a supervised learning approach to predict PEAD, using earnings, fundamental and technical factors. However, there is a lack of study on how the context of the earnings call can be used for the PEAD prediction task. This paper uses computational linguistics techniques and large language models to examine the effectiveness of incorporating textual and contextual features from earnings calls for the PEAD prediction task. Our proposed supervised model includes four categories of features: 1) textual features, 2) contextual features, 3) earnings features, and 4) fundamental and technical features. We study the proposed model using earnings from 2010/01/01 to 2022/12/31 of all point-in-time S&P500 constituents in the US stock market. Our results show that contextual features provide information unexplained by earnings, fundamental and technical features, improving the average returns per trade of a hypothetical long-short portfolio against baseline solution in out-of-sample across all four different abnormal return calculations, ranging from 53 to 354 basis points and 16.9% to 108.5% improvement from baseline model, which uses only earnings, fundamental and technical features. © 2023 Elsevier B.V., All rights reserved.",computational linguistics; earnings call; large language models; machine learning; Post-earnings announcement drift,Scopus
10.1016/j.jfds.2023.100113,10.1016/j.jfds.2023.100113,A general framework for portfolio construction based on generative models of asset returns,"In this paper, we present an integrated approach to portfolio construction and optimization, leveraging high-performance computing capabilities. We first explore diverse pairings of generative model forecasts and objective functions used for portfolio optimization, which are evaluated using performance-attribution models based on least absolute shrinkage and selection operator (LASSO). We illustrate our approach using extensive simulations of crypto-currency portfolios, and we show that the portfolios constructed using the vine-copula generative model and the Sharpe-ratio objective function consistently outperform. To accommodate a wide array of investment strategies, we further investigate portfolio blending and propose a general framework for evaluating and combining investment strategies. We employ an extension of the multi-armed bandit framework and use value models and policy models to construct eclectic blended portfolios based on past performance. We consider similarity and optimality measures for value models and employ probability-matching (“blending”) and a greedy algorithm (“switching”) for policy models. The eclectic portfolios are also evaluated using LASSO models. We show that the value model utilizing cosine similarity and logit optimality consistently delivers robust superior performances. The extent of outperformance by eclectic portfolios over their benchmarks significantly surpasses that achieved by individual generative model-based portfolios over their respective benchmarks. © 2023 Elsevier B.V., All rights reserved.",Cryptocurrency; Generative model; Multi-armed bandit; Portfolio blending; Portfolio construction,Scopus
10.1145/3583780.3614886,10.1145/3583780.3614886,Follow the Will of the Market: A Context-Informed Drift-Aware Method for Stock Prediction,"The dynamic nature of stock market styles, referred to as concept drift, poses a formidable challenge when applying deep learning to stock prediction. Models trained on historical data often struggle to adapt to the latest market styles, as the patterns they have learned may no longer hold true over time. To alleviate this issue, the recently popularized concept of In-Context learning has provided us with valuable insights. In this approach, large language models (LLMs) are exposed to multiple examples of input-label pairs, also known as demonstrations, as part of the prompt before performing a task on an unseen example. By thoroughly analyzing these demonstrations, LLMs can uncover potential patterns and effectively adapt to new tasks. Building upon this concept, we propose a Context-Informed drift-aware method for Stock Prediction (CISP), which continually adjusts to the latest market styles and offers more accurate predictions. Our proposed method consists of two key parts. Firstly, we introduce a straightforward and efficient technique for designing demonstrations that aggregate current market information, thereby indicating the prevailing stock market style. Secondly, we incorporate a prediction module with dynamic parameters, allowing it to appropriately adjust its model parameters based on the market patterns embedded in the aforementioned demonstrations. Through extensive experiments conducted on real-world stock market datasets, our approach consistently outperforms the most advanced existing methods for stock prediction. © 2023 Elsevier B.V., All rights reserved.",Context-Informed; Drift-Aware; Stock Prediction,Scopus
10.1016/j.eswa.2023.119862,10.1016/j.eswa.2023.119862,A review on sentiment analysis from social media platforms,"Sentiment analysis has proven to be a valuable tool to gauge public opinion in different disciplines. It has been successfully employed in financial market prediction, health issues, customer analytics, commercial valuation assessment, brand marketing, politics, crime prediction, and emergency management. Many of the published studies have focused on sentiment analysis of Twitter messages, mainly because a large and diverse population expresses opinions about almost any topic daily on this platform. This paper proposes a comprehensive review of the multifaceted reality of sentiment analysis in social networks. We not only review the existing methods for sentiment analysis in social networks from an academic perspective, but also explore new aspects such as temporal dynamics, causal relationships, and applications in industry. We also study domains where these techniques have been applied, and discuss the practical applicability of emerging Artificial Intelligence methods. This paper emphasizes the importance of temporal characterization and causal effects in sentiment analysis in social networks, and explores their applications in different contexts such as stock market value, politics, and cyberbullying in educational centers. A strong interest from industry in this discipline can be inferred by the intense activity we observe in the field of intellectual protection, with more than 8,000 patents issued on the topic in only five years. This interest compares positively with the effort from academia, with more than 2,300 articles published in 15 years. But these papers are unevenly split across domains: there is a strong presence in marketing, politics, economics, and health, but less activity in other domains such as emergencies. Regarding the techniques employed, traditional techniques such as dictionaries, neural networks, or Support Vector Machines are widely represented. In contrast, we could still not find a comparable representation of advanced state-of-the-art techniques such as Transformers-based systems like BERT, T5, T0++, or GPT-2/3. This reality is consistent with the results found by the authors of this work, where computationally expensive tools such as GPT-3 are challenging to apply to achieve competitive results compared to those from simpler, lighter and more conventional techniques. These results, together with the interest shown by industry and academia, suggest that there is still ample room for research opportunities on domains, techniques and practical applications, and we expect to keep observing a sustained cadence in the number of published papers, patents and commercial tools made available. © 2023 Elsevier B.V., All rights reserved.",Causal rule predictions; Causality; Professional and academic methodologies; Reproducibility studies; Sentiment analysis; Social media; Temporal sentiment analysis; Twitter,Scopus
10.3390/math11132883,10.3390/math11132883,"Price, Complexity, and Mathematical Model","The whole world has entered the era of the Vuca. Some traditional methods of problem analysis begin to fail. Complexity science is needed to study and solve problems from the perspective of complex systems. As a complex system full of volatility and uncertainty, price fluctuations have attracted wide attention from researchers. Therefore, through a literature review, this paper analyzes the research on complex theories on price prediction. The following conclusions are drawn: (1) The price forecast receives widespread attention year by year, and the number of published articles also shows a rapid rising trend. (2) The hybrid model can achieve higher prediction accuracy than the single model. (3) The complexity of models is increasing. In the future, the more complex methods will be applied to price forecast, including AI technologies such as LLM. (4) Crude-oil prices and stock prices will continue to be the focus of research, with carbon prices, gold prices, Bitcoin, and others becoming new research hotspots. The innovation of this research mainly includes the following three aspects: (1) The whole analysis of all the articles on price prediction using mathematical models in the past 10 years rather than the analysis of a single field such as oil price or stock price. (2) Classify the research methods of price forecasting in different fields, and found the common problems of price forecasting in different fields (including data processing methods and model selection, etc.), which provide references for different researchers to select price forecasting models. (3) Use VOSviewer to analyze the hot words appearing in recent years according to the timeline, find the research trend, and provide references for researchers to choose the future research direction. © 2023 Elsevier B.V., All rights reserved.",algorithm; chaos; complexity; fluctuate; mathematic; price; volatility,Scopus
10.1016/j.resourpol.2023.103568,10.1016/j.resourpol.2023.103568,Impact of geopolitical risk on the volatility of natural resource commodity futures prices in China,"Volatile natural resource prices greatly affect economic growth, economic volatility, and financial market. Analyzing the factors affecting price volatility is of great significance for policymakers to formulate regulations, for financial institutions to control financial risks and for investors to improve their investment returns. We study the impact of geopolitical risk on the price volatility of coal, copper, crude oil, gold, and iron ore in the Chinese futures market. The paper uses the Geopolitical Risk (GPR) index, the Geopolitical Threat (GPT) sub-index and the Geopolitical Action (GPA) sub-index developed by Caldara and Iacoviello to measure geopolitical risk in broader sense. We utilize the closing prices of the most recently expired futures contracts from their starting trading date to 1 August 2022 to determine volatility represented by conditional variance. The GARCH and CGARCH models are built with the help of the Kalman filtering method and a TVP-VAR-SV model. The results of GARCH model show that geopolitical risk significantly increases the price volatility of coal, iron ore, and crude oil futures; significantly decreases the price volatility of gold; and has no significant effect on the price volatility of copper futures. By CGARCH model, we illustrate that geopolitical risk significantly increases the overall volatility, persistent volatility, and temporary volatility of crude oil; significantly increases the overall volatility and temporary volatility of coal and iron ore futures; significantly decreases the overall volatility and persistent volatility of gold futures; and has no significant impact on all three types of volatility of copper futures prices. The results of the Kalman filter analysis uncover that the response of each commodity volatility to changes in geopolitical risk increases when geopolitical risk is high. Additionally, geopolitical risk has the most effect on the price volatility of copper and crude oil with high external dependence. Estimates from the TVP-VAR-SV model reveal that the short-term impact of geopolitical risk shocks on the volatility of each the futures prices of each commodity is large and of long duration, and the response of commodity futures volatility to the same level of geopolitical risk shocks is higher and longer when major geopolitical events occur such as Paris Terrorist Attack, USA/Iran Tension Escalation, Syria Missile Attack, and Russian-Ukraine War. Moreover, geopolitical shocks have the most effect on the energy commodities of crude oil and coal. © 2023 Elsevier B.V., All rights reserved.",Commodity futures; GARCH; Geopolitical risk; Natural resources; TVP-VAR-SV; Volatility,Scopus
10.3390/computers12050102,10.3390/computers12050102,Info-Autopoiesis and the Limits of Artificial General Intelligence,"Recent developments, begun by the ascending spiral of the anticipated endless prospects of ChatGPT, promote artificial intelligence (AI) as an indispensable tool and commodity whose time has come. Yet the sinister specter of a technology that has hidden and unmanageable attributes that might be harmful to society looms in the background, as well as the likelihood that it will never deliver on the purported promise of artificial general intelligence (AGI). Currently, the prospects for the development of AI and AGI are more a matter of opinion than based on a consistent methodological approach. Thus, there is a need to take a step back to develop a general framework from which to evaluate current AI efforts, which also permits the determination of the limits to its future prospects as AGI. To gain insight into the development of a general framework, a key question needs to be resolved: what is the connection between human intelligence and machine intelligence? This is the question that needs a response because humans are at the center of AI creation and realize that, without an understanding of how we become what we become, we have no chance of finding a solution. This work proposes info-autopoiesis, the self-referential, recursive, and interactive process of self-production of information, as the needed general framework. Info-autopoiesis shows how the key ingredient of information is fundamental to an insightful resolution to this crucial question and allows predictions as to the present and future of AGI. © 2023 Elsevier B.V., All rights reserved.",Claude Shannon; communication; Gregory Bateson; info-autopoiesis; information; semantic; syntactic,Scopus
10.1109/CSCE60160.2023.00302,10.1109/CSCE60160.2023.00302,Content Analysis of Items in Newspaper Data Using Table Arrangement Technology and ChatGPT for Stock Price Prediction,"In this study, we employed table arrangement techniques and ChatGPT to analyze newspaper content relevant to stock prices. Using table arrangement techniques, we effectively organized sentences from articles into tables, extracting 22 key content elements. Additionally, we discovered that ChatGPT possesses the ability to extract and present newspaper data in tabular form. Factors were found to influence stock price movements. Drops in stock prices were impacted by factors such as crude oil prices, and the COVID-19 pandemic. Conversely, rising stock prices were supported by global trends, and vac-cine effectiveness. Furthermore, we propose a highly effective, large-scale method for constructing tables by combining table arrangement techniques and ChatGPT. The proposed method achieves an accuracy rate of 0.95 under a lenient criterion. © 2024 Elsevier B.V., All rights reserved.",ChatGPT; content analysis; newspaper data; Regular Research Paper; stock prices; table arrangement,Scopus
10.1109/BigDIA60676.2023.10429428,10.1109/BigDIA60676.2023.10429428,A Wavelet Based Method for Un-Stationary Complex System,"It is known that stock system is chaotic, nonlinear and un-stationary system. Stock market analysis system including deep learning method and generative models usually utilize historical datasets to get the stock market features to predict the future trend. The nonlinearity of the stock market system have determined that although the features can be acquired by deep learning and generative models, it consume considerable resources including labelled cost and computing. In order to analyze such system, researchers have proposed a novel wavelet based nonlinear model, along with the interpretable feature from nonlinear and unstationary series data. Wavelet based OLS method is able to get the features of nonlinear system in a relative low cost with the acceptable result accuracy decline. What's more, it will give an interpretability analysis form the model analysis. To sum up, the Comprehensive performance shows that the predictive power of nonlinear wavelet models outperforms than other baseline methods. © 2024 Elsevier B.V., All rights reserved.",Deep Learning; Nonlinear System; Prediction; Time series; Wavelet,Scopus
10.18653/v1/2023.emnlp-industry.69,10.18653/v1/2023.emnlp-industry.69,Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting,"Applying machine learning to financial time series has been an active area of industrial research enabling innovation in market insights, risk management, strategic decision-making, and policy formation. This paper explores the novel use of Large Language Models (LLMs) for explainable financial time series forecasting, addressing challenges in cross-sequence reasoning, multi-modal data integration, and result interpretation that are inherent in traditional approaches. Focusing on NASDAQ-100 stocks, we utilize public historical stock data, company metadata, and economic/financial news. Our experiments employ GPT-4 for zero-shot/few-shot inference and Open LLaMA for instruction-based fine-tuning. The study demonstrates LLMs' ability to generate well-reasoned decisions by leveraging cross-sequence information and extracting insights from text and price time series. We show that our LLM-based approach outperforms classic ARMA-GARCH and gradient-boosting tree models. Furthermore, fine-tuned public LLMs, such as Open-LLaMA, can generate reasonable and explainable forecasts, although they underperform compared to GPT-4. © 2025 Elsevier B.V., All rights reserved.",,Scopus
10.1109/ICSCNA58489.2023.10370253,10.1109/ICSCNA58489.2023.10370253,An Imperial Analysis of Large Language Models for Automated Tweet Sentiment Prediction,"Company' s brand perception majorly depends on customer experience and the reviews which follow that. A customer is capable of influencing many more people just on the basis of reviews given by him/her. Google released Pathways Language Model (PaLM) which is a major advancement in Artificial Intelligence (AI). It has been trained with the Pathways System, which allows it to generalize tasks in various domains. In this work, a trustworthy platform is provided for the examination of millions of people's continually moving and changing perspectives. Twitter data is captured, and effective sentiment and data analysis is used to generate trustworthy and helpful info graphics reflecting public opinion. Product sales, stock returns, election outcomes, and other commercial and social events may all be predicted and explained using the information found in tweets. Brands, product manufacturers, and other companies may utilise the information derived from data analysis to better understand their brand image, expand their market share by targeting the relevant demographics at the right moments, and enhance their offerings in terms of both quality and customer service. © 2024 Elsevier B.V., All rights reserved.",Attention Units; Data visualization; Masks; Sentiment Analysis; Tokenization,Scopus
10.1109/HPEC58863.2023.10363573,10.1109/HPEC58863.2023.10363573,"Energy Estimates Across Layers of Computing: From Devices to Large-Scale Applications in Machine Learning for Natural Language Processing, Scientific Computing, and Cryptocurrency Mining1","Estimates of energy usage in layers of computing from devices to algorithms have been determined and analyzed. Building on the previous analysis [3], energy needed from single devices and systems including three large-scale computing applications such as Artificial Intelligence (AI)/Machine Learning for Natural Language Processing, Scientific Simulations, and Cryptocurrency Mining have been estimated. In contrast to the bit-level switching, in which transistors achieved energy efficiency due to geometrical scaling, higher energy is expended both at the at the instructions and simulations levels of an application. Additionally, the analysis based on AI/ML Accelerators indicate that changes in architectures using an older semiconductor technology node have comparable energy efficiency with a different architecture using a newer technology. Further comparisons of the energy in computing systems with the thermodynamic and biological limits, indicate that there is a 27-36 orders of magnitude higher energy requirements for total simulation of an application. These energy estimates underscore the need for serious considerations of energy efficiency in computing by including energy as a design parameter, enabling growing needs of compute-intensive applications in a digital world. © 2024 Elsevier B.V., All rights reserved.",ATP; Biological Limit; Bitcoin; ChatGPT; Energy as a design parameter; Energy for Crypto coin mining; Energy for High Performance Scientific Computations; Energy for Machine Learning and Artificial Intelligence; Energy per Bit; Energy per Instruction; From Bits to Architectures and Applications; Instructions per Second; Moore's law; Natural Language Processing; Specialized Architectures; Sustainable Computing; Thermodynamical Limit,Scopus
10.12720/jait.14.6.1372-1381,10.12720/jait.14.6.1372-1381,Synthetic Financial Time Series Generation with Regime Clustering,"Methods for synthetic data generation are extremely valuable nowadays since they allow researchers and practitioners to develop and test their models without the risk and cost associated with using real data. In this paper, we propose a method for the generation of synthetic financial time series. The method adopts time series regimes clustering to perform generative models training on the data from each cluster separately. Also, we suggest the modification of Quantum Generative Adversarial Networks (QuantGAN) architecture that is able to produce synthetic data with frequency characteristics closer to the corresponding real-world time series ones. Our experiments show that (1) synthetic financial time series can be effectively generated by our method; (2) the distribution characteristics of synthetic time series generated by the method are closer to the initial ones in comparison with Fourier Flows and QuantGAN; (3) training the forecasting model on the synthetics generated by the proposed method (Fourier Flows model is used within it) can reduce the forecasting error on the real-world series. © 2023 Elsevier B.V., All rights reserved.",Generative Adversarial Networks (GAN); normalising flows; regime clustering; synthetic time series; time series generation,Scopus
10.26615/978-954-452-092-2_114,10.26615/978-954-452-092-2_114,Tackling the Myriads of Collusion Scams on YouTube Comments of Cryptocurrency Videos,"Despite repeated measures, YouTube's comment section has been a fertile ground for scammers. With the growth of the cryptocurrency market and obscurity around it, a new form of scam, namely ""Collusion Scam"" has emerged as a dominant force within YouTube's comment space. Unlike typical scams and spams, collusion scams employ a cunning persuasion strategy, using the facade of genuine social interactions within comment threads to create an aura of trust and success to entrap innocent users. In this research, we collect 1,174 such collusion scam threads and perform a detailed analysis, which is tailored towards the successful detection of these scams. We find that utilization of the collusion dynamics can provide an accuracy of 96.67% and an F1-score of 93.04%. Furthermore, we demonstrate the robust predictive power of metadata associated with these threads and user channels, which act as compelling indicators of collusion scams. Finally, we show that modern LLM, like chatGPT, can effectively detect collusion scams without the need for any training. © 2023 Elsevier B.V., All rights reserved.",,Scopus
2-s2.0-85178938908,,Non-adversarial training of Neural SDEs with signature kernel scores,"Neural SDEs are continuous-time generative models for sequential data. State-of-the-art performance for irregular time series generation has been previously obtained by training these models adversarially as GANs. However, as typical for GAN architectures, training is notoriously unstable, often suffers from mode collapse, and requires specialised techniques such as weight clipping and gradient penalty to mitigate these issues. In this paper, we introduce a novel class of scoring rules on pathspace based on signature kernels and use them as objective for training Neural SDEs non-adversarially. By showing strict properness of such kernel scores and consistency of the corresponding estimators, we provide existence and uniqueness guarantees for the minimiser. With this formulation, evaluating the generator-discriminator pair amounts to solving a system of linear path-dependent PDEs which allows for memory-efficient adjoint-based backpropagation. Moreover, because the proposed kernel scores are well-defined for paths with values in infinite dimensional spaces of functions, our framework can be easily extended to generate spatiotemporal data. Our procedure permits conditioning on a rich variety of market conditions and significantly outperforms alternative ways of training Neural SDEs on a variety of tasks including the simulation of rough volatility models, the conditional probabilistic forecasts of real-world forex pairs where the conditioning variable is an observed past trajectory, and the mesh-free generation of limit order book dynamics. © 2025 Elsevier B.V., All rights reserved.",,Scopus
2-s2.0-85175630767,,Few Shot Profiling of Cryptocurrency Influencers using Natural Language Inference & Large Language Models,"This paper introduces the system proposed by team NLP-CIMAT for the PAN 2023 shared task, ""Profiling Cryptocurrency Influencers with Few-shot Learning."" The shared task involves three classification subtasks, each featuring low-resource datasets with a limited number of examples per label. The first subtask focuses on predicting the magnitude of an influencer. The second subtask involves classifying the interest of the influencer. Lastly, the third subtask focuses on predicting the intent of the tweet, with the aim of identifying its underlying purpose or motivation. Our system exploits pre-trained language models by adapting two distinct training frameworks: traditional fine-tuning and entailment-based fine-tuning. The traditional fine-tuning approach trains a transformer encoder to predict the class of each tweet. In contrast, the entailment-based approach utilizes a model pre-trained for the NLI task and further trains it using the task data by reframing the classification problem as an entailment problem. Although the former is suitable for ample labeled data, the entailment-based approach is more effective in low-resource scenarios. We found that, in the tasks’ data, entailment-based and traditional fine-tuning schemes showed outstanding performance, we propose an ensembling technique that combines the strengths of both strategies through a soft-voting approach over the traditional fine-tuning predictions and the entailment-probabilities of the entailment approach. Furthermore, we also employ a Data Augmentation strategy by prompting ChatGPT to generate another synthetic tweet for each of the tweets in the dataset. Our submitted system ranked first for the second subtask, and obtained highly competitive results in the other two. Overall, our team obtained the first place in the shared task, demonstrating the effectiveness of our approach. © 2023 Elsevier B.V., All rights reserved.",data augmentation; ensemble; fine tuning; natural language inference; pretrained language models; text classification; transformers,Scopus
10.1109/ACCAI58221.2023.10200052,10.1109/ACCAI58221.2023.10200052,Automated AI - Equity Market Lead-Lag Prediction Based on Multivariate Time Series,"The lead-lag structure among time-series factors is the recognition that in multivariate time-series frameworks, some factor clusters significantly drive improvements in the framework, while various factors follow this development with time lags arises from. In this article, we propose a multivariate framework for the identification of lead-lag bundles in time series. We demonstrate that pairwise lead-lag interactions between time series can be viewed as a directed organization. There is a practical calculation for locating the lead-lag bundle set with significant pairwise imbalance in this instance. We investigate various options for the system's directed network clustering models and pairwise lead lag metric. Daily cost data on actual US values and the constructed generative model of the multivariate lead-lag time series framework are used to test the system. Using the pairwise lead-lag metric and directed tissue clustering computations, we offer a method for identifying lead-lag clusters in multivariate time series without a doubt. We demonstrate that the stationary tissue of pairwise lead-lag interactions between time series can be conceptualized as a directed tissue and that a suitable computation exists for locating the lead-lag groups in this type of tissue that have significant pairwise imbalances. increase. © 2024 Elsevier B.V., All rights reserved.",Automated AI; clustering; Equity market; lead-lag prediction; Multivariate time series,Scopus
10.1080/14765284.2023.2245279,10.1080/14765284.2023.2245279,From fiction to fact: the growing role of generative AI in business and finance,"Generative Artificial Intelligence (AI), such as ChatGPT by OpenAI, has revolutionized the business world, with benefits including improved accessibility, efficiency, and cost reduction. This article reviews recent developments of generative AI in business and finance, summarizes its practical applications, provides examples of the latest generative AI tools, and demonstrates that generative AI can revolutionize data analysis in industry and academia. To test the ability of generative AI to support decision-making in financial markets, we use the ChatGPT to capture corporate sentiments towards environmental policy by inputting text extracted from corporate financial statements. Our results demonstrate that the sentiment scores generated by ChatGPT can predict firms’ risk-management capabilities and stock return performance. This study also highlights the potential challenges and limitations associated with generative AI. Finally, we propose several questions for future research at the intersection of generative AI with business and finance. © 2023 Elsevier B.V., All rights reserved.",ChatGPT; Generative AI; Natural Language Processing; Practical Applications; Sentiment Analysis,Scopus
10.11834/jig.230110,10.11834/jig.230110,A brief analysis of ChatGPT：historical evolution，current applications，and future prospects; 浅析 ChatGPT: 历史沿革、应用现状及前景展望,"Artificial intelligence（AI）technology has been developing intensively，especially for such scenarios in relevance to its applications of 1）natural language processing，2）computer vision，3）recommendation systems，and 4）fore-cast analysis. AI technology has been challenging for human cognition over the past decade. In recent years，natural language processing techniques can be focused on more. ChatGPT，as a case of emerging generative AI technology，is launched in December of 2022. ChatGPT，as an advanced language model，is commonly used on the basis of its a）larger model sizes，b）advanced pretraining methods，c）faster computing resources，and d）more language processing tasks. This ChatGPT-related literature review is focused on its（1）public awareness and application status，（2）characteristics，（3）mechanisms，（4）scalability，（5）challenges and limitations，（6）future development and application prospects，and （7）improvements of GPT-4 relative to ChatGPT. Cognitive computing and AI-based ChatGPT can be as a sort of language model in terms of the Transformer architecture and Generative Pre-Training（GPT）. This GPT-trained model can be related to natural language processing，which can predict the probability distribution of the next token using a multi-layer Transformer to generate natural language text. It can be outreached by training the learned language patterns on a large corpus of text. The OpenAI’s language model has shown a significant improvement in their level of intelligence from GPT-1（117 million parameters）in 2018 to GPT-3（175 billion parameters）in 2020. The language processing and generation capabilities of GPT have been improving dramatically in terms of consistent optimization like its 1）model size，2）generative models，and 3）self-supervised learning. Thereafter，reinforcement learning-based InstructGPT is originated from Human Feedback and such probability of infeasible，untrue，and biased outputs can be significantly reduced in January 2022. In December 2022，ChatGPT is introduced as the sister model of InstructGPT. ChatGPT is not only add InstructGPT-based chat attributes，and a test version is opened to the public. The core technologies of ChatGPT can be linked to 1）reinforcement learning from human feedback（RLHF），2）supervised fine-tuning（SFT），3）instruction fine-tnning（IFT），and 4）chain-of-thought （CoT）as well. ChatGPT has attracked about 100 million active users per month after the launch of two months. In comparison，TikTok took nine months to achieve 100 million monthly active users，and Instagram took two and a half years. According to Similar Web，more than 13 million independent visitors use ChatGPT on average each day in January of 2023，which is more than twice in December of 2022. The leading US new media company Buzzfeed accurately seized the opportunity of ChatGPT and saw its stock price triple in two days. The ChatGPT-derived impact shows its potential preference for consumers. The ChatGPT can play mulitiple roles for such domain like clinics，translation，official administrations，and programming tasks. Such extensive application of ChatGPT is still to be developed. However，while ChatGPT has the potential for widespread application in various industries，it cannot be universally applied to all industries. For example，as certain industrial production processes typically rely on digitalization and do not necessitate the handling of human language，natural language processing techniques may not be required. Furthermore，various other factors，such as legal restrictions and data privacy concerns，may also impinge upon the application of natural language processing technologies within certain industries. For industries that require the processing of sensitive information，such as the healthcare industry，natural language processing technologies may need to comply with strict legal regulations to ensure data privacy and security. In addition to industry-specific reasons，it should be noted that ChatGPT has not yet achieved perfection in natural language processing tasks. In summary，as a phenomenal and technological product，AI-generated ChatGPT’s potentials are beneficial for textual and multi-modal AIGC applications to a certain extent，and it may have an impact on the a）survival of corporations，b）competition among countries，and c）entire social structure. However，the current various positive evaluations of ChatGPT can only be seen as a phenomenon of good rain after a long drought，and it cannot change the fact that ChatGPT is a questions and answers（Q&A）solution based on prior knowledge and models. It is required to be acknowledged that ChatGPT does not have its true recognition，intention，and creativity yet，and its true intelligence need to be tackled further. © 2023 Elsevier B.V., All rights reserved.",artificial intelligence generated content （AIGC）; artificial intelligence（AI）; ChatGPT; deep learning; natural language processing,Scopus
10.7717/peerj-cs.1377,10.7717/peerj-cs.1377,Evaluation of transformer models for financial targeted sentiment analysis in Spanish,"Nowadays, financial data from social media plays an important role to predict the stock market. However, the exponential growth of financial information and the different polarities of sentiment that other sectors or stakeholders may have on the same information has led to the need for new technologies that automatically collect and classify large volumes of information quickly and easily for each stakeholder. In this scenario, we conduct a targeted sentiment analysis that can automatically extract the main economic target from financial texts and obtain the polarity of a text towards such main economic target, other companies and society in general. To this end, we have compiled a novel corpus of financial tweets and news headlines in Spanish, constituting a valuable resource for the Spanish-focused research community. In addition, we have carried out a performance comparison of different Spanish-specific large language models, with MarIA and BETO achieving the best results. Our best result has an overall performance of 76.04%, 74.16%, and 68.07% in macro F1-score for the sentiment classification towards the main economic target, society, and other companies, respectively, and an accuracy of 69.74% for target detection. We have also evaluated the performance of multi-label classification models in this context and obtained a performance of 71.13% © 2023 Elsevier B.V., All rights reserved.",Financial domain; Natural language processing; Sentiment analysis; Targeted sentiment analysis,Scopus
10.1007/978-981-19-5845-8_61,10.1007/978-981-19-5845-8_61,A Hybrid Approach on Conditional GAN for Portfolio Analysis,"Over the decades, the Markowitz framework has been used extensively in portfolio analysis though it puts too much emphasis on the analysis of the market uncertainty rather than on the trend prediction. While generative adversarial network (GAN), conditional GAN (CGAN), and autoencoding CGAN (ACGAN) have been explored to generate financial time series and extract features that can help portfolio analysis. The limitation of the CGAN or ACGAN framework stands in putting too much emphasis on generating series and finding the internal trends of the series rather than predicting the future trends. In this paper, we introduce a hybrid approach on conditional GAN based on deep generative models that learns the internal trend of historical data while modeling market uncertainty and future trends. We evaluate the model on several real-world datasets from both the US and Europe markets, and show that the proposed HybridCGAN and HybridACGAN models lead to better portfolio allocation compared to the existing Markowitz, CGAN, and ACGAN approaches. © 2022 Elsevier B.V., All rights reserved.",Autoencoding conditional GAN (ACGAN); Conditional GAN; Hybrid CGAN; Markowitz framework; Portfolio analysis and allocation; Sharpe ratio; Synthetic series,Scopus
10.1007/s10994-022-06250-4,10.1007/s10994-022-06250-4,Lead–lag detection and network clustering for multivariate time series with an application to the US equity market,"In multivariate time series systems, it has been observed that certain groups of variables partially lead the evolution of the system, while other variables follow this evolution with a time delay; the result is a lead–lag structure amongst the time series variables. In this paper, we propose a method for the detection of lead–lag clusters of time series in multivariate systems. We demonstrate that the web of pairwise lead–lag relationships between time series can be helpfully construed as a directed network, for which there exist suitable algorithms for the detection of pairs of lead–lag clusters with high pairwise imbalance. Within our framework, we consider a number of choices for the pairwise lead–lag metric and directed network clustering model components. Our framework is validated on both a synthetic generative model for multivariate lead–lag time series systems and daily real-world US equity prices data. We showcase that our method is able to detect statistically significant lead–lag clusters in the US equity market. We study the nature of these clusters in the context of the empirical finance literature on lead–lag relations, and demonstrate how these can be used for the construction of predictive financial signals. © 2022 Elsevier B.V., All rights reserved.",Clustering; Directed networks; Financial markets; Flow imbalance; High-dimensional time series; Lead–lag; Unsupervised learning,Scopus
10.1016/j.ribaf.2022.101747,10.1016/j.ribaf.2022.101747,Synthetic data generation with deep generative models to enhance predictive tasks in trading strategies,"This work develops machine learning (ML) predictive models on price signals for financial instruments and their integration into trading strategies. In general, ML models have been shown powerful when trained with large amounts of data. In practice, the time-series nature of financial datasets limits the effective amount of data available to train, validate and retrain models since special care must be taken not to include future data in any way. In this setting, we develop deep generative models to produce synthetic time-series data, enhancing the amount of data available for training predictive models. Synthetic data obtained this way replicates the distribution properties of real historical data, leads to better performance, and enables thorough validation of predictive models for price signals. We leverage machine-generated predictive signals on synthetic data to build trading strategies. We show consistent improvement leading up to profits in our simulations for commodities and forex exchange markets. © 2022 Elsevier B.V., All rights reserved.",Deep generative models; Deep learning; Machine learning; Synthetic data; Trading simulations; Trading strategies,Scopus
10.1016/j.ailsci.2022.100031,10.1016/j.ailsci.2022.100031,The commoditization of AI for molecule design,"Anyone involved in designing or finding molecules in the life sciences over the past few years has witnessed a dramatic change in how we now work due to the COVID-19 pandemic. Computational technologies like artificial intelligence (AI) seemed to become ubiquitous in 2020 and have been increasingly applied as scientists worked from home and were separated from the laboratory and their colleagues. This shift may be more permanent as the future of molecule design across different industries will increasingly require machine learning models for design and optimization of molecules as they become “designed by AI”. AI and machine learning has essentially become a commodity within the pharmaceutical industry. This perspective will briefly describe our personal opinions of how machine learning has evolved and is being applied to model different molecule properties that crosses industries in their utility and ultimately suggests the potential for tight integration of AI into equipment and automated experimental pipelines. It will also describe how many groups have implemented generative models covering different architectures, for de novo design of molecules. We also highlight some of the companies at the forefront of using AI to demonstrate how machine learning has impacted and influenced our work. Finally, we will peer into the future and suggest some of the areas that represent the most interesting technologies that may shape the future of molecule design, highlighting how we can help increase the efficiency of the design-make-test cycle which is currently a major focus across industries. © 2023 Elsevier B.V., All rights reserved.",Artificial intelligence; Design-make-test; Machine learning; Molecule design; Recurrent neural networks,Scopus
10.1145/3501305,10.1145/3501305,Generation of Realistic Synthetic Financial Time-series,"Financial markets have always been a point of interest for automated systems. Due to their complex nature, financial algorithms and fintech frameworks require vast amounts of data to accurately respond to market fluctuations. This data availability is tied to the daily market evolution, so it is impossible to accelerate its acquisition. In this article, we discuss several solutions for augmenting financial datasets via synthesizing realistic time-series with the help of generative models. This problem is complex, since financial time series present very specific properties, e.g., fat-tail distribution, cross-correlation between different stocks, specific autocorrelation, cluster volatility and so on. In particular, we propose solutions for capturing cross-correlations between different stocks and for transitioning from fixed to variable length time-series without resorting to sequence modeling networks, and adapt various network architectures, e.g., fully connected and convolutional GANs, variational autoencoders, and generative moment matching networks. Finally, we tackle the problem of evaluating the quality of synthetic financial time-series. We introduce qualitative and quantitative metrics, along with a portfolio trend prediction framework that validates our generative models' performance. We carry out experiments on real-world financial data extracted from the US stock market, proving the benefits of these techniques. © 2022 Elsevier B.V., All rights reserved.",financial data prediction; fintech; generative models; synthetic financial data generation; Time-series,Scopus
10.1016/j.knosys.2022.108712,10.1016/j.knosys.2022.108712,A self-regulated generative adversarial network for stock price movement prediction based on the historical price and tweets,"Stock price movement prediction is an important task of the financial prediction field. The current mainstream approaches usually apply financial texts and some corresponding stock price information to predict the stock price movement. However, the current methods usually suffer from two shortcomings: (1) To reduce the stochasticity in the stock price and financial text information, some researchers adopt generative models to better treat the stochasticity while enduring the overfitting problem during training. (2) Although the current state-of-the-art methods based on the generative adversarial network have been proposed to reduce the overfitting, they only concentrate on the overfitting problem of the stock price information and neglect the above problem of financial text information with higher stochasticity. In this paper, we propose a self-regulated generative adversarial network by combining the generative adversarial network and cooperative network for the stock price movement prediction. Furthermore, the proposed model can effectively reduce the stochasticity and overfitting problems simultaneously for the stock price and the financial text information. The experimental results on the currently commonly used stock dataset based on tweets confirm that the proposed method can achieve the novelly state-of-the-art performance compared with some current advances. © 2022 Elsevier B.V., All rights reserved.",Cooperative network; Generative adversarial network; Pre-trained language model; Stock price movement prediction,Scopus
10.1109/TBDATA.2019.2941887,10.1109/TBDATA.2019.2941887,Forecasting People's Needs in Hurricane Events from Social Network,"Social networks can serve as a valuable communication channel for asking for help, offering assistance, and coordinating rescue activities in disaster because it allows users to continuously update critical information in the fast-changing disaster environment. This paper presents a novel sequence to sequence based framework for forecasting people's needs during disasters using social media and weather data. It consists of two Long Short-Term Memory (LSTM) models, one of which encodes input sequences of weather information and the other plays as a conditional decoder that decodes the encoded vector and forecasts the survivors' needs. Case studies using data collected during Hurricane Sandy in 2012, Hurricane Harvey and Hurricane Irma in 2017 demonstrate that the proposed approach outperformed the statistical language model n-gram, LSTM generative model, and convolutional neural network (CNN) based model. This research indicates its great promise for enhancing disaster management such as evacuation planning and commodity delivery. © 2022 Elsevier B.V., All rights reserved.",Concern flow; Disaster relief; Hurricane events; LSTM; Needs forecasting; Sequence to sequence model,Scopus
10.1016/j.procs.2023.01.121,10.1016/j.procs.2023.01.121,Forecasting Daily Stock Movement Using a Hybrid Normalization Based Intersection Feature Selection and ANN,"The potential financial benefits of stock market forecasting have drawn a lot of interest. Due to the various interconnected aspects, predicting these markets is a difficult endeavour that necessitates a thorough as well as efficient feature selection procedure to discover the highest useful aspects. Stock price changes are also influenced by previous trading days' movements, which is a time series problem. In stock forecasting, feature selection techniques are commonly used, although most known systems use a single feature selection methodology that probably can neglect some key notions about the regression function that is at the root of the problem relating the variables for input and output. This study employs an artificial neural network (ANN) based generative model to forecast pricing changes in the future by combining features preferred by different feature picking strategies to build an ideal optimal feature group. We begin by calculating an expanded set of 83 technical indicators using day-to-day stock data of six stock indices, and then we normalize them using the Hybrid-Normalization (HN) technique. The important features are selected using various types of feature selection techniques and then considering the common features for the stock movement prediction. For stock trend predictions, we used a variety of classifiers such as Support Vector Machine, K Nearest Neighbour and Artificial Neural Network and. The system was given a performance review after simulations were done on 6 stock indices from various portions of the international market. The outcomes show that joining highlighted features got by various feature choice calculations and taking care of them into a profound generative model beats best in class techniques. © 2023 Elsevier B.V., All rights reserved.",Artificial Neural Network; Hybrid Normalization; Intersection Feature selection; K Nearest Neighbour; Stock market indices; Support Vector Machines,Scopus
10.1109/ICCWAMTIP56608.2022.10016580,10.1109/ICCWAMTIP56608.2022.10016580,Tabnet With Data Augmentation Apporach in Stock Return Prediction Task,"Despite the advent of deep learning, stock return prediction task still has many challenges. Due to the scarcity of stock data, we adopt a GAN-based deep generative model to create synthetic data samples. To deal with the intrinsic low signal-to-noise ratio property of stock price time series, we formulate the return prediction as a supervised learning problem with tabular dataset, where we do feature engineering before training with a TabNet model. We conduct extensive experiments on real Chinese stock market with 6 different models, which proves that our proposed model makes larger profit and remains stability. © 2023 Elsevier B.V., All rights reserved.",Conditional Tabular Generative Adversarial Network; Deep Learning; Small Dataset Problem; Stock Return Prediction; TabNet,Scopus
10.1007/978-981-19-2456-9_110,10.1007/978-981-19-2456-9_110,An Effective GAN-Based Multi-classification Approach for Financial Time Series,"Deep learning has achieved significant success in various applications due to its powerful feature representations of complex data. Financial time series forecasting is no exception. In this work we leverage Generative Adversarial Nets (GAN), which has been extensively studied recently, for the end-to-end multi-classification of financial time series. An improved generative model based on Convolutional Long Short-Term Memory (ConvLSTM) and Multi-Layer Perceptron (MLP) is proposed to effectively capture temporal features and mine the data distribution of volatility trends (short, neutral, and long) from given financial time series data. We empirically compare the proposed approach with state-of-the-art multi-classification methods on real-world stock dataset. The results show that the proposed GAN-based method outperforms its competitors in precision and F1 score. © 2022 Elsevier B.V., All rights reserved.",Classification; Convolutional LSTM; Financial time series; GAN,Scopus
10.1109/LSP.2021.3135793,10.1109/LSP.2021.3135793,Learning Sentimental and Financial Signals With Normalizing Flows for Stock Movement Prediction,"Stockmovement prediction using Tweets (text) and historical price signals (time series) remains a challenging task due to the complex, noisy and dynamic nature of the stock market. The key to improve prediction performance is effectively capturing the complementarity between market sentiment signal from Tweets and time-series signal from the stock price. In this paper, we contribute a new solution <bold>StockNF</bold> by exploiting a deep generative model technique, Normalizing Flow (NF), to learn more flexible and expressive posterior distributions of latent variables of Tweets and price signals, which can largely ameliorate the bias inference problem in existing methods. We empirically evaluate the NF technique on a public stock movement prediction dataset and show that StockNF outperforms the state-of-the-art baselines. © 2022 Elsevier B.V., All rights reserved.",Data models; Noise measurement; Predictive models; Social networking (online); Stochastic processes; Task analysis; Time series analysis,Scopus
10.1007/s11042-021-11670-w,10.1007/s11042-021-11670-w,Generative adversarial network (GAN) and enhanced root mean square error (ERMSE): deep learning for stock price movement prediction,"The prediction of stock price movement direction is significant in financial circles and academic. Stock price contains complex, incomplete, and fuzzy information which makes it an extremely difficult task to predict its development trend. Predicting and analysing financial data is a nonlinear, time-dependent problem. With rapid development in machine learning and deep learning, this task can be performed more effectively by a purposely designed network. This paper aims to improve prediction accuracy and minimizing forecasting error loss through deep learning architecture by using Generative Adversarial Networks. It was proposed a generic model consisting of Phase-space Reconstruction (PSR) method for reconstructing price series and Generative Adversarial Network (GAN) which is a combination of two neural networks which are Long Short-Term Memory (LSTM) as Generative model and Convolutional Neural Network (CNN) as Discriminative model for adversarial training to forecast the stock market. LSTM will generate new instances based on historical basic indicators information and then CNN will estimate whether the data is predicted by LSTM or is real. It was found that the Generative Adversarial Network (GAN) has performed well on the enhanced root mean square error to LSTM, as it was 4.35% more accurate in predicting the direction and reduced processing time and RMSE by 78 s and 0.029, respectively. This study provides a better result in the accuracy of the stock index. It seems that the proposed system concentrates on minimizing the root mean square error and processing time and improving the direction prediction accuracy, and provides a better result in the accuracy of the stock index. © 2022 Elsevier B.V., All rights reserved.",Deep learning; Generative adversarial networks; Phase-space reconstruction; Stock market prediction,Scopus
10.1007/s41109-021-00357-8,10.1007/s41109-021-00357-8,On the challenges of predicting microscopic dynamics of online conversations,"To what extent can we predict the structure of online conversation trees? We present a generative model to predict the size and evolution of threaded conversations on social media by combining machine learning algorithms. The model is evaluated using datasets that span two topical domains (cryptocurrency and cyber-security) and two platforms (Reddit and Twitter). We show that it is able to predict both macroscopic features of the final trees and near-future microscopic events with moderate accuracy. However, predicting the macroscopic structure of conversations does not guarantee an accurate reconstruction of their microscopic evolution. Our model’s limited performance in long-range predictions highlights the challenges faced by generative models due to the accumulation of errors. © 2024 Elsevier B.V., All rights reserved.",Conversation trees; Information cascades; Machine learning; Prediction; Social media,Scopus
10.1007/s43546-021-00106-0,10.1007/s43546-021-00106-0,Construction of a news article evaluation model utilizing high-frequency data and a large-scale language generation model,"News articles have significant impacts on asset prices in financial markets. A great number of attempts have been conducted to ascertain how news articles influence stock prices. News articles have been reported to contain sentimental and fundamental information that affects stock price fluctuations, and many studies have been conducted to evaluate stock price fluctuations using them as analytical data. However, the limitations in the number of available datasets usually become the hurdle for the model accuracy. This study aims to improve the analytical model’s accuracy by generating news articles using language generation technology. We tested whether the model that used the generated data was better than the trained model with real-world data. The model constructed in this research is a model that evaluates news articles distributed to financial markets based on the price fluctuation rate of stock prices and predicts and evaluates stock price fluctuations. This study labeled based on high-frequency trading data and generated news articles using a large-scale language generation model (GPT-2). Also, we analyzed and verified the effect. In this study, we succeeded in generating news articles using the large-scale language generation model and improving the classification accuracy. Our method proposed in this paper has great potential to improve text analysis accuracy in various areas. © 2025 Elsevier B.V., All rights reserved.",BiLSTM; Deep learning; GPT-2; LSTM; Natural language generation; Natural language processing; RoBERTa; Stock market analysis,Scopus
10.1016/j.eswa.2020.114444,10.1016/j.eswa.2020.114444,Forecasting daily stock trend using multi-filter feature selection and deep learning,"Stock market forecasting has attracted significant attention mainly due to the potential monetary benefits. Predicting these markets is a challenging task due to numerous interrelated factors, and needs a complete and efficient feature selection process to identify the most informative factors. As a time series problem, stock price movements are also dependent on movements on its previous trading days. Feature selection techniques have been widely applied in stock forecasting, but existing approaches usually use a single feature selection technique, which may overlook some important assumptions about the underlying regression function linking the input and output variables. In this study, we combine features selected by multiple feature selection techniques to generate an optimal feature subset and then use a deep generative model to predict future price movements. First, we compute an extended set of forty-four technical indicators from daily stock data of eighty-eight stocks and then compute their importance by independently training logistic regression model, support vector machine and random forests. Based on a prespecified threshold, the lowest ranked features are dropped and the rest are grouped into clusters. The variable importance measure is reused to select the most important feature from each cluster to generate the final subset. The input is then fed to a deep generative model comprising of a market signal extractor and an attention mechanism. The market signal extractor recurrently decodes market movement from the latent variables to deal with stochastic nature of the stock data and the attention mechanism discriminates between predictive dependencies of different temporal auxiliary outputs. The results demonstrate that combining features selected by multiple feature selection approaches and using them as input into a deep generative model outperforms state-of-the-art approaches. © 2020 Elsevier B.V., All rights reserved.",Deep learning; Feature selection; Machine learning; Stock trend prediction,Scopus
10.1109/CAIDA51941.2021.9425223,10.1109/CAIDA51941.2021.9425223,A Methodology for Securities and Cryptocurrency Trading Using Exploratory Data Analysis and Artificial Intelligence,"This paper discusses securities and cryptocurrency trading using artificial intelligence (AI) in the sense that it focuses on performing Exploratory Data Analysis (EDA) on selected technical indicators before proceeding to modelling, and then to develop more practical models by introducing new reward loss function that maximizes the returns during training phase. The results of EDA reveal that the complex patterns within the data can be better captured by discriminative classification models and this was endorsed by performing back-testing on two securities using Artificial Neural Network (ANN) and Random Forests (RF) as discriminative models against their counterpart Naïve Bayes as a generative model. To enhance the learning process, the new reward loss function is utilized to retrain the ANN with testing on AAPL, IBM, BRENT CRUDE and BTC using auto-trading strategy that serves as the intelligent unit, and the results indicate this loss superiorly outperforms the conventional cross-entropy used in predictive models. The overall results of this work suggest that there should be larger focus on EDA and more practical losses in the research of machine learning modelling for stock market prediction applications. © 2021 Elsevier B.V., All rights reserved.",artificial intelligence; artificial neural network; classification models; cryptocurrency; machine learning; naïve bayes; probabilistic modelling; random forests; Securities; stock market,Scopus
10.1145/3430936,10.1145/3430936,The decline of computers as a general purpose technology,"PERHAPS IN NO other technology has there been so many decades of large year-over-year improvements as in computing. It is estimated that a third of all productivity increases in the U.S. since 1974 have come from information technology,a,4 making it one of the largest contributors to national prosperity. The rise of computers is due to technical successes, but also to the economics forces that fnanced them. Bresnahan and Trajtenberg3 coined the term general purpose technology (GPT) for products, like computers, that have broad technical applicability and where product improvement and market growthcould fuel each other for many decades. But, they also predicted that GPTs could run into challenges at the end of their life cycle: as progress slows, other technologies can displace the GPT in particular niches and undermine this economically reinforcing cycle. We are observing such a transition today as improvements in central processing units (CPUs) slow, and so applications move to specialized processors, for example, graphics processing units (GPUs), which can do fewer things than traditional universal processors, but perform those functions better. Many high profle applications are already following this trend, including deep learning (a form of machine learning) and Bitcoin mining. © 2021 Elsevier B.V., All rights reserved.",,Scopus
10.5817/MB2021-2-5,10.5817/MB2021-2-5,Generating Genre-Specific Musical Transcriptions of Antonín Dvorák through a Variational Autoencoder; Generování žánrove specifické hudební transkripce Antonína Dvoráka prostrednictvím variacního autoenkodéru,"Apart from traditional deep learning tasks such as pattern recognition, stock price prediction, and machine translation, this method also finds practical application within algorithmic composition. This paper explores the use of a generative model based on unsupervised learning of a musical style from a pre-selected corpus and the subsequent prediction of samples from the estimated distribution. The model uses a Long Short-Term Memory neural network whose training data contains genre-specific melodies in symbolic representation. © 2022 Elsevier B.V., All rights reserved.",Algorithmic composition; artificial intelligence; autoencoder; deep learning; generative art; LSTM network; machine learning; recurrent neural network,Scopus
10.1109/ICNSC52481.2021.9702208,10.1109/ICNSC52481.2021.9702208,Stock Price Prediction Based on Conditional Flows Scenario Generation,"Stock price forecasting is an important issue in the financial field. However, most of the existing studies were focused on the prediction of a single stock, ignoring the correlation among different assets. A possible way to solve the above problem is to provide a set of scenarios which include the future returns of several stocks, instead of a single one. The flow-based model is a kind of deep learning model proposed in recent years, which has powerful data generation abilities. In this paper, we use a flow-based conditional generative model to forecast the stock price scenario. We use real stock market data to verify the proposed method. The simulation results show that the model based on the proposed method can capture the complex dependence of the future stock relationship and provide more accurate and diversified forecasting results. © 2022 Elsevier B.V., All rights reserved.",flow-based model; scenario; stock price forecasting,Scopus
10.1109/SMC52423.2021.9659283,10.1109/SMC52423.2021.9659283,Stock Price Prediction Using Sentiment Analysis,"We investigate the influence of financial news headline sentiment on the predictability of stock prices using Long Term Short Term Memory (LSTM) networks. The investigation is performed on intraday data with specific lag-times between published article headlines and realised stock prices. FinBERT, a natural language processing model which is fine-tuned specifically for financial news is used to perform sentiment analysis on the company related news headlines. Two base models, one with only historical stock price data as inputs and the other with both historical stock price data and sentiment data from the original BERT model is tested. An alternative model with have both historical stock price data and sentiment data from the fine tuned FinBERT model as additional features. A comparison is performed on both the base and alternative models using Root Mean Square Error (RMSE) and mean absolute error (MAE) as performance metrics. The results suggest that the use of news headline sentiment features from FinBERT significantly improve the predictive performance of LSTM networks in intraday stock price prediction. FinBERT features are also found to outperform features based BERT model trained on a general corpus, illustrating the positive effect of domain specific fine tuning for Large Language models. © 2022 Elsevier B.V., All rights reserved.",FinBERT; language model; LSTM; prediction; sentiment analysis,Scopus
10.1109/SSCI47803.2020.9308192,10.1109/SSCI47803.2020.9308192,Probabilistic Analysis of Market Impact of Analysts' Recommendation Revisions,"In this paper, we propose to model the short-term impact of recommendation revisions on stock price movements in probabilistic framework. Through the Bayesian models, we can consolidate the information of all analysts' recommendations on stocks and predict the post-recommendation price drifts of the underlying stocks. In addition, typically there are only a small number of recommendation revisions on specific stocks on each day. It implies that other analysts' views to a specific stock are unobservable. With the advantage of generative models, missing observations in the data of recommendation revisions can be accommodated easily. Secondly, we perform an empirical investigation of the Hong Kong equity market and find that the impact of recommendation revisions on stock prices is significant in the 1-day horizon, but insignificant in the longer time horizon when taking account of the transaction costs. Also, we propose trading strategies derived from the posterior probability of directions of price drifts based on the Bayesian models. In our experiment, during the out-of-sample period (1 Jan, 2019 to 21 Feb, 2020), the trading strategies gain double-digit profit returns after transaction costs. © 2025 Elsevier B.V., All rights reserved.",analyst recommendations; Bayesian; machine learning; trading strategy,Scopus
10.1145/3383455.3422518,10.1145/3383455.3422518,Connecting the dots: Forecasting and explaining short-term market volatility,"Market volatility prediction is of significant theoretical and practical importance in the financial market, and the news is a significant source to influence the market. By using deep learning networks, we can forecast the volatility based on the news; meanwhile, how to explain the deep neural network is a prevalent topic, especially the attention mechanism in the NLP field. Current studies mainly focus on unveiling the principles behind attention mechanisms without considering generating human-readable explanations. In this work, we attempt to generate a human-readable explanation about the evidence that led to the prediction. To achieve our goal, we propose news-powered neural models to forecast short-term volatility and present a soft-constrained dynamic beam allocation algorithm to control the state-of-the-art language model (GPT-2) to generate fluent and informative explanations. © 2021 Elsevier B.V., All rights reserved.",Attention mechanisms; Explanation; Forecasting; Market volatility; Neural networks,Scopus
10.1109/ICASSP40776.2020.9053276,10.1109/ICASSP40776.2020.9053276,CORRGAN: Sampling Realistic Financial Correlation Matrices Using Generative Adversarial Networks,"We propose a novel approach for sampling realistic financial correlation matrices. This approach is based on generative adversarial networks. Experiments demonstrate that generative adversarial networks are able to recover most of the known stylized facts about empirical correlation matrices estimated on asset returns. This is the first time such results are documented in the literature. Practical financial applications range from trading strategies enhancement to risk and portfolio stress testing. Such generative models can also help ground empirical finance deeper into science by allowing for falsifiability of statements and more objective comparison of empirical methods. © 2020 Elsevier B.V., All rights reserved.",correlation matrices; generative adversarial networks; hierarchical clustering; random matrices; stock returns,Scopus
10.1016/j.eneco.2019.104624,10.1016/j.eneco.2019.104624,Geopolitical risk uncertainty and oil future volatility: Evidence from MIDAS models,"Using a textual analysis based geopolitical risk (GPR) index, this paper exploits the effects of geopolitical risk uncertainty on oil futures price volatility within a mixed data sampling (MIDAS) modeling framework. With a variety of MIDAS specifications, our in-sample estimation results suggest that the short-term (e.g. one-day-ahead) oil realized volatility is positively associated with GPR uncertainty, and our out-of-sample forecasting exercise indicates that the GPR index is useful for improving short-term oil futures volatility prediction. In addition, we find that the categorical GPR index: GPR action related index (GPA), contributes more to the long-term oil volatility forecasting, compared with GPR threat related index (GPT). © 2020 Elsevier B.V., All rights reserved.",Geopolitical risk uncertainty; MIDAS; Oil futures; Realized volatility,Scopus
2-s2.0-85107149696,,Stock trend prediction using financial market news and bert,"Stock market trend prediction is an attractive research topic since successful predictions of the market's future movement could result in significant profits. Recent advances in language representation such as Generative Pre-trained Transformer (GPT) and Bidirectional Encoder Representations from Transformers (BERT) models have shown success in incorporating a pre-trained transformer language model and fine-tuning operations to improve downstream natural language processing (NLP) systems. In this paper, we apply the popular BERT model to leverage financial market news to predict stock price movements. Experimental results show that our proposed methods are simple but very effective, which can significantly improve the stock prediction accuracy on a standard financial database over the baseline system and existing work © 2021 Elsevier B.V., All rights reserved.",Financial and business news; Financial market; Information extraction; Language model; Natural language processing; Neural networks; Stock market,Scopus
10.1007/978-3-030-58790-1_7,10.1007/978-3-030-58790-1_7,News Articles Evaluation Analysis in Automotive Industry Using GPT-2 and Co-occurrence Network,"News articles have great impacts on asset prices in the financial markets. Many attempts have been reported to ascertain how news influences stock prices. Stock price fluctuations of highly influential companies can have a major impact on the economy as a whole. In particular, the automobile industry is a colossal industry that leads the Japanese industry. However, the limitations in the number of available data sets usually become the hurdle for the model accuracy. In this study, we constructed a news evaluation model utilizing GPT-2. A news evaluation model is a model that evaluates news articles distributed to financial markets based on price fluctuation rates and predicts fluctuations in stock prices. We have added news articles generated by GPT-2 as data for analysis. Besides, we used a co-occurrence network analysis to review the overview of the news articles. News articles were classified through Long Short-Term Memory (LSTM). The results showed that the accuracy of the news evaluation model improved by generating news articles using a language generation model through GPT-2. More detailed analyses are planned for the future. © 2020 Elsevier B.V., All rights reserved.",Co-occurrence network; Deep learning; Financial markets; GPT-2; Language generation; LSTM,Scopus
10.3390/risks7040111,10.3390/risks7040111,High frequency price change spillovers in bitcoin markets,"The study of connectedness is key to assess spillover effects and identify lead-lag relationships among market exchanges trading the same asset. By means of an extension of Diebold and Yilmaz (2012) econometric connectedness measures, we examined the relationships of five major Bitcoin exchange platforms during two periods of main interest: The 2017 surge in prices and the 2018 decline. We concluded that Bitfinex and Gemini are leading exchanges in terms of return spillover transmission during the analyzed time-frame, while Bittrexs act as a follower. We also found that connectedness of overall returns fell substantially right before the Bitcoin price hype, whereas it leveled out during the period the down market period. We confirmed that the results are robust with regards to the modeling strategies. © 2019 Elsevier B.V., All rights reserved.",Bitcoin; Forecast error variance decomposition; Market linkages; Market risk; Spillovers; Vector error correction,Scopus
10.1109/NYSDS.2019.8909804,10.1109/NYSDS.2019.8909804,Stacking with Neural Network for Cryptocurrency investment,"Predicting the direction of assets have been an active area of study and difficult task. Machine learning models have been used to build robust models to model the above task. Ensemble methods are one of them resulting better than single supervised method. We have used generative and discriminative classifiers to create the stack, particularly 3 generative and 6 discriminative classifiers and optimized over one-layer Neural Network to model the direction of price cryptocurrencies. Features used are technical indicators not limited to trend, momentum, volume, volatility indicators and sentiment indicators. For Cross validation, Purged Walk forward cross validation has been used. In terms of accuracy, we have done comparative analysis of the performance of Ensemble method with Stacking and individual models. We have also developed methodology for features importance for stacked model. Important indicators are identified based on feature importance. © 2020 Elsevier B.V., All rights reserved.",Bitcoin; Discriminative Models; Generative Models; LightGBM; Stacked Generalization; Xgboost,Scopus
2-s2.0-85075285618,,Modelling non-stationary financial time series with input warped student t-processes,"The evolution of financial assets is known to be non-stationary and to present long tails and non-Gaussian. Gaussian processes are a flexible and general Bayesian nonparametric generative model that provide flexible priors on function spaces and interpretable uncertainty quantification. While GP are extremely flexible function approximators, their Gaussian marginal distribution makes them inappropriate to model financial assets returns distributions. We present the Student t-processes that are known to fit heavier tail. We also augment the model with input warping to account with the financial time series non stationarity. We present a case study of fitting the evolution of SP500 index stressing the importance of good uncertainty estimates, especially when the series manifests structural breaks. © 2019 Elsevier B.V., All rights reserved.",Bayesian nonparametric; Gaussian processes; Student processes; Stylized facts,Scopus
10.1587/transinf.2016IIP0016,10.1587/transinf.2016IIP0016,Stock price prediction by deep neural generative model of news articles,"In this study, we propose a deep neural generative model for predicting daily stock price movements given news articles. Approaches involving conventional technical analysis have been investigated to identify certain patterns in past price movements, which in turn helps to predict future price movements. However, the financial market is highly sensitive to specific events, including corporate buyouts, product releases, and the like. Therefore, recent research has focused on modeling relationships between these events that appear in the news articles and future price movements; however, a very large number of news articles are published daily, each article containing rich information, which results in overfitting to past price movements used for parameter adjustment. Given the above, we propose a model based on a generative model of news articles that includes price movement as a condition, thereby avoiding excessive overfitting thanks to the nature of the generative model. We evaluate our proposed model using historical price movements of Nikkei 225 and Standard & Poor's 500 Stock Index, confirming that our model predicts future price movements better than such conventional classifiers as support vector machines and multilayer perceptrons. Further, our proposed model extracts significant words from news articles that are directly related to future stock price movements. © 2018 Elsevier B.V., All rights reserved.",Deep learning; Generative model; News articles; Stock price prediction,Scopus
10.1145/3130800.3130830,10.1145/3130800.3130830,Online generative model personalization for hand tracking,"We present a new algorithm for real-time hand tracking on commodity depth-sensing devices. Our method does not require a user-specific calibration session, but rather learns the geometry as the user performs live in front of the camera, thus enabling seamless virtual interaction at the consumer level. The key novelty in our approach is an online optimization algorithm that jointly estimates pose and shape in each frame, and determines the uncertainty in such estimates. This knowledge allows the algorithm to integrate per-frame estimates over time, and build a personalized geometric model of the captured user. Our approach can easily be integrated in state-of-the-art continuous generative motion tracking software. We provide a detailed evaluation that shows how our approach achieves accurate motion tracking for real-time applications, while significantly simplifying the workflow of accurate hand performance capture. We also provide quantitative evaluation datasets at http://gfx.uvic.ca/datasets/handy © 2017 Elsevier B.V., All rights reserved.",Articulated registration; Generative tracking; Motion capture; Real-time calibration; Real-time hand tracking,Scopus
10.3233/IDA-150770,10.3233/IDA-150770,Topic factor models: Uncovering thematic structure in equity market data,"We examine the task of finding thematic structure in a data corpus comprising text and time series. To achieve this we introduce topic factor modelling (TFM). We develop a novel, joint generative model for both data types which resembles supervised latent Dirichlet allocation. TFM allows the decomposition of time series into factors which also reflect the thematic content of the text. We describe a variational method for inference and demonstrate its effectiveness on a synthetic corpus. For a corpus of publicly available equity data, we show that a TFM can simultaneously and robustly model both stock price time series and text data describing the corresponding companies. We also discuss how topic modelling could assist with external tasks such as robust covariance estimation. © 2017 Elsevier B.V., All rights reserved.",computational finance; latent dirichlet allocation; text mining; Topic modelling; variational inference,Scopus
10.1145/2766462.2767757,10.1145/2766462.2767757,Predicting search intent based on pre-search context,"While many studies have been conducted on query understanding, there is limited understanding on why users start searches and how to predict search intent. In this paper, we propose to study this important but less explored problem. Our key intuition is that searches are triggered by different pre-search contexts, but the triggering relations are often hidden. For example, a user may search ""bitcoin"" because of a news article or an email the user just read, but the system does not know which of the pre-search contexts (the news article or the email) is the triggering source. Following this intuition, we conduct an in-depth analysis of pre-search context on a large-scale user log, which not only verifies the hidden triggering relations in the real world but also identifies a set of important characteristics of pre-search context and their triggered queries. Since the hidden triggering relations make it challenging to directly use pre-search context for intent prediction, we develop a mixture generative model to learn without any supervision how queries are triggered by different types of pre-search context. Further, we discuss how to apply our model to improve query prediction and query auto-completion. Our experiments on a large-scale of real-world data show that our model could accurately predict user search intent with pre-search context and improve upon the state-of-the-art methods significantly. © 2016 Elsevier B.V., All rights reserved.",Pre-search context; Query auto-completion; Query prediction; Search context; Search intent,Scopus
10.18653/v1/d15-1184,10.18653/v1/d15-1184,Reading documents for Bayesian Online Change Point Detection,"Modeling non-stationary time-series data for making predictions is a challenging but important task. One of the key issues is to identify long-term changes accurately in time-varying data. Bayesian Online Change Point Detection (BO-CPD) algorithms efficiently detect long-term changes without assuming the Markov property which is vulnerable to local signal noise. We propose a Document based BO-CPD (DBO-CPD) model which automatically detects long-term temporal changes of continuous variables based on a novel dynamic Bayesian analysis which combines a non-parametric regression, the Gaussian Process (GP), with generative models of texts such as news articles and posts on social networks. Since texts often include important clues of signal changes, DBO-CPD enables the accurate prediction of long-term changes accurately. We show that our algorithm outperforms existing BO-CPDs in two real-world datasets: stock prices and movie revenues. © 2022 Elsevier B.V., All rights reserved.",,Scopus
10.1214/14-AOS1250,10.1214/14-AOS1250,Estimating time-changes in noisy Lévy models,"In quantitative finance, we often model asset prices as a noisy Itô semimartingale. As this model is not identifiable, approximating by a timechanged Lévy process can be useful for generative modelling. We give a new estimate of the normalised volatility or time change in this model, which obtains minimax convergence rates, and is unaffected by infinite-variation jumps. In the semimartingale model, our estimate remains accurate for the normalised volatility, obtaining convergence rates as good as any previously implied in the literature. © 2021 Elsevier B.V., All rights reserved.",Itô semimartingale; Lévy process; Microstructure noise; Timechange; Volatility,Scopus
10.1016/j.egypro.2014.02.176,10.1016/j.egypro.2014.02.176,Solar energy in urban environment: How urban densification affects existing buildings,"The paper is focused on a new solar urban planning approach for building densification and preservation in existing urban areas. Dense urban environments provide a complex settlement, where solar availability and urban daylight can become a scarce commodity, especially since buildings become increasingly taller. This is mainly due to the complex and dynamic overshadowing effects created on the building envelope. Accurately quantifying these effects could be the key to predicting reductions in solar availability which, in turn, can significantly affect daylight and the thermal performance of buildings, as well as the potential for PVs and other renewables sources. It is therefore necessary to use simulation tools in order to predict the mutual complex effects. In accordance with European building regulations, which are going toward a Net Zero Energy City, this paper presents a new design approach using generative modeling tools and dynamic simulation software in order to develop a sustainable urban planning method. © 2017 Elsevier B.V., All rights reserved.",Dynamic simulation; Solar access; Solar Potential; Urban densification and preservation,Scopus
2-s2.0-84871531453,,A kernel-based technique for direction-of-change financial time series forecasting,"This paper presents a generative approach to direction-of-change time series forecasting. Kernel methods are used to estimate densities for the distribution of positive and negative returns, and these distributions are then combined toproduce probability estimates for return forecasts. An advantage of the technique is that it involves very few parameters compared to regression-based approaches, the only free parameters being those that control the shape of the windowing kernel. A special form is proposed for the kernel covariance matrix. This allows recent data more influence than less recent data in determining the densities, and is important in preventing overfitting. The technique is applied to predicting the direction of change on the Australian All Ordinaries Index over a 15 year out-of-sample period. © 2013 Elsevier B.V., All rights reserved.",Financial markets; Generative models; Model selection; Neural networks; Non-parametric methods; Probability forecasting,Scopus
10.1108/02686900610705037,10.1108/02686900610705037,The stock market reaction to Ernst & Young's sale of its consulting unit to Cap Gemini,"Purpose - The purpose of this paper is to investigate how the stock prices of Ernst & Young's (E&Y's) audit clients reacted to the sale of the accounting firm's consulting unit to Cap Gemini. The study is motivated by the debate on how the provision of non-audit services by auditors affects investor perceptions of auditor independence. Design/methodology/approach - This paper uses the event study approach and examines market model prediction errors around relevant dates. Findings - E&Y client firms' mean and median abnormal stock returns are significantly positive for two events, the approval of the sale by E&Y's partners, and the approval of the transaction by Cap Gemini stockholders. Research limitations/implications - This study is limitedto one major audit firm for reasons discussed in the paper. Originality/value - This study offers evidence on investor perceptions of auditor independence without relying on an earnings management model as is common in the literature. This study's evidence suggests that investors view the separation of auditing and consulting favorably. © 2006 Elsevier B.V., All rights reserved.",Auditing; Auditors; Stock markets; Stock returns,Scopus
WOS:001443057200012,10.1145/3677052.3698647,NeuralFactors: A Novel Factor Learning Approach to Generative Modeling of Equities,"The use of machine learning for statistical modeling (and thus, generative modeling) has grown in popularity with the proliferation of time series models, text-to-image models, and especially large language models. Fundamentally, the goal of classical factor modeling is statistical modeling of stock returns, and in this work, we explore using deep generative modeling to enhance classical factor models. Prior work has explored the use of deep generative models in order to model hundreds of stocks, leading to accurate risk forecasting and alpha portfolio construction; however, that specific model does not allow for easy factor modeling interpretation in that the factor exposures cannot be deduced. In this work, we introduce Neural-Factors, a novel machine-learning based approach to factor analysis where a neural network outputs factor exposures and factor returns, trained using the same methodology as variational autoencoders. We show that this model outperforms prior approaches both in terms of log-likelihood performance and computational efficiency. Further, we show that this method is competitive to prior work in generating realistic synthetic data, covariance estimation, risk analysis (e.g., value at risk, or VaR, of portfolios), and portfolio optimization. Finally, due to the connection to classical factor analysis, we analyze how the factors our model learns cluster together and show that the factor exposures could be used for embedding stocks.",Stock Returns; Generative Modeling; Variational Autoencoders; Statistical Factors; Risk Forecasting; Portfolio Optimization,WoS
WOS:000874755600008,10.1016/j.ribaf.2022.101747,Synthetic data generation with deep generative models to enhance predictive tasks in trading strategies,"This work develops machine learning (ML) predictive models on price signals for financial instruments and their integration into trading strategies. In general, ML models have been shown powerful when trained with large amounts of data. In practice, the time-series nature of financial datasets limits the effective amount of data available to train, validate and retrain models since special care must be taken not to include future data in any way. In this setting, we develop deep generative models to produce synthetic time-series data, enhancing the amount of data available for training predictive models. Synthetic data obtained this way replicates the distribution properties of real historical data, leads to better performance, and enables thorough validation of predictive models for price signals. We leverage machine-generated predictive signals on synthetic data to build trading strategies. We show consistent improvement leading up to profits in our simulations for commodities and forex exchange markets.",Trading strategies; Machine learning; Synthetic data; Deep generative models; Deep learning; Trading simulations,WoS
WOS:000614253600001,10.1016/j.eswa.2020.114444,Forecasting daily stock trend using multi-filter feature selection and deep learning,"Stock market forecasting has attracted significant attention mainly due to the potential monetary benefits. Predicting these markets is a challenging task due to numerous interrelated factors, and needs a complete and efficient feature selection process to identify the most informative factors. As a time series problem, stock price movements are also dependent on movements on its previous trading days. Feature selection techniques have been widely applied in stock forecasting, but existing approaches usually use a single feature selection technique, which may overlook some important assumptions about the underlying regression function linking the input and output variables. In this study, we combine features selected by multiple feature selection techniques to generate an optimal feature subset and then use a deep generative model to predict future price movements. First, we compute an extended set of forty-four technical indicators from daily stock data of eighty-eight stocks and then compute their importance by independently training logistic regression model, support vector machine and random forests. Based on a prespecified threshold, the lowest ranked features are dropped and the rest are grouped into clusters. The variable importance measure is reused to select the most important feature from each cluster to generate the final subset. The input is then fed to a deep generative model comprising of a market signal extractor and an attention mechanism. The market signal extractor recurrently decodes market movement from the latent variables to deal with stochastic nature of the stock data and the attention mechanism discriminates between predictive dependencies of different temporal auxiliary outputs. The results demonstrate that combining features selected by multiple feature selection approaches and using them as input into a deep generative model outperforms state-of-the-art approaches.",Stock trend prediction; Feature selection; Deep learning; Machine learning,WoS
WOS:000932922500101,10.1109/ICCWAMTIP56608.2022.10016580,TABNET WITH DATA AUGMENTATION APPORACH IN STOCK RETURN PREDICTION TASK,"Despite the advent of deep learning, stock return prediction task still has many challenges. Due to the scarcity of stock data, we adopt a GAN-based deep generative model to create synthetic data samples. To deal with the intrinsic low signal-to-noise ratio property of stock price time series, we formulate the return prediction as a supervised learning problem with tabular dataset, where we do feature engineering before training with a TabNet model. We conduct extensive experiments on real Chinese stock market with 6 different models, which proves that our proposed model makes larger profit and remains stability.",Stock Return Prediction; Deep Learning; Small Dataset Problem; Conditional Tabular Generative Adversarial Network; TabNet,WoS
WOS:000748371000034,10.1109/LSP.2021.3135793,Learning Sentimental and Financial Signals With Normalizing Flows for Stock Movement Prediction,"Stockmovement prediction using Tweets (text) and historical price signals (time series) remains a challenging task due to the complex, noisy and dynamic nature of the stock market. The key to improve prediction performance is effectively capturing the complementarity between market sentiment signal from Tweets and time-series signal from the stock price. In this paper, we contribute a new solution StockNF by exploiting a deep generative model technique, Normalizing Flow (NF), to learn more flexible and expressive posterior distributions of latent variables of Tweets and price signals, which can largely ameliorate the bias inference problem in existing methods. We empirically evaluate the NF technique on a public stock movement prediction dataset and show that StockNF outperforms the state-of-the-art baselines.",Predictive models; Time series analysis; Stochastic processes; Data models; Noise measurement; Task analysis; Social networking (online); Stock movement prediction; Fintech; normalizing flow; variational inference; generative models,WoS
WOS:001124982700019,10.1145/3604237.3626884,Generative Machine Learning for Multivariate Equity Returns,"The use of machine learning to generate synthetic data has grown in popularity with the proliferation of text-to-image models and especially large language models. The core methodology these models use is to learn the distribution of the underlying data, similar to the classical methods common in finance of fitting statistical models to data. In this work, we explore the efficacy of using modern machine learning methods, specifically conditional importance weighted autoencoders (a variant of variational autoencoders) and conditional normalizing flows, for the task of modeling the returns of equities. The main problem we work to address is modeling the joint distribution of all the members of the S&P 500, or, in other words, learning a 500-dimensional joint distribution. We show that this generative model has a broad range of applications in finance, including generating realistic synthetic data, volatility and correlation estimation, risk analysis (e.g., value at risk, or VaR, of portfolios), and portfolio optimization.",Stock Returns; Generative Modeling; Variational Autoencoders; Normalizing Flows; Risk Forecasting; Portfolio Optimization,WoS
WOS:001414176500027,10.1109/BIGDIA63733.2024.10808510,A Novel Wavelet based Generative Model for Time Series Prediction,"Generative models have become an exciting area of research in recent years. Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs) have been utilized in various data augmentation applications. However, generative models can learn high-dimensional features of data through adversarial learning, making them suitable for nonlinear and nonstationary time series analysis, such as stock market prediction, high-frequency trading, and ocean current forecasting. In this paper, the researchers focus on using a wavelet-based GAN to predict stock market prices by generating synthetic stock market price trends. Historical stock price data from 2014 to 2024 is used for our experiments, and the results show that the wavelet-based GAN outperforms deep learning baseline models..",Stock Market Prediction; Data Augmentation; Generative Adversarial Network; Wavelet Transform,WoS
WOS:000431772600009,10.1587/transinf.2016IIP0016,Stock Price Prediction by Deep Neural Generative Model of News Articles,"In this study, we propose a deep neural generative model for predicting daily stock price movements given news articles. Approaches involving conventional technical analysis have been investigated to identify certain patterns in past price movements, which in turn helps to predict future price movements. However, the financial market is highly sensitive to specific events, including corporate buyouts, product releases, and the like. Therefore, recent research has focused on modeling relationships between these events that appear in the news articles and future price movements; however, a very large number of news articles are published daily, each article containing rich information, which results in overfitting to past price movements used for parameter adjustment. Given the above, we propose a model based on a generative model of news articles that includes price movement as a condition, thereby avoiding excessive overfitting thanks to the nature of the generative model. We evaluate our proposed model using historical price movements of Nikkei 225 and Standard & Poor's 500 Stock Index, confirming that our model predicts future price movements better than such conventional classifiers as support vector machines and multilayer perceptrons. Further, our proposed model extracts significant words from news articles that are directly related to future stock price movements.",stock price prediction; news articles; deep learning; generative model,WoS
WOS:001310563200001,10.1007/s10614-024-10668-4,Modeling Asset Price Process: An Approach for Imaging Price Chart with Generative Diffusion Models,"Artificial Intelligence (AI) models have been recently studied to discover data patterns for prediction and forecasting tasks in finance. However, the use of deep generative models in finance remains relatively unexplored. In this paper, we investigate the potential of deep generative diffusion models to estimate unknown dynamics using multiple simulations based on stock chart images. We first demonstrate a novel pre-processing framework and synthetic image generation using opening, high, low, and closing stock chart images to train neural networks. Without assuming the specific process as the underlying asset price process, we can generate synthetic data without predetermined assumptions of the underlying movements of stock prices by trained generative diffusion models. The experimental results demonstrate that the proposed method successfully replicates well-known asset price processes. With various simulation paths, we can also accurately estimate option pricing on the S &P 500. We conclude that financial simulation with AI can be a novel approach to financial decision-making.",Deep learning; Generative diffusion model; Asset price process; Financial simulation; Price chart; Option pricing,WoS
WOS:001518088100001,10.1007/s10614-025-11024-w,Stock Market Forecasting: From Traditional Predictive Models to Large Language Models,"Stock market forecasting is a complex research problem due to the complexity of the factors influencing stock market trends. This survey provides a comprehensive overview of recent advancements in stock market forecasting, focusing on the impact of large language models (LLMs) in financial analytics. The survey explores the strengths and challenges of feature engineering, ensemble methods, hybrid models, text-based prediction and reinforcement learning. It then presents the transformative impact of LLMs, highlighting their capabilities in utilizing transfer learning and few-shot learning to understand complex financial information, enhancing sentiment analysis, improving portfolio management, and stock forecasting accuracy. A key novelty of this survey lies in presenting comprehensive analysis of the strengths and weaknesses of LLMs for different financial tasks in addition to exploring how LLMs can be combined with machine learning and reinforcement learning approaches to overcome their limitations in handling unstructured data, improving model explainability, and enhancing generalizability. Finally, this survey identifies existing research gaps and limitations, proposing future research directions aimed at improving prediction accuracy and utilizing both LLMs and predictive models' capabilities in stock market forecasting.",Stock market forecasting; Large language models; Reinforcement learning; Feature engineering; Machine learning; LLM-based financial agents,WoS
WOS:001218136400001,10.1016/j.frl.2024.105227,Sentiment trading with large language models,"We analyse the performance of the large language models (LLMs) OPT, BERT, and FinBERT, alongside the traditional Loughran -McDonald dictionary, in the sentiment analysis of 965,375 U.S. financial news articles from 2010 to 2023. Our findings reveal that the GPT-3-based OPT model significantly outperforms the others, predicting stock market returns with an accuracy of 74.4%. A long -short strategy based on OPT, accounting for 10 basis points (bps) in transaction costs, yields an exceptional Sharpe ratio of 3.05. From August 2021 to July 2023, this strategy produces an impressive 355% gain, outperforming other strategies and traditional market portfolios. This underscores the transformative potential of LLMs in financial market prediction and portfolio management and the necessity of employing sophisticated language models to develop effective investment strategies based on news sentiment.",Natural language processing (NLP); Large language models; Generative pre-trained transformer (GPT); pre (GPT) Machine learning in stock return prediction; Artificial intelligence investment strategies,WoS
WOS:001513317600001,10.1080/14697688.2025.2511115,Stock market simulator using hidden Markov generative model and its application in risk measurement,"We propose a novel data-driven framework, called hidden Markov generative model, which combines the hidden Markov model (HMM) and a generative model for simulating a sequence of data. Specifically, we use the Wasserstein generative adversarial network (WGAN) as the generative model and use the resulting setup, HMM-WGAN, for simulating multivariate stock returns. In line with the original GAN model for images, we depict the invisible hands in financial markets as market painters and the different market regimes as distinct observable painting styles. The framework comprises of two phases. In Phase I, we train a time-homogeneous HMM to identify market painters for each trading day using a set of realized exogenous features. In Phase II, the painting style for each market painter is learned adversarially from a set of realized stock returns using WGAN. Subsequently, the market painter for the next trading day is simulated with the current regime and the trained HMM's transition matrix, and the consequent painting, i.e. multivariate stock returns, is then generated using the market painter's trained WGAN generator. Our empirical results demonstrate that the simulated multivariate stock returns not only replicate a comprehensive set of well-documented stylized facts-including heavy-tailed distributions, volatility clustering, and leverage effects-but also yield a more robust value-at-risk estimates compared to traditional approaches. As such, our framework provides a flexible, data-driven alternative to conventional parametric models without imposing restrictive assumptions.",Stock market simulation; Hidden Markov models; Generative models; Deep learning; Stylized facts; Risk measurement; G17; G32; C15; C63; C53,WoS
WOS:001476893200002,10.24425/ijet.2025.153538,LLM-Based multi-agent system for individual investment in energy and natural resources,"Recent advancements in large language models and multiagent large language model based systems show that these technologies can be applied to a large number of problems. They can automate complex tasks and perform advanced analyses that would take an expert a significant amount of time. This article describes a multiagent large language model (LLM) based platform for investment advisory in the energy natural resources sector. The system integrates multiple types of investment analyses e.g. technical analysis, fundamental analysis, sentiment analysis and stock price prediction. The approach of integrating multiple types of analyses in one system allows the investor to save significant amount of time on analyzing potential investments.",Multiagent systems; Energy Minerals Market; Investment Advisory System; Autonomous LLM Agents; Lang-Graph,WoS
WOS:001301355000001,10.1016/j.jfds.2023.100113,A general framework for portfolio construction based on generative models of asset returns,"In this paper, we present an integrated approach to portfolio construction and optimization, leveraging high-performance computing capabilities. We first explore diverse pairings of generative model forecasts and objective functions used for portfolio optimization, which are evaluated using performance-attribution models based on least absolute shrinkage and selection operator (LASSO). We illustrate our approach using extensive simulations of crypto-currency portfolios, and we show that the portfolios constructed using the vine-copula generative model and the Sharperatio objective function consistently outperform. To accommodate a wide array of investment strategies, we further investigate portfolio blending and propose a general framework for evaluating and combining investment strategies. We employ an extension of the multi-armed bandit framework and use value models and policy models to construct eclectic blended portfolios based on past performance. We consider similarity and optimality measures for value models and employ probability-matching (""blending"") and a greedy algorithm (""switching"") for policy models. The eclectic portfolios are also evaluated using LASSO models. We show that the value model utilizing cosine similarity and logit optimality consistently delivers robust superior performances. The extent of outperformance by eclectic portfolios over their benchmarks significantly surpasses that achieved by individual generative model-based portfolios over their respective benchmarks.",Portfolio construction; Generative model; Multi-armed bandit; Portfolio blending; Cryptocurrency,WoS
WOS:001327326300001,10.1109/ACCESS.2024.3445413,"Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study","This paper comprehensively examines Large Language Models (LLMs) in sentiment analysis, specifically focusing on financial markets and exploring the correlation between news sentiment and Bitcoin prices. We systematically categorize various LLMs used in financial sentiment analysis, highlighting their unique applications and features. We also investigate the methodologies for effective data collection and categorization, underscoring the need for diverse and comprehensive datasets. Our research features a case study investigating the correlation between news sentiment and Bitcoin prices, utilizing advanced sentiment analysis and financial analysis methods to demonstrate the practical application of LLMs. The findings reveal a modest but discernible correlation between news sentiment and Bitcoin price fluctuations, with historical news patterns showing a more substantial impact on Bitcoin's longer-term price than immediate news events. This highlights LLMs' potential in market trend prediction and informed investment decision-making.",Sentiment analysis; Bitcoin; Analytical models; Predictive models; Large language models; Correlation; Quality assessment; Large language model; Bitcoin price; sentiment analysis; machine learning; market dynamics,WoS
WOS:001511546300008,10.1371/journal.pone.0326034,Enhancing stock timing predictions based on multimodal architecture: Leveraging large language models (LLMs) for text quality improvement,"This study aims to enhance stock timing predictions by leveraging large language models (LLMs), specifically GPT-4, to filter and analyze online investor comment data. Recognizing challenges such as variable comment quality, redundancy, and authenticity issues, we propose a multimodal architecture that integrates filtered comment data with stock price dynamics and technical indicators. Using data from nine Chinese banks, we compare four filtering models and demonstrate that employing GPT-4 significantly improves financial metrics like profit-loss ratio, win rate, and excess return rate. The multimodal architecture outperforms baseline models by effectively preprocessing comment data and combining it with quantitative financial data. While focused on Chinese banks, the approach can be adapted to broader markets by modifying the prompts of large language models. Our findings highlight the potential of LLMs in financial forecasting and provide more reliable decision support for investors.",,WoS
WOS:001567571700001,10.3389/frai.2025.1608365,"Large Language Models in equity markets: applications, techniques, and insights","Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector.",Large Language Models; LLMS; finance; NLP; stock; equity; investing; algorithmic trading,WoS
WOS:000776441600007,10.1145/3501305,Generation of Realistic Synthetic Financial Time-series,"Financial markets have always been a point of interest for automated systems. Due to their complex nature, financial algorithms and fintech frameworks require vast amounts of data to accurately respond to market fluctuations. This data availability is tied to the daily market evolution, so it is impossible to accelerate its acquisition. In this article, we discuss several solutions for augmenting financial datasets via synthesizing realistic time-series with the help of generative models. This problem is complex, since financial time series present very specific properties, e.g., fat-tail distribution, cross-correlation between different stocks, specific autocorrelation, cluster volatility and so on. In particular, we propose solutions for capturing cross-correlations between different stocks and for transitioning from fixed to variable length time-series without resorting to sequence modeling networks, and adapt various network architectures, e.g., fully connected and convolutional GANs, variational autoencoders, and generative moment matching networks. Finally, we tackle the problem of evaluating the quality of synthetic financial time-series. We introduce qualitative and quantitative metrics, along with a portfolio trend prediction framework that validates our generative models' performance. We carry out experiments on real-world financial data extracted from the US stock market, proving the benefits of these techniques.",Time-series; synthetic financial data generation; financial data prediction; generative models,WoS
WOS:001548409500009,10.1109/IDS66066.2025.00016,LLM-Processed Financial News: An Improved Approach Using DeepSeek-V3,"The use of AI techniques to improve stock market related operations has been benefiting traders in the stock market. FinRL is a framework that has been shown to be effective in building Reinforcement Learning (RL) based Trading Agents. Use of LLMs for performance improvement of the Agents is one of the recent initiatives. LLMs are being used to generate signals that could be combined with historical stock prices for better prediction of stock price movement trends leading to profitable trading. This paper aims to develop efficiently engineered prompts to generate DeepSeek-V3-based sentiment signals, integrate them into the FinRL environment, and improve the performance of reinforcement learning trading agents. The code, data, and trading agents are at: https://github.com/SatishChandraPhD/FinRL2025",Financial Reinforcement Learning; FinRL; trading agent; prompt; large language model; DeepSeek; stock market; financial news; stock price trend,WoS
WOS:001528297000001,10.1007/s11156-025-01437-x,Using Generative AI to predict the weather impact on future stock returns,"This study explores the use of Generative AI, specifically OpenAI's ChatGPT, for forecasting the impacts of severe weather events on stock returns. Employing prompts that assess textual weather descriptions, ChatGPT, a powerful generative AI large language model (LLM), provides predictions incorporated into econometric models. Results show that when ChatGPT forecasts negative stock impacts from storms, larger, more profitable firms with lower leverage and higher liquidity experience lower subsequent returns, suggesting investor underreaction to weather risk. ChatGPT's predictive abilities are stronger during favorable economic conditions like uptrends, low volatility, and robust employment growth, implying investor underreaction amid bullish sentiment.",Weather risk; Stock returns; Generative AI; ChatGPT; Large language model (LLM),WoS
WOS:001583103700010,10.1016/j.frl.2025.108489,Readability of financial reports and stock price crash risk,"The rapid evolution of machine learning makes text analysis more feasible. Utilizing a large language model, BERT, this article explores whether and how the readability of financial reports predicts firms' stock price crash risk. Grounded in Chinese evidence, this research uncovers that the degree of readability is strongly negatively linked to firm stock price crash risk. This effect is stronger among firms led by more entrenched CEOs. These findings remain robust to various model specifications and to the instrumental variable method. Overall, this study, by shedding light on a novel driver of stock price crash risk, advances corporate finance literature.",Large language model; BERT; Text analysis; Readability; Crash risk,WoS
WOS:001513423100003,10.1016/j.econlet.2025.112404,Predicting stock price trends using language models to extract the sentiment from analyst reports: Evidence from IBEX 35-listed companies,"This study investigates the utility of large language models to extract sentiment from sell-side equity analysts' reports and their potential ability to predict stock price trends, using the IBEX 35 index as a case study. The RoBERTa, FinBERT, and GPT natural language processing models are employed to analyze a corpus of analysts' equity research reports over 2016-2022. The results indicate that the extracted sentiment can serve as a valuable tool for forecasting stock price movements, avoiding the potential bias in analyst reports when assigning a target price. This highlights the transformative potential of language models in the financial industry and their role in assisting investors in making informed investment decisions.",Natural language processing; Large language models; Stock market prediction; Analyst recommendations,WoS
WOS:001281996200042,10.1145/3652037.3652047,Assessment of the Applicability of Large Language Models for Quantitative Stock Price Prediction,"In accordance with the findings presented in [34], this study examines the applicability of Machine Learning (ML) models and training strategies from the Natural Language Processing (NLP) domain in addressing time series problems, emphasizing the structural and operational aspects of these models and strategies. Recognizing the structural congruence within the data, we opt for Stock Price Prediction (SPP) as the designated domain to assess the transferability of NLP models and strategies. Building upon initial positive outcomes derived from quantitative SPP models in our ongoing research endeavors, we provide a rationale for exploring a range of additional methods and conducting subsequent research experiments. The outlined research aims to elucidate the efficacy of leveraging NLP models and techniques for addressing time series problems exemplified as SPP.",stock price prediction; quantitative analysis; stock embeddings; large language models; natural language processing; big data,WoS
WOS:001424958800096,,Prediction of Foreign Exchange Rates by a Large Language Model,"This paper proposes a prompt-based method utilizing a large language model (LLM) to predict changes in foreign exchange rates based on limit order information. While traditional deep learning models for prediction utilize numerical values as input and output, LLMs use sentences and prompts. To address this, we design prompts that incorporate the numerical values. GPT-2, a widely adopted LLM, is employed and fine-tuned using a training dataset. The effectiveness of our proposed method is demonstrated through empirical analysis using actual time series data.",Large language model; Foreign exchange rate; Finance; Time series; Machine learning,WoS
WOS:001314921000019,10.1007/978-981-97-5934-7_19,News that Moves the Market: DSEX-News Dataset for Forecasting DSE Using BERT,"Stock market is a complex and dynamic industry that has always presented challenges for stakeholders and investors due to its unpredictable nature. This unpredictability motivates the need for more accurate prediction models. Traditional prediction models have limitations in handling the dynamic nature of the stock market. Additionally, previous methods have used less relevant data, leading to suboptimal performance. This study proposes the use of Bidirectional Encoder Representations from Transformers (BERT), a pre-trained Large Language Model (LLM), to predict Dhaka Stock Exchange (DSE) market movements. We also introduce a new dataset designed specifically for this problem, capturing important characteristics and patterns that were missing in other datasets. We test our new dataset of headlines and stock market indexes on various machine learning techniques, including Decision Tree (DT), Logistic Regression (LR), K-Nearest Neighbors (KNN), Random Forest (RF), Linear Support Vector Machine (LSVM), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs), Bidirectional Long Short-Term Memory (Bi-LSTM), BERT, Financial Bidirectional Encoder Representations from Transformers (FinBERT), and RoBERTa, which are compared to assess their predictive capabilities. Our proposed model achieves 99.83% accuracy on the training set and 99.78% accuracy on the test set, outperforming previous methods.",Deep Learning; Natural Language Processing; Sentiment Analysis; Machine Learning; Stock Exchange; Large Language Model,WoS
WOS:001525041300009,10.1016/j.iref.2025.104281,A multifactor model using large language models and multimodal investor sentiment,"This study constructs multimodal investor sentiment indices using news and image data from the China News Service, covering the period from January 1, 2017, to December 31, 2024. We employ the RoBERTa model for text-based sentiment measurement and the Google Inception(v3) model for image-based sentiment measurement. We use a multimodal semantic correlation fusion model to integrate textual and visual sentiment features. These sentiment indices are categorised as industry-specific and market-wide investor sentiment, enabling separate analyses of their effects on stock markets. Furthermore, we develop a multifactor stock selection model that incorporates these sentiment indices with other microeconomic factors. Our findings demonstrate that multimodal sentiment analysis yields superior predictive accuracy. Industry-specific investor sentiment influences stock market returns, which in turn exacerbates changes in market-wide investor sentiment. Incorporating industry-specific sentiment into the multifactor stock selection model enhances portfolio returns, and combining market-wide sentiment with timing strategies further improves performance.",Large language model; Multifactor model; Investor sentiment; Deep learning,WoS
WOS:001441835400001,10.1016/j.frl.2025.106967,AT-FinGPT: Financial risk prediction via an audio-text large language model,"Financial risk prediction is crucial for investment decision-making. Traditional machine learning methods are limited by their structures and parameter size, which hinders their generalizability and effectiveness. Large language models (LLMs), which are pretrained with very large dataset and many GPUs have recently shown promising improvements in financial risk prediction. Despite this progress, most existing financial LLMs mainly rely on textual data for training and prediction, overlooking audio data and limiting analysis to text summarization. However, natural language processing studies have shown that audio from CEOs' quarterly earnings calls is crucial for financial risk prediction. In this work, we introduce an audio-text LLM named ATFinGPT, which fuses financial audio data and summarization texts for financial risk prediction. The empirical experimental results show that AT-FinGPT is superior to most advanced methods. Through an ablation study, we demonstrate that different data sources can facilitate financial risk assessment and discuss the effectiveness of each part in the AT-FinGPT model.",Quantitative finance; Large language model; FinGPT; Multi-sources data fusion,WoS
WOS:001510284300001,10.1016/j.eswa.2025.127864,"Investigating the impact of sentiments on stock market using digital proxies: Current trends, challenges, and future directions","Social media and online news have emerged as significant sources of market sentiment, influencing stock market dynamics globally. With the growing availability of digital data, the current research focus is on leveraging advanced computational techniques for sentiment-driven stock market prediction. The era of financial forecasting has been revolutionized by integrating cutting-edge technologies such as Machine Learning, Deep Learning, and Large Language Models. In this paper, a comprehensive survey of 108 research articles has been undertaken to explore the recent advancements in these technologies, with a focus on utilizing sentiment data extracted from social media platforms and news sources. The technology-wise state-of-the-art findings, current trends, challenges, and literature gaps in this domain are analyzed, and potential future directions are proposed to address these gaps. Additionally, publicly available benchmark datasets for social media and news sentiment indices are compiled and analyzed, with insights into their limitations and potential improvements. A comparative evaluation of prediction methods across heterogeneous user-generated datasets is performed, identifying the most effective techniques for various data types and problem formulations. Recommendations are offered for selecting suitable techniques based on the nature of the data and the specific problem formulation. By incorporating the latest advancements in the field of sentiment analysis and stock market prediction, this work provides actionable insights for researchers and practitioners, advancing the understanding and development of sentiment-driven financial forecasting.",Stock market prediction; Social media; Digital news; Machine learning; Deep learning; Large language models,WoS
WOS:001356731804003,,Can Large Language Models Mine Interpretable Financial Factors More Effectively? A Neural-Symbolic Factor Mining Agent Model,"Finding interpretable factors for stock returns is the most vital issue in the empirical asset pricing domain. As data-driven methods, existing factor mining models can be categorized into symbol-based and neural-based models. Symbol-based models are interpretable but inefficient, while neural-based approaches are efficient but lack interpretability. Hence, mining interpretable factors effectively presents a significant challenge. Inspired by the success of Large Language Models (LLMs) in various tasks, we propose a FActor Mining Agent (FAMA) model that enables LLMs to integrate the strengths of both neural and symbolic models for factor mining. In this paper, FAMA consists of two main components: Cross-Sample Selection (CSS) and Chain-of-Experience (CoE). CSS addresses the homogeneity challenges in LLMs during factor mining by assimilating diverse factors as in-context samples, whereas CoE enables LLMs to leverage past successful mining experiences, expediting the mining of effective factors. Experimental evaluations on real-world stock market data demonstrate the effectiveness of our approach by surpassing the SOTA RankIC by 0.006 and RankICIR by 0.105 in predicting S&P 500 returns. Furthermore, the investment simulation shows that our model can achieve superior performance with an annualized return of 38.4% and a Sharpe ratio of 667.2%.",,WoS
WOS:001443057200030,10.1145/3677052.3698689,ECC Analyzer: Extracting Trading Signal from Earnings Conference Calls using Large Language Model for Stock Volatility Prediction,"In the realm of financial analytics, leveraging unstructured data, such as earnings conference calls (ECCs), to forecast stock volatility is a critical challenge that has attracted both academics and investors. While previous studies have used multimodal deep learning-based models to obtain a general view of ECCs for volatility predicting, they often fail to capture detailed, complex information. Our research introduces a novel framework: ECC Analyzer, which utilizes large language models (LLMs) to extract richer, more predictive content from ECCs to aid the model's prediction performance. We use the pre-trained large models to extract textual and audio features from ECCs and implement a hierarchical information extraction strategy to extract more fine-grained information. This strategy first extracts paragraph-level general information by summarizing the text and then extracts fine-grained focus sentences using Retrieval-Augmented Generation (RAG). These features are then fused through multimodal feature fusion to perform volatility prediction. Experimental results demonstrate that our model outperforms traditional analytical benchmarks, confirming the effectiveness of advanced LLM techniques in financial analysis.",Large Language Model; Earnings Conference Call Analysis; Volatility forecasting; Retrieval-Augmented Generation,WoS
WOS:001498731600002,10.1007/s10791-025-09573-7,Leveraging large language model as news sentiment predictor in stock markets: a knowledge-enhanced strategy,"In the fast-evolving artificial intelligence era, the intersection of natural language processing and financial analysis has attracted significant attention, primarily due to its potential to provide valuable insights into financial market behavior. Sentiment analysis of financial news articles is a crucial aspect of this intersection, providing cues about market sentiment that may affect stock price dynamics. Traditional sentiment analysis methods often rely on rules or machine learning algorithms trained on labeled datasets, but these methods face challenges in capturing the context within the text. This paper proposes a framework that incorporates prompt engineering strategies, including a novel Domain Knowledge Chain-of-Thought (DK-CoT) strategy, integrating domain-specific financial knowledge with chain-of-thought reasoning, designed to leverage and enhance the performance of large language models (LLMs) in financial news sentiment analysis. DK-CoT has been compared with various prompt engineering techniques, including zero-shot, few-shot, and chain-of-thought, as well as other benchmark models like BERT and RoBERTa. Through comprehensive experiments and evaluations, we introduce the weighted F1 score as a more practical metric, emphasizing the disproportionate impact of negative news on financial markets, which better reflects real-world financial dynamics, as negative sentiments often lead to more significant market reactions than positive or neutral sentiments. Experimental results have shown that DK-CoT adopted in an LLM called GLM is effective in improving the performance and reliability of financial news sentiment analysis. Our findings provide insights into optimal prompt designs and highlight the importance of incorporating financial knowledge to uplift LLM performance while reducing the need for extensive computational resources and fine-tuning.",Sentiment analysis; Financial news; Natural language processing; Accessible machine learning; Large language model; Prompt engineering,WoS
WOS:001421376600001,10.1016/j.dss.2024.114362,Revisiting time-varying dynamics in stock market forecasting: A multi-source sentiment analysis approach with large language model,"This paper presents the Heterogeneous Dynamic Seemingly Unrelated Regression with Dynamic Linear Models (HD-SURDLM), an innovative framework for stock return prediction that combines cutting-edge sentiment analysis with dynamic financial modeling. The model integrates sentiment data from 2.5 million Twitter posts and various news sources, utilizing state-of-the-art sentiment analysis tools such as VADER, TextBlob, and RoBERTa. HD-SURDLM refines Gibbs sampling for enhanced numerical stability and efficiency while capturing cross-sectional dependencies across multiple assets such as a portfolio. The model consistently outperforms traditional methods like LSTM, Random Forest, and RNN in forecasting accuracy. Empirical results show a 1.02% improvement in 1-day horizon forecasts, a 0.42% gain for 20-day predictions, and a 0.36% increase for 50-day forecasts. By effectively merging public sentiment with dynamic asset modeling, HD-SURDLM offers substantial improvements in short- and long-term prediction accuracy. Its capacity to capture both crosssectional insights and temporal dynamics makes it an invaluable tool for investors, traders, and financial institutions navigating sentiment-driven markets. HD-SURDLM not only enhances predictive accuracy but also provides a robust decision-support system for financial stakeholders.",Sentiment analysis; Time series prediction; Seemingly unrelated regression; Dynamic linear models; Large language model; Decision system,WoS
WOS:001554251400021,10.1007/978-3-031-96235-6_21,Comparative Analysis and Evaluation of SLMs and LLMs for Stock Price Movement Prediction,"This paper investigates the performance disparities between Small Language Models (SLMs) and Large Language Models (LLMs) in predicting stock price movements using data from two different datasets containing news articles and tweets. The study emphasizes the potential of SLMs as a more accessible and resource-efficient alternative to LLMs, enabling local and in-house deployment. Critical gaps are addressed, including the lack of direct price movement predictions, the utilization and comparison of State-of-the-Art (SotA) models, and the integration of diverse data sources. The research employed a fundamental trading strategy based on predicted stock price movement as the sole trading signal. The Phi-2 model, fine-tuned with Quantized Low-Rank Adaptation (QLoRA) on consumer-grade hardware, was compared with GPT-4, serving as a SotA benchmark. Performance was evaluated using accuracy, precision, recall, and F1-score. The results indicate that the fine-tuned SML (Phi-2) outperformed the LLM (GPT-4), albeit by a small margin, demonstrating the potential of a trained SML over a general LLM.",Artificial Intelligence; Large Language Models; Small Language Models; Stock Price Prediction; Algorithmic Trading,WoS
WOS:001416057000001,10.1021/acs.analchem.4c05046,Large Language Models (such as ChatGPT) as Tools for Machine Learning-Based Data Insights in Analytical Chemistry,"Artificial intelligence (AI), especially through the development of deep learning techniques like convolutional neural networks (CNNs), has revolutionized numerous fields. CNNs, introduced by Yann LeCun in the 1990s (Hubbard, W.; Jackel, L. D. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Comput. 1989, 1 (4), 541- 551. https://doi.org/10.1162/neco.1989.1.4.541), have found applications in healthcare for medical diagnostics, autonomous vehicles in transportation, stock market prediction in finance, and image recognition in computer vision to name just a few. Similarly, in analytical chemistry, deep learning has enhanced data analysis from techniques like MS spectrometry, NMR, fluorescence spectroscopy, and chromatography. Another AI branch, Natural Language Processing (NLP), has surged recently with the advent of Large Language Models (LLMs), such as OpenAI's ChatGPT. This paper demonstrates the application of an LLM via a smartphone to conduct multivariate data analyses, in an interactive conversational manner, of a hyper-spectral imaging data set from laser-induced breakdown spectroscopy (LIBS). We demonstrate the potential of LLMs to process and analyze data sets, which automatically generate and execute code in response to user queries, and anticipate their growing role in the future of analytical chemistry.",,WoS
WOS:001339512700136,10.1109/DOCS63458.2024.10704454,Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach,"Accurate stock market predictions following earnings reports are crucial for investors. Traditional methods, particularly classical machine learning models, struggle with these predictions because they cannot effectively process and interpret extensive textual data contained in earnings reports and often overlook nuances that influence market movements. This paper introduces an advanced approach by employing Large Language Models (LLMs) instruction fine-tuned with a novel combination of instruction-based techniques and quantized low-rank adaptation (QLoRA) compression. Our methodology integrates 'base factors', such as financial metric growth and earnings transcripts, with 'external factors', including recent market indices performances and analyst grades, to create a rich, supervised dataset. This comprehensive dataset enables our models to achieve superior predictive performance in terms of accuracy, weighted F1, and Matthews correlation coefficient (MCC), especially evident in the comparison with benchmarks such as GPT-4. We specifically highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases significant improvements over baseline models. The paper also discusses the potential of expanding the output capabilities to include a 'Hold' option and extending the prediction horizon, aiming to accommodate various investment styles and time frames. This study not only demonstrates the power of integrating cutting-edge AI with fine-tuned financial data but also paves the way for future research in enhancing AI-driven financial analysis tools.",Large Language Model; Quantized Low-Rank Adaptation; Instruction Fine Tuning,WoS
WOS:001124982700047,10.1145/3604237.3626861,Predictability of Post-Earnings Announcement Drift with Textual and Contextual Factors of Earnings Calls,"Post-Earnings Announcement Drift (PEAD), a well-known anomaly in financial markets, describes the tendency of cumulative stock returns to drift in the direction of an earnings surprise for a prolonged period following an earnings announcement. Numerous studies have used a supervised learning approach to predict PEAD, using earnings, fundamental and technical factors. However, there is a lack of study on how the context of the earnings call can be used for the PEAD prediction task. This paper uses computational linguistics techniques and large language models to examine the effectiveness of incorporating textual and contextual features from earnings calls for the PEAD prediction task. Our proposed supervised model includes four categories of features: 1) textual features, 2) contextual features, 3) earnings features, and 4) fundamental and technical features. We study the proposed model using earnings from 2010/01/01 to 2022/12/31 of all point-in-time S&P500 constituents in the US stock market. Our results show that contextual features provide information unexplained by earnings, fundamental and technical features, improving the average returns per trade of a hypothetical long-short portfolio against baseline solution in out-of-sample across all four different abnormal return calculations, ranging from 53 to 354 basis points and 16.9% to 108.5% improvement from baseline model, which uses only earnings, fundamental and technical features.",Post-earnings announcement drift; earnings call; computational linguistics; large language models; machine learning,WoS
WOS:001356731803018,,LLMFactor: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction,"Recently, Large Language Models (LLMs) have attracted significant attention for their exceptional performance across a broad range of tasks, particularly in text analysis. However, the finance sector presents a distinct challenge due to its dependence on time-series data for complex forecasting tasks. In this study, we introduce a novel framework called LLMFactor, which employs Sequential Knowledge-Guided Prompting (SKGP) to identify factors that influence stock movements using LLMs. Unlike previous methods that relied on keyphrases or sentiment analysis, this approach focuses on extracting factors more directly related to stock market dynamics, providing clear explanations for complex temporal changes. Our framework directs the LLMs to create background knowledge through a fill-in-the-blank strategy and then discerns potential factors affecting stock prices from related news. Guided by background knowledge and identified factors, we leverage historical stock prices in textual format to predict stock movement. An extensive evaluation of the LLMFactor framework across four benchmark datasets from both the U.S. and Chinese stock markets demonstrates its superiority over existing state-of-the-art methods and its effectiveness in financial time-series forecasting.",,WoS
WOS:000362966800005,10.3233/IDA-150770,Topic factor models: Uncovering thematic structure in equity market data,"We examine the task of finding thematic structure in a data corpus comprising text and time series. To achieve this we introduce topic factor modelling (TFM). We develop a novel, joint generative model for both data types which resembles supervised latent Dirichlet allocation. TFM allows the decomposition of time series into factors which also reflect the thematic content of the text. We describe a variational method for inference and demonstrate its effectiveness on a synthetic corpus. For a corpus of publicly available equity data, we show that a TFM can simultaneously and robustly model both stock price time series and text data describing the corresponding companies. We also discuss how topic modelling could assist with external tasks such as robust covariance estimation.",Topic modelling; latent dirichlet allocation; variational inference; computational finance; text mining,WoS
WOS:001295908300001,10.1016/j.inffus.2024.102616,Data-driven stock forecasting models based on neural networks: A review,"As a core branch of financial forecasting, stock forecasting plays a crucial role for financial analysts, investors, and policymakers in managing risks and optimizing investment strategies, significantly enhancing the efficiency and effectiveness of economic decision-making. With the rapid development of information technology and computer science, data-driven neural network technologies have increasingly become the mainstream method for stock forecasting. Although recent review studies have provided a basic introduction to deep learning methods, they still lack detailed discussion on network architecture design and innovative details. Additionally, the latest research on emerging large language models and neural network structures has yet to be included in existing review literature. In light of this, this paper comprehensively reviews the literature on data- driven neural networks in the field of stock forecasting from 2015 to 2023, discussing various classic and innovative neural network structures, including Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), Transformers, Graph Neural Networks (GNNs), Generative Adversarial Networks (GANs), and Large Language Models (LLMs). It analyzes the application and achievements of these models in stock market forecasting. Moreover, the article also outlines the commonly used datasets and various evaluation metrics in the field of stock forecasting, further exploring unresolved issues and potential future research directions, aiming to provide clear guidance and reference for researchers in stock forecasting.",Stock forecast; Finance; Financial market; Neural network; Deep learning,WoS
WOS:001554251400031,10.1007/978-3-031-96235-6_23,Enhancing Cryptocurrency Sentiment Analysis with GPT-4: A Comparative Study,"Attracting investors seeking distributed investing possibilities, cryptocurrencies are gradually taking front stage on financial markets. But sentiment analysis is essential for understanding market dynamics with considerable volatility molded by news, social media trends, and investor mood. This paper investigates the relevance of Large Language Models (LLMs), particularly fine-tuned GPT-4, in cryptocurrency sentiment analysis. By fine-tuning GPT-4 using a cryptocurrency news dataset, this paper compares its sentiment classification performance against other models, including FinBERT, BERT, Flan-T5, and Gemma-7B. The results indicate higher accuracy since finely tuned LLMs show better in classifying sentiments as positive, neutral, or negative. These results highlight the need of optimizing to raise sentiment analysis capability. This paper contributes to both academic research and financial applications, offering insights into how LLMs can be leveraged for market trend predictions and risk management strategies.",Sentiment Analysis; Large Language Model; GPT-4; Fine-Tuning; Cryptocurrency; Comparative Study,WoS
WOS:000684483700001,10.1007/s41109-021-00357-8,On the challenges of predicting microscopic dynamics of online conversations,"To what extent can we predict the structure of online conversation trees? We present a generative model to predict the size and evolution of threaded conversations on social media by combining machine learning algorithms. The model is evaluated using datasets that span two topical domains (cryptocurrency and cyber-security) and two platforms (Reddit and Twitter). We show that it is able to predict both macroscopic features of the final trees and near-future microscopic events with moderate accuracy. However, predicting the macroscopic structure of conversations does not guarantee an accurate reconstruction of their microscopic evolution. Our model's limited performance in long-range predictions highlights the challenges faced by generative models due to the accumulation of errors.",Information cascades; Conversation trees; Prediction; Social media; Machine learning,WoS
WOS:001461762600014,10.1109/ICDMW65004.2024.00019,Leveraging Large Language Models for Predicting Stock Option Valuation and Financial Risk Mitigation,"The prediction of short-term stock options with near-future expiration dates is a challenging task due to high volatility, limited information, market noise and the risk of time decay. This work focuses on the new approach to the stock options valuation by leveraging Large Language Models (LLMs) through the integration of quantitative (i.e. financial features-lagged prices, moving averages, and volatility indicators) and qualitative data (i.e. news data, including article titles, full textual content, and publication dates). More specifically, our approach fuses sentiment analysis from LLMs applied to financial news from two reputable outlets (i.e. Economic Times and Yahoo Finance India) with quantitative data on stock options, which includes stock option closing price. By conducting experiments on companies from the NIFTY 50 index using ChatGPT-3.5, ChatGPT-4, and LLaMA 3.1, we show that our method achieves superior prediction accuracy compared to other similar approaches. The paper develops a new framework to improve the valuation of short-term stock options using advanced natural language processing behaviors afforded by LLMs to achieve a more holistic capture of market dynamics and sentiment in option pricing.",Financial Markets; Short-term Options; Option Valuation; Large Language Models; ChatGPT-3.5; ChatGPT-4; LLaMA 3.1; Bullish Prediction; Bearish Prediction; NIFTY50; Sentiment Analysis; Risk Management,WoS
WOS:001480260000001,10.1109/TCSS.2025.3557911,Enhancing Hybrid Bike-Sharing Systems Through Long-Term Inventory Management: A Generative-Model-Informed Reinforcement Learning Approach,"Hybrid bike-sharing systems (operating both bikes and ebikes) are emerging worldwide for flexibility and sustainability. Excessive rebalancing, while addressing supply-demand imbalances, causes financial burdens and resource waste. Hence, long-term daily operations (e.g., rebalancing at midnights for upcoming days) have practical economic significance, but they remain underexplored due to difficulties in tracking high within-day and between-day demand variability and the interplay between demand and daily inventory management strategies. Besides, cooperative operation of bikes and ebikes expands solution space, given their inherent demand coupling. This study is the first to explore long-term daily inventory strategies for the hybrid system (ebikes get charged at stations), determining spatial-heterogeneous inventory at midnight to maximize profits. To address the demand variability perception issue, we develop a recurrent-attentive neural process (RANP) model to predict hour-to-hour demand of the upcoming day. The RANP is integrated into a long-term optimization model, referred to as the generative-models-informed Markov decision process (GMI-MDP), where two cooperative intelligent agents determine the bike-ebike allocation based on demand perception and system rewards. A suite of numerical experiments utilizing a real-world dataset from New York is carried out, and various strategies are compared. The proposed method, through online and offline tests, demonstrates superiority over other MDP-based and rule-based methods, achieving a faster solution-seeking process and more stable rewards than MDP with exact upcoming demand. By comparing inventory volatility, we offer insights into managerial operations.",Predictive models; Inventory management; Vehicle dynamics; Resource management; Hybrid power systems; Heuristic algorithms; Shared transport; Electronic mail; Training; Systems operation; Bike-ebike allocation; generative models; long-term management; Markov decision process (MDP),WoS
WOS:001417473700002,10.12720/jait.16.1.12-20,Initial Coin Offerings Success Prediction Using Social Media and Large Language Models,"Coin Offering (ICO) is a fundraising method utilized by blockchain startups to raise capital by issuing and selling digital tokens to investors. ICOs have become widely popular for cryptocurrency fundraising, often generating millions of dollars, and surpassing traditional crowdfunding methods like Initial Public Offerings. However, ICO is a risky way of investing and raising capital due to the lack of regulations and standardisation. In this research, we delve into the impact of social media and sentiment analysis on the success of ICOs, employing various machine learning models and Large Language Models. Our analysis is based on data from over 1,000 ICOs gathered from diverse ICO information platforms, coupled with a corpus of 910,478 tweets associated with these ICOs. We extend our investigation to include other social media platforms such as BitcoinTalk, Telegram, Facebook, and Medium. Our analysis revealed that valuable insights regarding the success of ICOs can be derived by examining text sentiment and investigating metadata across these diverse social media channels.",token sales; web scraping; sentiment analysis; social media; Bidirectional Encoder Representations from; Transformers (BERT),WoS
WOS:001556876600058,10.1109/CNIOT65435.2025.11070984,Incorporating related stock and text for stock price movement prediction based on information fusion,"Investors have long been concerned with the analysis of textual information related to target stocks when making stock investments. We collected and extracted stock news headlines from the Chinese stock market and utilized a Large Language Model (LLM) to identify stocks related to the target stock and the relationships among them. Based on these relationships, we constructed a related stock relationship graph. Considering the dynamic changes in the relationship weights between stocks, we employed Graph Attention Networks (GAT) to build a feature fusion model for integrating the features of related stock news. Factors influencing prediction were considered, including different methods of text concatenation, the identification of related stocks, the relationship modeling between related stocks, and the fusion of related stock features. A comparative analysis of the Long Short-Term Memory (LSTM) model, the Bidirectional Long Short-Term Memory (Bi-LSTM) model, and the Long Short-Term Memory with Attention (LSTM-Attention) model revealed that both the news headlines of the target stock and the related stocks, along with their relationships, impact stock price movement prediction. Conversely, ignoring feature fusion and textual feature extraction can negatively affect prediction accuracy.",LLM; GAT; fusion model; stock price movement prediction; LSTM,WoS
WOS:001502658900017,,Using Large Language Models to Estimate Novel Risk: Impact on Volatility,"This article presents an integrated framework to estimate hard to measure (novel) financial risk for volatility forecasting. Recognizing the limitations of traditional models-which often overlook emerging ""novel risks""-the article leverages advanced large language models (LLMs) to extract and quantify key risk factors, including ESG, geopolitical, and supply chain disruption risks, from corporate disclosures. These LLM-derived risk scores are then combined with conventional financial indicators such as leverage, beta, and short interest, and incorporated into a long short-term memory (LSTM) neural network to predict firm-specific (idiosyncratic) volatility. Empirical analysis, conducted on over 18,000 regulatory filings spanning 2015 to 2024, demonstrates that the integrated model significantly improves volatility forecasting, as evidenced by enhanced R2 values and reduced mean squared error. Additionally, feature importance analyses confirm the pivotal role of novel risk measures. Overall, the findings underscore the benefits of merging unstructured and hard to quantify data with quantitative models to offer a more nuanced approach to estimation of novel financial risk.",,WoS
WOS:001480988900009,10.1109/CIFER64978.2025.10975739,Leveraging Large Language Models and Retrieval-Augmented Generation for Enhanced Multi-Asset Portfolio Construction,"This study assesses the Large Language Models (LLMs) in creating investment portfolios. We implement a few-shot learning technique, followed by Retrieval Augmented Generation (RAG) enhanced with comprehensive up-to-date financial data, using Meta's latest LLM, Llama 3.1-8b. In the first phase, We assess the models' efficacy using key financial indicators, including total returns, annualized volatility, riskadjusted performance (Sharpe ratio), potential loss estimates (value-at-risk), and their pre-training knowledge with the S&P 500 Index performance baseline. In the second phase, we enhance the LLM's knowledge base by RAG and the latest historical and statistical metrics (such as earnings per share (EPS), dividends per share (DPS), profit margin, and many more) for each asset from different classes. The study constrains model inputs to specific sets of financial assets, such as equities, exchange-traded funds (ETFs), commodities, cryptocurrencies, and bonds. To evaluate model performance and adaptability, we analyzed across two distinct time frames: (1) within the models' training data cutoff, and (2) from the cutoff date to the present. This approach enables the assessment of model generalization to past and present market conditions. The research quantifies LLMs' capabilities in financial asset allocation, comparing baseline performance against RAG-augmented strategies. Our results demonstrate that RAG-enhanced LLM significantly outperforms vanilla LLM in portfolio construction across various asset classes. We contemplate that these results could influence AI-driven financial decision-making processes such as automated trading, real-time sentiment analysis, and investment management.",Generative AI; Computational Finance; Asset Allocation; Large Language Models; Llama; Portfolio management,WoS
WOS:000766749800005,10.5817/MB2021-2-5,Generating Genre-Specific Musical Transcriptions of Antonin Dvorak through a Variational Autoencoder,"Apart from traditional deep learning tasks such as pattern recognition, stock price prediction, and machine translation, this method also finds practical application within algorithmic composition. This paper explores the use of a generative model based on unsupervised learning of a musical style from a pre-selected corpus and the subsequent prediction of samples from the estimated distribution. The model uses a Long Short-Term Memory neural network whose training data contains genre-specific melodies in symbolic representation.",algorithmic composition; artificial intelligence; autoencoder; deep learning; generative art; LSTM network; machine learning; recurrent neural network,WoS
WOS:001142853500001,10.1016/j.eswa.2023.122952,Stock market forecasting using DRAGAN and feature matching,"Applying machine learning methods to forecast stock prices has been a topic of interest in recent years. However, a few studies have been reported based on generative adversarial networks (GANs) in this area, but their results are promising. While GANs are powerful generative models successfully applied in different areas, they suffer from inherent challenges such as training instability and mode collapse. Another primary concern is capturing correlations in stock prices. Therefore, the main challenges fall into two categories: capturing correlations and addressing the inherent problems of GANs. In this paper, we introduce a novel framework based on DRAGAN1 and feature matching for stock price forecasting, which improves training stability and alleviates mode collapse. We employ windowing to acquire temporal correlations by the generator and exploit conditioning on discriminator inputs to capture temporal correlations and correlations between prices and features. Experimental results on data from several stocks indicate that proposed method outperforms long short-term memory (LSTM) as a baseline method, as well as basic GANs and WGAN-GP2 as two different variants of GANs.",Stock price prediction; Time series forecasting; Generative Adversarial Networks; Feature matching,WoS
WOS:001349725700001,10.1109/ACCESS.2024.3488363,Leveraging LLMs for Financial News Analysis and Macroeconomic Indicator Nowcasting,"Approximating macroeconomic indicators is challenging due to the complex interaction of various factors, including global and national economic trends, political decisions, and unpredictable events like pandemics and natural disasters. These complexities, combined with the volatility of economies and the limitations of available data, make accurate modeling difficult. Sentiment analysis of economic news offers a novel approach to this challenge by providing instantaneous insights into public mood and market trends, capturing psychological and behavioral aspects that traditional models may miss. This method can enhance understanding of consumer confidence, investment trends, and stock market performance, for instance. In this study, we developed a dictionary and transformer-based sentiment model applied to over two decades of Hungarian economic news. To improve the model's accuracy, we utilized large language models (LLMs) with active learning to efficiently augment the manually labeled sentiment dataset. We then compared the resulting sentiment-based time series with macroeconomic indicators such as GDP (Gross Domestic Product), PMI (Purchasing Managers' Index), and unemployment rate. Our results show that integrating LLMs significantly enhances the accuracy of the sentiment models, and the sentiment-based indicators can serve as effective nowcasting tools for the inspected macroeconomic indicators.",Biological system modeling; Macroeconomics; Economics; Transformers; Analytical models; Data models; Sentiment analysis; Predictive models; Market research; Encoding; GDP; large language model (LLM); macroeconomic indicator; natural language processing (NLP); PMI; sentiment analysis; unemployment rate,WoS
WOS:001529393500012,10.1016/j.eswa.2025.128676,In the beginning was the Word: LLM-VaR and LLM-ES,"This study introduces LLM-VaR and LLM-ES, novel risk estimation metrics that utilize general-purpose large language models (LLMs) for the forecasting tasks of Value at Risk (VaR) and Expected Shortfall (ES) in a zero-shot setting. Building on the input encoding mechanism of the LLMTime framework, we extend its application by defining new financial risk measures and performing an empirical evaluation of three generations of GPT models, GPT-3.5, GPT-4 and GPT-4o, versus advanced benchmark models such as GARCH with Student innovations and EWMA with Dynamic Conditional Score (DCS). Financial time series are encoded as numerical strings, allowing for model-free inference without requiring retraining. Results show that LLMs perform well when short rolling windows are used, particularly in volatile markets like cryptocurrencies. GPT-3.5 frequently outperforms or matches the performance of newer models, raising questions about model complexity, alignment, and biases. In contrast, performance deteriorates with longer windows, where the econometric models prove more reliable. Our findings demonstrate the potential of general-purpose LLMs as adaptive tools for short-horizon financial risk assessment and contribute a first-of-its-kind benchmark for LLM-based VaR/ES estimation.",Value at risk; Expected shortfall; GPT; LLM-VaR; LLM-ES; Large language models,WoS
WOS:001542110000002,10.1016/j.econlet.2025.112511,Finfluencer recommendations,"Using a novel dataset of videos posted by prominent Financial YouTubers in India, we analyse the factors affecting Financial Influencers' stock recommendations. Our findings reveal that finfluencers are more likely to positively recommend stocks with strong past performance and high trading volumes, valuations and intraday activity. Additionally, the number of recommendations made by finfluencers predicts future stock returns.",Social media; YouTube; India; Finfluencers; Asset-pricing; Large language models,WoS
WOS:001496348300001,10.3390/math13101599,MambaLLM: Integrating Macro-Index and Micro-Stock Data for Enhanced Stock Price Prediction,"Accurate stock price prediction requires the integration of heterogeneous data streams, yet conventional techniques struggle to simultaneously leverage fine-grained micro-stock features and broader macroeconomic indicators. To address this gap, we propose MambaLLM, a novel framework that fuses macro-index and micro-stock inputs through the synergistic use of state-space models (SSMs) and large language models (LLMs). Our two-branch architecture comprises (i) Micro-Stock Encoder, a Mamba-based temporal encoder for processing granular stock-level data (prices, volumes, and technical indicators), and (ii) Macro-Index Analyzer, an LLM module-employing DeepSeek R1 7B distillation-capable of interpreting market-level index trends (e.g., S&P 500) to produce textual summaries. These summaries are then distilled into compact embeddings via FinBERT. By merging these multi-scale representations through a concatenation mechanism and subsequently refining them with multi-layer perceptrons (MLPs), MambaLLM dynamically captures both asset-specific price behavior and systemic market fluctuations. Extensive experiments on six major U.S. stocks (AAPL, AMZN, MSFT, TSLA, GOOGL, and META) reveal that MambaLLM delivers up to a 28.50% reduction in RMSE compared with suboptimal models, surpassing traditional recurrent neural networks and MAMBA-based baselines under volatile market conditions. This marked performance gain highlights the framework's unique ability to merge structured financial time series with semantically rich macroeconomic narratives. Altogether, our findings underscore the scalability and adaptability of MambaLLM, offering a powerful, next-generation tool for financial forecasting and risk management.",time series forecasting; stock price prediction; Mamba; large language model,WoS
WOS:000682772902030,,Probabilistic Analysis of Market Impact of Analysts' Recommendation Revisions,"In this paper, we propose to model the short-term impact of recommendation revisions on stock price movements in probabilistic framework. Through the Bayesian models, we can consolidate the information of all analysts' recommendations on stocks and predict the post-recommendation price drifts of the underlying stocks. In addition, typically there are only a small number of recommendation revisions on specific stocks on each day. It implies that other analysts' views to a specific stock are unobservable. With the advantage of generative models, missing observations in the data of recommendation revisions can be accommodated easily. Secondly, we perform an empirical investigation of the Hong Kong equity market and find that the impact of recommendation revisions on stock prices is significant in the 1-day horizon, but insignificant in the longer time horizon when taking account of the transaction costs. Also, we propose trading strategies derived from the posterior probability of directions of price drifts based on the Bayesian models. In our experiment, during the out-of-sample period (1 Jan, 2019 to 21 Feb, 2020), the trading strategies gain double-digit profit returns after transaction costs.",Bayesian; analyst recommendations; machine learning; trading strategy,WoS
WOS:001384143500001,10.3390/app142411897,Large Language Models and the Elliott Wave Principle: A Multi-Agent Deep Learning Approach to Big Data Analysis in Financial Markets,"Traditional technical analysis methods face limitations in accurately predicting trends in today's complex financial markets. Meanwhile, existing AI-driven approaches, while powerful in processing large datasets, often lack interpretability due to their black-box nature. This paper presents ElliottAgents, a multi-agent system that combines the Elliott wave principle with LLMs, showcasing the application of deep reinforcement learning (DRL) and natural language processing (NLP) in financial analysis. By integrating retrieval-augmented generation (RAG) and deep reinforcement learning (DRL), the system processes vast amounts of market data to identify Elliott wave patterns and generate actionable insights. The system employs a coordinated team of specialized agents, each responsible for specific aspects of analysis, from pattern recognition to investment strategy formulation. We tested ElliottAgents on both stock and cryptocurrency markets, evaluating its effectiveness in pattern identification and trend prediction across different time scales. Our experimental results demonstrate improvements in prediction accuracy when combining classical technical analysis with AI-driven approaches, particularly when enhanced by DRL-based backtesting process. This research contributes to the advancement of financial technology by introducing a scalable, interpretable framework that enhances market analysis capabilities, offering a promising new methodology for both practitioners and researchers.",multi-agent systems; Elliott wave principle; large language models (LLMs); investment strategies; deep reinforcement learning (DRL); financial markets,WoS
WOS:001497934400018,10.1145/3672608.3707874,Deep Generative Calibration on Stochastic Volatility Models with Applications in FX Barrier Options,"This paper proposes a two-step approach to efficiently calibrate the stochastic models for the foreign exchange (FX) barrier options by utilising the predictive and generative power of machine learning. To tackle the limited availability of market prices from brokers, we propose a framework to first augment the model parameters via a generative model, the Variational Autoencoder Generative Adversarial Network (VAE-GAN) model, and then calibrate the model parameters with neural networks to approximate the mapping between synthetic market data and model parameters. In this work, we examine the performance of our two-step calibration approach by comparing it with the traditional calibration process in terms of robustness and efficiency. We evaluate our calibration using two performance metrics employed by major financial institutions. The results indicate that our method not only speeds up the calibration process from hours to seconds but also increases the variety of the dataset, covering a broader range of market conditions. Finally, we use the values output by our calibration method as initial values in the traditional calibrator. This approach helps the traditional calibrator achieve optimal parameters by either improving running time or the quality of the solutions, resulting in a closer match between the model-implied prices and the market prices.",Generative Models; Variational Autoencoder; Generative adversarial network; Stochastic Local Volatility Models; Financial Model Calibration,WoS
WOS:001382641900011,,Large Language Models for Financial and Investment Management: Applications and Benchmarks,"The rapid evolution and unprecedented advancements in large language models (LLMs) have ushered in a new era of innovation in the realm of machine learning, with far-reaching implications for the finance and investment management sectors. These models have exhibited remarkable prowess in contextual understanding, processing vast and complex datasets, and generating content that aligns closely with human preferences. The transformative potential of LLMs in finance has catalyzed a surge of research and applications. As the integration of LLMs into financial practices continues to accelerate, there is an urgent need for a systematic examination of their diverse applications, methodologies, and impact, which necessitates a comprehensive review and synthesis of recent developments in this rapidly evolving field. This article aims to bridge the gap between cutting-edge artificial intelligence technology and its practical implementation in finance, providing a robust framework for understanding and leveraging LLMs in financial contexts. The authors explore the application of LLMs on various financial tasks, focusing on their potential to transform traditional practices and drive innovation. The article is highlighted for categorizing the existing literature into key application areas, including linguistic tasks, sentiment analysis, financial time series, financial reasoning, and agent-based modeling. For each application area, the authors delve into specific methodologies, such as textual analysis, knowledge-based analysis, forecasting, data augmentation, planning, decision support, and simulations. Furthermore, the article provides a comprehensive collection of datasets, benchmarks, and useful code associated with mainstream applications, offering valuable resources for researchers and practitioners. The authors hope their work can help facilitate the adoption and further development ofLLMs in finance and investment management.",,WoS
WOS:000615970408146,10.1109/icassp40776.2020.9053276,CORRGAN: SAMPLING REALISTIC FINANCIAL CORRELATION MATRICES USING GENERATIVE ADVERSARIAL NETWORKS,We propose a novel approach for sampling realistic financial correlation matrices. This approach is based on generative adversarial networks. Experiments demonstrate that generative adversarial networks are able to recover most of the known stylized facts about empirical correlation matrices estimated on asset returns. This is the first time such results are documented in the literature. Practical financial applications range from trading strategies enhancement to risk and portfolio stress testing. Such generative models can also help ground empirical finance deeper into science by allowing for falsifiability of statements and more objective comparison of empirical methods.,generative adversarial networks; correlation matrices; stock returns; random matrices; hierarchical clustering,WoS
WOS:001582925800001,10.1016/j.knosys.2025.114449,Enhancing large language models for bitcoin time series forecasting,"In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50% improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection.",Time series forecasting; Language models; Financial time series,WoS
WOS:001190209000001,10.1007/s10115-024-02085-8,Multi-factor stock price prediction based on GAN-TrellisNet,"Applying deep learning, especially time series neural networks, to predict stock price, has become one of the important applications in quantitative finance. Recently, some GAN-based stock prediction models are proposed, where LSTM or GRU is used as the generator. However, these generators lack the function of feature extraction, and the prediction accuracies are slightly low. Meanwhile, these models choose some simple volume-price factors (such as OCHLV and OCHLVC) as inputs, without considering the impact of other factors on stock prices. In order to solve these problems, a stock prediction method based on multiple factors and GAN-TrellisNet is proposed. Instead of ""OCHLV"" or ""OCHLVC,"" a multi-factor strategy with ""alpha158+OCHLVC"" is introduced to enrich the stock data of inputs. The proposed generative adversarial network (GAN) is a combination of two neural networks which are TrellisNet as generative model and convolutional neural network (CNN) as discriminative model for adversarial training to forecast the stock market. TrellisNet, which integrates the feature extraction capabilities of CNN and the temporal processing capabilities of recurrent neural network (RNN), will generate new predicted results based on historical data, and then CNN will distinguish between predicted results and real stock prices. In order to demonstrate the performance of our method, we selected the decade data of different stocks from four markets (A-shares, U.S. stocks, U.K. stocks and Hong Kong stocks) as dataset and conducted two groups of comparative experiments. Compared with the state-of-the-art methods based on GAN, our method has better performance in terms of MSE, MAE, RMSE and MAPE. In addition, the multi-factor strategy with ""alpha158+OCHLVC"" is more effective than the original strategy with OCHLVC factors.",Stock price prediction; Multi-factor strategy; Alpha158; OCHLVC; GAN; TrellisNet; CNN,WoS
WOS:001443057200067,10.1145/3677052.3698688,FinVision: A Multi-Agent Framework for Stock Market Prediction,"Financial trading has been a challenging task, as it requires the integration of vast amounts of data from various modalities. Traditional deep learning and reinforcement learning methods require large training data and often involve encoding various data types into numerical formats for model input, which limits the explainability of model behavior. Recently, LLM-based agents have demonstrated remarkable advancements in handling multi-modal data, enabling them to execute complex, multi-step decision-making tasks while providing insights into their thought processes. This research introduces a multi-modal multi-agent system designed specifically for financial trading tasks. Our framework employs a team of specialized LLM-based agents, each adept at processing and interpreting various forms of financial data, such as textual news reports, candle-stick charts, and trading signal charts. A key feature of our approach is the integration of a reflection module, which conducts analyses of historical trading signals and their outcomes. This reflective process is instrumental in enhancing the decision-making capabilities of the system for future trading scenarios. Furthermore, the ablation studies indicate that the visual reflection module plays a crucial role in enhancing the decision-making capabilities of our framework.",Large Language Models; Multi-Agent Framework,WoS
WOS:000488977300003,,MODELLING NON-STATIONARY FINANCIAL TIME SERIES WITH INPUT WARPED STUDENT T-PROCESSES,"The evolution of financial assets is known to be non-stationary and to present long tails and non-Gaussian. Gaussian processes are a flexible and general Bayesian nonparametric generative model that provide flexible priors on function spaces and interpretable uncertainty quantification. While GP are extremely flexible function approximators, their Gaussian marginal distribution makes them inappropriate to model financial assets returns distributions. We present the Student t-processes that are known to fit heavier tail. We also augment the model with input warping to account with the financial time series non stationarity. We present a case study of fitting the evolution of SP500 index stressing the importance of good uncertainty estimates, especially when the series manifests structural breaks.",Bayesian nonparametric; Student processes; Gaussian processes; stylized facts,WoS
WOS:001324524205008,10.1145/3637528.3671629,FNSPID: A Comprehensive Financial News Dataset in Time Series,"Financial market predictions utilize historical data to anticipate future stock prices and market trends. Traditionally, these predictions have focused on the statistical analysis of quantitative factors, such as stock prices, trading volumes, inflation rates, and changes in industrial production. Recent advancements in large language models motivate the integrated financial analysis of both sentiment data, particularly market news, and numerical factors. Nonetheless, this methodology frequently encounters constraints due to the paucity of extensive datasets that amalgamate both quantitative and qualitative sentiment analyses. To address this challenge, we introduce a large-scale financial dataset, namely, Financial News and Stock Price Integration Dataset (FNSPID). It comprises 29.7 million stock prices and 15.7 million time-aligned financial news records for 4,775 S&P500 companies, covering the period from 1999 to 2023, sourced from 4 stock market news websites. We demonstrate that FNSPID excels existing stock market datasets in scale and diversity while uniquely incorporating sentiment information. Through financial analysis experiments on FNSPID, we propose: (1) the dataset's size and quality significantly boost market prediction accuracy; (2) adding sentiment scores modestly enhances performance on the transformer-based model; (3) a reproducible procedure that can update the dataset. Completed work, code, documentation, and examples are available at github.com/Zdong104/FNSPID. FNSPID offers unprecedented opportunities for the financial research community to advance predictive modeling and analysis.",Financial Market Prediction; Sentiment Analysis; Time Series; Machine Learning; Financial Dataset,WoS
WOS:000722981800002,10.1007/s11042-021-11670-w,Generative adversarial network (GAN) and enhanced root mean square error (ERMSE): deep learning for stock price movement prediction,"The prediction of stock price movement direction is significant in financial circles and academic. Stock price contains complex, incomplete, and fuzzy information which makes it an extremely difficult task to predict its development trend. Predicting and analysing financial data is a nonlinear, time-dependent problem. With rapid development in machine learning and deep learning, this task can be performed more effectively by a purposely designed network. This paper aims to improve prediction accuracy and minimizing forecasting error loss through deep learning architecture by using Generative Adversarial Networks. It was proposed a generic model consisting of Phase-space Reconstruction (PSR) method for reconstructing price series and Generative Adversarial Network (GAN) which is a combination of two neural networks which are Long Short-Term Memory (LSTM) as Generative model and Convolutional Neural Network (CNN) as Discriminative model for adversarial training to forecast the stock market. LSTM will generate new instances based on historical basic indicators information and then CNN will estimate whether the data is predicted by LSTM or is real. It was found that the Generative Adversarial Network (GAN) has performed well on the enhanced root mean square error to LSTM, as it was 4.35% more accurate in predicting the direction and reduced processing time and RMSE by 78 s and 0.029, respectively. This study provides a better result in the accuracy of the stock index. It seems that the proposed system concentrates on minimizing the root mean square error and processing time and improving the direction prediction accuracy, and provides a better result in the accuracy of the stock index.",Stock market prediction; Phase-space reconstruction; Generative adversarial networks; Deep learning,WoS
WOS:001319989300001,10.1080/14697688.2024.2396977,FuNVol: multi-asset implied volatility market simulator using functional principal components and neural SDEs,"We introduce a new approach for generating sequences of implied volatility (IV) surfaces across multiple assets that are faithful to historical prices. We do so using a combination of functional data analysis and neural stochastic differential equations (SDEs) combined with a probability integral transform penalty to reduce model misspecification. We demonstrate that learning the joint dynamics of IV surfaces and prices produces market scenarios that are consistent with historical features and lie within the sub-manifold of surfaces that are essentially free of static arbitrage. Finally, we demonstrate that delta hedging using the simulated surfaces generates profit and loss (P&L) distributions that are consistent with realized P&Ls.",Generative models; Neural SDEs; Functional data analysis; Implied volatility,WoS
WOS:000877409000003,10.1007/s10994-022-06250-4,Lead-lag detection and network clustering for multivariate time series with an application to the US equity market,"In multivariate time series systems, it has been observed that certain groups of variables partially lead the evolution of the system, while other variables follow this evolution with a time delay; the result is a lead-lag structure amongst the time series variables. In this paper, we propose a method for the detection of lead-lag clusters of time series in multivariate systems. We demonstrate that the web of pairwise lead-lag relationships between time series can be helpfully construed as a directed network, for which there exist suitable algorithms for the detection of pairs of lead-lag clusters with high pairwise imbalance. Within our framework, we consider a number of choices for the pairwise lead-lag metric and directed network clustering model components. Our framework is validated on both a synthetic generative model for multivariate lead-lag time series systems and daily real-world US equity prices data. We showcase that our method is able to detect statistically significant lead-lag clusters in the US equity market. We study the nature of these clusters in the context of the empirical finance literature on lead-lag relations, and demonstrate how these can be used for the construction of predictive financial signals.",High-dimensional time series; Unsupervised learning; Lead-lag; Clustering; Financial markets; Directed networks; Flow imbalance,WoS
WOS:001443057200095,10.1145/3677052.3698684,Transformers and attention-based networks in quantitative trading: a comprehensive survey,"Since the advent of the transformer neural network architecture, there has been a rapid adoption and investigation of its applicability in various domains, such as computer vision, speech processing, and natural language processing, with the latter most notably exemplified by the rise of Large Language Models. These accomplishments have also led to increased interest in other network architectures that rely on attention mechanisms, one of the building blocks of transformers. Transformers and other attention-based networks are being applied to the quantitative analysis, management, and trading of financial assets, be it for price movement prediction, discovery of trading strategies, portfolio optimization, and risk management. The applications range across different asset categories, including equity markets, foreign exchange pairs, cryptocurrencies, and futures markets. This survey aims to provide a comprehensive overview of the applications of attention-based networks within the field of quantitative analysis, management, and trading of financial assets. After a brief overview of transformers and attention mechanisms, we analyze the existing applications of these architectures for quantitative finance in a taxonomy of four specializations: Alpha Seeking, Risk Management, Portfolio Construction, and Execution. After comparing the literature in light of the research problems, modeling approaches, and complementary results, we discuss current challenges and research opportunities.",Quantitative trading; Machine Learning; Transformers,WoS
WOS:000344632400012,10.1214/14-AOS1250,ESTIMATING TIME-CHANGES IN NOISY LEVY MODELS,"In quantitative finance, we often model asset prices as a noisy Ito semimartingale. As this model is not identifiable, approximating by a time-changed Levy process can be useful for generative modelling. We give a new estimate of the normalised volatility or time change in this model, which obtains minimax convergence rates, and is unaffected by infinite-variation jumps. In the semimartingale model, our estimate remains accurate for the normalised volatility, obtaining convergence rates as good as any previously implied in the literature.",Ito semimartingale; Levy process; microstructure noise; volatility; time-change,WoS
WOS:001226314400008,10.1109/MSEC.2024.3385549,Degenerative AI?,"It is not secret that generative AI, especially in the form of large language models (LLMs), is extremely popular today. One might go so far as to say that it's eaten the world. It may be a bubble, or it may last-though the death of cryptocurrencies has long been predicted, as I write this Bitcoin has just reached an all-time high value against the American dollar-but for now and at least the next few years, generative AI will be with us. As people who care about security and privacy, we need to understand the implications of it: is it good or bad for our field, and if the latter, what should we do about it? Ignoring it is not an option.",,WoS
WOS:000996387100005,10.7717/peerj-cs.1377,Evaluation of transformer models for financial targeted sentiment analysis in Spanish,"Nowadays, financial data from social media plays an important role to predict the stock market. However, the exponential growth of financial information and the different polarities of sentiment that other sectors or stakeholders may have on the same information has led to the need for new technologies that automatically collect and classify large volumes of information quickly and easily for each stakeholder. In this scenario, we conduct a targeted sentiment analysis that can automatically extract the main economic target from financial texts and obtain the polarity of a text towards such main economic target, other companies and society in general. To this end, we have compiled a novel corpus of financial tweets and news headlines in Spanish, constituting a valuable resource for the Spanish-focused research community. In addition, we have carried out a performance comparison of different Spanish-specific large language models, with MarIA and BETO achieving the best results. Our best result has an overall performance of 76.04%, 74.16%, and 68.07% in macro F1-score for the sentiment classification towards the main economic target, society, and other companies, respectively, and an accuracy of 69.74% for target detection. We have also evaluated the performance of multi-label classification models in this context and obtained a performance of 71.13%.",Sentiment analysis; Natural language processing; Financial domain; Targeted sentiment analysis,WoS
WOS:001454654900001,10.1093/rof/rfaf015,"CEO turnover, sequential disclosure, and stock returns","We document that firms experience large negative stock returns during, and positive returns following, the first informational events after forced CEO turnovers. This V-shaped return pattern is driven by the strategic sequential disclosure of bad news and good news, aligned with incoming CEOs' incentives to manage expectations. The pattern is more pronounced when these incentives are stronger, such as when firms earn higher stock returns and have higher valuation uncertainty leading up to the informational events. Evidence from firms' earnings surprises, analysts' forecast revisions, and large language model-based measures of disclosure behavior indicates that incoming CEOs often initially release bad news about realized and short-term earnings, projecting a broadly pessimistic outlook for the firm's future performance, and subsequently disclose favorable news about longer-term earnings prospects. Our findings suggest that investors make the costly mistake of failing to discern the incentives behind managers' disclosure.",CEO turnover; stock returns; expectation management; G12; G14; M12; D84,WoS
WOS:001543110200001,10.1007/s10844-025-00971-3,From news to trends: a financial time series forecasting framework with LLM-driven news sentiment analysis and selective state spaces,"Stock price prediction is inherently challenging due to market volatility and the influence of external factors. Traditional forecasting methods primarily rely on historical price data, limiting their ability to capture market sentiment embedded in financial news. To address this limitation, we propose MambaMoE, a novel model that integrates historical stock prices with sentiment information extracted from financial news. Specifically, we fine-tune a DeepSeek-based large language model (LLM) for financial sentiment classification and incorporate the extracted sentiment information into our predictive framework. At the core of our approach is MambaMoE layer, which leverages the efficiency of state space models (SSMs) to model long-range dependencies while maintaining linear computational complexity, making it well-suited for financial time series forecasting. Additionally, the Mixture of Experts (MoE) mechanism improves the model's ability to capture diverse market behaviors by dynamically selecting specialized experts based on stock data patterns. Experimental results demonstrate that MambaMoE outperforms LSTM-based models by 23.7% and Transformer-based models by 6.3%, highlighting its superior performance in short-term stock prediction.",Sentiment analysis; Time series forecasting; Mamba; LLM,WoS
WOS:001161549502037,10.1145/3583780.3614886,Follow the Will of the Market: A Context-Informed Drift-Aware Method for Stock Prediction,"The dynamic nature of stock market styles, referred to as concept drift, poses a formidable challenge when applying deep learning to stock prediction. Models trained on historical data often struggle to adapt to the latest market styles, as the patterns they have learned may no longer hold true over time. To alleviate this issue, the recently popularized concept of In-Context learning has provided us with valuable insights. In this approach, large language models (LLMs) are exposed to multiple examples of input-label pairs, also known as demonstrations, as part of the prompt before performing a task on an unseen example. By thoroughly analyzing these demonstrations, LLMs can uncover potential patterns and effectively adapt to new tasks. Building upon this concept, we propose a Context-Informed drift-aware method for Stock Prediction (CISP), which continually adjusts to the latest market styles and offers more accurate predictions. Our proposed method consists of two key parts. Firstly, we introduce a straightforward and efficient technique for designing demonstrations that aggregate current market information, thereby indicating the prevailing stock market style. Secondly, we incorporate a prediction module with dynamic parameters, allowing it to appropriately adjust its model parameters based on the market patterns embedded in the aforementioned demonstrations. Through extensive experiments conducted on real-world stock market datasets, our approach consistently outperforms the most advanced existing methods for stock prediction.",Stock Prediction; Context-Informed; Drift-Aware,WoS
WOS:001551945700001,10.1016/j.egyai.2025.100562,Toward profitable energy futures trading strategies using reinforcement learning incorporating disagreement and connectedness methods enabled by large language models,"The energy market plays a fundamental role in the global economy, shaping energy prices, inflation, and financial stability across nations. As the world transitions toward low-carbon energy solutions, optimizing trading strategies in this complex and dynamic market has become increasingly critical for investors, policymakers, and energy brokers. Traditional data-driven models often struggle to capture the multifaceted and interconnected factors influencing energy markets, such as macroeconomic conditions, investor sentiment, and the accelerating shift toward decarbonization. To address these challenges, a novel framework is proposed that combines reinforcement learning with methods for analyzing disagreement and connectedness, alongside advanced natural language processing techniques, to develop trading strategies for energy markets. The proposed method integrates structured time-series data with unstructured textual data to incorporate diverse factors, including the interplay between economic influences, green energy transitions, and investor sentiment. The proposed framework also employs a chain-of-reasoning technique to classify investor types, distinguishing between sentiment-driven disagreement and cross-disagreement, and utilizes a connectedness-based method to model the interrelationships among market variables, providing a comprehensive understanding of market dynamics. As a showcase, this framework is applied to the West Texas Intermediate crude oil market, demonstrating its ability to outperform traditional price-prediction-based trading strategies. Experimental results highlight that the proposed framework delivers superior investment returns while addressing key limitations of existing models in terms of data integration and flexibility. This study underscores the potential of the proposed framework as a robust and adaptable solution for optimizing trading strategies across the broader energy market, with particular relevance to the global transition toward sustainable energy systems.",Energy market; Energy future; Reinforcement learning; Large language models; Investor disagreement; Connectedness analysis,WoS
WOS:001503391700001,,"Comparing Vision-Instruct LLMs, Vision-Based Deep Learning, and Numeric Models for Stock Movement Prediction","This research conducts a comparative study of several stock movement prediction approaches, evaluating large language models (LLMs) and vision-based deep learning models with stock image as input, as well as models that utilize numerical data. Specifically, the study investigates a prompt-based LLM framework that processes candlestick charts, comparing its performance with image-based models such as MobileNetV2, Vision Transformer, and Convolutional Neural Network (CNN), as well as models with numerical inputs including Support Vector Machine (SVM), Random Forest, LSTM, and CNN-LSTM. Although LLMs have demonstrated promising results in stock prediction, directly applying them to stock images poses challenges compared to numerical approaches. To address this, this study further improves LLM performance with post-hoc calibration, reducing prediction biases. Experimental results demonstrate that post-hoc calibrated LLMs with visual input achieve competitive performance compared to other models, highlighting their potential as a viable alternative to traditional stock prediction methods while simplifying the prediction process.",Convolutional Neural Network (CNN); Large Lan-guage Model (LLM); MobileNetV2; stock price prediction; time series forecasting; vision transformer,WoS
WOS:001552739700001,10.1007/s11063-025-11787-1,Detecting Bitcoin Sentiment: Leveraging Language Model Applications in Sentiment Analysis for Bitcoin Price Prediction,"As Bitcoin continues to establish itself as a global asset and discussions around relevant regulations become more active, there is an increasing demand for a comprehensive price prediction framework. To address this necessity, this study aims to enhance the accuracy of Bitcoin price predictions by integrating sentiment information with technical indicators, on-chain data, and cryptocurrency price data. Recognizing Bitcoin's sensitivity to market sentiment, the proposed framework incorporates sentiment features derived from both lexicon-based methods and large language models. As unsupervised sentiment tools can introduce label noise particularly in domain-specific or ambiguous financial contexts, this study combines the outputs of multiple sentiment models at the feature level to construct a more stable representation. This design improves the robustness of downstream regression performance and distinguishes the framework from previous hybrid models that relied on a single sentiment source without component-wise evaluation. Experimental results using a dataset spanning 2700 days showed that the long short-term memory (LSTM) model with a 3-day window achieves the best performance with mean absolute percentage error (MAPE) of 3.93% and R-squared value of 0.99106. Feature importance analysis further demonstrates sentiment index as the most impactful feature, as excluding it resulted in the largest decline in predictive accuracy. Additionally, the model's performance was evaluated under four major volatility periods, revealing MAPE values ranging from 1.49 to 4.03%, highlighting the framework's practical capability in rapidly adapting to sudden market shifts. In summary, integrating sentiment information attained from multiple language models significantly enhanced prediction accuracy compared to single source approaches. These findings highlight the framework's practical value for sentiment-informed investment strategies and risk alerts, with a modular design that enables flexible adaptation and potential integration into automated trading systems.",Large language models; Sentiment analysis; Time series analysis; Bitcoin; Price prediction,WoS
WOS:000800532000005,10.1109/SMC52423.2021.9659283,Stock Price Prediction Using Sentiment Analysis,"We investigate the influence of financial news headline sentiment on the predictability of stock prices using Long Term Short Term Memory (LSTM) networks. The investigation is performed on intraday data with specific lag-times between published article headlines and realised stock prices. FinBERT, a natural language processing model which is fine-tuned specifically for financial news is used to perform sentiment analysis on the company related news headlines. Two base models, one with only historical stock price data as inputs and the other with both historical stock price data and sentiment data from the original BERT model is tested. An alternative model with have both historical stock price data and sentiment data from the fine tuned FinBERT model as additional features. A comparison is performed on both the base and alternative models using Root Mean Square Error (RMSE) and mean absolute error (MAE) as performance metrics. The results suggest that the use of news headline sentiment features from FinBERT significantly improve the predictive performance of LSTM networks in intraday stock price prediction. FinBERT features are also found to outperform features based BERT model trained on a general corpus, illustrating the positive effect of domain specific fine tuning for Large Language models.",FinBERT; language model; sentiment analysis; prediction; LSTM,WoS
WOS:001541419200001,10.1080/15427560.2025.2538879,Intraday Stock Prediction Using Sentiment Analysis: Evidence from Dividend Announcements,"This study explores whether sentiment extracted from financial news using large language models (LLMs) can predict abnormal intraday stock returns following dividend announcements. Drawing on 4,682 news items linked to 1,258 announcements from 394 S&P 500 companies (January 2023-January 2024), we use ChatGPT to extract sentiment polarity scores and we apply different models to forecast cumulative abnormal returns (CARs) in 30-minute intervals. Our findings reveal that sentiment - especially when captured immediately after news releases - has significant predictive power over intraday price movements. Strategies based on ChatGPT-derived sentiment consistently outperform benchmark models, particularly within the first two hours of trading. These results remain robust across alternative specifications and placebo tests, highlighting the value of LLMs for real-time market prediction. This research advances the literature on sentiment analysis and behavioral finance by linking emotion-driven news interpretation to high-frequency trading performance.",Financial news; intraday trading; investment strategies; market reaction; sentiment analysis,WoS
WOS:001284942100029,10.1038/s41598-024-68959-7,Meta graphical lasso: uncovering hidden interactions among latent mechanisms,"In complex systems, it's crucial to uncover latent mechanisms and their context-dependent relationships. This is especially true in medical research, where identifying unknown cancer mechanisms and their impact on phenomena like drug resistance is vital. Directly observing these mechanisms is challenging due to measurement complexities, leading to an approach that infers latent mechanisms from observed variable distributions. Despite machine learning advancements enabling sophisticated generative models, their black-box nature complicates the interpretation of complex latent mechanisms. A promising method for understanding these mechanisms involves estimating latent factors through linear projection, though there's no assurance that inferences made under specific conditions will remain valid across contexts. We propose a novel solution, suggesting data, even from systems appearing complex, can often be explained by sparse dependencies among a few common latent factors, regardless of the situation. This simplification allows for modeling that yields significant insights across diverse fields. We demonstrate this with datasets from finance, where we capture societal trends from stock price movements, and medicine, where we uncover new insights into cancer drug resistance through gene expression analysis.",Graphical model; Graphical lasso; Latent factor; Stiefel manifolds,WoS
WOS:001341220800001,10.1080/14697688.2024.2399285,Path shadowing Monte Carlo,"We introduce a Path Shadowing Monte Carlo method, which provides the prediction of future paths, given any generative model. At any given date, it averages future quantities over generated price paths whose past history matches, or 'shadows', the actual (observed) history. We test our approach using paths generated from a maximum entropy model of financial prices, based on a recently proposed multi-scale analogue of the standard skewness and kurtosis called 'Scattering Spectra'. This model promotes the diversity of generated paths while reproducing main statistical properties of financial prices, including stylized facts such as volatility roughness. Our method yields state-of-the-art predictions for future realized volatility and allows one to determine conditional option smiles for the S&P500 that outperform both the most recent low-parametric models and the option market itself. The code is available at https://github.com/RudyMorel/shadowing (This work is supported by the PRAIRIE 3IA Institute of the French ANR-19-P3IA-0001 program and the ENS-CFM models and data science chair.).",Volatility prediction; Option pricing; Wavelets; G17; C02,WoS
WOS:001540598500049,10.2478/picbe-2025-0043,LLM-Driven Stock Prediction: Capturing Market Trends with LLaMA,"Stock price forecasting remains a challenging task due to the dynamic nature of financial markets and the influence of external factors such as investor sentiment and macroeconomic events. Traditional time series statistical models often struggle to capture complex nonlinear dependencies and market signals embedded in unstructured data. With advancements in Large Language Models (LLMs), it is now possible to integrate textual information from financial news, social media, and earnings reports to enhance predictive accuracy. In this study, we leverage the LLaMA family of LLMs to improve stock price forecasting by combining historical price with news. We evaluate the performance of LLaMA 3.3 against LLaMA 3.1 and the benchmark ARIMA model to assess its effectiveness in capturing time series patterns and textual signals. Our results indicate that LLaMA 3.3 outperforms both LLaMA 3.1 and ARIMA, demonstrating its superior capability in modeling complex financial relationships. Additionally, our analysis confirms that market sentiment has an impact on stock returns, with sentiments influencing short-term price fluctuations. By incorporating news sentiment in LLMs prompt, we achieve improved forecasts compared to models without news. This highlights the importance of integrating both structured (numerical time series) and unstructured (news sentiment) data for enhanced financial modeling. Our findings suggest that LLM-driven forecasting methods hold substantial promise for traders, analysts, and financial institutions seeking more accurate market predictions. Future work will explore fine-tuning LLaMA models for domain-specific financial tasks and improving interpretability in decision making processes.",LLMs; LLaMA; ARIMA; News Sentiment; Time series forecasting; Stock Price,WoS
WOS:000525556200013,10.1109/nysds.2019.8909804,Stacking with Neural Network for Cryptocurrency investment,"Predicting the direction of assets have been an active area of study and difficult task. Machine learning models have been used to build robust models to model the above task. Ensemble methods are one of them resulting better than single supervised method. We have used generative and discriminative classifiers to create the stack, particularly 3 generative and 6 discriminative classifiers and optimized over one-layer Neural Network to model the direction of price cryptocurrencies. Features used are technical indicators not limited to trend, momentum, volume, volatility indicators and sentiment indicators. For Cross validation, Purged Walk forward cross validation has been used. In terms of accuracy, we have done comparative analysis of the performance of Ensemble method with Stacking and individual models. We have also developed methodology for features importance for stacked model. Important indicators are identified based on feature importance.",Generative Models; Discriminative Models; Stacked Generalization; Xgboost; LightGBM; Bitcoin,WoS
WOS:001443057200009,10.1145/3677052.3698649,A Financial Time Series Denoiser Based on Diffusion Models,"Financial time series often exhibit low signal-to-noise ratio, posing significant challenges for accurate data interpretation and prediction and ultimately decision making. Generative models have gained attention as powerful tools for simulating and predicting intricate data patterns, with diffusion models emerging as particularly effective methods. This paper introduces a novel approach utilizing a diffusion model as a denoiser for financial time series in order to improve data predictability and trading performance. By leveraging the forward and reverse processes of a conditional diffusion model to add and remove noise progressively, we reconstruct original data from noisy inputs. Our extensive experiments demonstrate that diffusion model-based denoised time series significantly enhance the performance on downstream future return classification tasks. Moreover, trading signals derived from the denoised data yield more profitable trades with fewer transactions, thereby minimizing transaction costs and increasing overall trading efficiency. Finally, we show that by using classifiers trained on denoised time series, we can recognize how noisy the market is and obtain excess returns.",Financial Time Series; Diffusion Model; Denoising; Trading,WoS
WOS:001179937400001,10.1016/j.jedc.2024.104821,Dynamic CVaR portfolio construction with attention-powered generative factor learning,"The dynamic portfolio construction problem requires dynamic modeling of the joint distribution of multivariate stock returns. To achieve this, we propose a dynamic generative factor model which uses random variable transformation as an implicit way of distribution modeling and relies on the Attention-GRU network for dynamic learning and forecasting. The proposed model captures the dynamic dependence among multivariate stock returns, especially focusing on the tail -side properties. We also propose a two-step iterative algorithm to train the model and then predict the time -varying model parameters, including the time -invariant tail parameters. At each investment date, we can easily simulate new samples from the learned generative model, and we further perform CVaR portfolio optimization with the simulated samples to form a dynamic portfolio strategy. The numerical experiment on stock data shows that our model leads to wiser investments that promise higher reward -risk ratios and present lower tail risks.",Dynamic portfolio construction; Generative factor model; Attention-GRU network; Tail properties; CVaR portfolio optimization,WoS
WOS:000916595600002,10.1016/j.knosys.2022.108712,A self-regulated generative adversarial network for stock price movement prediction based on the historical price and tweets,"Stock price movement prediction is an important task of the financial prediction field. The current mainstream approaches usually apply financial texts and some corresponding stock price information to predict the stock price movement. However, the current methods usually suffer from two shortcomings: (1) To reduce the stochasticity in the stock price and financial text information, some researchers adopt generative models to better treat the stochasticity while enduring the overfitting problem during training. (2) Although the current state-of-the-art methods based on the generative adversarial network have been proposed to reduce the overfitting, they only concentrate on the overfitting problem of the stock price information and neglect the above problem of financial text information with higher stochasticity. In this paper, we propose a self-regulated generative adversarial network by combining the generative adversarial network and cooperative network for the stock price movement prediction. Furthermore, the proposed model can effectively reduce the stochasticity and overfitting problems simultaneously for the stock price and the financial text information. The experimental results on the currently commonly used stock dataset based on tweets confirm that the proposed method can achieve the novelly state-of-the-art performance compared with some current advances. (c) 2022 Elsevier B.V. All rights reserved.",Stock price movement prediction; Generative adversarial network; Pre-trained language model; Cooperative network,WoS
WOS:001515398300001,10.3390/e27060550,"Artificial Intelligence Models for Predicting Stock Returns Using Fundamental, Technical, and Entropy-Based Strategies: A Semantic-Augmented Hybrid Approach","This study examines the effectiveness of combining semantic intelligence drawn from large language models (LLMs) such as ChatGPT-4o with traditional machine-learning (ML) algorithms to develop predictive portfolio strategies for NASDAQ-100 stocks over the 2020-2025 period. Three different predictive frameworks--fundamental, technical, and entropy-based--are tested through examination of novel combinations of ML- and LLM-derived semantic metrics. The empirical results reveal a considerable divergence in optimal blending methods across the methodologies; namely, the technical methodology exhibits the best performance when using only ML predictions, with around 1978% cumulative returns with monthly rebalancing. In contrast, the fundamental methodology achieves its full potential when it is based primarily on LLM-derived semantic insights. The Entropy methodology is improved by a balanced combination of both semantic and ML signals, thus highlighting the potential of LLMs to improve predictive power by offering interpretative context for complex market interactions. These findings highlight the strategic importance of tailoring the semantic-algorithmic fusion to suit the nature of the predictive data and the investment horizon, with significant implications for portfolio management and future research in financial modeling.",artificial intelligence; trading; fuzzy logic; technical; fundamental,WoS
WOS:001431695500063,,CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading,"The utilization of Large Language Models (LLMs) in financial trading has primarily been concentrated within the stock market, aiding in economic and financial decisions. Yet, the unique opportunities presented by the cryptocurrency market, noted for its on-chain data's transparency and the critical influence of off-chain signals like news, remain largely untapped by LLMs. This work aims to bridge the gap by developing an LLM-based trading agent, CryptoTrade, which uniquely combines the analysis of on-chain and off-chain data. This approach leverages the transparency and immutability of on-chain data, as well as the timeliness and influence of off-chain signals, providing a comprehensive overview of the cryptocurrency market. CryptoTrade incorporates a reflective mechanism specifically engineered to refine its daily trading decisions by analyzing the outcomes of prior trading decisions. This research makes two significant contributions. Firstly, it broadens the applicability of LLMs to the domain of cryptocurrency trading. Secondly, it establishes a benchmark for cryptocurrency trading strategies. Through extensive experiments, CryptoTrade has demonstrated superior performance in maximizing returns compared to time-series baselines, but not compared to traditional trading signals, across various cryptocurrencies and market conditions. Our code and data are available at https://github. com/Xtra-Computing/CryptoTrade.",,WoS
WOS:001419757200001,10.1111/exsy.70018,"Generative AI for Finance: Applications, Case Studies and Challenges","Generative AI (GAI), which has become increasingly popular nowadays, can be considered a brilliant computational machine that can not only assist with simple searching and organising tasks but also possesses the capability to propose new ideas, make decisions on its own and derive better conclusions from complex inputs. Finance comprises various difficult and time-consuming tasks that require significant human effort and are highly prone to errors, such as creating and managing financial documents and reports. Hence, incorporating GAI to simplify processes and make them hassle-free will be consequential. Integrating GAI with finance can open new doors of possibility. With its capacity to enhance decision-making and provide more effective personalised insights, it has the power to optimise financial procedures. In this paper, we address the research gap of the lack of a detailed study exploring the possibilities and advancements of the integration of GAI with finance. We discuss applications that include providing financial consultations to customers, making predictions about the stock market, identifying and addressing fraudulent activities, evaluating risks, and organising unstructured data. We explore real-world examples of GAI, including Finance generative pre-trained transformer (GPT), Bloomberg GPT, and so forth. We look closer at how finance professionals work with AI-integrated systems and tools and how this affects the overall process. We address the challenges presented by comprehensibility, bias, resource demands, and security issues while at the same time emphasising solutions such as GPTs specialised in financial contexts. To the best of our knowledge, this is the first comprehensive paper dealing with GAI for finance.",applications; case studies; finance; generative AI; large language models,WoS
WOS:000280563600008,10.1162/NECO_a_00007,Bayesian Online Learning of the Hazard Rate in Change-Point Problems,"Change-point models are generative models of time-varying data in which the underlying generative parameters undergo discontinuous changes at different points in time known as change points. Change-points often represent important events in the underlying processes, like a change in brain state reflected in EEG data or a change in the value of a company reflected in its stock price. However, change-points can be difficult to identify in noisy data streams. Previous attempts to identify change-points online using Bayesian inference relied on specifying in advance the rate at which they occur, called the hazard rate (h). This approach leads to predictions that can depend strongly on the choice of h and is unable to deal optimally with systems in which h is not constant in time. In this letter, we overcome these limitations by developing a hierarchical extension to earlier models. This approach allows h itself to be inferred from the data, which in turn helps to identify when change-points occur. We show that our approach can effectively identify change-points in both toy and real data sets with complex hazard rates and how it can be used as an ideal-observer model for human and animal behavior when faced with rapidly changing inputs.",,WoS
WOS:001167619100016,10.12720/jait.14.6.1372-1381,Synthetic Financial Time Series Generation with Regime Clustering,"Methods for synthetic data generation are extremely valuable nowadays since they allow researchers and practitioners to develop and test their models without the risk and cost associated with using real data. In this paper, we propose a method for the generation of synthetic financial time series. The method adopts time series regimes clustering to perform generative models training on the data from each cluster separately. Also, we suggest the modification of Quantum Generative Adversarial Networks (QuantGAN) architecture that is able to produce synthetic data with frequency characteristics closer to the corresponding real-world time series ones. Our experiments show that (1) synthetic financial time series can be effectively generated by our method; (2) the distribution characteristics of synthetic time series generated by the method are closer to the initial ones in comparison with Fourier Flows and QuantGAN; (3) training the forecasting model on the synthetics generated by the proposed method (Fourier Flows model is used within it) can reduce the forecasting error on the real-world series.",regime clustering; Generative Adversarial Networks (GAN); normalising flows; time series generation; synthetic time series,WoS
WOS:001418568100001,10.3390/math13030487,LLM-Augmented Linear Transformer-CNN for Enhanced Stock Price Prediction,"Accurately predicting stock prices remains a challenging task due to the volatile and complex nature of financial markets. In this study, we propose a novel hybrid deep learning framework that integrates a large language model (LLM), a Linear Transformer (LT), and a Convolutional Neural Network (CNN) to enhance stock price prediction using solely historical market data. The framework leverages the LLM as a professional financial analyst to perform daily technical analysis. The technical indicators, including moving averages (MAs), relative strength index (RSI), and Bollinger Bands (BBs), are calculated directly from historical stock data. These indicators are then analyzed by the LLM, generating descriptive textual summaries. The textual summaries are further transformed into vector representations using FinBERT, a pre-trained financial language model, to enhance the dataset with contextual insights. The FinBERT embeddings are integrated with features from two additional branches: the Linear Transformer branch, which captures long-term dependencies in time-series stock data through a linearized self-attention mechanism, and the CNN branch, which extracts spatial features from visual representations of stock chart data. The combined features from these three modalities are then processed by a Feedforward Neural Network (FNN) for final stock price prediction. Experimental results on the S&P 500 dataset demonstrate that the proposed framework significantly improves stock prediction accuracy by effectively capturing temporal, spatial, and contextual dependencies in the data. This multimodal approach highlights the importance of integrating advanced technical analysis with deep learning architectures for enhanced financial forecasting.",stock price prediction; Linear Transformer; CNN; LLM; deep learning; financial forecasting,WoS
WOS:000873142500002,10.1016/j.matcom.2022.07.015,Encoded Value-at-Risk: A machine learning approach for portfolio risk measurement,"Measuring risk is at the center of modern financial risk management. As the world economy is becoming more complex and standard modelling assumptions are violated, the advanced artificial intelligence solutions may provide the right tools to analyse the global market. In this paper, we provide a novel approach for measuring market risk called Encoded Value-at-Risk (Encoded VaR), which is based on a type of artificial neural network, called Variational Auto-encoders (VAEs). Encoded VaR is a generative model which can be used to reproduce market scenarios from a range of historical cross-sectional stock returns, while increasing the signal-to-noise ratio present in the financial data, and learning the dependency structure of the market without any assumptions about the joint distribution of stock returns. We compare Encoded VaR out-of-sample results with twelve other methods and show that it is competitive to many other well-known VaR algorithms presented in the literature. (C) 2022 International Association for Mathematics and Computers in Simulation (IMACS). Published by Elsevier B.V. All rights reserved.",Value-at-risk; Financial risk management; Machine learning; Artificial neural networks; Variational autoencoders,WoS
WOS:001547468700001,10.1287/mnsc.2023.00936,TAIL-GAN: Learning to Simulate Tail Risk Scenarios,"The estimation of loss distributions for dynamic portfolios requires the simulation of scenarios representing realistic joint dynamics of their components. We propose a novel data-driven approach for simulating realistic, high-dimensional multiasset scenarios, focusing on accurately representing tail risk for a class of static and dynamic trading strategies. We exploit the joint elicitability property of Value-at-Risk and Expected Shortfall to design a Generative Adversarial Network that learns to simulate price scenarios preserving these tail risk features. We demonstrate the performance of our algorithm on synthetic and market data sets through detailed numerical experiments. In contrast to previously proposed data-driven scenario generators, our proposed method correctly captures tail risk for a broad class of trading strategies and demonstrates strong generalization capabilities. In addition, combining our method with principal component analysis of the input data enhances its scalability to large-dimensional multiasset time series, setting our framework apart from the univariate settings commonly considered in the literature.",scenario simulation; generative models; generative adversarial networks (GANs); multivariate time series; universal approximation; expected shortfall; value at risk; risk measures; elicitability,WoS
WOS:001514420800001,10.1007/s12530-025-09694-w,Information diffusion prediction using hybrid GCNN-LSTM and stock market based sentiment analysis in social media,"With the advancement of social media, the information diffusion popularity prediction has attracted wide attention in many applications. However, due to the real-time changes in networks and the complexity of social interactions, analyzing the exact mechanism of the information dissemination process remains extremely difficult. However, conventional popularity prediction methods rely heavily on human expertise to create features and define the generative model, or completely depend on the underlying user relation network for embedding learning. To address these concerns, this proposed work designed an information diffusion prediction model using a Hybrid Graph Convolutional Neural Network-Long Short Term Memory (GCNN-LSTM). The sentiment of the diffused information is analyzed through a hybrid Long Short Term Memory-Support Vector Machine (LSTM-SVM) in social media applications. The proposed work comprises two phases: the first phase is for effective popularity prediction of information diffusion, and the second phase is for analyzing the users' sentiment based on the influence of diffused information. In the detection of the information diffusion phase, the user data from social media is gathered to make a graphical representation based on the comment node attributes, and the effective features are extracted with the assistance of the graph convolutional neural network. After that, the features are given in the LSTM model for the detection of popularity. The diffused information in social media is considered in the sentimental analysis phase; initially, the data is subjected to preprocessing, and features are extracted with Term Frequency Inverse Document Frequency (TFIDF). Finally, with the help of a hybrid LSTM-SVM, the sentiment of the social media data is detected. The proposed model is implemented in MATLAB software and achieved 96% accuracy for phase 1 and 96% for phase 2. Thus, the proposed model effectively detects the spread of information in social media, which can assist various applications.",Information diffusion prediction; Popularity prediction sentiment analysis; Hybrid GCNN-LSTM; Hybrid LSTM-SVM; TFIDF,WoS
WOS:001575809900001,10.1186/s40854-025-00789-6,The power of ChatGPT in processing text: Evidence from analysis and prediction in the exchange rate markets,"This study investigates the application of large language models in analyzing sentiment features within the exchange rate markets. Traditional natural language processing methods, such as LDA and BERT, are effective in extracting topics from text; however, they fail to assess the relative importance of these topics in relation to target exchange rates. To bridge this gap, this paper employs ChatGPT to extract topics from texts and evaluate their importance scores, further enhancing exchange rate forecasting by integrating topic importance into the sentiment analysis framework. Through empirical analysis, the superiority of ChatGPT over LDA and BERT in both topic extraction and importance assessment is demonstrated. Furthermore, this study utilizes the topic importance scores generated by ChatGPT to develop a novel interval-valued sentiment index (TIS index). This index not only accounts for the relative importance of various events influencing exchange rate fluctuations but also captures the dynamic evolution of market sentiment within an interval. Empirical results highlight that the TIS Index significantly enhances the forecasting accuracy of interval models such as TARI and IMLP for exchange rates. These findings further demonstrate the advantages of ChatGPT in sentiment analysis within the foreign exchange market. These findings offer new insights into the application of ChatGPT in financial text research.",ChatGPT; Sentiment analysis; Exchange rate; Topic analysis; Interval,WoS
WOS:001502486900023,10.1111/1911-3846.13036,Can investors learn from patent documents? Evidence from textual analysis,"This paper examines the role of patent texts in the stock market valuation of patents. Utilizing the large language model BERT (Bidirectional Encoder Representations from Transformers) to summarize contextual information within patent texts, I find that patent texts explain 31.5% of the variation in the stock market valuation of patents and provide large incremental explanatory power beyond other structured patent characteristics, firm characteristics, and technological trends. Additionally, patent texts significantly predict the level, volatility, and cumulation speed of future earnings, suggesting they contain genuine information about firms' performance. However, investors do not fully incorporate such information within patent texts into stock prices, as evidenced by the predictive power of patent texts for future stock returns. This underreaction is diminished after the pre-grant publication of patent applications is mandated. My findings underscore the value of patent texts as a source of information on internally developed intangibles and have implications for academics, practitioners, and regulators. Les investisseurs peuvent-ils tirer de l'information de documents de brevets? Donn & eacute;es probantes tir & eacute;es d'une analyse textuelleLa pr & eacute;sente & eacute;tude se penche sur le r & ocirc;le des textes de brevets dans l'& eacute;valuation de la valeur boursi & egrave;re des brevets. En utilisant le grand mod & egrave;le de langage BERT (Bidirectional Encoder Representations from Transformers) pour obtenir un aper & ccedil;u de l'information contextuelle qui se trouve dans les textes de brevets, j'& eacute;tablis que ces textes expliquent 31,5 % de la variation de la capitalisation boursi & egrave;re des brevets et fournissent un vaste pouvoir explicatif outre les autres caract & eacute;ristiques structur & eacute;es des brevets, les caract & eacute;ristiques de l'entreprise et les tendances technologiques. De plus, les textes de brevets pr & eacute;disent de fa & ccedil;on significative le niveau, la volatilit & eacute; et la vitesse d'accumulation des revenus & agrave; venir, ce qui donne & agrave; penser qu'ils contiennent de l'information authentique sur le rendement des entreprises. Toutefois, les investisseurs n'int & egrave;grent pas pleinement ce type de renseignements au cours des actions, comme le montre le pouvoir pr & eacute;dictif des textes de brevets sur les futurs rendements boursiers. Cette sous-r & eacute;action s'att & eacute;nue apr & egrave;s l'imposition de l'obligation de publier les demandes de brevet avant leur d & eacute;livrance. Mes observations mettent en lumi & egrave;re la valeur des textes de brevets en tant que source d'information sur les actifs incorporels d & eacute;velopp & eacute;s & agrave; l'interne et ont des cons & eacute;quences pour les chercheurs, les praticiens et les organismes de r & eacute;glementation.",BERT; big data; patent; textual analysis; voluntary disclosure; analyse textuelle; brevet; divulgation volontaire; m & eacute;gadonn & eacute;es,WoS
WOS:001227224001010,,Non-adversarial training of Neural SDEs with signature kernel scores,"Neural SDEs are continuous-time generative models for sequential data. State-of-the-art performance for irregular time series generation has been previously obtained by training these models adversarially as GANs. However, as typical for GAN architectures, training is notoriously unstable, often suffers from mode collapse, and requires specialised techniques such as weight clipping and gradient penalty to mitigate these issues. In this paper, we introduce a novel class of scoring rules on pathspace based on signature kernels and use them as objective for training Neural SDEs non-adversarially. By showing strict properness of such kernel scores and consistency of the corresponding estimators, we provide existence and uniqueness guarantees for the minimiser. With this formulation, evaluating the generator-discriminator pair amounts to solving a system of linear path-dependent PDEs which allows for memory-efficient adjoint-based backpropagation. Moreover, because the proposed kernel scores are well-defined for paths with values in infinite dimensional spaces of functions, our framework can be easily extended to generate spatiotemporal data. Our procedure permits conditioning on a rich variety of market conditions and significantly outperforms alternative ways of training Neural SDEs on a variety of tasks including the simulation of rough volatility models, the conditional probabilistic forecasts of real-world forex pairs where the conditioning variable is an observed past trajectory, and the mesh-free generation of limit order book dynamics.",,WoS
WOS:001479397300002,10.1109/TEM.2025.3554567,Being an Emotionally Unaffected Investor: Evidence From Bitcoin,"As one of the most prominent cryptocurrencies, Bitcoin has been at the forefront of a major revolution in the financial and technological sectors. This study utilizes data from social media to extract the emotional tendencies of investors in the Bitcoin market and analyze differences in investor behavior under various emotional features. We find that when investors exhibit reluctance (such as Sadness and Fear) to buy Bitcoin, it is the opportune moment to invest and achieve returns higher than expected. Conversely, when the emotional tone of investors becomes positive (such as Joy and Love), indicating a tendency to invest, we choose to avoid investing. Our research has also revealed that such emotional cues can assist in better predicting returns in the Bitcoin market. Analyzing market emotions contributes to a deeper understanding of market fluctuations and investor behavior. Our findings help stakeholders recognize the role of subjective emotions in the market and provide them with prudent investment advice: avoid relying excessively on the feelings of others, as this may trigger investment losses.",Bitcoin; Investment; Fluctuations; Social networking (online); Sentiment analysis; Electronic mail; Data mining; Finance; Predictive models; Blogs; BERT; bitcoin; investor behavior; large language models; machine learning; return prediction; textual analysis,WoS
WOS:001417508100023,10.1109/CIFER62890.2024.10772910,Semantic Graph Learning for Trend Prediction from Long Financial Documents,"The advent of large language models (LLMs) has initiated much research into their various financial applications. However, in applying LLMs on long documents, semantic relations are not explicitly incorporated, and a full or arbitrarily sparse attention operation is employed. In recent years, progress has been made in Abstract Meaning Representation (AMR), which is a graph-based representation of text to preserve its semantic relations. Since AMR can represent semantic relationships at a deeper level, it can be beneficially utilized by graph neural networks (GNNs) for constructing effective document-level graph representations built upon LLM embeddings to predict target metrics in the financial domain. We propose FLAG: Financial Long document classification via AMR-based GNN, an AMR graph based framework to generate document-level embeddings for long financial document classification. We construct document-level graphs from sentence-level AMR graphs, endow them with specialized LLM word embeddings in the financial domain, apply a deep learning mechanism that utilizes a GNN, and examine the efficacy of our AMR-based approach in predicting labeled target data from long financial documents. Extensive experiments are conducted on a dataset of quarterly earnings calls transcripts of companies in various sectors of the economy, as well as on a corpus of more recent earnings calls of companies in the S&P 1500 Composite Index. We find that our AMR-based approach outperforms fine-tuning LLMs directly on text in predicting stock price movement trends at different time horizons in both datasets. Our work also outperforms previous work utilizing document graphs and GNNs for text classification.",,WoS
WOS:001192446400001,10.3390/jtaer19010029,The Impact of Academic Publications over the Last Decade on Historical Bitcoin Prices Using Generative Models,"Since 2012, researchers have explored various factors influencing Bitcoin prices. Up until the end of July 2023, more than 9100 research papers on cryptocurrencies were published and indexed in the Web of Science Clarivate platform. The objective of this paper is to analyze the impact of publications on Bitcoin prices. This study aims to uncover significant themes within these research articles, focusing on cryptocurrencies in general and Bitcoin specifically. The research employs latent Dirichlet allocation to identify key topics from the unstructured abstracts. To determine the optimal number of topics, perplexity and topic coherence metrics are calculated. Additionally, the abstracts are processed using BERT-transformers and Word2Vec and their potential to predict Bitcoin prices is assessed. Based on the results, while the research helps in understanding cryptocurrencies, the potential of academic publications to influence Bitcoin prices is not significant, demonstrating a weak connection. In other words, the movements of Bitcoin prices are not influenced by the scientific writing in this specific field. The primary topics emerging from the analysis are the blockchain, market dynamics, transactions, pricing trends, network security, and the mining process. These findings suggest that future research should pay closer attention to issues like the energy demands and environmental impacts of mining, anti-money laundering measures, and behavioral aspects related to cryptocurrencies.",cryptocurrency; research publication; topic modelling; latent Dirichlet allocation; sentiment analysis; Bitcoin prices,WoS
WOS:000957190000002,10.1007/s44196-023-00212-x,An Efficient GAN-Based Multi-classification Approach for Financial Time Series Volatility Trend Prediction,"Deep learning has achieved tremendous success in various applications owing to its robust feature representations of complex high-dimensional nonlinear data. Financial time-series prediction is no exception. Hence, the volatility trend prediction in financial time series (FTS) has been an active topic for several decades. Inspired by generative adversarial networks (GAN), which have been studied extensively in image processing and have achieved excellent results, we present the ordinal regression GAN for financial volatility trends (ORGAN-FVT) method for the end-to-end multi-classification task of FTS. An improved generative model based on convolutional long short-term memory (ConvLSTM) and multilayer perceptron (MLP) is proposed to capture temporal features effectively and mine the data distribution of volatility trends (short, neutral, and long) from given FTS data. Meanwhile, ordinal regression is leveraged for the discriminator to improve the multi-classification performance, making the model more practical. Finally, we empirically compare ORGAN-FVT with several state-of-the-art approaches on three real-world stock datasets: MICROSOFT(MSFT), Tesla(TSLA), and The People's Insurance Company of China(PAICC). ORGAN-FVT demonstrated significantly better AUC and F1 scores, at most 20.81% higher than its competitors.",Financial time series; Generative adversarial nets; Convolutional LSTM; Classification,WoS
WOS:001221698100004,10.1016/j.mlwa.2023.100508,Transforming sentiment analysis in the financial domain with ChatGPT,"Financial sentiment analysis plays a crucial role in decoding market trends and guiding strategic trading decisions. Despite the deployment of advanced deep learning techniques and language models to refine sentiment analysis in finance, this study breaks new ground by investigating the potential of large language models, particularly ChatGPT 3.5, in financial sentiment analysis, with a strong emphasis on the foreign exchange market (forex). Employing a zero -shot prompting approach, we examine multiple ChatGPT prompts on a meticulously curated dataset of forex-related news headlines, measuring performance using metrics such as precision, recall, f1 -score, and Mean Absolute Error (MAE) of the sentiment class. Additionally, we probe the correlation between predicted sentiment and market returns as an addition evaluation approach. ChatGPT, compared to FinBERT, a well-established sentiment analysis model for financial texts, exhibited approximately 35% enhanced performance in sentiment classification and a 36% higher correlation with market returns. By underlining the significance of prompt engineering, particularly in zero -shot contexts, this study spotlights ChatGPT's potential to substantially boost sentiment analysis in financial applications. By sharing the utilized dataset, our intention is to stimulate further research and advancements in the field of financial services.",ChatGPT; Artificial intelligence; Finance; Sentiment analysis; Risk assessment,WoS
WOS:001439640200001,10.1016/j.iswa.2025.200496,Emulating fundamental analysts: Analytical stage-based multi-agent framework enhanced with expert guidance and Preference-Anchored Likelihood Adjustment,"With the rapid advancement of large language models (LLMs), some studies have explored their potential for predicting stock prices based on financial texts. However, previous research often overlooked the depth of analysis generated by LLMs, resulting in reasoning processes inferior to those of human analysts. In fundamental investing, which requires in-depth company analysis, conclusions from imperfect reasoning lack persuasiveness. In this study, inspired by the analysis process of human analysts, we propose an ""Analytical Stage-Based Multi-Agent Framework""to enable LLMs to perform in-depth fundamental analysis. This framework divides the analysis into multiple stages, assigning an LLM agent to each. We enhance each agent's capabilities for its specific task through expert guidance or fine-tuning, allowing them to collectively emulate the workflow of human analysts. Furthermore, we introduce Preference-Anchored Likelihood Adjustment, anew method for fine-tuning LLMs. This approach addresses the decline in likelihood of generating correct responses that occurs after using existing preference alignment methods. It employs an objective function with two terms: one to increase likelihood and another to preserve aligned preference. We conducted experiments using our framework to analyze company earnings releases. We evaluated the analysis quality based on comprehensiveness and logical soundness, while correctness was assessed by using stock prices as the ground truth to calculate the Matthews correlation coefficient and F1 score. Results demonstrate that even without expert guidance and fine-tuning, our multi-agent framework can enhance LLMs in both analysis quality and correctness. When combined with expert guidance and fine-tuning, the performance is further improved.",LLMs; Multi-agent; Fine-tuning; Financial fundamental analysis; Stock price analysis,WoS
WOS:001150392400001,10.1109/ACCESS.2024.3350638,Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering,"Blockchain technology has revolutionized the financial landscape, witnessing widespread adoption of cryptocurrencies due to their decentralized and transparent nature. As sentiments expressed on social media platforms wield substantial influence over cryptocurrency market dynamics, sentiment analysis has emerged as a crucial tool for gauging public opinion and predicting market trends. This paper explores fine-tuning techniques for large language models to enhance sentiment analysis performance. Experimental results demonstrate a significant average zero-shot performance gain of 40% on unseen tasks after fine-tuning, highlighting its potential. Additionally, the impact of instruction-based fine-tuning on models of varying scales is examined, revealing that larger models benefit from instruction tuning, achieving the highest average accuracy score of 75.16%. In contrast, smaller-scale models may experience reduced generalization due to complete model capacity utilization. To gain deeper insight into instruction effectiveness, the paper presents experimental investigations under different instruction tuning setups. Results show the model achieves an average accuracy score of 72.38% for short and simple instructions, outperforming long and complex instructions by over 12%. Finally, the paper explores the relationship between fine-tuning corpus size and model performance, identifying an optimal corpus size of 6,000 data points for the highest performance across different models. Microsoft's MiniLM, a distilled version of BERT, excels in efficient data use and performance optimization, while Google's FLAN-T5 demonstrates consistent and reliable performance across diverse datasets.",Cryptocurrency; Social networking (online); Analytical models; Training; Context modeling; Sentiment analysis; Transformers; Zero-shot learning; Supervised learning; in-context learning; supervised fine-tuning; instruction tuned; prompt engineering,WoS
WOS:000382307300052,10.1145/2766462.2767757,Predicting Search Intent Based on Pre-Search Context,"While many studies have been conducted on query understanding, there is limited understanding on why users start searches and how to predict search intent. In this paper, we propose to study this important but less explored problem. Our key intuition is that searches are triggered by different pre-search contexts, but the triggering relations are often hidden. For example, a user may search ""bitcoin"" because of a news article or an email the user just read, but the system does not know which of the pre-search contexts (the news article or the email) is the triggering source. Following this intuition, we conduct an in-depth analysis of pre-search context on a large-scale user log, which not only verifies the hidden triggering relations in the real world but also identifies a set of important characteristics of pre-search context and their triggered queries. Since the hidden triggering relations make it challenging to directly use pre-search context for intent prediction, we develop a mixture generative model to learn without any supervision how queries are triggered by different types of pre-search context. Further, we discuss how to apply our model to improve query prediction and query auto-completion. Our experiments on a large-scale of real-world data show that our model could accurately predict user search intent with pre-search context and improve upon the state-of-the-art methods significantly.",Search Context; Pre-Search Context; Search Intent; Query Auto-Completion; Query Prediction,WoS
WOS:001453741700001,10.3390/electronics14061090,Comparative Investigation of GPT and FinBERT's Sentiment Analysis Performance in News Across Different Sectors,"GPT (Generative Pre-trained Transformer) is a groundbreaking generative model that has facilitated substantial progress in natural language processing (NLP). As the GPT-n series has continued to evolve, its applications have garnered considerable attention across various industries, particularly in finance. In contrast, traditional financial research has primarily focused on analyzing structured data such as stock prices. However, recent trends highlight the growing importance of natural language techniques that address unstructured factors like investor sentiment and the impact of news. Positive or negative information about specific companies, industries, or the overall economy found in news or social media can influence investor behavior and market volatility, highlighting the critical need for robust sentiment analysis. In this context, we utilize the state-of-the-art language model GPT and the finance-specific sentiment analysis model FinBERT to perform sentiment and time-series analyses on financial news data, comparing the performance of the two models to demonstrate the potential of GPT. Furthermore, by examining the relationship between sentiment shifts in financial markets and news events, we aim to provide actionable insights for investment decision-making, emphasizing both the performance and interpretability of the models. To enhance the performance of GPT-4o, we employed a systematic approach to prompt design and optimization. This process involved iterative refinement, guided by insights derived from a labeled dataset. This approach emphasized the pivotal importance of prompt design in improving model accuracy, resulting in GPT-4o achieving higher performance than FinBERT. During the experiment phase, sentiment scores were generated from New York Times news data and visualized through time-series graphs for both models. Although both models exhibited similar trends, significant differences arose depending on news content characteristics across categories. According to the results, the performance of GPT-4o, optimized through prompt engineering, outperformed that of FinBERT by up to 10% depending on the sector. These findings emphasize the importance of prompt engineering and demonstrate GPT-4o's potential to improve sentiment analysis. Furthermore, the categorized news data approach suggests potential applications in predicting the outlook of categorized financial products.",sentiment analysis; GPT; FinBERT; prompt design; The New York Times,WoS
WOS:001526720800001,10.1007/s12525-025-00815-6,Wisdom of the crowd signals: Predictive power of social media trading signals for cryptocurrencies,"The emergence of cryptocurrencies and decentralized finance (DeFi) applications brings unique challenges, including high volatility, limited fundamental valuation methods, and significant informational reliance on social media. Consequently, traditional trading algorithms and decision support systems (DSS) often fall short in effectively capturing these dynamics, underscoring the need for tailored solutions. Recent research on sentiment analysis in cryptocurrency trading has provided mixed evidence regarding its predictive power, highlighting limitations in generalizability and reliability due to the inherent noise of social media content. Addressing these limitations, this study explores crowd-based trading signals, explicit buy and sell recommendations shared by users on social media platforms including X (formerly Twitter), Reddit, Stocktwits, and Telegram. We apply an event study methodology to analyze over 28,000 trading signals extracted using natural language processing (NLP) techniques based on large language models (LLMs). Our findings demonstrate that these explicit crowd-based signals significantly predict short-term cryptocurrency price movements, particularly for assets with lower market capitalization and recent negative returns. An out-of-sample trading strategy using these signals achieves superior risk-adjusted returns, outperforming both a standard cryptocurrency index (CCI30) and the S&P 500. Additionally, we uncover the role of automated accounts (signal bots) actively disseminating trading recommendations. This research advances literature by introducing a precise alternative to sentiment analysis, contributing to the understanding of social media as a distributed financial information environment, and raising theoretical considerations about algorithmic agency and trust. Practical implications span investors, social media platforms, and regulators.",Social media signals; Cryptocurrencies; Collective intelligence; Trading signals; Predictive power; Wisdom of crowds; G10; D8; D7; G14; G41,WoS
WOS:000799454300035,10.5220/0010172103250332,Stock Trend Prediction using Financial Market News and BERT,"Stock market trend prediction is an attractive research topic since successful predictions of the market's future movement could result in significant profits. Recent advances in language representation such as Generative Pre-trained Transformer (GPT) and Bidirectional Encoder Representations from Transformers (BERT) models have shown success in incorporating a pre-trained transformer language model and fine-tuning operations to improve downstream natural language processing (NLP) systems. In this paper, we apply the popular BERT model to leverage financial market news to predict stock price movements. Experimental results show that our proposed methods are simple but very effective, which can significantly improve the stock prediction accuracy on a standard financial database over the baseline system and existing work.",Language Model; Information Extraction; Neural Networks; Natural Language Processing; Financial Market; Stock Market; Financial and Business News,WoS
WOS:001461762600016,10.1109/ICDMW65004.2024.00021,Sentiment Score of Bloomberg Market Wraps with ChatGPT,"In this paper, we used a large dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines affect stock market movements. To make this analysis more effective, we employed ChatGPT. First, from the summary of daily financial updates, we identify top global news headlines that could have a significant influence on stock markets. Second, for each headline, we questioned ChatGPT to answer whether the news might lead to a rise, a fall in stock prices or an indecisive future. This two-stage method proves more effective than a direct question on the entire text. By gathering ChatGPT's predictions day by day, we formed an overall market sentiment score and transform this score into a practical investment strategy in the NASDAQ index, demonstrating the significance of minimizing noise in sentiment scores by initially accumulating and then detrending them. This approach showcases that ChatGPT's analysis of news headlines can provide valuable insights into future stock market behaviours and be a valuable tool to develop intuitive NLP-driven investment strategies leveraging news predictive power.",NLP; ChatGPT; SentimentScore; Bloomberg News,WoS
WOS:001509582400001,10.26650/acin.1616088,The Impact of Social Networks on the Stock Market Using Sentiment Analysis and Machine Learning: Application to the Turkish Stock Market,"The proliferation of portable devices and social media has transformed opinion sharing, impacting individual behavior, particularly in financial markets. This research explores how online sentiments influence investors' decision-making, highlighting the complexities of sentiment measurement in behavioral finance. AI-driven techniques have been developed to quantify opinions from social media data, focusing on Twitter (rebranded as X). The transformer architecture, which is a cutting-edge deep learning method widely used in generative AI models, is employed for sentiment analysis. The relationship between digitized sentiment scores and share prices within T & uuml;rkiye's Borsa & Idot;stanbul (BIST 30) index was analyzed using machine learning techniques. Social media activity, as indicated by tweet volume, was investigated in relation to stock prices. The dataset comprises nearly 1.9 million tweets related to BIST 30 stocks, collected from early 2021 to late 2022. Independent variables include tweet volume, sentiment (positivenegative), and tweet timing, whereas dependent variables comprise stock prices and index closures. The findings reveal that tweet volume effectively predicts stock prices. Positive sentiment demonstrates stronger predictive power for individual stocks, whereas overall tweet sentiment does not significantly affect index-wide prices. Conversely, tweet timing is ineffective for price prediction. This research exemplifies the growing application of AI and machine learning in the social sciences by quantifying human opinions. The proposed model offers both theoretical and practical contributions, serving as a model for future research while delivering new insights and recommendations. The insights gained underscore the potential to harness information systems to advance financial literacy, stimulate economic growth, and empower informed decision-making across diverse global contexts.",Artificial Intelligence; Machine Learning; Sentiment Analysis; Stock Market Forecasting; Social Networks,WoS
WOS:001281386400001,10.1111/exsy.13681,Integrating spotted hyena optimization technique with generative artificial intelligence for time series forecasting,"Generative artificial intelligence (AI) has developed as an effective tool for time series predicting, revolutionizing the typical methods of prediction. Different classical approaches that depend on existing approaches and assumptions, generative AI controls advanced deep learning (DL) approaches like generative adversarial networks (GANs) and recurrent neural networks (RNNs), to identify designs and connections in time series data. DL has accomplished major success in optimizing performances connected with AI. In the financial area, it can be extremely utilized for the stock market predictive, trade implementation approaches, and set of optimizers. Stock market predictive is the most important use case in this field. GANs with advanced AI approaches have become more significant in recent times. However, it can be utilized in image-image-translation and other computer vision (CV) conditions. GANs could not utilized greatly for stock market prediction because of their effort to establish the proper set of hyperparameters. This study develops an integrated spotted hyena optimization algorithm with generative artificial intelligence for time series forecasting (SHOAGAI-TSF) technique. The purpose of the SHOAGAI-TSF technique is to accomplish a forecasting process for the utilization of stock price prediction. The SHOAGAI-TSF technique uses probabilistic forecasting with a conditional GAN (CGAN) approach for the prediction of stock prices. The CGAN model learns the data generation distribution and determines the probabilistic prediction from it. To boost the prediction results of the CGAN approach, the hyperparameter tuning can be performed by the use of the SHOA. The simulation result analysis of the SHOAGAI-TSF technique takes place on the stock market dataset. The experimental outcomes determine the significant solution of the SHOAGAI-TSF algorithm with other compared methods in terms of distinct metrics.",artificial intelligence; generative adversarial network; spotted hyena optimization; stock market prediction; time series forecasting,WoS
WOS:001390971000001,10.1007/s10614-024-10835-7,"Forecasting Brazilian Stock Market Using Sentiment Indices from Textual Data, Chat-GPT-Based and Technical Indicators","The rapid advancement of artificial intelligence, exemplified by tools such as Chat-GPT, has significantly transformed the landscape of stock market analysis. This paper aims to leverage these technological developments to predict the daily returns of the Ibovespa by utilizing predictors derived from technical indicators and sentiment indices extracted from textual data and Chat-GPT-generated sentiment indices. Our findings reveal that the Chat-GPT-based sentiment index does not enhance the out-of-sample prediction of Ibovespa returns. Conversely, the sentiment index derived from financial news data, utilizing a time-varying dictionary, demonstrates improved out-of-sample predictive accuracy for the Ibovespa. Notably, the predictor based on the technical indicator Accumulation-Distribution (AD) outperforms the historical average benchmark, establishing itself as the superior forecasting model. This study contributes to the ongoing discourse on the integration of artificial intelligence and traditional financial analysis, offering insights into the efficacy of sentiment indices and technical indicators for forecasting stock market returns in the Brazilian context.",Artificial intelligence; Chat-GPT; Sentiment analysis; Technical indicators; Stock market forecasting; Ibovespa; C01; C22,WoS
WOS:001281996200011,10.1145/3652037.3652076,Stock Price Trend Prediction using Emotion Analysis of Financial Headlines with Distilled LLM Model,"Capturing the volatility of stock prices helps individual traders, stock analysts, and institutions alike increase their returns in the stock market. Financial news headlines have been shown to have a significant effect on stock price mobility. Lately, many financial portals have restricted web scraping of stock prices and other related financial data of companies from their websites. In this study we demonstrate that emotion analysis of financial news headlines alone can be sufficient in predicting stock price movement, even in the absence of any financial data. We propose an approach that eliminates the need for web scraping of financial data. We use API based mechanism to retrieve financial news headlines. In this study we train and subsequently leverage light and computationally fast Distilled LLM Model to gather emotional tone and strength of financial news headlines for companies. We then use this information with several machine learning-based classification algorithms to predict the stock price direction based solely on the emotion analysis of news. We demonstrate that emotion analysis-based attributes of financial news headlines are as accurate in predicting the price direction as running the algorithms with the financial data alone.",Artificial intelligence; neural networks; machine learning; trend prediction; logistic regression; Random Forest; Artifical Neural Network; stock price direction prediction; LLM; emotion analysis; sentiment analysis; Distilled LLM,WoS
WOS:001379233400001,10.1007/s10614-024-10811-1,MoF: A Background-Aware Multi-source Fusion Financial Trend Forecasting Mechanism,"With the rapid growth of economic globalization and digital economics, accurately predicting stock price fluctuations has become crucial yet challenging due to high volatility and market noise. Existing forecasting methods, relying primarily on time-series data, technical indicators, and sentiment analysis, often fail to capture the semantic depth of background knowledge, particularly the influence of real-time events. To address this limitation, we propose MoF, a background-aware multi-source fusion mechanism for financial trend forecasting. MoF integrates stock price data with background knowledge on the impact of real-time events on stock trends, which includes key information from policy documents and stock commentaries, and subsequently leverages the MacBERT model to generate feature vectors for stock prediction. Our results show that MoF, by incorporating the influence of real-time events, improves accuracy and interpretability in stock trend forecasting, surpassing LSTM-based models with over 90% accuracy in predicting market fluctuations and providing reliable directional predictions.",Background-aware; LLM; Macbert; Financial trend,WoS
WOS:001363868100001,10.3390/bdcc8110143,"Innovative Sentiment Analysis and Prediction of Stock Price Using FinBERT, GPT-4 and Logistic Regression: A Data-Driven Approach","This study explores the comparative performance of cutting-edge AI models, i.e., Finaance Bidirectional Encoder representations from Transsformers (FinBERT), Generatice Pre-trained Transformer GPT-4, and Logistic Regression, for sentiment analysis and stock index prediction using financial news and the NGX All-Share Index data label. By leveraging advanced natural language processing models like GPT-4 and FinBERT, alongside a traditional machine learning model, Logistic Regression, we aim to classify market sentiment, generate sentiment scores, and predict market price movements. This research highlights global AI advancements in stock markets, showcasing how state-of-the-art language models can contribute to understanding complex financial data. The models were assessed using metrics such as accuracy, precision, recall, F1 score, and ROC AUC. Results indicate that Logistic Regression outperformed the more computationally intensive FinBERT and predefined approach of versatile GPT-4, with an accuracy of 81.83% and a ROC AUC of 89.76%. The GPT-4 predefined approach exhibited a lower accuracy of 54.19% but demonstrated strong potential in handling complex data. FinBERT, while offering more sophisticated analysis, was resource-demanding and yielded a moderate performance. Hyperparameter optimization using Optuna and cross-validation techniques ensured the robustness of the models. This study highlights the strengths and limitations of the practical applications of AI approaches in stock market prediction and presents Logistic Regression as the most efficient model for this task, with FinBERT and GPT-4 representing emerging tools with potential for future exploration and innovation in AI-driven financial analytics.",FinBERT model; logistic regression; FinBERT; Optuna; time series cross-validation,WoS
WOS:001173911600001,10.1080/23270012.2024.2306929,Dividend announcement and the value of sentiment analysis,"Payout policy constitutes one of the most important corporate financial decisions since dividends are essential factors in determining a firm's value. A dividend announcement generates a market signal which translates into changes in stock returns, impacting short-term price fluctuations and producing abnormal returns. The sample consists of 394 companies listed on the S&P500 index, from which 1574 dividend announcements and 7222 news items are derived during the years 2022-2023. News pieces are obtained from 58 specialized sources, and ChatGPT is used to automate the sentiment extracted from them. Using sentiment analysis, this paper shows the key role played by sentiments derived from financial news posted just after dividend announcements in predicting market reaction and helping investors to select optimal investment strategies. This paper contributes to the current literature, highlighting the influence that sentiments have on determining stock market returns.",payout policy; dividend announcement; sentiment analysis; financial news; market reaction; investment strategies,WoS
WOS:001155792600001,10.1016/j.techsoc.2024.102454,Nexus between Chat GPT usage dimensions and investment decisions making in Pakistan: Moderating role of financial literacy,"This study's primary goal is to investigate and gain better knowledge of the relationship between ChatGPT usage dimensions such as analyzing data, managing risk, optimizing portfolios, forecasting market trends, and conducting sentiment analysis and investment decisions of investors in the Pakistan stock market, as well as the moderating role of financial literacy. The sample for this study included individual stock market investors in Pakistan. Using a self-administered questionnaire and a cross-sectional design, a non-probability convenience sampling technique followed by snowball techniques was used to collect data from 388 active and potential individual investors. The study's findings showed that ChatGPT usage dimensions have a positive and significant impact on investment decision making. Furthermore, financial literacy is found to moderate the relationship between optimizing portfolios, forecasting market trends, and investment decision making. The study's findings outlined practical implications for the researcher, financial advisors, individual investors, governmental decision-makers, policymakers, and stock market authorities who are interested in leveraging the benefits of artificial intelligence and machine learning in investment decision making in the context of emerging economies like Pakistan.",ChatGPT; Analyzing data; Managing risk; Optimizing portfolios; Forecasting market trends; Conducting sentiment analysis; Financial literacy and investment decision; making,WoS
WOS:001028470800001,10.3390/math11132883,"Price, Complexity, and Mathematical Model","The whole world has entered the era of the Vuca. Some traditional methods of problem analysis begin to fail. Complexity science is needed to study and solve problems from the perspective of complex systems. As a complex system full of volatility and uncertainty, price fluctuations have attracted wide attention from researchers. Therefore, through a literature review, this paper analyzes the research on complex theories on price prediction. The following conclusions are drawn: (1) The price forecast receives widespread attention year by year, and the number of published articles also shows a rapid rising trend. (2) The hybrid model can achieve higher prediction accuracy than the single model. (3) The complexity of models is increasing. In the future, the more complex methods will be applied to price forecast, including AI technologies such as LLM. (4) Crude-oil prices and stock prices will continue to be the focus of research, with carbon prices, gold prices, Bitcoin, and others becoming new research hotspots. The innovation of this research mainly includes the following three aspects: (1) The whole analysis of all the articles on price prediction using mathematical models in the past 10 years rather than the analysis of a single field such as oil price or stock price. (2) Classify the research methods of price forecasting in different fields, and found the common problems of price forecasting in different fields (including data processing methods and model selection, etc.), which provide references for different researchers to select price forecasting models. (3) Use VOSviewer to analyze the hot words appearing in recent years according to the timeline, find the research trend, and provide references for researchers to choose the future research direction.",price; fluctuate; volatility; complexity; chaos; algorithm; mathematic,WoS
WOS:001568406000001,10.1111/jifm.70004,Carbon Neutrality Uncertainty and the Cross-Section of Stock Returns: Evidence From China,"Climate change impacts future stock returns, though prior literature offers mixed evidence. In this study, we explore how carbon neutrality uncertainty (CNU) affects the cross-section of stock returns in the Chinese market. Our data set includes 3489 stocks from January 2011 to December 2022. Utilizing keywords generated by ChatGPT, we construct a CNU index and estimate the stocks' sensitivity to this uncertainty. Portfolio-level analyzes and cross-sectional regressions indicate a negative cross-sectional relationship between sensitivity to CNU and future stock returns. This relationship remains robust across alternative rolling windows and various measures of the CNU index, and other uncertainty indices cannot account for it. From the perspective of market impediments, arbitrage asymmetry appears to explain this negative relationship. Overall, our results highlight the important role of CNU in determining stock prices.",arbitrage asymmetry; carbon neutrality uncertainty; climate change; stock returns,WoS
WOS:001380553500001,10.1111/1475-679X.12593,Context-Based Interpretation of Financial Information,"To what extent does the narrative context surrounding the numbers in financial statements alter the informativeness of these numbers, that is, contextualize them? Answering this question empirically presents a methodological challenge. Leveraging recent advances in deep learning, we propose a method to uncover the value of contextual information learned from the (deep) interactions between numeric and narrative disclosures. We show that the contextualization of accounting numbers makes them substantially more informative in shaping beliefs about a firm's future, especially when numeric data are less reliable. In fact, the informational value of interactions dominates the direct informational value of the narrative context. We corroborate this finding by showing that stock markets and financial analysts incorporate the interactions between narrative and numeric information when making forecasts. We also demonstrate the value of our approach by identifying rich firm-year-specific heterogeneity in earnings persistence. We discuss a number of avenues for future research.",earnings; cash flows; LLMs; deep learning; narrative context; earnings persistence; MD&A; neural networks; heterogeneity,WoS
WOS:001259255100001,10.1080/12460125.2024.2371670,ChatGPT's crystal ring: simulating auditors' use of machine learning in stock price prediction,"This study investigates the influence of technological factors on the intent to use Machine Learning (ML) tools such as Python for the purpose of predicting stock prices. Further, it investigates the moderate impact of Artificial Intelligence (AI) models usage, in particular ChatGPT, on these associations. The outcomes of a simulation involving 400 auditors, accounting for the heterogeneity of their competencies, were obtained through code utilisation based on the Python programming language. The technological factors drawn from diffusion of innovation theory (DOI), including relative advantages, Complexity, compatibility, observability, and triability, all showed positive associations with behavioural intent. The use of ChatGPT significantly fortified these connections. These results suggest a fruitful symbiotic outcome may be achieved by combining AI capabilities with these variables. The findings underscore the significance of planning for the adoption of AI in financial decision-making and auditing and also illustrate the potential of AI in these areas.",Python; ChatGPT; simulation; stock prices; auditor; DOI,WoS
WOS:001188142300001,10.1287/ijoc.2022.0055,Let the Laser Beam Connect the Dots: Forecasting and Narrating Stock Market Volatility,"Forecasting market volatility, especially high-volatility incidents, is a critical issue in financial market research and practice. Business news as an important source of market information is often exploited by artificial intelligence-based volatility forecasting models. Computationally, deep learning architectures, such as recurrent neural networks, on extremely long input sequences remain infeasible because of time complexity and memory limitations. Meanwhile, understanding the inner workings of deep neural networks is challenging because of the largely black box nature of large neural networks. In this work, we address the first challenge by proposing a long- and short-term memory retrieval (LASER) architecture with flexible memory and horizon configurations to forecast market volatility. Then, we tackle the interpretability issue by devising a BEAM algorithm that leverages a large pretrained language model (GPT-2). It generates human-readable narratives verbalizing the evidence leading to the model prediction. Experiments on a Wall Street Journal news data set demonstrate the superior performance of our proposed LASERBEAM pipeline in predicting high-volatility market scenarios and generating high-quality narratives compared with existing methods in the literature.",forecasting; memory retrieval; narrative generation; mode interpretability,WoS
WOS:000959456700001,10.1016/j.eswa.2023.119862,A review on sentiment analysis from social media platforms,"Sentiment analysis has proven to be a valuable tool to gauge public opinion in different disciplines. It has been successfully employed in financial market prediction, health issues, customer analytics, commercial valuation assessment, brand marketing, politics, crime prediction, and emergency management. Many of the published studies have focused on sentiment analysis of Twitter messages, mainly because a large and diverse population expresses opinions about almost any topic daily on this platform. This paper proposes a comprehensive review of the multifaceted reality of sentiment analysis in social networks. We not only review the existing methods for sentiment analysis in social networks from an academic perspective, but also explore new aspects such as temporal dynamics, causal relationships, and applications in industry. We also study domains where these techniques have been applied, and discuss the practical applicability of emerging Artificial Intelligence methods. This paper emphasizes the importance of temporal characterization and causal effects in sentiment analysis in social networks, and explores their applications in different contexts such as stock market value, politics, and cyberbullying in educational centers. A strong interest from industry in this discipline can be inferred by the intense activity we observe in the field of intellectual protection, with more than 8,000 patents issued on the topic in only five years. This interest compares positively with the effort from academia, with more than 2,300 articles published in 15 years. But these papers are unevenly split across domains: there is a strong presence in marketing, politics, economics, and health, but less activity in other domains such as emergencies. Regarding the techniques employed, traditional techniques such as dictionaries, neural networks, or Support Vector Machines are widely represented. In contrast, we could still not find a comparable representation of advanced state-of-the-art techniques such as Transformers-based systems like BERT, T5, T0++, or GPT-2/3. This reality is consistent with the results found by the authors of this work, where computationally expensive tools such as GPT-3 are challenging to apply to achieve competitive results compared to those from simpler, lighter and more conven-tional techniques. These results, together with the interest shown by industry and academia, suggest that there is still ample room for research opportunities on domains, techniques and practical applications, and we expect to keep observing a sustained cadence in the number of published papers, patents and commercial tools made available.",Sentiment analysis; Social media; Twitter; Causality; Temporal sentiment analysis; Professional and academic methodologies; Reproducibility studies; Causal rule predictions,WoS
WOS:001313758400031,10.1007/978-3-031-66336-9_31,Language as a Lens: A Hybrid Text Summarization and Sentiment Analysis Approach for Multiclass Stock Return Prediction,"This research explores the application of text summarization and sentiment analysis techniques in the multiclass classification of hourly stock price returns, studying six companies from the Dow Jones Index between 2017 and the first quarter of 2020. The study employs three distinct text summarization methods to efficiently process a substantial volume of financial news. This approach enhances the depth and accuracy of subsequent sentiment analysis. Sentiment is assessed through a combination of lexicon-based and deep learning methods. These insights, along with technical market data, are integrated into a Light Gradient Boosting Machine (LGBM) model, which is refined through Bayesian hyperparameter optimization and assessed via cross-validation. The results demonstrate that the model's performance peaks at a standard deviation coefficient of 0.25, indicating an optimal balance for the three-class classification problem. Furthermore, the feature importance analysis reveals that while temporal and market-related factors play a significant role, sentiment features captured by FinBERT and VADER substantially contribute to the model's predictive power. A notable finding of this research is the superior performance of FinBERT over GPT-3.5 in feature importance analysis, underscoring the efficacy of specialized language models in financial contexts. By marrying natural language processing techniques with machine learning, the study presents a novel approach to understanding the predictive power of news sentiment in financial markets.",Sentiment analysis; Text summarization; LGBM; Feature importance; Financial forecasting,WoS
WOS:000774471300007,10.1007/978-3-030-58790-1_7,News Articles Evaluation Analysis in Automotive Industry Using GPT-2 and Co-occurrence Network,"News articles have great impacts on asset prices in the financial markets. Many attempts have been reported to ascertain how news influences stock prices. Stock price fluctuations of highly influential companies can have a major impact on the economy as a whole. In particular, the automobile industry is a colossal industry that leads the Japanese industry. However, the limitations in the number of available data sets usually become the hurdle for the model accuracy. In this study, we constructed a news evaluation model utilizing GPT-2. A news evaluation model is a model that evaluates news articles distributed to financial markets based on price fluctuation rates and predicts fluctuations in stock prices. We have added news articles generated by GPT-2 as data for analysis. Besides, we used a co-occurrence network analysis to review the overview of the news articles. News articles were classified through Long Short-Term Memory (LSTM). The results showed that the accuracy of the news evaluation model improved by generating news articles using a language generation model through GPT-2. More detailed analyses are planned for the future.",Language generation; GPT-2; Financial markets; Co-occurrence network; LSTM; Deep learning,WoS
WOS:001541282100001,10.1016/j.gfj.2025.101151,Disaggregated geopolitical risks and global stock returns,"We introduce a novel framework to measure how geopolitical risk exposure (GRE) affects stock returns. Using data from 40 countries over 1995-2022, we construct three factors: geopolitical risk factor (GPRF), geopolitical act factor (GPAF), and geopolitical threat factor (GPTF). This study documents four main findings. First, geopolitical threats (GPTs) have markedly stronger GRE than geopolitical acts (GPAs), with 58% of countries showing significant GPTF results vs. 35% for GPAF. Second, predictability is strongest at shorter horizons, with 68% of countries demonstrating significant one-month predictability for GPTF effects. Third, these effects persist even after accounting for established market risk factors, with 33% of countries maintaining significant GPTF relationships. Fourth, our factors provide economically meaningful out-of-sample forecasting ability, yielding positive R2 values in 60% of countries and utility gains for mean-variance investors. The findings offer a practical framework for integrating GRE assessments into decisions.",Geopolitical risk; Geopolitical act; Geopolitical threat; Geopolitical risk exposure; Stock return; Generalized Autoregressive Conditional; Heteroskedasticity,WoS
WOS:001527543600070,10.1145/3701716.3715235,HRFT: Mining High-Frequency Risk Factor Collections End-to-End via Transformer,"In quantitative trading, transforming historical stock data into interpretable, formulaic risk factors enhances the identification of market volatility and risk. Despite recent advancements in neural networks for extracting latent risk factors, these models remain limited to feature extraction and lack explicit, formulaic risk factor designs. By viewing symbolic mathematics as a language-where valid mathematical expressions serve as meaningful ""sentences""-we propose framing the task of mining formulaic risk factors as a language modeling problem. In this paper, we introduce an end-to-end methodology, Intraday Risk Factor Transformer (IRFT), to directly generate complete formulaic risk factors, including constants. We use a hybrid symbolic-numeric vocabulary where symbolic tokens represent operators and stock features, and numeric tokens represent constants. We train a Transformer model on high-frequency trading (HFT) datasets to generate risk factors without relying on a predefined skeleton of operators (e.g., +, x, /, root x, log x, cos x). It determines the general form of the stock volatility law, including constants; for example, f (x) = tan(ax + b), where.. is the stock price. We refine the predicted constants (a,b) using the BroydenFletcher-Goldfarb-Shanno (BFGS) algorithm to mitigate non-linear issues. Compared to the ten approaches in SRBench, an active benchmark for symbolic regression (SR), IRFT achieves a 30% higher investment return on the HS300 and S&P500 datasets, while achieving inference times that are orders of magnitude faster than existing methods in HF risk factor mining tasks. Our code and dataset are publicly accessible via the following GitHub repository: https: //github.com/wencyxu/IRF-LLM- accepted- at-WWW25-.",Computational Finance; Stock Volatility Forecasting; Transformer; Factor Analysis,WoS
WOS:000380809500069,10.1063/1.4952549,Parameters Estimation using the First Passage Times Method in a Jump-Diffusion Model,"The main purposes of this paper are two contributions: (1) it presents a new method, which is the first passage time (FPT method) generalized for all passage times (GPT method), in order to estimate the parameters of stochastic Jump-Diffusion process. (2) it compares in a time series model, share price of gold, the empirical results of the estimation and forecasts obtained with the GPT method and those obtained by the moments method and the FPT method applied to the Merton Jump-Diffusion (MJD) model.",,WoS
WOS:001044938900001,10.1080/14765284.2023.2245279,From fiction to fact: the growing role of generative AI in business and finance,"Generative Artificial Intelligence (AI), such as ChatGPT by OpenAI, has revolutionized the business world, with benefits including improved accessibility, efficiency, and cost reduction. This article reviews recent developments of generative AI in business and finance, summarizes its practical applications, provides examples of the latest generative AI tools, and demonstrates that generative AI can revolutionize data analysis in industry and academia. To test the ability of generative AI to support decision-making in financial markets, we use the ChatGPT to capture corporate sentiments towards environmental policy by inputting text extracted from corporate financial statements. Our results demonstrate that the sentiment scores generated by ChatGPT can predict firms' risk-management capabilities and stock return performance. This study also highlights the potential challenges and limitations associated with generative AI. Finally, we propose several questions for future research at the intersection of generative AI with business and finance.",Generative AI; ChatGPT; Natural Language Processing; Sentiment Analysis; Practical Applications,WoS
WOS:001495832200001,10.3390/ai6050095,Cybersecure XAI Algorithm for Generating Recommendations Based on Financial Fundamentals Using DeepSeek,"Background: Investment decisions in stocks are one of the most complex tasks due to the uncertainty of which stocks will increase or decrease in their values. A diversified portfolio statistically reduces the risk; however, stock choice still substantially influences the profitability. Methods: This work proposes a methodology to automate investment decision recommendations with clear explanations. It utilizes generative AI, guided by prompt engineering, to interpret price predictions derived from neural networks. The methodology also includes the Artificial Intelligence Trust, Risk, and Security Management (AI TRiSM) model to provide robust security recommendations for the system. The proposed system provides long-term investment recommendations based on the financial fundamentals of companies, such as the price-to-earnings ratio (PER) and the net margin of profits over the total revenue. The proposed explainable artificial intelligence (XAI) system uses DeepSeek for describing recommendations and suggested companies, as well as several charts based on Shapley additive explanation (SHAP) values and local-interpretable model-agnostic explanations (LIMEs) for showing feature importance. Results: In the experiments, we compared the profitability of the proposed portfolios, ranging from 8 to 28 stock values, with the maximum expected price increases for 4 years in the NASDAQ-100 and S&P-500, where both bull and bear markets were, respectively, considered before and after the custom duties increases in international trade by the USA in April 2025. The proposed system achieved an average profitability of 56.62% while considering 120 different portfolio recommendations. Conclusions: A t-Student test confirmed that the difference in profitability compared to the index was statistically significant. A user study revealed that the participants agreed that the portfolio explanations were useful for trusting the system, with an average score of 6.14 in a 7-point Likert scale.",DeepSeek; explainable artificial intelligence; financial fundamentals; investment recommendation; stock price prediction; XAI security,WoS
WOS:001548319900001,10.3389/fbloc.2025.1627769,Short-term cryptocurrency price forecasting based on news headline analysis,"Introduction This article presents a method for short-term cryptocurrency price forecasting utilizing news headlines.Methods The study analyzes the impact of news on asset prices within one hour of publication, employing machine learning-based classification with BERT and GPT models, as well as GloVe vector representations.Results The proposed cascade classifier model enhances prediction accuracy by initially assessing the strength of a news item and subsequently forecasting the direction of price movement. Experimental results demonstrate the effectiveness of the developed classification model.Discussion The model achieves an accuracy of 79% in predicting price movements, confirming the potential of leveraging news headlines to improve short-term forecasts in cryptocurrency markets.",cryptocurrency; short-term forecasting; machine learning; Global Vectors for word representation (GloVe); bidirectional encoder representations from transformers (BERT); Generative Pre-trained Transformer (GPT); Bitcoin (BTC),WoS
WOS:001399801800002,10.24136/oc.3109,"Enterprise generative artificial intelligence technologies, Internet of Things and blockchain-based fintech management, and digital twin industrial metaverse in the cognitive algorithmic economy","Research background: Enterprise generative AI system-based worker behavior tracking and monitoring, socially responsible organizational practices, employee performance management satisfaction, and human resource management procedures, relationships, and outcomes develop on hiring and objective performance assessment algorithms in terms of human resource management activities, functions, processes, practices, policies, and productivity. Deep reinforcement and machine learning techniques, operational and analytical generative AI and cloud capabilities, and real-time anomalous behavior recognition systems further fintech development for credit and lending services, payment analytics processes, and risk assessment, monitoring, and mitigation. Generative AI tools can bolster predictive analytics by collaborative and interconnected sensor and machine data for tailored, seamless, and finetuned product, operational process, and organizational workflow development, efficiency, and innovation, driving agile transformative changes in digital twin industrial metaverse. Purpose of the article: We show that enterprise generative AI-driven schedule prediction tools, job search and algorithmic hiring systems, and synthetic training data can improve team selection, job performance and firing decisions, hiring decision processes, and workforce productivity in terms of prediction and decision-making by use of algorithmic management, system performance, and production process tracking tools. Blockchain-based fintech operations can shape cloud-based financial and digital banking services, quote-to-cash process automation, cash-settled crypto futures, digital loan decisioning, asset tokenization simulated transactions, transaction switching and routing operations, tailored peer-to-peer lending, and proactive credit line management. Collaborative unstructured enterprise data processing, infrastructure, and governance can develop on AI decision and behavior automation technology, retrieval augmented generation and development management systems, and real-time data descriptive and predictive analytics, driving productivity surges and competitive advantage in digital twin industrial metaverse. Methods: Reference and review management tools, together with evidence synthesis screening software, harnessed were Abstrackr, AMSTAR, ASReview Lab, CASP, Catchii, Citation- chaser, DistillerSR, JBI SUMARI, Litstream, PICO Portal, and Rayyan. Findings & value added: The current state of the art is improved for theory on organizational issues and for policy making as deep learning-based generative AI tools and workplace monitoring systems can augment performance and productivity, gauge employee effectiveness, build resilient, satisfied, and engaged workforce, assess human capital, skill, and career development, drive employee and productivity expectations in relation to flexibility and stability, and shape turnover, retention, and loyalty. Cloud and account servicing technologies can be deployed in generative AI fintechs for embedded cryptocurrency trading, transaction moni toring and processing, digital asset transfers, payment screening, corporate and retail banking operations, and fraud prevention. Generative AI technologies can reshape jobs and reimagine meaningful work, involving creativity and innovation and adaptable and resilient sustained performance, providing valuable constructive feedback, optimizing workplace flexibility and psychological safety, and measuring and supporting autonomy and flexibility-based efficien- cy, performance, and productivity, while configuring demanding, engaging, and rewarding experiences by cloud and edge computing devices in digital twin industrial metaverse.",enterprise generative artificial intelligence; Internet of Thing; blockchain; fintech; digital twin industrial metaverse; cognitive algorithmic economy,WoS
WOS:001270048700002,10.2478/mmcks-2024-0008,Emoji driven crypto assets market reactions,"In the burgeoning realm of cryptocurrency, social media platforms like Twitter have become pivotal in influencing market trends and investor sentiments. In our study, we leverage GPT-4 and a fine-tuned transformer-based BERT model for a multimodal sentiment analysis, focusing on the impact of emoji sentiment on cryptocurrency markets. By translating emojis into quantifiable sentiment data, we correlate these insights with key market indicators such as BTC Price and the VCRIX index. Our architecture's analysis of emoji sentiment demonstrated a distinct advantage over FinBERT's pure text sentiment analysis in such predicting power. This approach may be fed into the development of trading strategies aimed at utilizing social media elements to identify and forecast market trends. Crucially, our findings suggest that strategies based on emoji sentiment can facilitate the avoidance of significant market downturns and contribute to the stabilization of returns. This research underscores the practical benefits of integrating advanced AI-driven analyzes into financial strategies, offering a nuanced perspective on the interaction between digital communication and market dynamics in an academic context.",emoji; LLM; VCRIX; crypto; bitcoin,WoS
WOS:000527281900034,10.1016/j.eneco.2019.104624,Geopolitical risk uncertainty and oil future volatility: Evidence from MIDAS models,"Using a textual analysis based geopolitical risk (GPR) index, this paper exploits the effects of geopolitical risk uncertainty on oil futures price volatility within a mixed data sampling (MIDAS) modeling framework. With a variety of MIDAS specifications, our in-sample estimation results suggest that the short-term (e.g. one-day-ahead) oil realized volatility is positively associated with GPR uncertainty, and our out-of-sample forecasting exercise indicates that the GPR index is useful for improving short-term oil futures volatility prediction. In addition, we find that the categorical GPR index: GPR action related index (GPA), contributes more to the long-term oil volatility forecasting, compared with GPR threat related index (GPT). (C) 2019 Elsevier B.V. All rights reserved.",Oil futures; Realized volatility; Geopolitical risk uncertainty; MIDAS,WoS
WOS:001001157900001,10.1016/j.resourpol.2023.103568,Impact of geopolitical risk on the volatility of natural resource commodity futures prices in China,"Volatile natural resource prices greatly affect economic growth, economic volatility, and financial market. Analyzing the factors affecting price volatility is of great significance for policymakers to formulate regulations, for financial institutions to control financial risks and for investors to improve their investment returns. We study the impact of geopolitical risk on the price volatility of coal, copper, crude oil, gold, and iron ore in the Chinese futures market. The paper uses the Geopolitical Risk (GPR) index, the Geopolitical Threat (GPT) sub-index and the Geopolitical Action (GPA) sub-index developed by Caldara and Iacoviello to measure geopolitical risk in broader sense. We utilize the closing prices of the most recently expired futures contracts from their starting trading date to 1 August 2022 to determine volatility represented by conditional variance. The GARCH and CGARCH models are built with the help of the Kalman filtering method and a TVP-VAR-SV model. The results of GARCH model show that geopolitical risk significantly increases the price volatility of coal, iron ore, and crude oil futures; significantly decreases the price volatility of gold; and has no significant effect on the price volatility of copper futures. By CGARCH model, we illustrate that geopolitical risk significantly increases the overall volatility, persistent volatility, and temporary volatility of crude oil; significantly increases the overall volatility and temporary volatility of coal and iron ore futures; significantly decreases the overall volatility and persistent volatility of gold futures; and has no significant impact on all three types of volatility of copper futures prices. The results of the Kalman filter analysis uncover that the response of each commodity volatility to changes in geopolitical risk increases when geopolitical risk is high. Additionally, geopolitical risk has the most effect on the price volatility of copper and crude oil with high external dependence. Estimates from the TVP-VAR-SV model reveal that the short-term impact of geopolitical risk shocks on the volatility of each the futures prices of each commodity is large and of long duration, and the response of commodity futures volatility to the same level of geopolitical risk shocks is higher and longer when major geopolitical events occur such as Paris Terrorist Attack, USA/Iran Tension Escalation, Syria Missile Attack, and Russian-Ukraine War. Moreover, geopolitical shocks have the most effect on the energy commodities of crude oil and coal.",Geopolitical risk; Natural resources; Commodity futures; Volatility; GARCH; TVP-VAR-SV,WoS
WOS:001346974300001,10.1080/1369118X.2024.2420021,The supply chain capitalism of AI: a call to (re)think algorithmic harms and resistance through environmental lens,"Artificial Intelligence (AI) is woven into a supply chain of capital, commodities and human labour that has been neglected in critical debates. Given the current surge in generative AI - which is estimated to drive up the extraction of natural resources such as minerals, fossil fuels or water - it is vital to investigate its entire production line from a critical infrastructural perspective. Drawing on the supply chain capitalism, a concept coined by Anna L. Tsing in 2009, this paper contributes to critical AI studies by investigating the structure of AI supply chains, taking into account the mining, electronics, digital and e-waste industry. This paper illustrates how the supply chain capitalism of AI is precipitating geographical asymmetries connected to contested struggles in M & eacute;xico by focusing on a key element of these chains: data centres. In times of climate emergency, this paper calls to reconsider algorithmic harms and resistance by investigating the entire capitalist production line of the AI industry from critical and environmental lens.",Supply chain; AI; capitalism; infrastructure; environment; data centre,WoS
WOS:001490082400007,10.1016/j.frl.2025.107472,Decoding risk sentiment in 10-K filings: Predictability for US stock indices,"This study demonstrates that the tone of the risk factors section in the 10-K reports of U.S. public companies predicts returns on major U.S. stock indices. We created five tone indicators using text mining, the Loughran-McDonald dictionary, and AI-calibrated alternatives (GPT-3.5-turbo-0125, GPT-4, GPT-4o, and GPT-4o-mini). These indicators showed significant predictive power for weekly returns, with optimism correlated with higher returns. Tone measurements based on GPT-4 outperformed the others in terms of predictive accuracy. We analyzed the Loughran-McDonald dictionary's utility and highlighted the underexplored risk factors section, offering novel insights into sentiment analysis and financial forecasting.",Textual analysis; Risk factors tone metrics; Artificial intelligence; TVP-VAR; QVAR,WoS
WOS:001156959800068,10.1109/HPEC58863.2023.10363573,"Energy Estimates Across Layers of Computing: From Devices to Large-Scale Applications in Machine Learning for Natural Language Processing, Scientific Computing, and Cryptocurrency Mining","Estimates of energy usage in layers of computing from devices to algorithms have been determined and analyzed. Building on the previous analysis [3], energy needed from single devices and systems including three large-scale computing applications such as Artificial Intelligence (AI)/Machine Learning for Natural Language Processing, Scientific Simulations, and Cryptocurrency Mining have been estimated. In contrast to the bit-level switching, in which transistors achieved energy efficiency due to geometrical scaling, higher energy is expended both at the at the instructions and simulations levels of an application. Additionally, the analysis based on AI/ML Accelerators indicate that changes in architectures using an older semiconductor technology node have comparable energy efficiency with a different architecture using a newer technology. Further comparisons of the energy in computing systems with the thermodynamic and biological limits, indicate that there is a 27-36 orders of magnitude higher energy requirements for total simulation of an application. These energy estimates underscore the need for serious considerations of energy efficiency in computing by including energy as a design parameter, enabling growing needs of compute-intensive applications in a digital world.",Moore's law; From Bits to Architectures and Applications; Energy per Instruction; Energy per Bit; Instructions per Second; Specialized Architectures; Energy for Machine Learning and Artificial Intelligence; Natural Language Processing; ChatGPT; Energy for High Performance Scientific Computations; Energy for Crypto coin mining; Bitcoin; Thermodynamical Limit; Biological Limit; ATP; Sustainable Computing; Energy as a design parameter,WoS
WOS:001399801800006,10.24136/oc.3283,Generative artificial intelligence algorithms in Internet of Things blockchain-based fintech management,"Research background: Big data-driven artificial Internet of Things (IoT) fintech algorithms can provide real-time personalized financial service access, strengthen risk management, and manage, monitor, and mitigate transaction operational risks by operational credit risk management, suspicious financial transaction abnormal pattern detection, and synthetic financial data-based fraud simulation. Blockchain technologies, automated financial planning and investment advice services, and risk scoring and fraud detection tools can be leveraged in financial trading forecasting and planning, cryptocurrency transactions, and financial workflow automation and fraud detection. Algorithmic trading and fraud detection tools, distributed ledger and cryptocurrency technologies, and ensemble learning and support vector machine algorithms are pivotal in predictive analytics-based risk mitigation, customer behavior and preference-based financial product and service personalization, and financial transaction and fraud detection automation. Credit scoring and risk management tools can offer financial personalized recommendations based on customer data, behavior, and preferences, in addition to transaction history, by generative adversarial and deep learning recurrent neural networks. Purpose of the article: We show that blockchain and edge computing technologies, generative artificial IoT-based fintech algorithms, and transaction monitoring and credit scoring tools can be harnessed in financial decision-making processes and loan default rate mitigation for transaction, payment, and credit process efficiency. Generative and predictive artificial intelligence (AI) algorithmic trading systems can drive coherent customer service operations, provide tailored financial and investment advice, and influence financial decision processing, while performing real-time risk assessment and financial and trading risk scenario simulation across fluctuating market conditions. Fraud and money laundering prevention tools, block- chain and financial transaction technologies, and federated and decentralized machine learning algorithms can articulate algorithmic profiling-based transaction data patterns and structures, credit assessment, loan repaying likelihood prediction, and interest rate and credit lending risk management by real-time financial pattern and economic forecast-based credit analysis across investment payment and transaction record infrastructures. Methods: Research published between 2023 and 2024 was identified and analyzed across ProQuest, Scopus, and the Web of Science databases by use of screening and quality assessment software systems such as Abstrackr, AMSTAR, AXIS, CADIMA, CASP, Catchii, DistillerSR, Eppi-Reviewer, MMAT, Nested Knowledge, PICO Portal, Rayyan, ROBIS, and SRDR+. Findings & value added: The main value added derived from the systematic literature review is that generative AI-based operational risk management, fraud detection, and transaction monitoring tools can provide personalized financial support and services and clarify financial and credit decisions and operations by financial decision-making process automation in dynamic business environments based on fraud detection capabilities and transaction data analysis and assessment. The benefits for theory and current state of the art are that credit risk and financial forecasting tools, artificial IoT-based fintech and generative AI algorithms, and algorithmic trading and distributed ledger technologies can be deployed in financial decision- making and customer behavior pattern optimization, credit score assessment, and money laundering and fraudulent payment detection. Policy implications reveal that investment management and algorithmic credit scoring tools can streamline financial activity operational efficiency, design financial planning analysis and forecasting, and carry out financial service and transaction data analysis for informed transaction decision-making and fraudulent behavior pattern and incident detection, taking into account credit history and risk evaluation and improving personalized experiences.",generative artificial intelligence; Internet of Things; blockchain; fintech; fraud detection; algorithmic trading,WoS
WOS:001505285200091,10.1145/3696410.3714588,The Poorest Man in Babylon: A Longitudinal Study of Cryptocurrency Investment Scams,"Governments and regulatory bodies have recognized investment scams as a prevalent form of cryptocurrency fraud. These scams typically use professional-looking websites to lure unsuspecting victims with promises of unrealistically high returns. In this paper, we introduce Crimson, a distributed system designed to continuously detect cryptocurrency investment scam websites as they are created in the wild. During the first 8 months of 2024, Crimson processed approximately 6 billion domain names and classified 43, 572 unique cryptocurrency investment scam websites in real-time. Beyond detection, we provide insights into the design and infrastructure of these websites that can help users recognize scam patterns and assist hosting providers in detecting and blocking such sites. Furthermore, we investigate the inclusion of our detected scam websites in block-lists used by popular web browsers and applications, finding that the vast majority of these websites were absent. On the financial side, by analyzing the transactions incoming to scammer wallets on 6.7% of the sites detected by Crimson, we observe an estimated lower bound of 2.04M USD in losses due to cryptocurrency investment scams.",Cryptocurrency; Scam; Blockchain; LLM; Financial Loss,WoS
WOS:001361954400001,10.1016/j.frl.2024.106487,Intelligent forecasting in bitcoin markets,"This paper examines the effectiveness of Artificial Intelligence (AI) in predicting Bitcoin's price movements. To achieve this, we developed two distinct trading strategies and compared their performance against each other and the traditional Buy and Hold (B&H) strategy. Over the period from January 2018 to September 2023, we found that the strategy optimized by ChatGPT 01-Preview, which integrates multiple technical indicators and sentiment analysis into a weighted composite index, delivered an exceptional total return of 944.85 %. The second strategy, that is using Extreme Gradient Boosting (XGBoost) technique achieved a total return of 189.05%. The AI strategy's excess return of 755.8 % over the XGBoost strategy highlights the significant advantage of AI particularly in utilizing diverse data sources, such as social media, to predict Bitcoin's price trends more effectively than relying solely on economic data. Both trading strategies significantly outperformed the traditional B&H strategy, which returned 73.08 % over the same period. Furthermore, we found that AI has an advantage during periods of high Bitcoin price volatility.",Bitcoin; AI; Machine learning; Random forest,WoS
WOS:001427383300001,10.1080/23322039.2025.2468387,A systematic approach to predicting NFT prices using time series forecasting and macroeconomic factors in digital assets,"Non-fungible tokens (NFTs) have gained mainstream attention in the fintech community, but there is little research on their statistical properties. This study investigates the long-memory characteristics of NFT returns and volatility, focusing on their potential for predicting price movements. As NFTs do not conform to traditional models, understanding their unique features is crucial for comprehending complex market dynamics. This study aims to reveal the impact of macroeconomic factors on NFT prices, understand their correlation and develop predictive models using autoregression and artificial intelligence (AI) technology. This research utilized datasets from the Centers for Disease Control and Prevention (CDC), U.S. Bureau of Labor Statistics, Bureau of Economic Analysis, Christie's, Dune, and Google Trends. Correlation and p value tests revealed strong relationships between NFT prices and variables such as weekly volume, pandemics, inflation and security. The Baseline Model using autoregression with NFT volume, security and technology factors outperformed all other models demonstrating the speculative volatility of NFTs. The Transformer Model using transformers, an architecture used by ChatGPT, Gemini and Stable Diffusion, showed high accuracy with less feature selection and preprocessing efforts. This study provides a novelty using a systematic approach for researchers to perform financial forecasting and contributes to the scarce literature on NFTs. This research offers valuable insights to investors and private agents regarding the right economic conditions for NFT investments by reducing portfolio risks and making informed decisions. To the authors' best knowledge, this is the first study to utilize time-series transformers for forecasting NFTs based on macroeconomic factors.",NFTs; time series; artificial intelligence; prediction; transformer; fintech; macroeconomics; Finance; Macroeconomics; Artificial Intelligence; Technology; Econometrics; Risk Management; Financial Management,WoS
WOS:001578014500001,10.1016/j.comnet.2025.111508,MGGPT: A Multi-Graph GPT-enhanced framework for dynamic fraud detection in cryptocurrency networks,"The rapid increase in cryptocurrency transactions has increased demand for advanced fraud detection systems. Conventional methods are often rigid and do not effectively capture cryptocurrency networks' intricate temporal and structural patterns, while existing dynamic approaches struggle with incomplete or missing information. To tackle this issue, we present MGGPT, a new hybrid framework that integrates Graph Attention Neural Networks (GAT) with GPT-based transformers to improve fraud detection within cryptocurrency transaction networks. Our approach utilizes temporal graph structures through reachability networks (reach-nets) to derive essential node features, while also directly integrating edge labels into the embedding vectors, and introduces an innovative mechanism for predicting missing information to address the challenges posed by incomplete data in blockchain networks. The model features a dual-perspective learning strategy, employing local graph structures via GAT Networks and global contextual patterns through GPT-based sequence modeling to capture both structural and temporal dynamics in transaction networks. Our MGGPT framework implements a sophisticated edge classification mechanism using Support Vector Machines (SVM) for the final prediction. Experimental findings on actual cryptocurrency transaction datasets indicate superior efficacy in identifying fraudulent patterns, achieving notable improvements of 8.5% AUC, a 10.2% increase in Precision, 29.5% increment in recall, and 20.5% improvement in F1-score. Compared to baseline models such as STA-GT and CTGN, the proposed MGGPT improves the representation of dynamic relationships and faster convergence. Overall, the analysis reveals that our framework is not only more accurate but also more robust and scalable for real-world temporal graph applications. Ultimately, we assessed the robustness of our framework against adversarial attacks to show its practical applications in blockchains.",Graph neural networks; Cryptocurrency fraud detection; Temporal graph analysis; GPT-2 transformers; Missing information prediction,WoS
WOS:001467563200004,10.1145/3383455.3422518,Connecting The Dots: Forecasting and Explaining Short-Term Market Volatility,"Market volatility prediction is of significant theoretical and practical importance in the financial market, and the news is a significant source to influence the market. By using deep learning networks, we can forecast the volatility based on the news; meanwhile, how to explain the deep neural network is a prevalent topic, especially the attention mechanism in the NLP field. Current studies mainly focus on unveiling the principles behind attention mechanisms without considering generating human-readable explanations. In this work, we attempt to generate a human-readable explanation about the evidence that led to the prediction. To achieve our goal, we propose news-powered neural models to forecast short-term volatility and present a soft-constrained dynamic beam allocation algorithm to control the state-of-the-art language model (GPT-2) to generate fluent and informative explanations.",market volatility; neural networks; forecasting; attention mechanisms; explanation,WoS
WOS:001404832400001,10.1007/s12144-025-07430-w,Beyond the hype: AI advice and investor dissonance in crypto trading,"This study examines the impact of cognitive dissonance on the relationship between investors' intentions to use AI advice and their investment behaviour in the cryptocurrency market. The study recruited 348 individuals through a non-random snow-ball sampling technique. Utilising ChatGPT for investment recommendations, the research involves a trading experiment accompanied by a two-stage survey to evaluate investor attitudes towards AI before and their cognitive dissonance levels after the experiment. Structural Equation Modelling (SEM) identifies the connection between the intent to use AI and the influence of cognitive dissonance on investment decisions. Results indicate that investors following AI advice outperformed those who did not, attributable not to AI's predictive power but to reduced cognitive dissonance. This reduction allowed investors using AI to cut losses more effectively, in contrast to those who eschewed AI advice and tended to hold onto losing positions longer, leading to worse performance. Although focused on the cryptocurrency market, the findings suggest a potential for broader applicability in conventional financial markets. The study's key contribution is demonstrating that AI recommendations can mitigate the disposition effect, implying that AI's broader implementation could enhance market efficiency.",Artificial intelligence; Cognitive dissonance; Investment behaviour; Cryptocurrency; ChatGPT,WoS
WOS:001402083300001,10.1016/j.techfore.2024.123965,"Quantifying a firm's AI engagement: Constructing objective, data-driven, AI stock indices using 10-K filings","This paper proposes an objective, data-driven approach using natural language processing (NLP) techniques to classify AI stocks by analyzing annual 10-K filings from 3395 NASDAQ-listed firms between 2010 and 2022. Each company's engagement with AI is classified through binary and weighted AI scores based on the frequency of AIrelated terms. Using these metrics, we construct four AI stock indices-the Equally Weighted AI Index (AII), the Size-Weighted AI Index (SAII), and two Time-Discounted AI Indices (TAII05 and TAII5X)-offering different perspectives on AI investment. We validate our methodology through an event study on the launch of OpenAI's ChatGPT, demonstrating that companies with higher AI engagement saw significantly greater positive abnormal returns, with analyses supporting the predictive power of our AI measures. Our indices perform on par with or surpass 14 existing AI-themed ETFs and the Nasdaq Composite Index in risk-return profiles, market responsiveness, and overall performance, achieving higher average daily returns and risk-adjusted metrics without increased volatility. These results suggest our NLP-based approach offers a reliable, market-responsive, and costeffective alternative to existing AI-related ETF products. Our methodology can also guide investors, asset managers, and policymakers in using corporate data to construct other thematic portfolios, contributing to a more transparent, data-driven, and competitive approach.",Artificial intelligence; Market efficiency; Natural language processing; Corporate disclosures; Exchange-traded funds; ChatGPT,WoS
WOS:001447238900028,10.1007/978-3-031-78541-2_28,Exploring Relationships Between Cryptocurrency News Outlets and Influencers' Twitter Activity and Market Prices,"Academics increasingly acknowledge the predictive power of social media for a wide variety of events and, more specifically, for financial markets. Anecdotal and empirical findings show that cryptocurrencies are among the financial assets that have been affected by news and influencers' activities on Twitter. However, the extent to which Twitter crypto influencer's posts about trading signals and their effect on market prices is mostly unexplored. In this paper, we use LLMs to uncover buy and not-buy signals from influencers and news outlets' Twitter posts and use a VAR analysis with Granger Causality tests and cross-correlation analysis to understand how these trading signals are temporally correlated with the top nine major cryptocurrencies' prices. Overall, the results show a mixed pattern across cryptocurrencies and temporal periods. However, we found that for the top three cryptocurrencies with the highest presence within news and influencer posts, their aggregated LLM-detected trading signal over the preceding 24 h granger-causes fluctuations in their market prices, exhibiting a lag of at least 6 h. In addition, the results reveal fundamental differences in how influencers and news outlets cover cryptocurrencies.",Social Prediction; NLP; LLM; Prompt Engineering; Time Series Analysis,WoS
WOS:001563374700001,10.1142/S2424786325500161,Contract sentence-level evaluation (Con-SEN): A sentence-level semantic engine for accurate recognition of financial contract clauses,"Financial contracts under regulatory review are often characterized by excessive length, intricate clause nesting, implicit negations, and cross-sentence legal dependencies - posing significant challenges for automated compliance systems. To address these issues, we propose Contract Sentence-level Evaluation (Con-SEN), a sentence-level semantic framework designed for fine-grained clause recognition and risk-oriented interpretation in financial documents. This work introduces three core innovations. First, we construct Con-SEN-Corpus, a domain-specific dataset spanning over 30 financial sub-industries from 2010 to 2024. Each sentence is annotated along three legal dimensions - clause type, legality status, and risk level - enabling multi-dimensional supervision. Second, we develop a structure-aware encoder based on an enhanced Longformer, incorporating a sliding-window mechanism and a novel clause-anchor global attention module to capture long-range dependencies and structural hierarchies across chapters. Third, we introduce a negation polarity and regulatory keyword injection module, which improves the model's ability to resolve adversarial logic, implicit obligations, and exemption clauses - often overlooked by general-purpose LLMs. To ensure coherent predictions across the three dimensions, we propose a multi-task consistency learning strategy that jointly optimizes clause classification, legality assessment, and risk estimation. Extensive experiments on real-world contract datasets show that Con-SEN significantly outperforms leading LLMs such as ChatGPT and Claude, achieving 18-25 percentage points higher document-level accuracy, up to 23% greater sentence coverage, and up to 6% improvements in clause-level classification. Moreover, it reduces volatility across evaluation metrics by an order of magnitude. These results position Con-SEN as a precise, regulation-aware framework for contract analysis, capable of handling the linguistic and structural complexity inherent in financial compliance tasks.",Sentence-level semantic modeling; structure-aware encoding; multi-task learning; long-document processing; financial contracts,WoS
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10824953,10.1109/BigData62323.2024.10824953,Large Language Models for Financial Aid in Financial Time-series Forecasting,"Considering the difficulty of financial time series forecasting in financial aid, much of the current research focuses on leveraging big data analytics in financial services. One modern approach is to utilize ""predictive analysis"", analogous to forecasting financial trends. However, many of these time series data in Financial Aid (FA) pose unique challenges due to limited historical datasets and high dimensional financial information, which hinder the development of effective predictive models that balance accuracy with efficient runtime and memory usage. Pre-trained foundation models are employed to address these challenging tasks. We use state-of-the-art time series models including pre-trained LLMs (GPT-2 as backbone), transformers, and linear models to demonstrate their ability to outperform traditional approaches, even with minimal (""few-shot"") or no fine-tuning (""zero-shot""). Our benchmark study, which includes financial aid with seven other time series tasks, shows the potential of using LLMs for scarce financial datasets.",Runtime;Time series analysis;Memory management;Predictive models;Big Data;Transformers;Market research;Data models;Forecasting;Predictive analytics;Financial Aid;Time Series Forecast;Deep Learning;Foundation Models;Large Language Models,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10652178,10.1109/ICoDSA62899.2024.10652178,Estimating Value at Risk for Central Counterparties: A Generative AI Approach,"Central counterparties (CCPs) play an important role in the stability of financial markets by helping to mitigate systemic risk. It is important that CCPs have robust risk management tools in order to protect themselves from failing due to a defaulting member. In this paper a new model using a Bidirectional Generative Adversarial Network (BiGAN), a type of generative AI model, is proposed to estimate Value at Risk (VaR), a common metric used to compute initial margin for CCPs. Fifteen years of closing prices from the S&P 500 index was used as the dataset. The model was backtested for a period of four years. The results were evaluated using the number of breaches, Kupiec test, excess margin as well as two procyclicality measures: the standard deviation and peak to trough ratio of margin. The results were compared against three widely used models: filtered historical simulation method, historical VaR and parametric VaR. The results from this study showed that VaR computed using the BiGAN model produced 19 breaches on average for the four-year test period. While the experimental results show the proposed model is comparable with other models in terms of accuracy, its standard deviation for margin calls is lower which results in more short-term stability and a lower excess margin compared to the traditional models. The results of this research encourage further research on using BiGAN to estimate VAR.",Reactive power;Generative AI;Computational modeling;Stability criteria;Estimation;Predictive models;Generative adversarial networks;Value-at-Risk;Bidirectional Generative Adversarial Networks;Financial Risk Management;Central Counterparty;Generative AI,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851487,10.1109/ISCMI63661.2024.10851487,A Comparative Study of Sequential Deep Learning Models in Financial Time Series Forecasting,"Time series analysis of daily stock prices is challenging due to the inherent complexity, nonlinearity, and nonstationarity of financial data. In this paper, we compare three sequential deep learning models—LSTM, Transformer, and Large Language Models (LLMs)—for stock price prediction. By transforming the regression problem of predicting daily log returns into a classification task, we evaluate the models’ classification accuracies, with the Transformer achieving the highest accuracy of 22%, followed by LSTM (15.6%) and LLM (15.3%). Regression metrics showed LSTM initially performing better, with a lower RMSE (180.92) than LLM (1739.61). However, outlier predictions in the LLM, caused by incomplete number outputs, inflated its error. After removing these outliers, LLM’s RMSE improved significantly to 33.85, surpassing LSTM. These results demonstrate the potential of Transformer and LLM models for financial time series prediction. Future work will explore incorporating self-reflection mechanisms in LLM predictions and extending the comparison to multivariate financial time series incorporating textual data and other features.",Measurement;Deep learning;Accuracy;Large language models;Time series analysis;Predictive models;Transformers;Forecasting;Long short term memory;Machine intelligence;Time Series Forecasting;Survey;Large Language Model;Deep Learning;Finance,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11129507,10.1109/BigDataService65758.2025.00026,Stock Market Forecasting with Pretrained Deep Learning Models,"To perform stock market-related forecasting, we developed a synchronized framework that employs pretrained deep learning models to automatically analyze real-time public information from social media and forecast market trends. In the proposed framework, market related tweets are aligned with stock market index data, textual entailment method for zero-shot classification is adopted to perform sentiment analysis of tweets, and market forecast is generated by applying pretrained time series foundation model. The models were trained and tested with approximately 188,000 tweets and three major indices from the New York Stock Exchange for the year 2021. The experiments demonstrated consistently strong performance. This framework can be extended to analyze text documents from various sources for forecasting.",Deep learning;Analytical models;Sentiment analysis;Social networking (online);Time series analysis;Predictive models;Real-time systems;Synchronization;Stock markets;Forecasting;Sentimental Analysis;Social Media;Stock Market Change;Twitter;Large Language Models;Zero-shot Classification;Textual Entailment;Random Forest Classifier;Time-series Forecasting,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10859808,10.1109/ICIICS63763.2024.10859808,Enhanced Stock Market Trend Prediction on the Indonesia Stock Exchange Using Improved Bacterial Foraging Optimization and Elitist Whale Optimization Algorithms,"It was difficult to find low-risk firms in 2022 due to the large number of 825 listed on the Indonesia Stock Exchange (IDX). Essential concerns in financial works include stock price forecasting and price movement forecast. The stock market research has shown encouraging outcomes in the past. We still don't have a consensus on the finest stock value forecasting classical due to the fact that each study report has different architecture and uses different stock issuers. This paper presents a new method for optimizing bacterial foraging that uses optimal deep learning to forecast stock market trends. For the prediction process, the given model employs a multiplicative long short term memory (MLSTM) perfect, with IBFO serving as the model's fine-tuner. The research paper presents a modified whale optimization technique for feature selection. This research proposes an elitist whale optimization algorithm with the nonlinear parameter (EWOANP) to fix the issue where the whale optimization procedure does not strike a balance among exploration and exploitation and instead falls into the local optimum. To improve the odds of evading the local optimum, the shrinking encircling mechanism employs an elitist tactic based on random Cauchy mutation. Using the random Cauchy mutation as a starting point, the method cleverly selects the population with the best mutation solutions to move on to the next iteration. To strike a compromise among the two, the logarithmic spiral mechanism makes use of a nonlinear parameter. There are 2,588,451 entries in the dataset representing 727 IDX firms' open, highest, lowest, closed, and volume transactions. Various stock time records are used to examine the trial findings using current methodologies in terms of distinct metrics.",Microorganisms;Spirals;Predictive models;Feature extraction;Market research;Prediction algorithms;Whale optimization algorithms;Stock markets;Forecasting;Tuning;indonesia stock exchange;multiplicative long short term memory;elitist whale optimization nonlinear parameter;improved bacterial foraging optimization;stock market trend prediction,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10918002,10.1109/ICDMW65004.2024.00019,Leveraging Large Language Models for Predicting Stock Option Valuation and Financial Risk Mitigation,"The prediction of short-term stock options with near-future expiration dates is a challenging task due to high volatility, limited information, market noise and the risk of time decay. This work focuses on the new approach to the stock options valuation by leveraging Large Language Models (LLMs) through the integration of quantitative (i.e. financial features-lagged prices, moving averages, and volatility indicators) and qualitative data (i.e. news data, including article titles, full textual content, and publication dates). More specifically, our approach fuses sentiment analysis from LLMs applied to financial news from two reputable outlets (i.e. Economic Times and Yahoo Finance India) with quantitative data on stock options, which includes stock option closing price. By conducting experiments on companies from the NIFTY 50 index using ChatGPT-3.5, ChatGPT-4, and LLaMA 3.1, we show that our method achieves superior prediction accuracy compared to other similar approaches. The paper develops a new framework to improve the valuation of short-term stock options using advanced natural language processing behaviors afforded by LLMs to achieve a more holistic capture of market dynamics and sentiment in option pricing.",Sentiment analysis;Accuracy;Large language models;Biological system modeling;Soft sensors;Companies;Indexes;Stock markets;Forecasting;Cost accounting;Financial Markets;Short-term Options;Option Valuation;Large Language Models;ChatGPT-3.5;ChatGPT-4;LLaMA 3.1;Bullish Prediction;Bearish Prediction;NIFTY50;Sentiment Analysis;Risk Management,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10429428,10.1109/BigDIA60676.2023.10429428,A Wavelet Based Method for Un-Stationary Complex System,"It is known that stock system is chaotic, nonlinear and un-stationary system. Stock market analysis system including deep learning method and generative models usually utilize historical datasets to get the stock market features to predict the future trend. The nonlinearity of the stock market system have determined that although the features can be acquired by deep learning and generative models, it consume considerable resources including labelled cost and computing. In order to analyze such system, researchers have proposed a novel wavelet based nonlinear model, along with the interpretable feature from nonlinear and unstationary series data. Wavelet based OLS method is able to get the features of nonlinear system in a relative low cost with the acceptable result accuracy decline. What’s more, it will give an interpretability analysis form the model analysis. To sum up, the Comprehensive performance shows that the predictive power of nonlinear wavelet models outperforms than other baseline methods.",Deep learning;Analytical models;Costs;Computational modeling;Predictive models;Wavelet analysis;Stock markets;Wavelet;Time series;Prediction;Nonlinear System;Deep Learning,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11147253,10.1109/ISEC64801.2025.11147253,Comparative Analysis of Stock Price Prediction Using LSTM and GPT-2 Models,"Stock price prediction is a challenging task in both financial and academic sectors, as stock prices often behave unpredictably and nonlinearly within complex systems. This research presents a comparative study of two models: LSTM and GPT-2 which are applied to stock price prediction using Apple Inc.’s open-source data from Yahoo Finance, covering the period from 2000 to 2024. The LSTM model produces more accurate results and is better at handling long-term dependencies compared to GPT-2. The GPT-2 model from Hugging Face struggles with temporal modeling, generating inconsistent and unpredictable outputs due to its lack of design for time series data. LSTM excels at finding patterns in the complex financial data, making it a more suitable choice for this project. The LSTM model benefits from the data preparation steps that include feature selection, normalization, handling missing values and all factors that can influence its prediction. GPT-2 shows a weakness in capturing the nonlinear time series stock prices. Its reliance on pre-trained language modeling makes it not suitable for modeling stock data without the specialized adaptations. GPT-2’s outputs often differ from the real time stock data because of its lack of temporal awareness which results in unpredictable predictions. This study shows the strengths and limitations of the two models and emphasizes LSTM’s capability in finding and producing consistent stock price predictions. While GPT-2 performs well in broader contexts, this study demonstrates that LSTM is more effective for stock price prediction. This research shows how machine learning systems can improve and help with future directions of stock price predictions. The work presented in this paper by no means provides any guidance for stock purchasing but is an effort to integrate AI and Machine learning techniques to understand the process of stock price prediction that can be improved by incorporating sophisticated techniques.",Adaptation models;Analytical models;Technological innovation;Accuracy;Time series analysis;Machine learning;Predictive models;Data models;Stock markets;Long short term memory;Machine Learning;Stock Market;LLM;LSTM,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10808510,10.1109/BigDIA63733.2024.10808510,A Novel Wavelet Based Generative Model for Time Series Prediction,"Generative models have become an exciting area of research in recent years. Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs) have been utilized in various data augmentation applications. However, generative models can learn high-dimensional features of data through adversarial learning, making them suitable for nonlinear and nonstationary time series analysis, such as stock market prediction, high-frequency trading, and ocean current forecasting. In this paper, the researchers focus on using a wavelet-based GAN to predict stock market prices by generating synthetic stock market price trends. Historical stock price data from 2014 to 2024 is used for our experiments, and the results show that the wavelet-based GAN outperforms deep learning baseline models..",Wavelet transforms;Analytical models;Oceans;Time series analysis;Noise reduction;Predictive models;Generative adversarial networks;Wavelet analysis;Data models;Stock markets;Stock Market Prediction;Data Augmentation;Generative Adversarial Network;Wavelet Transform,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11141054,10.1109/ICMI65310.2025.11141054,A Hybrid Attention-BiGRU Model for Accurate Stock Market Prediction,"In today's fast-paced financial markets, investors are constantly seeking strategies to gain an edge and make informed decisions. While achieving 100 % accuracy in stock price predictions remains a challenge, advancements in artificial intelligence (AI) have made it possible to examine past data and uncover potential trends. This article explores the application of AI techniques, specifically the Bidirectional Gated Recurrent Unit (BiGRU) combined with an Attention Mechanism, for stock price prediction. These tools enable investors to better understand market behaviour and make well-informed investment decisions. In this study, datasets from CL=F, DAX, ${ }^{\wedge}$ GDAXI, and ${ }^{\wedge}$ HSI were utilized. The results indicated that the proposed model successfully achieved RMSE and MAE values ranging between 0.011 to 0.065 across all stock datasets.",Accuracy;Attention mechanisms;Computational modeling;Large language models;Gated recurrent units;Predictive models;Market research;Stock markets;Machine intelligence;Investment;BiGRU;Stock price prediction;Attention Mechanism;Hybrid Model,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10892779,10.1109/IKT65497.2024.10892779,LLM-Driven Feature Extraction for Stock Market Prediction: A Case Study of Tehran Stock Exchange,"Stock market prediction is one of the most challenging research areas in recent years. With the emergence of deep learning and artificial intelligence, researchers have proposed various methods to predict stock market directions, considering different financial variables. One of the most significant variables influencing stock movement is user opinions and social media, which has attracted much attention from researchers in recent years. Although existing studies have introduced various methods to combine stock price and textual features, a reliable and comprehensive method has not yet been established, and there is still room for improvement. In this research, a novel method based on large language models is introduced for feature extraction from financial texts, and a self-attention mechanism is proposed to capture the internal relationships between textual and financial features. The results of the model presented in this study show a 3.10% improvement in accuracy compared to the latest competing models on a newly collected dataset",Deep learning;Accuracy;Social networking (online);Large language models;Predictive models;Feature extraction;Reliability;Stock markets;Stock Market Prediction;Self-Attention Mechanism;Large Language Models;Information Fusion;Graph NeuralNetworks,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11038771,10.1109/IDS66066.2025.00016,Enhancing FinRL Trading Agents with Advance LLM-Processed Financial News: An Improved Approach Using DeepSeek-V3,"The use of AI techniques to improve stock market related operations has been benefiting traders in the stock market. FinRL is a framework that has been shown to be effective in building Reinforcement Learning (RL) based Trading Agents. Use of LLMs for performance improvement of the Agents is one of the recent initiatives. LLMs are being used to generate signals that could be combined with historical stock prices for better prediction of stock price movement trends leading to profitable trading. This paper aims to develop efficiently engineered prompts to generate DeepSeek-V3-based sentiment signals, integrate them into the FinRL environment, and improve the performance of reinforcement learning trading agents. The code, data, and trading agents are at: https://github.com/SatishChandraPhD/FinRL2025",Codes;Large language models;Buildings;Reinforcement learning;Market research;Security;Stock markets;Financial Reinforcement Learning;FinRL;trading agent;prompt;large language model;DeepSeek;stock market;financial news;stock price trend,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10927923,10.1109/ICCA62237.2024.10927923,Enhancing Stock Price Prediction: A Hybrid Approach Leveraging Large Language Models and Deep Learning,"Accurate stock price prediction is a challenging yet crucial goal in finance, with significant implications for investment decisions and risk management. This paper presents a comprehensive review of machine learning techniques for stock price prediction, examining traditional methods such as regression and ensemble models, as well as advanced approaches that integrate sentiment analysis and textual data sources. With the emergence of powerful Large Language Models (LLMs) such as ChatGPT, Llama and Gemini, we explore their potential for enhancing predictive accuracy using historical stock data. Key challenges are discussed, including data quality, model interpretability, and adapting to dynamic market conditions. Additionally, this paper proposes a trustworthy stock price prediction model based on LLMs enabling informed investment decision-making. Experimental results demonstrate that ChatGPT-4o model achieved a prediction accuracy of approximately 97%, which can be improved by tuning model parameters. Consequently, the paper highlights the potential of LLMs in improving stock price forecasting.",Adaptation models;Accuracy;Biological system modeling;Large language models;Semantics;Predictive models;Data models;Forecasting;Tuning;Investment;Large Language Models (LLMs);Machine Learning;Stock Price Prediction,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825449,10.1109/BigData62323.2024.10825449,Combining Financial Data and News Articles for Stock Price Movement Prediction Using Large Language Models,"Predicting financial markets and stock price movements requires analyzing a company’s performance, historic price movements, industry-specific events alongside the influence of human factors such as social media and press coverage. We assume that financial reports (such as income statements, balance sheets, and cash flow statements), historical price data, and recent news articles can collectively represent aforementioned factors.We combine financial data in tabular format with textual news articles and employ pre-trained Large Language Models (LLMs) to predict market movements. Recent research in LLMs has demonstrated that they are able to perform both tabular and text classification tasks, making them our primary model to classify the multi-modal data. We utilize retrieval augmentation techniques to retrieve and attach relevant chunks of news articles to financial metrics related to a company and prompt the LLMs in zero, two, and four-shot settings. Our dataset contains news articles collected from different sources, historic stock price, and financial report data for 20 companies with the highest trading volume across different industries in the stock market. We utilized recently released language models for our LLM-based classifier, including GPT- 3 and 4, and LLaMA- 2 and 3 models.We introduce an LLM-based classifier capable of performing classification tasks using combination of tabular (structured) and textual (unstructured) data. By using this model, we predicted the movement of a given stock’s price in our dataset with a weighted F1-score of 58.5% and 59.1% and Matthews Correlation Coefficient of 0.175 for both 3-month and 6-month periods.The dataset and codes for this paper can be found on Github. https://github.com/aliielahi/FinedFMP 1",Measurement;Presses;Social networking (online);Large language models;Text categorization;Companies;Predictive models;Data models;Stock markets;Software development management;Financial Stock Price Movement Prediction;Large Language Models;Information Retrieval;Retrieval Augmented Generation,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11127241,10.1109/AITest66680.2025.00018,Hybrid LSTM-Transformer Model for Stock Market Prediction: A Deep Learning Approach,"Stock market prediction is a complex and dynamic task due to the volatile nature of financial markets, influenced by economic, social, and geopolitical factors. Traditional machine learning models, including Long Short-Term Memory (LSTM) networks, have shown potential but often fall short in capturing both short-term price fluctuations and long-term dependencies. This paper proposes a novel LSTM-Transformer hybrid model that integrates the sequential modeling capabilities of LSTM with the attention-based long-range pattern recognition of Transformers. To enhance predictive performance, we incorporate key technical indicators—Relative Strength Index (RSI), Moving Average Convergence Divergence (MACD), Bollinger Bands—as well as sentiment features derived from FinBERT, a finance-specific large language model.The model is trained on historical stock data spanning 2015 to 2024 and evaluated using an $80 \%-20 \%$ training-testing split. Performance is assessed using Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), and Sharpe Ratio to capture both prediction accuracy and risk-adjusted returns. A rolling-window backtesting approach is used to simulate real-world trading behavior across varying market conditions. Our hybrid model outperforms standalone LSTM, GRU, and Transformer baselines, achieving an MSE of 0.0021, RMSE of 0.0467, and a directional accuracy of $76.4 \%$. These findings highlight the value of combining deep learning, financial indicators, and sentiment analysis for robust stock market forecasting. A conceptual extension discussing the role of generative models like GPT for unstructured financial data is also presented.",Deep learning;Sentiment analysis;Accuracy;Biological system modeling;Predictive models;Transformers;Data models;Stock markets;Forecasting;Long short term memory;Stock Market Prediction;LSTM-Transformer Hybrid;Deep Learning;Technical Indicators;Sentiment Analysis;Algorithmic Trading;Financial Forecasting;Machine Learning;Time-Series Analysis;Backtesting,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10569928,10.1109/ICCCBDA61447.2024.10569928,Large Language Model for Dynamic Strategy Interchange in Financial Markets,"With the widespread application of large language model technologies, various industries have adopted this technology to optimize existing solutions, including the field of quantitative trading. Large language models, relying on their rich pretrained knowledge, have achieved significant results in key tasks of quantitative trading such as news analysis, market sentiment judgment, and financial data forecasting. These quantitative strategies based on specific tasks can achieve considerable profits in the financial market. However, the instability of financial markets means it is difficult to maintain a market advantage by relying on a single strategy over the long term. In this paper, we draw on the principles of reinforcement learning to propose a dynamic strategy switching method based on large language models, to adapt to market changes. This method dynamically selects the most suitable strategy for execution based on the current financial market data status and predefined multiple quantitative strategies. Evaluation on two real datasets shows that our method outperforms single-strategy models in several aspects. Furthermore, the application of multi-strategy dynamic switching, combining large language models and reinforcement learning, not only demonstrates superiority but also reveals its great development potential.",Industries;Cloud computing;Computational modeling;Switches;Reinforcement learning;Market research;Data models;Large Language Model;Multi-Strategy;Quantitative Trading;Reinforcement Learning,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11134255,10.1109/CISCT62494.2024.11134255,Transforming Financial Market Prediction Through Generative AI-Powered Data Management,"Predicting financial markets remains essential for decision-making in trading and investment. However, traditional models often fall short due to low-quality data, market volatility, and the complexity of global economic trends. Generative AI offers a transformative approach by improving data management processes, enhancing prediction accuracy, and overcoming the limitations of current forecasting models. This research explores the potential of Generative AI to enrich financial data through techniques like data augmentation, synthetic data generation, and anomaly detection. Specifically, the study investigates how integrating Generative AI into data preprocessing can enhance predictive modeling using Long Short-Term Memory (LSTM) networks for time series forecasting, particularly in stock prices. The research also explores feature engineering techniques such as moving averages, Relative Strength Index (RSI), and volatility metrics, which are crucial for capturing market trends. Generative Adversarial Networks (GANs) are employed to create additional realistic trading scenarios, boosting model robustness. Implemented using Python, the findings reveal that the combined LSTM and GAN model improved prediction accuracy over traditional methods, achieving an RMSE of 0.096 and R-squared ($\mathbf{R}^{\mathbf{2}}$) $\mathbf{0. 8 5}$ in stock price forecasts. The incorporation of synthetic data with traditional financial metrics leads to an improvement in the model's ability to predict short-term market trends. These findings suggest that the use of Generative AI can provide a more resilient and adaptive approach to financial market prediction, opening new avenues for research in the domain. Future research could focus on expanding the scope to include multi-market scenarios and incorporating real-time data streams.",Measurement;Generative AI;Biological system modeling;Predictive models;Market research;Generative adversarial networks;Data models;Forecasting;Long short term memory;Synthetic data;generative AI;financial market prediction;data augmentation;synthetic data;LSTM;GAN,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11088423,10.1109/ICCSP64183.2025.11088423,Prophetic markets: Multi-modal deep learning redefines stock market predictions,"Stock market prediction is a vital resource for investors and financial experts looking to reduce risk and maximize profits. In this article, we propose a novel multi-modal deep learning-based method to improve predictions of stock market trends. This study uses an integrated framework of state-of-the-art machine learning techniques, deep learning with LLM, and RAG. We use data retrieval techniques, such as web scraping, to download financial reports containing corporate balance sheets. Further, our method includes real-time sentiment analysis in order to understand the investors’ current mentality which can be crucial in determining the market movements. Technical analysis uses deep learning models to interpret important indicators such as RSI, MACD, CCI, and Stochastic oscillators to uncover underlying patterns and correlations in stock trends. Our experiments demonstrate that this integrated strategy performs better than conventional single-dimensional techniques. We are combining data from corporate financial, sentiment analysis, and technical factors as well as active news sentiment analysis to improve the accuracy and reliability of market predictions by demonstrating the performance of a combined set of data sources. This work draws attention to the importance of the multifaceted integration of data by demonstrating RAG benefits for accurate financial data retrieval and multi-modal analysis in the practical applications of stock markets. The results demonstrate how these new approaches can be combined for profit maximization with better decision-making and risk reduction in financial markets.",Deep learning;Sentiment analysis;Accuracy;Soft sensors;Predictive models;Data retrieval;Market research;Data models;Numerical models;Stock markets;Stock prediction;multi-modal deep learning;LLM;RAG;news sentiment analysis;financial data;and technical indicators,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10808820,10.1109/ICICEC62498.2024.10808820,Global Stock Market Prediction Using Stock Chart Images with Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) Networks Enhanced by Deep Q-Learning,"The global financial markets have seen rapid advancements in predictive modelling, particularly in the use of deep learning techniques to forecast stock market trends. This research presents a novel deep learning framework that enhances global stock market prediction by leveraging Convolutional Neural Networks (CNNs) combined with Long Short-Term Memory (LSTM) networks and optimized through Deep Q-Learning to detect patterns across international markets. The model was trained on U.S. stock chart images and tested across 31 countries over a 12-year period. Pre-processing tailored for CNNs and LSTMs enabled it to capture both visual and sequential features. Deep Q-Learning further enhanced decision-making accuracy, leading to consistent returns across diverse markets, including smaller ones. The results show that this integrated approach surpasses traditional methods, offering robust predictions and valuable insights into global market trends, benefiting investors and analysts worldwide.",Deep learning;Visualization;Q-learning;Computational modeling;Globalization;Predictive models;Market research;Convolutional neural networks;Stock markets;Long short term memory;Global stock market prediction;Deep learning;Convolutional Neural Networks (CNNs);Long Short-Term Memory (LSTM) networks;Deep Q-Learning,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11070984,10.1109/CNIOT65435.2025.11070984,Incorporating related stock and text for stock price movement prediction based on information fusion,"Investors have long been concerned with the analysis of textual information related to target stocks when making stock investments. We collected and extracted stock news headlines from the Chinese stock market and utilized a Large Language Model (LLM) to identify stocks related to the target stock and the relationships among them. Based on these relationships, we constructed a related stock relationship graph. Considering the dynamic changes in the relationship weights between stocks, we employed Graph Attention Networks (GAT) to build a feature fusion model for integrating the features of related stock news. Factors influencing prediction were considered, including different methods of text concatenation, the identification of related stocks, the relationship modeling between related stocks, and the fusion of related stock features. A comparative analysis of the Long Short-Term Memory (LSTM) model, the Bidirectional Long Short-Term Memory (Bi-LSTM) model, and the Long Short-Term Memory with Attention (LSTM-Attention) model revealed that both the news headlines of the target stock and the related stocks, along with their relationships, impact stock price movement prediction. Conversely, ignoring feature fusion and textual feature extraction can negatively affect prediction accuracy.",Analytical models;Accuracy;Computational modeling;Large language models;Predictive models;Feature extraction;Transformers;Vectors;Stock markets;Long short term memory;LLM;GAT;fusion model;stock price movement prediction;LSTM,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10933431,10.1109/ICADEIS65852.2025.10933431,The Effect of News Sentiment on Jakarta Composite Index Prediction Using Support Vector Regression Method,"This research investigates the impact of news sentiment on predicting the Jakarta Composite Index (JCI) using the Support Vector Regression (SVR) method. Market sentiment, derived from news articles, has been analyzed to understand its influence on stock price movements. A dual dataset approach was employed, consisting of financial news articles from Kompas.com and historical JCI stock data. The research incorporates sentiment analysis using ChatGPT large language models (LLMs), which are then integrated as features into the prediction model. Five scenarios of sentiment integration were evaluated to identify the most effective approach. The results indicate that Scenario 4 consistently delivers the highest prediction accuracy across different evaluation metrics, with Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) values of 0.009555 and 0.007298 in the log metric evaluation, 47.616867 and 36.52605 in the absolute metric evaluation, and 85.146387 and 70.34775 in the stock closing price evaluation. While sentiment integration shows potential, its success is scenario-dependent and influenced by hyperparameter tuning. This research underscores the utility of sentiment analysis in enhancing stock price predictions and provides a foundation for further exploration of sentiment based predictive models in financial markets.",Support vector machines;Measurement;Sentiment analysis;Accuracy;Large language models;Predictive models;Indexes;Root mean square;Tuning;Information systems;sentiment analysis;stock price prediction;support vector regression,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851549,10.1109/ISCMI63661.2024.10851549,Foreign Exchange Rate Forecast by a Large Language Model Integrated with Trend Description,"In this paper, we propose a large language model to forecast the direction of change in a foreign exchange rate. The input of the proposed model is textual information as a prompt, whereas that of conventional forecast models is numerical information. A recent trend in the exchange rate is added to input textual information to enhance forecast accuracy. GPT-2 is adopted as our large language model and is fine-tuned using training data. The effectiveness of the proposed model is empirically examined using actual data.",Exchange rates;Accuracy;Large language models;Training data;Predictive models;Market research;Data models;Numerical models;Machine intelligence;machine learning;deep learning;large language model;time series;finance,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11009071,10.1109/RIVF64335.2024.11009071,Leveraging Automatically Optimized Forecasters and Large Language Model for Predicting Vietnamese Rice Export Price,"This study evaluates the reliability of Vietnamese rice export price forecasting through an end-to-end framework, emphasizing systematic ablation studies across statistical and machine learning models. Input combinations range from univariate price data to macroeconomic indicators, sentiment signals derived via Large Language Models, and their integration. Results demonstrate that gradient boosting methods, particularly CatBoost, consistently outperform statistical models. Notably, sentiment-based models achieve performance comparable to those using full macroeconomic data. The integration of sentiment and macroeconomic features yields the most reliable forecasts, validating the role of sentiment signals in enhancing economic forecasting.",Sentiment analysis;Systematics;Statistical analysis;Biological system modeling;Large language models;Time series analysis;Predictive models;Feature extraction;Data models;Macroeconomics;rice export price;time series forecasting;large language models;feature selection;machine learning,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10805163,,Prediction of Foreign Exchange Rates by a Large Language Model,"This paper proposes a prompt-based method utilizing a large language model (LLM) to predict changes in foreign exchange rates based on limit order information. While traditional deep learning models for prediction utilize numerical values as input and output, LLMs use sentences and prompts. To address this, we design prompts that incorporate the numerical values. GPT-2, a widely adopted LLM, is employed and fine-tuned using a training dataset. The effectiveness of our proposed method is demonstrated through empirical analysis using actual time series data.",Training;Deep learning;Exchange rates;Costs;Profitability;Large language models;Time series analysis;Predictive models;Iron;Numerical models;Large language model;Foreign exchange rate;Finance;Time series;Machine learning,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10016580,10.1109/ICCWAMTIP56608.2022.10016580,Tabnet With Data Augmentation Apporach in Stock Return Prediction Task,"Despite the advent of deep learning, stock return prediction task still has many challenges. Due to the scarcity of stock data, we adopt a GAN-based deep generative model to create synthetic data samples. To deal with the intrinsic low signal-to-noise ratio property of stock price time series, we formulate the return prediction as a supervised learning problem with tabular dataset, where we do feature engineering before training with a TabNet model. We conduct extensive experiments on real Chinese stock market with 6 different models, which proves that our proposed model makes larger profit and remains stability.",Training;Computational modeling;Time series analysis;Predictive models;Data models;Stability analysis;Task analysis;Stock Return Prediction;Deep Learning;Small Dataset Problem;Conditional Tabular Generative Adversarial Network;TabNet,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10933440,10.1109/ICADEIS65852.2025.10933440,A Sentiment-Augmented Machine Learning Approach to Forecasting IHSG Prices Using XGBoost,"Stocks are a commonly used investment instrument, representing ownership in a company, and offering opportunities for investors to gain profits through the appreciation of stock value as well as dividend distribution. As one of the main financial assets, stocks are also influenced by various external factors, such as economic conditions, government policies, and market sentiment. All of these factors play a crucial role in determining stock price movements. This study integrates sentiment analysis with the XGBoost algorithm to predict IHSG stock prices. By utilizing historical stock data and sentiment derived from financial news, the study evaluates the impact of sentiment data integration on prediction accuracy. Three types of returns (absolute, relative, and logarithmic) and five sentiment scenarios were employed to assess the contribution of sentiment features to the prediction model. The results indicate that sentiment integration consistently improves the predictive performance of the model compared to using historical data alone. Among the tested scenarios, Scenario 2, 4, and 5 demonstrated the best performance, with an RMSE value of 0.009163 and an MAE value of 0.007432, using the logarithmic return type. These findings suggest that incorporating sentiment features into predictive models can enhance the accuracy of stock price predictions and highlight the potential of Natural Language Processing (NLP) and Large Language Models (LLMs) in stock market analysis.",Sentiment analysis;Adaptation models;Analytical models;Accuracy;Large language models;Predictive models;Prediction algorithms;Transformers;Data models;Stock markets;XGBoost algorithm;stock prediction;sentiment analysis;large language models,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10702147,10.1109/CIBCB58642.2024.10702147,The Development of CanPrompt Strategy in Large Language Models for Cancer Care,"Background: The recent revolution in Large Language Models (LLMs) is transforming industries, enhancing communication, and reshaping research methodologies. LLMs have found significant applications across various sectors, notably in finance for stock market predictions, and in healthcare, where complex medical data is analyzed for diagnosis at an early stage, improving diagnostic procedures, and personalized treatment planning. In healthcare, where complex medical data is analyzed for diagnosis at an early stage. Despite the immense potential, challenges such as overwhelming Big Data, model hallucinations, and ethical concerns about patient privacy and bias persist. Method: We implemented novel strategies like CanPrompt to mitigate the accuracy and hallucination concerns to ensure responsible deployment. The CanPrompt strategy utilizes prompt engineering combined with few-shot and in-context learning to significantly enhance model accuracy by generating more relevant answers. The models were tested against a specialized dataset from MedQuAD, focusing on cancer, and evaluated using metrics like ROUGE and BERTScore to assess the semantic and syntactic accuracy of generated responses against validated ""Gold Answers"". Through this approach, the study seeks to outline the potential and limitations of LLMs in improving cancer care. Result: After applying CanPrompt with models Mistral 7x8b, Falcon 40b, and Llama 3-8b, BERTScore results showed Mistral leading with an accuracy around 84%, Falcon slightly lower, and Llama the least, with respective precision scores also reflecting a similar trend. Conclusion: The study demonstrates the promise of LLMs in cancer care through the introduction of CanPrompt.",Accuracy;Large language models;Semantics;Medical services;Syntactics;Planning;Prompt engineering;Stock markets;Medical diagnostic imaging;Cancer;Large Language Model (LLM);Cancer;prompt;ROGUE score;BERTScore;Mistral 7x8B;Falcon 40b;and Llama 3-8b,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10981791,10.1109/TNNLS.2025.3561811,Pleno-Alignment Framework for Stock Trend Prediction,"Predicting stock trends is a highly rewarding but high-risk endeavor due to the complex interplay of market dynamics, irrational behaviors, and diverse sentiments. Previous studies have used time-series analysis on historical prices or sentiment analysis on textual information. However, these methods often fail to capture the dynamic interactions between text and time-series modalities and overlook the different perspectives embedded in textual data. To address these limitations, we propose the pleno-alignment framework (PAFrame) that enhances multimodal stock information through intermodal and intramodal alignment to capture market dynamics. Our framework first integrates textual and time-series data in a shared representation space to learn modal-invariant information. To tackle divergent sentiments in textual data, we employ a contrastive learning approach to extract abstract semantic meanings from objective and subjective perspectives, thereby improving the robustness of language representations. Finally, we use a hybrid approach that explicitly combines cross-attention mechanisms to create a unified representation and utilizes prompts to implicitly guide language models with numerical financial indicators for final prediction. Our comprehensive experiments on five real-world datasets show that PAFrame outperforms existing methods in predicting stock trends.",Market research;Predictive models;Social networking (online);Accuracy;Stock markets;Analytical models;Data mining;Biological system modeling;Time series analysis;Semantics;Contrastive learning;language model;multimodal;stock trend prediction;time series,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10863422,10.1109/InCoWoCo64194.2024.10863422,Comparing the Best-Fit and Integrating Generative Deep Learning with Time Series Models for Metal Price Forecasting: A Predictive Analysis,"Forecasting metal prices in volatile financial markets is a challenging task due to the non-linear and stochastic nature of price movements. This research integrates deep learning techniques with time series models to predict metal prices, focusing on the MCX Index. A novel Generative Adversarial Network (GAN) framework, coupled with a Convolutional Neural Network (CNN) as a discriminator and Gated Recurrent Units (GRU) as a generator, is proposed. Historical NSE metal spot price data, specifically gold and silver, were used for model training and evaluation. The empirical results demonstrated that the proposed GAN-based architecture outperformed other deep learning models, including LSTM and Bi-LSTM, in terms of forecasting accuracy. The study provides valuable insights into the application of deep generative models for financial forecasting, addressing key challenges associated with modeling non-stationary and noisy financial data.",Deep learning;Training;Computational modeling;Time series analysis;Stochastic processes;Predictive models;Generative adversarial networks;Data models;Convolutional neural networks;Forecasting;commodity spot price;gated recurrent unit (GRU);generative adversarial network (GAN);time-reries forecasting;metal price prediction,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181526,10.1109/eScience65000.2025.00071,CryptexLLM: How LLM Generalizability Forecasts High Volatility,"We present CryptexLLM, an approach to time series forecasting that adapts large language models (LLMs) for predicting high volatility data. We extend the TimeLLM framework with an adaptive weighted loss function, feature engineering, and sentiment analysis. Our experiments show that the approach we took outperforms traditional LSTM models and statistical methods, with our best performing model being Llama 3.1. The adaptations we made improve directional accuracy, which is particularly useful for financial applications, while still maintaining computational efficiency. Our results suggest that LLMs have the potential to effectively generalize to volatile time series domains.",Adaptation models;Sentiment analysis;Statistical analysis;Computational modeling;Large language models;Time series analysis;Data models;Pattern recognition;Forecasting;Long short term memory;time series;volatile;llm,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10927897,10.1109/ICCA62237.2024.10927897,Assessing the Correlation Between News Sentiment and Stock Price Movements: A Case Study of ‘WeWork’ Using Advanced NLP Techniques,"This research explores the intricate relationship between news article sentiment and stock price movements, with the company ‘WeWork’ serving as a case study. Leveraging advanced Natural Language Processing (NLP) techniques and Large Language Models (LLMs) such as Open AI, this study aims to transform unstructured textual data into actionable financial insights. Through rigorous data collection and preprocessing, sentiment scores were derived from a wide range of news sources and correlated with historical stock prices. Statistical analyses, including linear regression and correlation metrics, revealed a weak positive correlation of 16.47% between sentiment and stock prices. Although the correlation suggests that sentiment analysis can offer valuable insights into market trends, it is insufficient as a standalone predictor for investment decisions. The findings underscore the importance of integrating sentiment analysis with traditional financial metrics, and call for the development of more robust models incorporating diverse data sources in future research.",Measurement;Sentiment analysis;Correlation;Statistical analysis;Large language models;Soft sensors;Linear regression;Transforms;Market research;Investment;Sentiment Analysis;Stock Price Prediction;Natural Language Processing (NLP);Large Language Models (LLMs),IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112242,10.1109/SIU66497.2025.11112242,Stock Price Prediction with Multimodal Data,"In today's financial markets, the influence of dynamic factors is becoming increasingly evident, and markets are affected by real-time data from various sources. In this study, a multimodal machine learning approach is adopted by integrating traditional technical analysis metrics, tweets, and news articles with historical price data. Market sentiment and investor psychology are measured through sentiment analysis of textual data using both the FinBERT and ChatGPT-4o models, and the obtained outputs are combined with financial metrics to construct an LSTM-based stock price prediction model. To enhance the model's stability, LSTM models derived from different training sessions are merged using an ensemble learning method, and the two approaches are compared. The results demonstrate that the ensemble model outperforms the standard LSTM model, and integrating financial indicators with tweet and news data, as opposed to relying solely on price data, leads to increased overall profit.",Measurement;Training;Analytical models;Predictive models;Signal processing;Data models;Stability analysis;Stock markets;Long short term memory;Standards;Financial Forecasting;Stock Market Prediction;Deep Learning;Deep Neural Networks;Multimodal Machine Learning;Large Language Models,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10704454,10.1109/DOCS63458.2024.10704454,Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach,"Accurate stock market predictions following earnings reports are crucial for investors. Traditional methods, particularly classical machine learning models, struggle with these predictions because they cannot effectively process and interpret extensive textual data contained in earnings reports and often overlook nuances that influence market movements. This paper introduces an advanced approach by employing Large Language Models (LLMs) instruction fine-tuned with a novel combination of instruction-based techniques and quantized low-rank adaptation (QLoRA) compression. Our methodology integrates ‘base factors‘, such as financial metric growth and earnings transcripts, with ‘external factors‘, including recent market indices performances and analyst grades, to create a rich, supervised dataset. This comprehensive dataset enables our models to achieve superior predictive performance in terms of accuracy, weighted Fl, and Matthews correlation coefficient (M CC), especially evident in the comparison with benchmarks such as GPT-4. We specifically highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases significant improvements over baseline models. The paper also discusses the potential of expanding the output capabilities to include a ‘Hold’’’’’ option and extending the prediction horizon, aiming to accommodate various investment styles and time frames. This study not only demonstrates the power of integrating cutting-edge AI with fine-tuned financial data but also paves the way for future research in enhancing AI -driven financial analysis tools.",Measurement;Adaptation models;Accuracy;Large language models;Machine learning;Predictive models;Stock markets;Tuning;Optimization;Investment;Large Language Model;Quantized Low-Rank Adaptation;Instruction Fine Tuning,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10967744,10.1109/CSNT64827.2025.10967744,Recommender Systems for Sector-Specific Stock Analysis,"Recommender systems are essential tools that assist users in making informed decisions by providing suggestions based on their previous actions and preferences. Traditional methods like content based and collaborative filtering work well for smaller datasets but often fail to extract information from large datasets due to their limited ability to capture complex patterns. This paper introduces a novel approach for stock recommendation that leverages a large language model, Llama 3.1, fine-tuned on financial news data. Financial news headlines and summaries were collected using the FinnHub API which served as the primary dataset. The system integrates stock price forecasting, sentiment analysis, and performance indicators to generate an effective analysis for decision making. The forecasting algorithm generates the stock price predictions which were integrated with sentiment analysis and stock performance indicators to create an informative prompt-response dataset for fine-tuning. The proposed system ranks stocks based on positive developments, potential concerns, and forecasted closing prices, providing Buy or Sell recommendations. Experimental results demonstrated moderate performance for predicting Buy recommendations, while Sell predictions exhibited lower accuracy comparatively. Analysis based on sectors revealed that the consumer cyclical and healthcare sectors yielded the best performance for Buy and Sell recommendations, respectively.",Analytical models;Sentiment analysis;Social networking (online);Large language models;Predictive models;Prediction algorithms;Real-time systems;Forecasting;Stock markets;Recommender systems;Recommender Systems;Large Language Models;Ranking Algorithm,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10638546,10.1109/ACCESS.2024.3445413,"Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study","This paper comprehensively examines Large Language Models (LLMs) in sentiment analysis, specifically focusing on financial markets and exploring the correlation between news sentiment and Bitcoin prices. We systematically categorize various LLMs used in financial sentiment analysis, highlighting their unique applications and features. We also investigate the methodologies for effective data collection and categorization, underscoring the need for diverse and comprehensive datasets. Our research features a case study investigating the correlation between news sentiment and Bitcoin prices, utilizing advanced sentiment analysis and financial analysis methods to demonstrate the practical application of LLMs. The findings reveal a modest but discernible correlation between news sentiment and Bitcoin price fluctuations, with historical news patterns showing a more substantial impact on Bitcoin’s longer-term price than immediate news events. This highlights LLMs’ potential in market trend prediction and informed investment decision-making.",Sentiment analysis;Bitcoin;Analytical models;Predictive models;Large language models;Correlation;Quality assessment;Large language model;Bitcoin price;sentiment analysis;machine learning;market dynamics,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050563,10.1109/CAI64502.2025.00032,Graph LLM-Based Portfolio Management Algorithm,"This paper explores the integration of large language models (LLMs) with graph-based financial networks for quantitative trading. By leveraging GPT-3 for stock network return predictions, we develop a Graph-LLM trading strategy. Experimental results demonstrate that the proposed strategy achieves lower volatility and more stable performance than traditional baselines. Our findings highlight the potential of combining LLMs with financial complex networks to enhance quantitative trading strategies.",Large language models;Complex networks;Prediction algorithms;Portfolios;Quantitative trading;Financial complex networks;Large language models;Graph-based trading strategies,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11051550,10.1109/ICAISISAS64483.2025.11051550,Machine Learning Approaches to Picking A-Shares Stocks: A Comparative Analysis,"This study explores the integration of advanced machine learning (ML) techniques and large language models (LLMs) in financial modeling, focusing on the Chinese stock market. It introduces the ChatGPT Score, an LLM-driven sentiment analysis factor, and compares the traditional Fama-French five-factor (FF5) model with its augmented version, FF5+ChatGPT Score. The research evaluates linear regression models against ML models, such as Random Forests, Extreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine (LightGBM), and Category Boosting (CatBoost), within five- and six-factor frameworks. Empirical results show that the ChatGPT Score outperforms traditional sentiment tools like SnowNLP and improves the predictive accuracy of the FF5 model. Additionally, CatBoost and Random Forests demonstrate strong portfolio management capabilities. Statistical validation through retrospective analysis confirms the effectiveness of the models, while industry feedback highlights their practical value in investment strategies. However, the study acknowledges the limitations of current models and recommends future research on deep learning techniques to improve financial market analysis and predictive accuracy.",Analytical models;Sentiment analysis;Accuracy;Predictive models;Chatbots;Boosting;Risk management;Stock markets;Random forests;Portfolios;Chinese Stock Market;Financial Modeling;Fama-French Models;Machine Learning;Random Forests;XGBoost;LightGBM;CatBoost;Large Language Models;Sentiment Analysis;ChatGPT Score,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825946,10.1109/BigData62323.2024.10825946,Stock Price Prediction Using LLM-Based Sentiment Analysis,"This paper examines the effectiveness of recent large language model-based news sentiment estimation for stock price forecasting with the combination of latest transformer-based prediction models. To achieve a better accuracy in sentiment classification, experiments are designed to compare six different models (GPT 4, Llama 3, Gemma 2, Mistral 7b, FinBERT, VADER) in financial news sentiment classification, and it was found that recent large language models can outperform FinBERT and VADER, which are the most commonly used models in financial sentiment analysis. Based on the experiment results, Llama 3, with relatively stable performance, is chosen to classify the news sentiments of the selected companies. Informer, Transformer, TCN, LSTM, SVR, Random Forest and Naive Forecast are used to predict the stock prices with different sliding window sizes. Experiments with different scenarios are designed to evaluate the prediction ability of news sentiment. Results show that adding news sentiment data can indeed improve the stock price prediction. Informer, one of the state-of-the-art transformer models for long-term prediction tasks, yields the best performances in most cases. Ablation study of Informer suggests that the generative style decoder plays an important role in performance improvement.",Sentiment analysis;Analytical models;Large language models;Time series analysis;Predictive models;Transformers;Data models;Decoding;Random forests;Long short term memory;time series forecasting;sentiment analysis;Transformer;Informer;LLM,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652123,10.1109/LSP.2021.3135793,Learning Sentimental and Financial Signals With Normalizing Flows for Stock Movement Prediction,"Stockmovement prediction using Tweets (text) and historical price signals (time series) remains a challenging task due to the complex, noisy and dynamic nature of the stock market. The key to improve prediction performance is effectively capturing the complementarity between market sentiment signal from Tweets and time-series signal from the stock price. In this paper, we contribute a new solution StockNF by exploiting a deep generative model technique, Normalizing Flow (NF), to learn more flexible and expressive posterior distributions of latent variables of Tweets and price signals, which can largely ameliorate the bias inference problem in existing methods. We empirically evaluate the NF technique on a public stock movement prediction dataset and show that StockNF outperforms the state-of-the-art baselines.",Predictive models;Time series analysis;Stochastic processes;Data models;Noise measurement;Task analysis;Social networking (online);Stock movement prediction;Fintech;normalizing flow;variational inference;generative models,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9702208,10.1109/ICNSC52481.2021.9702208,Stock Price Prediction Based on Conditional Flows Scenario Generation,"Stock price forecasting is an important issue in the financial field. However, most of the existing studies were focused on the prediction of a single stock, ignoring the correlation among different assets. A possible way to solve the above problem is to provide a set of scenarios which include the future returns of several stocks, instead of a single one. The flow-based model is a kind of deep learning model proposed in recent years, which has powerful data generation abilities. In this paper, we use a flow-based conditional generative model to forecast the stock price scenario. We use real stock market data to verify the proposed method. The simulation results show that the model based on the proposed method can capture the complex dependence of the future stock relationship and provide more accurate and diversified forecasting results.",Uncertainty;Simulation;Predictive models;Prediction algorithms;Data models;Sensors;Resource management;stock price forecasting;scenario;flow-based model,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10838194,10.1109/ASIANCON62057.2024.10838194,Future Finance: Predictive Insights and Chatbot Consultation,"The framework has four pillars on which the rest of it is built. Initially, the Stock Analysis sector is a data-driven approach where historical data is broken down into key components to reduce the amount of hidden information. This is as from there onwards the Stock Prediction module is run which applies predictive modeling methodologies to gain market revelations about future market trends and movements with precision which is informed to investors to help them not only to acquire profits but also maintain stability and to gain knowledge on what to expect. The Assystem, complementing smart wearables, utilizes AI Assistance, with forward facing conversational chatbot interface thus creating a natural environment for the users. This AI-enabled assistant provides customized suggestions, up-to-the-minute details, and impeccable representative behavior as it syncs to investors' expectations. Finally, the Market Guider feature offers users the news and updates from the stock market which were curated, enabling them to stay updated with the involved changes. For predictive analysis, we've opted for the LSTM model due to its superior performance compared to other models tested. It achieved an R-squared score of 0.89, indicating strong predictive power, and demonstrated robustness with a cross-validation score of 0.84 on both training and testing datasets. The model was serialized into a Hierarchical Data Format (HDF) file to save runtime operations and facilitate deployment in Streamlit. Through a Streamlit interface, users can input a stock ticker and receive predicted prices generated by the trained LSTM model.",Analytical models;Finance;Predictive models;User interfaces;Chatbots;Data models;Stock markets;Artificial intelligence;Wearable devices;Long short term memory;Future Finance;predictive insights;chatbot consultation;stock analysis;predictive modeling;AI assistance;market guider;real-time updates;proactive decision-making;Machine Learning;LSTM;Mean Squared Error (MSE);LLM,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10975739,10.1109/CiFer64978.2025.10975739,Leveraging Large Language Models and Retrieval-Augmented Generation for Enhanced Multi-Asset Portfolio Construction,"This study assesses the Large Language Models (LLMs) in creating investment portfolios. We implement a few-shot learning technique, followed by Retrieval Augmented Generation (RAG) enhanced with comprehensive up-to-date financial data, using Meta's latest LLM, Llama 3.1-8b. In the first phase, We assess the models' efficacy using key financial indicators, including total returns, annualized volatility, riskadjusted performance (Sharpe ratio), potential loss estimates (value-at-risk), and their pre-training knowledge with the S&P 500 Index performance baseline. In the second phase, we enhance the LLM's knowledge base by RAG and the latest historical and statistical metrics (such as earnings per share (EPS), dividends per share (DPS), profit margin, and many more) for each asset from different classes. The study constrains model inputs to specific sets of financial assets, such as equities, exchangetraded funds (ETFs), commodities, cryptocurrencies, and bonds. To evaluate model performance and adaptability, we analyzed across two distinct time frames: (1) within the models' training data cutoff, and (2) from the cutoff date to the present. This approach enables the assessment of model generalization to past and present market conditions. The research quantifies LLMs’ capabilities in financial asset allocation, comparing baseline performance against RAG-augmented strategies. Our results demonstrate that RAG-enhanced LLM significantly outperforms vanilla LLM in portfolio construction across various asset classes. We contemplate that these results could influence AI-driven financial decision-making processes such as automated trading, real-time sentiment analysis, and investment management.",Adaptation models;Analytical models;Biological system modeling;Large language models;Retrieval augmented generation;Training data;Data models;Resource management;Portfolios;Investment;Generative AI;Computational Finance;Asset Allocation;Large Language Models;Llama;Portfolio management,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825362,10.1109/BigData62323.2024.10825362,Leveraging Large Language Models for Institutional Portfolio Management: Persona-Based Ensembles,"Large language models (LLMs) have demonstrated promising performance in various financial applications, though their potential in complex investment strategies remains underexplored. To address this gap, we investigate how LLMs can predict price movements in stock and bond portfolios using economic indicators, enabling portfolio adjustments akin to those employed by institutional investors. Additionally, we explore the impact of incorporating different personas within LLMs, using an ensemble approach to leverage their diverse predictions. Our findings show that LLM-based strategies, especially when combined with the mode ensemble, outperform the buy-and-hold strategy in terms of Sharpe ratio during periods of rising consumer price index (CPI). However, traditional strategies are more effective during declining CPI trends or sharp market downturns. These results suggest that while LLMs can enhance portfolio management, they may require complementary strategies to optimize performance across varying market conditions.",Measurement;COVID-19;Fluctuations;Economic indicators;Large language models;Market research;Data models;Ensemble learning;Portfolios;Investment;Large language models;Finance;Prompt engineering;Persona;Ensemble method;Portfolio management,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10921844,10.1109/ICCIRT59484.2024.10921844,StockAI - Stock Analysis Tool Agent,"StockAI is a stock market analysis tool that integrates machine learning, traditional trading indicators, and intelligent agents to analyze live data and projections for stock investors. It does this by carrying out an analysis of the historical price trend of a stock and the ongoing stock markets from the use of mathematical indicators such as moving averages, relative strength index, and candlestick patterns. As a result, it aids in decision-making for both new and old traders. The system also leverages machine learning algorithms like random forests to generate price predictions with improved accuracy. StockAI’s interactive interface allows users to engage with the tool through natural language queries. However, challenges remain in evaluating the outputs of large language models, as current methods rely heavily on human evaluation. The ultimate goal of StockAI is to help investors make informed decisions, optimize market opportunities and mitigate risks through a combination of AI-driven analysis and traditional financial indicators.",Measurement;Sentiment analysis;Accuracy;Large language models;Natural languages;Real-time systems;Intelligent agents;Stock markets;Standards;Random forests;stock market analysis;agents;large language models;price prediction,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011880,10.1109/ICDSAAI65575.2025.11011880,AI-Driven Financial Analyst,"In the current study, large language models that process user queries and analyse stock market data are compared and used to construct an AI-enabled platform for real-time financial data analysis. In this regard, the proposed platform integrates many data sources that might be used for aggregate analysis, concentrating on the top 50 Indian NSE equities through front-end development using ReactJS and back-end development using Python Flask. The technology provides insights that are pertinent to time and events by gathering data at every imaginable level, from daily reports regarding filings and company actions to minute updates of stock tickers. The design, process, data classification, constraints, and suggestions for future iterations are the main topics of this study.",Data analysis;Large language models;Soft sensors;Query processing;Focusing;Data visualization;Companies;Real-time systems;Stock markets;Investment;Large Language Model (LLM);Financial data analysis;Real-time data processing;Flask;ReactJS;Stock market information;Query processing,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108638,10.1109/ICNLP65360.2025.11108638,Investigating the Predictive Capabilities of Large Language Models in Day Trading by Leveraging Multimodal Data,"This paper evaluates the predictive capabilities of six LLMs-GPT-4, GPT-4o, Llama 3, Claude 3.5, Mistral 0.3, and Gemma 2-in day trading using multimodal data. The LLMs process diverse inputs, including text-based price histories, news titles, and images. The lowest Mean Absolute Percentage Errors (MAPEs) (1.4%) were achieved by Claude 3.5 and Gemma 2 using only price history text and by Claude 3.5 and Mistral 0.3 with combined price and news history inputs, demonstrating LLMs' potential for accurate financial predictions through prompting without advanced technical expertise. Remarkably, GPT-4 and Claude 3.5 achieve MAPEs of just 1.7% and 1.5%, respectively, by processing only price history images. Furthermore, Gemma 2 achieves a MAPE of 1.5% using only news history inputs, without any information from the price history.",Accuracy;Large language models;Natural language processing;History;large language models;LLMs;multimodal;natural language processing;NLP,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10730589,10.1109/AiDAS63860.2024.10730589,GPT-4 Powered Virtual Analyst for Fundamental Stock Investment by Leveraging Qualitative Data,"This paper introduces an advanced AI-assisted tool, powered by GPT-4, for fundamental stock investment, offering human-like investment advice accompanied by supporting information to validate recommendations for users. While traditional stock market prediction tools rely heavily on quantitative data such as stock prices, volume, earnings, and dividends, the use of qualitative data for stock market analysis is an emerging trend. Recent advancements in AI, particularly with Generative AI like ChatGPT, have significantly influenced user interactions and decision-making processes. Recognizing the potential of AI across various industries, we have customized GPT-4 to perform fundamental analysis based on news, financial and annual reports of companies, government policies, and more. Our tool analyzes the above qualitative data and provide numerical scores along with logical and fact-based justifications for the short, medium, and long-term investment prospects of companies. The system delivers reliable recommendations for up to ten months without continuous monitoring, making it valuable to a wide range of users, from value investors to everyday traders. The benefits of using our tool are substantial, including significant time and cost savings.",Industries;Government policies;Costs;Optical character recognition;Companies;Market research;Reliability;Stock markets;Monitoring;Investment;Stock Market Investment;Qualitative Data;Fundamental Analysis;Generative AI;Virtual Analyst,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10967454,10.1109/CSICC65765.2025.10967454,LoopGAN: A Novel Multi-Step Generative Architecture for Sequential Stock Forecasting,"This paper introduces “LoopGAN,” an advanced generative model architecture designed for sequential stock forecasting, leveraging the strengths of Conditional GAN (CGAN) and Least Squares GAN (LSGAN) to enhance prediction accuracy in highly volatile financial time series. LoopGAN's unique recursive prediction mechanism allows each output to feed back as input, creating dynamic, extended forecasts across multiple time steps. Extensive evaluation of the Dow J ones Industrial Average (DJIA) dataset, highlights LoopGAN's superior performance, achieving a Mean Absolute Percentage Error (MAP E) of 0.005739. This result surpasses traditional models, with LoopGAN outperforming LSTM and RNN models, which registered MAPE scores of 0.006803 and 0.008023, respectively. These findings underscore LoopGAN's robustness, offering a marked improvement in prediction accuracy and confirming its reliability for complex financial forecasting tasks.",Accuracy;Computational modeling;Time series analysis;Computer architecture;Predictive models;Robustness;Feeds;Forecasting;Long short term memory;GAN;architecture;LSGAN;CGAN;stock forecasting,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10804210,10.1109/TEMPR.2024.3518624,Large Language Model-Based Bidding Behavior Agent and Market Sentiment Agent-Assisted Electricity Price Prediction,"Day-ahead electricity price prediction is crucial for market participants to make optimal trading decisions. The implementation of the five-minute settlement (5MS) process in the Australian National Electricity Market (NEM) on October 1, 2021, reduced the settlement interval from 30 minutes to 5 minutes. This change has led to more frequent adjustments in pricing, allowing for a more accurate reflection of real-time supply and demand conditions. However, this increased frequency has significantly heightened the complexity of price fluctuations in the wholesale market. Consequently, conventional machine learning and deep learning methods struggle to provide accurate predictions at this higher resolution. Since electricity prices are fundamentally determined by the supply-demand balance and the bidding behaviors of market participants, this work introduces individual participant's bidding behaviors into the prediction model. We fine-tune a pre-trained Large Language Model (LLM) to create bidding behavior agents, which forecasts day-ahead bidding behaviors. Moreover, market sentiment plays a significant role in electricity price volatility, yet it remains challenging to quantify and assess its impact. To address this, we employ a pre-trained LLM to analyze online resources, incorporating market sentiment into the price prediction model. Additionally, to enhance the accuracy of spike predictions, we improve the conditional time series generative adversarial network (CTSGAN) model by utilizing a spike confusion matrix and further strengthen the model by integrating bidding behavior and market sentiment as inputs. Case studies demonstrate that the proposed model significantly improves both electricity price and spike prediction accuracy, offering a robust tool for market participants to navigate the complexities of the modern electricity market.",Electricity;Predictive models;Accuracy;Data models;Electricity supply industry;Fluctuations;Supply and demand;Nanoelectromechanical systems;Generators;Adaptation models;Large language model (LLM);electricity price prediction;bidding behaviors;market sentiment;spike-enhanced,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10458651,10.1109/ISCMI59957.2023.10458651,Corporate Event Predictions Using Large Language Models,"This paper offers a thorough assessment of large language models (LLMs) in the context of corporate event prediction. To achieve this, we formally establish the task of corporate event prediction, construct a novel dataset containing summaries of earning call transcripts, and conduct comprehensive experiments involving both raw and fine-tuned variants of the primary LLMs. Our experimental findings underscore the viability of automating this intricate task using LLMs and highlight the unnecessariness of additional finetuning.",Predictive models;Task analysis;Machine intelligence;natural language processing;large language models;corporate events,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487580,10.1109/CSCE60160.2023.00302,Content Analysis of Items in Newspaper Data Using Table Arrangement Technology and ChatGPT for Stock Price Prediction,"In this study, we employed table arrangement techniques and ChatGPT to analyze newspaper content relevant to stock prices. Using table arrangement techniques, we effectively organized sentences from articles into tables, extracting 22 key content elements. Additionally, we discovered that ChatGPT possesses the ability to extract and present newspaper data in tabular form. Factors were found to influence stock price movements. Drops in stock prices were impacted by factors such as crude oil prices, and the COVID-19 pandemic. Conversely, rising stock prices were supported by global trends, and vac-cine effectiveness. Furthermore, we propose a highly effective, large-scale method for constructing tables by combining table arrangement techniques and ChatGPT. The proposed method achieves an accuracy rate of 0.95 under a lenient criterion.",COVID-19;Pandemics;Oils;Friction;Chatbots;Market research;Corona;stock prices;newspaper data;content analysis;table arrangement;ChatGPT;Regular Research Paper,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11064235,10.1109/ICECCC65144.2025.11064235,A Hybrid Genetic Algorithm and Large Language Model Approach for Agricultural Products Price Optimization,"This paper introduces a hybrid approach, based on Genetic Algorithm (GA) and Large Language Models (LLMs), namely Mixtral 8x7B, to optimize pricing strategies for agricultural products. The method processes real-time market data, using Machine Learning (ML) techniques to generate competitive and profitable price recommendations. GAs allow for adaptive optimization, while LLMs capture complex trends in the market, making this approach more precise with respect to the pricing strategy. Case studies related to onions and tomatoes illustrate the efficiency of the optimization process. The outcome shows that the optimized prices achieve a fitness score of 0.915 (onions) and a competitive index of 0.89 (onions) compared to the market averages. Compared to traditional methods, the proposed hybrid model provides a better approach towards decision making through multi-objective optimization and real-time data analysis. This research contributes to improved profitability for farmers by adopting sustainable pricing strategies and agricultural market efficiency.",Profitability;Large language models;Decision making;Pricing;Machine learning;Market research;Agricultural products;Real-time systems;Optimization;Genetic algorithms;Agricultural Price Optimization;Genetic Algorithms;Large Language Models;Mixtral 8x7B;Machine Learning;Market Efficiency;Farm Profitability;Sustainable Agriculture,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011079,10.1109/ICASSPW65056.2025.11011079,Hybrid Encoding-based Quantum Self Attention for Financial Time Series Analysis,"Self-attention mechanisms, central to Transformer architectures, have become foundational in the development of large language models (LLMs) and various advanced machine learning systems. These mechanisms are pivotal for effectively capturing complex data dependencies and relationships, which is crucial for tasks such as natural language understanding and generation. However, as dimensionality increases, self-attention mechanisms face significant challenges related to computational efficiency and scalability. This paper introduces an encoding-based quantum self-attention mechanism designed to address these issues by embedding classical data into quantum states. This approach facilitates more efficient computation and reduces model complexity. To further enhance performance for real-world applications, particularly in financial time series forecasting, we propose a hybrid model that integrates Long Short-Term Memory (LSTM) networks with quantum self-attention mechanism. Given the constraints of the Noisy Intermediate-Scale Quantum (NISQ) era, this hybrid approach represents a plausible solution, leveraging the strengths of both classical and quantum methods and focusing on achieving faster convergence. Experimental results demonstrate that our approach converges significantly quicker than traditional models, showcasing the advantages of integrating quantum techniques with classical machine learning for practical applications.",Computational modeling;Time series analysis;Predictive models;Signal processing;Transformers;Computational efficiency;Forecasting;Speech processing;Long short term memory;Convergence;Self-Attention;Transformers;Quantum Self-Attention;LSTM;Quantum Neural Networks,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11158803,10.1109/ICCTDC64446.2025.11158803,Temporal Data Analytics Through Reinforced LLM Architectures for Time-Series Pattern Discovery,"In these modern times, where much data are involved, temporal data analysis has become a significant medium toward meaningful pattern discovery for informed decision-making in many contemporary fields such as finance, healthcare, and environmental science. Traditional methods of time-series pattern discovery often cannot adequately provide insight into complex real-world datasets due to their high dimensionality and volume. This paper introduces an innovative paradigm that relies on the power of reinforcement-enhanced architectures of LLM to further enhance the improvement of temporal data analysis in timeseries pattern discovery. Our approach integrates the knowledge from state-of-the-art LLMs with reinforcement learning to improve the detection and explanation of complex temporal patterns. We have applied our proposed approach to several real datasets, including stock market indices from the S&P 500 and NOAA weather data. These results represent significant gains in the accuracy of pattern recognition and forecasting performance compared to traditional conventional methods of time-series analysis. Our further reinforced LLM architecture offers higher adaptability and scalability, making it suitable for diversified and large-scale temporal data sets. This advances not only the precision of time-series prediction but also provides deeper insights into the underlying temporal dynamics to drive more strategic and proactive decision-making processes. Our finding illustrates how reinforcement-aided LLM architectures may revolutionize temporal data analytics by opening ways to more robust and intelligent pattern-discovery systems in various real-world applications.",Adaptation models;Data analysis;Accuracy;Decision making;Finance;Reinforcement learning;Transformers;Forecasting;Standards;National Oceanic and Atmospheric Administration;Temporal Data Analytics;Reinforced LLM;Time-Series Patterns;Pattern Discovery;Real- World Datasets,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10881129,10.1109/DSIT61374.2024.10881129,Transformer-Based Models for Commodity Trading Price Forecasting,"Transformer-based models have gained significant traction across various fields such as natural language processing (NLP), large language models (LLM), smart transportation, and finance due to their ability to capture long-term dependencies and sequence patterns. However, their application in forecasting stock or commodity trading returns remains underexplored. In this study, we aim to compare the performance of three transformer-based models—Informer, Autoformer, and Transformer with Positional Encoder unit —alongside an LSTM for forecasting commodity returns. Specifically, the two datasets used will consist of historical commodity prices, including six types of metals. These models, known for their capacity to handle long sequence data, have shown promise in financial forecasting, particularly. Still, their potential in commodity trading price forecasting has been less studied. By evaluating these models based on historical metal prices, this research seeks to determine the most accurate model for predicting commodity returns, providing valuable insights for the commodity trading and financial sectors.",Accuracy;Large language models;Metals;Predictive models;Transformers;Natural language processing;Data models;Smart transportation;Forecasting;Long short term memory;Transformer;Positional Embedding;Encoder;Autoformer;Informer;Time series;Commodity Trading,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10647180,,Applying Large Language Models to Issue Classification,"Effective prioritization of issue reports in software engineering helps to optimize resource allocation and information recovery. However, manual issue classification is laborious and lacks scalability. As an alternative, many open source software (OSS) projects employ automated processes for this task, yet this relies on substantial datasets for adequate training. This research investigates an automated approach to issue classification based on Generative Pre-trained Transformers (GPT). By leveraging the capabilities of such models, we aim to develop a robust system for prioritizing issue reports accurately, mitigating the necessity for extensive training data while maintaining reliability. In our research, we have developed a GPT-based approach to label issues accurately with a reduced training dataset. By reducing reliance on massive data requirements and focusing on few-shot fine-tuning, we found a more accessible and efficient solution for issue classification. Our model predicted issue labels in individual projects up to $93.2 \%$ in precision, $95 \%$ in recall, and $89.3 \%$ in F1-score.",Training;Large language models;Focusing;Training data;Standardization;Transformers;Data models;Issue Report Classification;Large Language Model;Natural Language Processing;Software Engineering;Labeling;Multi-class Classification;Empirical Study,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659283,10.1109/SMC52423.2021.9659283,Stock Price Prediction Using Sentiment Analysis,"We investigate the influence of financial news headline sentiment on the predictability of stock prices using Long Term Short Term Memory (LSTM) networks. The investigation is performed on intraday data with specific lag-times between published article headlines and realised stock prices. FinBERT, a natural language processing model which is fine-tuned specifically for financial news is used to perform sentiment analysis on the company related news headlines. Two base models, one with only historical stock price data as inputs and the other with both historical stock price data and sentiment data from the original BERT model is tested. An alternative model with have both historical stock price data and sentiment data from the fine tuned FinBERT model as additional features. A comparison is performed on both the base and alternative models using Root Mean Square Error (RMSE) and mean absolute error (MAE) as performance metrics. The results suggest that the use of news headline sentiment features from FinBERT significantly improve the predictive performance of LSTM networks in intraday stock price prediction. FinBERT features are also found to outperform features based BERT model trained on a general corpus, illustrating the positive effect of domain specific fine tuning for Large Language models.",Measurement;Sentiment analysis;Analytical models;Conferences;Bit error rate;Predictive models;Data models;FinBERT;language model;sentiment analysis;prediction;LSTM,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963060,10.1109/CAIT64506.2024.10963060,FN-Agents: Analysis of Exchange Rate Volatility Prediction Based on Multi-Agent Systems,"Exchange rate prediction is challenging. While large language models (LLMs) offer new approaches, their lack of domain-specific fine-tuning hinders effective assessment of factors influencing exchange rates. To address this, we propose FN-Agents—a framework integrating technologies such as vector databases, Retrieval-Augmented Generation(RAG), and self-reflection—to enable LLMs to better utilize external resources for exchange rate tasks. FN-Agents assists LLMs in acquiring expert knowledge, learning through self-reflection, building fine-tuned datasets, and ultimately generating interpretable core feature sets autonomously. Experiments demonstrate that FN-Agents excels in feature selection and enhances the predictive accuracy of mainstream models.",Computers;Exchange rates;Databases;Large language models;Learning (artificial intelligence);Predictive models;Feature extraction;Vectors;Forecasting;Multi-agent systems;Agents;Privatized Knowledge;Exchange Rate Forecasting;Experiential Learning,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341469,10.1109/IROS45743.2020.9341469,Risk-Sensitive Sequential Action Control with Multi-Modal Human Trajectory Forecasting for Safe Crowd-Robot Interaction,"This paper presents a novel online framework for safe crowd-robot interaction based on risk-sensitive stochastic optimal control, wherein the risk is modeled by the entropic risk measure. The sampling-based model predictive control relies on mode insertion gradient optimization for this risk measure as well as Trajectron++, a state-of-the-art generative model that produces multimodal probabilistic trajectory forecasts for multiple interacting agents. Our modular approach decouples the crowd-robot interaction into learning-based prediction and model-based control, which is advantageous compared to end-to-end policy learning methods in that it allows the robot's desired behavior to be specified at run time. In particular, we show that the robot exhibits diverse interaction behavior by varying the risk sensitivity parameter. A simulation study and a real-world experiment show that the proposed online framework can accomplish safe and efficient navigation while avoiding collisions with more than 50 humans in the scene.",,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11144933,10.1109/TENSYMP63728.2025.11144933,LLM-Augmented Enhanced Graph Transformer for Stock Movement Prediction,"Predicting stock price movements remains challenging due to the complex interactions and dynamics of financial markets. Recent deep learning advances, particularly integrating numerical data with linguistic analysis via large language models (LLMs), have shown promise. This study proposes an LLM-Augmented Enhanced Graph Transformer that combines LLM-generated financial analyses, FinBERT semantic embeddings, and a Graph Transformer to predict daily stock movements for 260 selected S&P 500 stocks in 2024. We construct a static stock relationship graph based on the cosine similarity of aggregated textual embeddings, capturing long-term semantic dependencies while integrating numerical indicators. Experimental results show our approach outperforms traditional time-series models (e.g., LSTM, Transformer, Informer) and graph-based methods (e.g., GCN, GAT), demonstrating the effectiveness of multimodal fusion and graph-based attention. We also discuss computational constraints and the limitations of static graphs, highlighting future directions such as dynamic graph modeling and optimized text processing.",Large language models;Computational modeling;Semantics;Linguistics;Transformers;Graph neural networks;Numerical models;Optimization;Long short term memory;Text processing;Graph neural networks;Graph Transformer;Stock movement prediction;Large Language Model,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871633,10.1109/ICCCMLA63077.2024.10871633,Adapting Speech Models for Stock Price Prediction,"Large language models (LLMs) have demonstrated remarkable success in the field of natural language processing (NLP). Despite their origins in NLP, these algorithms possess the theoretical capability to process any data type represented in an NLP-like format. In this study, we use stock data to illustrate three methodologies for processing regression data with LLMs, employing tokenization and contextualized embeddings. By leveraging the well-known LLM algorithm Bidirectional Encoder Representations from Transformers (BERT) [1], we apply quantitative stock price prediction methodologies to predict stock prices and stock price movements, showcasing the versatility and potential of LLMs in financial data analysis.",Adaptation models;Machine learning algorithms;Large language models;Machine learning;Predictive models;Transformers;Prediction algorithms;Tokenization;Encoding;Speech processing;finance;quantitative stock price prediction;natural language processing;stock movement prediction;fintech;machine learning;large language models,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427326,10.1109/HICSS.2016.147,Detecting Negation Scopes for Financial News Sentiment Using Reinforcement Learning,"Applying natural language processing to the domain of financial news requires robust methods that process all sentences correctly, including those that are negated. So far, related research commonly utilizes rule-based algorithms to detect negated sentence fragments, named negation scopes. Nonetheless, these methods involve certain limitations when encountering complex language or particularities of the chosen prose. As an alternative, reinforcement learning offers an opportunity to learn suitable negation classifications through trial-and-error experience. This method tries to replicate human-like learning and thus appears well-suited for natural language processing. Its episode-based and flexible structure allows for the handling of even highly complex sentences. Our results provide evidence that reinforcement learning can outperform rule-based approaches from the related literature. The best performing implementation reveals a predictive accuracy of up to 76.37% on a manually-labeled dataset, exceeding the predictive accuracy of rule-based approaches by 2.55 %. When utilizing the already trained reinforcement learning implementation for sentiment analysis, we find a potential subjectivity bias that limits the predictive performance of forecasting stock market returns.",,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10918270,10.1109/ICDMW65004.2024.00021,Sentiment Score of Bloomberg Market Wraps with ChatGPT,"In this paper, we used a large dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines affect stock market movements. To make this analysis more effective, we employed ChatGPT. First, from the summary of daily financial updates, we identify top global news headlines that could have a significant influence on stock markets. Second, for each headline, we questioned ChatGPT to answer whether the news might lead to a rise, a fall in stock prices or an indecisive future. This two-stage method proves more effective than a direct question on the entire text. By gathering ChatGPT’s predictions day by day, we formed an overall market sentiment score and transform this score into a practical investment strategy in the NASDAQ index, demonstrating the significance of minimizing noise in sentiment scores by initially accumulating and then detrending them. This approach showcases that ChatGPT’s analysis of news headlines can provide valuable insights into future stock market behaviours and be a valuable tool to develop intuitive NLP-driven investment strategies leveraging news predictive power.",Social networking (online);Soft sensors;Noise;Transforms;Predictive models;Media;Chatbots;Market research;Stock markets;Investment;NLP;ChatGPT;SentimentScore;Bloomberg News,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10874037,10.1109/FMLDS63805.2024.00071,Can GPT Price Options?,"Options are financial instruments that grant the holder the right, but not the obligation, to buy or sell an underlying asset at a predetermined price within a specified time frame. Traditional option pricing models, such as the Black-Scholes equation, depend on simplifying assumptions and struggle to effectively capture complex market dynamics. The study investigates the viability of using the Generative Pretrained Transformer (GPT) model to assess the value of stock options. We fine-tune the state-of-the-art GPT-3.5-turbo model by utilizing past option chain data and evaluate its precision in predicting option prices for well-known technology stocks including Apple (AAPL), Google (GOOG), and Microsoft (MSFT). Our model employs many features, including strike price, underlying price, days to expiry, and volatility index (VIX), to precisely predict option prices. Extensive examination undertaken at various degrees of moneyness and time horizons demonstrates that GPT models consistently surpass Black-Scholes in terms of both mean absolute error and root mean squared error. Out of all the models that were assessed, the 5-year data models exhibit the greatest overall accuracy. An error study suggests that pricing for options at the money has improved, but there are issues in appropriately pricing options that are highly in the money or out of the money. The GPT technique shows promise in leveraging transformers for computational finance applications.",Analytical models;Accuracy;Computational modeling;Generative Pre-trainer transformer;Pricing;Predictive models;Transformers;Data models;Mathematical models;Stock markets;Generative Pre-trained Transformer;Options;Stocks;Pricing;Black-Scholes Model;Machine Learning;Volatility;Finance Applications,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10738800,10.1109/ACCESS.2024.3488363,Leveraging LLMs for Financial News Analysis and Macroeconomic Indicator Nowcasting,"Approximating macroeconomic indicators is challenging due to the complex interaction of various factors, including global and national economic trends, political decisions, and unpredictable events like pandemics and natural disasters. These complexities, combined with the volatility of economies and the limitations of available data, make accurate modeling difficult. Sentiment analysis of economic news offers a novel approach to this challenge by providing instantaneous insights into public mood and market trends, capturing psychological and behavioral aspects that traditional models may miss. This method can enhance understanding of consumer confidence, investment trends, and stock market performance, for instance. In this study, we developed a dictionary and transformer-based sentiment model applied to over two decades of Hungarian economic news. To improve the model’s accuracy, we utilized large language models (LLMs) with active learning to efficiently augment the manually labeled sentiment dataset. We then compared the resulting sentiment-based time series with macroeconomic indicators such as GDP (Gross Domestic Product), PMI (Purchasing Managers’ Index), and unemployment rate. Our results show that integrating LLMs significantly enhances the accuracy of the sentiment models, and the sentiment-based indicators can serve as effective nowcasting tools for the inspected macroeconomic indicators.",Biological system modeling;Macroeconomics;Economics;Transformers;Analytical models;Data models;Sentiment analysis;Predictive models;Market research;Encoding;GDP;large language model (LLM);macroeconomic indicator;natural language processing (NLP);PMI;sentiment analysis;unemployment rate,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077509,10.1109/AIRC64931.2025.11077509,Adversarially Enhanced Financial Misinformation: A Comparative Analysis of LLM- vs. GAN-Generated Content Exposing AI Moderation Vulnerabilities,"As Large Language Models (LLMs) become more pervasive, their capability to generate convincing financial news poses an escalating threat to investor decision-making and market stability. However, contemporary content moderation and AIbased verification systems exhibit notable vulnerabilities when confronted with the subtle linguistic manipulations introduced by advanced prompt engineering techniques and adversarial training. This study investigated the comparative credibility, influence, and detectability of AI-generated financial headlines produced via Zero-Shot, Few-Shot (8-Shot), and Chain-of-Thought (CoT) prompting, with CoT outputs further used to train a GAN for adversarially enhanced text generation. We compiled a combined dataset of NASDAQ-listed securities and web-scraped, human authored news, generated additional AI-driven headlines under three prompting paradigms, and conducted a survey of randomly sampled headlines ($\mathbf{n} \boldsymbol{=} \mathbf{3 0 0}$) to assess the credibility, market perception impact, investment influence, and AI detectability. The analysis revealed that headlines generated through Chain-of-Thought prompting consistently scored higher in perceived authenticity, influenced investment sentiment more profoundly, and were harder for participants to classify as AI-written. The findings underscore the urgent need for adversarially robust content moderation and verification mechanisms, capable of adapting to the rapidly evolving landscape of AI-generated financial misinformation, particularly when Chain-of-Thought reasoning is leveraged to enhance GAN-generated content.",Training;Surveys;Terminology;Large language models;Natural language processing;Stability analysis;Prompt engineering;Security;Fake news;Investment;Large Language Models (LLMs);Generative Adversarial Networks (GANs);AI-Generated Misinformation;Adversarial Learning;AI Content Moderation;Natural Language Processing (NLP);Misinformation Detection,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10913442,10.1109/ICICYTA64807.2024.10913442,The Role of News Sentiment in Predicting the Jakarta Composite Index Using Long Short-Term Memory,"This paper investigates the integration of sentiment analysis and historical data to enhance the accuracy of Jakarta Composite Index (JCI) stock return predictions using a Long Short-Term Memory (LSTM) model. The dataset spans January 3, 2014, to August 6, 2024, consisting of 2,647 daily observations enriched with sentiment scores derived from over 10,000 Kompas.com news articles. Sentiment analysis, performed using a Large Language Model (LLM)-based ChatGPT model, classified sentiment into Positive, Neutral, and Negative categories, which were then integrated as predictive features. Five scenarios for incorporating sentiment data were evaluated, with Scenario 2 (sequence of past sentiment scores) yielding the best performance. Specifically, it achieved the lowest Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) across various metrics: 36.4570 and 47.5527 for Absolute Return prediction, 0.005209 and 0.006804 for Relative Return prediction, and 50,725 and 65,653 for Close Price prediction. These findings underscore the significant role of sequential sentiment data in improving prediction accuracy, offering practical recommendations for investors to leverage sentiment analysis in making more informed decisions in the JCI market.",Measurement;Sentiment analysis;Analytical models;Accuracy;Predictive models;Data models;Indexes;Root mean square;Long short term memory;Testing;stock prediction;LSTM;sentiment analysis;JCI,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029970,10.1109/ICSE55347.2025.00070,Fairness Testing Through Extreme Value Theory,"Data-driven software is increasingly being used as a critical component of automated decision-support systems. Since this class of software learns its logic from historical data, it can encode or amplify discriminatory practices. Previous research on algorithmic fairness has focused on improving “average-case” fairness. On the other hand, fairness at the extreme ends of the spectrum, which often signifies lasting and impactful shifts in societal attitudes, has received significantly less emphasis. Leveraging the statistics of extreme value theory (EVT), we propose a novel fairness criterion called extreme counterfactual discrimination (ECD). This criterion estimates the worst-case amounts of disadvantage in outcomes for individuals solely based on their memberships in a protected group. Utilizing tools from search-based software engineering and generative AI, we present a randomized algorithm that samples a statistically significant set of points from the tail of ML outcome distributions even if the input dataset lacks a sufficient number of relevant samples. We conducted several experiments on four ML models (deep neural networks, logistic regression, and random forests) over 10 socially relevant tasks from the literature on algorithmic fairness. First, we evaluate the generative AI methods and find that they generate sufficient samples to infer valid EVT distribution in 95% of cases. Remarkably, we found that the prevalent bias mitigators reduce the average-case discrimination but increase the worst-case discrimination significantly in 35% of cases. We also observed that even the tail-aware mitigation algorithm-MiniMax-Fairness-increased the worst-case discrimination in 30% of cases. We propose a novel ECD-based mitigator that improves fairness in the tail in 90% of cases with no degradation of the average-case discrimination. We hope that the EVT framework serves as a robust tool for evaluating fairness in both average-case and worst-case discrimination.",Hands;Logistic regression;Generative AI;Prevention and mitigation;Software algorithms;Software;Logic;Random forests;Software engineering;Testing;software testing;fairness;extreme value theory,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10957017,10.1109/IC363308.2025.10957017,AI-Powered Business Administration Evaluation of Risk Models,"So to reveal the meaning of really working in the warp of the fastest changing enterprise you can start to click the following next spaces in future websites. It's because many traditional risk assessment models, while good at what they do, are often ill equipped to accurately source upon and analyze the types of dynamic, expansive and unstructured data sets that are commonplace in a modern enterprise. In this brief article we introduce a emerging application of AI–driven risk assessment models that builds on the Transformer architectures (e.g., BERT, GPT and their domain-specific adaptations) to overcome such challenges. Initially created for Natural Language Processing, these powerful models have now achieved state-of-the-art performance across a remarkably broad range of disciplines through previously unimaginable levels of contextual understanding, data synthesis and pattern recognition across multiple data-types. This paradigm shift can be attributed to handicap self-attention mechanisms followed by transformers — architectures in a position to grip through so a lot of info successfully with this self-attention mechanism. This aids in traversing the secondary sources (such as structured data and unstructured databases) of the end-user or legal reviews, which chronicles the risk characteristics in enterprise management. It shows how Transformers can be tuned to industry-specific nuances, and to signal risk — in the context to compliance, financial performance, cybersecurity and operational disruptions. They allow proactive risk management by identifying and managing potential risks before they materialize, employing real-time data streams and historical data analysis to develop predictive insights and recommendations for decision-makers. On the other hand, adding Transformers to existing risk assessment procedures provides wider scalability and adaptability in enterprise management systems. Traditional models take many time iterations to be generalized whereas Transformer models use transfer learning and pre-trained architectures, both of which allow them to scale in industries and be implemented relatively quickly as a result of pre-established architectures. (They can, in the case of financial services, for example, be used to detect credit risks by analyzing histories of borrowers and macroeconomic trends, etc.) In supply chain management for example, they identify vulnerabilities by integrating information about suppliers, market conditions and geopolitical elements. Besides, Transformer-based features-based AI integrated risk assessment models improve human-machine collaboration. The systems also offer human oversight, particularly due to the transparency of the reasoning behind the model outputs and the potential for confidence scores that allow condensation of the data — all essential attributes to ensure that major decision-makers in society are both transparent and accountable. It is particularly crucial in regulated industries, where auditability must be by law and ethics.",Adaptation models;Analytical models;Computational modeling;Predictive models;Transformers;Data models;Real-time systems;Natural language processing;Risk management;Artificial intelligence;AI-driven;risk assessment;Transformer architecture;enterprise management;natural language processing;predictive insights;real-time data;financial performance;supply chain vulnerabilities;operational disruptions,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425223,10.1109/CAIDA51941.2021.9425223,A Methodology for Securities and Cryptocurrency Trading Using Exploratory Data Analysis and Artificial Intelligence,"This paper discusses securities and cryptocurrency trading using artificial intelligence (AI) in the sense that it focuses on performing Exploratory Data Analysis (EDA) on selected technical indicators before proceeding to modelling, and then to develop more practical models by introducing new reward loss function that maximizes the returns during training phase. The results of EDA reveal that the complex patterns within the data can be better captured by discriminative classification models and this was endorsed by performing back-testing on two securities using Artificial Neural Network (ANN) and Random Forests (RF) as discriminative models against their counterpart Naïve Bayes as a generative model. To enhance the learning process, the new reward loss function is utilized to retrain the ANN with testing on AAPL, IBM, BRENT CRUDE and BTC using auto-trading strategy that serves as the intelligent unit, and the results indicate this loss superiorly outperforms the conventional cross-entropy used in predictive models. The overall results of this work suggest that there should be larger focus on EDA and more practical losses in the research of machine learning modelling for stock market prediction applications.",Training;Radio frequency;Analytical models;Data analysis;Artificial neural networks;Predictive models;Data models;securities;cryptocurrency;stock market;artificial intelligence;machine learning;probabilistic modelling;classification models;artificial neural network;random forests;naïve bayes,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10914764,10.1109/IDCIOT64235.2025.10914764,"Comparative Advances in Financial Sentiment Analysis:A Review of BERT,FinBert, and Large Language Models","Capturing market sentiments and supporting well-informed financial decision-making depend on the developing field of Financial Sentiment Analysis (FSA). Natural language processing (NLP) has made significant strides in comprehending and categorizing sentiment in intricate financial texts, especially with the use of Large Language Models (LLMs). The application of various LLMs, such as Bidirectional Encoder Representations form Transformers(BERT) and Financial BERT (FinBERT), as well as distilled models, such as DistilBERT and DistilRoBERTa, on a variety of financial datasets, including Financial Phrase Bank and LexisNexis news articles, was the main focus of this review article. highlighting different approaches such as model fine-tuning, zero-shot and few-shot learning, and prompt engineering. The study focuses on practical model predictions through a case study of sentimental analysis of cryptocurrencies. While FinBERT, a financial variant of BERT, exhibits high accuracy and robustness, other LLMs exhibit varying degrees of success based on the dataset and domain requirements. The analysis concentrates on the difficulties, compromises, and potential paths for improving LLMs for financial sentiment analysis.",Sentiment analysis;Technological innovation;Reviews;Large language models;Decision making;Bidirectional control;Market research;Encoding;Risk management;Indexing;Fin Bert;LLMs;BERT;Financial Sentimental Analysis;FSA;Financial Datasets;Data preprocessing,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10881868,10.1109/DSIT61374.2024.10881868,Comparative Analysis of LLM-based Market Prediction and Human Expertise with Sentiment Analysis and Machine Learning Integration,"This study conducts a comparative analysis of market prediction accuracy between Large Language Model (LLM)-based systems and human expertise within the financial analysis domain. Leveraging Quantum, an advanced LLM specialized for financial forecasting, we evaluate its predictive performance against human analysts and general-purpose LLMs, including GPT-3, GPT-4, FinGPT, and FinBERT. Employing a dataset of historical financial data, news headlines, and social media sentiment, we systematically assess predictive accuracy, response efficiency, and interpretability across models. The integration of sentiment analysis and machine learning further strengthens prediction reliability. Results reveal that Quantum’s specialized model demonstrates superior accuracy and speed in financial forecasting compared to human predictions and generalized LLMs, particularly in fast-moving, data-rich contexts. Nevertheless, limitations in nuanced contextual understanding and adaptability persist, highlighting the enduring value of human expertise. This research reinforces the potential of LLMs as robust tools for financial decision-making while identifying key areas for refinement to enhance synergy with human analytical insights. https://chatgpt.com/g/g-bS4Q76v0I-quantum",Analytical models;Adaptation models;Sentiment analysis;Accuracy;Machine learning;Predictive models;Data models;Reliability;Forecasting;Context modeling;Financial Prediction;Large Language Models;Sentiment Analysis;Market Forecasting;Machine Learning;Quantum AI,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8909804,10.1109/NYSDS.2019.8909804,Stacking with Neural Network for Cryptocurrency investment,"Predicting the direction of assets have been an active area of study and difficult task. Machine learning models have been used to build robust models to model the above task. Ensemble methods are one of them resulting better than single supervised method. We have used generative and discriminative classifiers to create the stack, particularly 3 generative and 6 discriminative classifiers and optimized over one-layer Neural Network to model the direction of price cryptocurrencies. Features used are technical indicators not limited to trend, momentum, volume, volatility indicators and sentiment indicators. For Cross validation, Purged Walk forward cross validation has been used. In terms of accuracy, we have done comparative analysis of the performance of Ensemble method with Stacking and individual models. We have also developed methodology for features importance for stacked model. Important indicators are identified based on feature importance.",Stacking;Predictive models;Neural networks;Bitcoin;Support vector machines;Bayes methods;Generative Models;Discriminative Models;Stacked Generalization;Xgboost;LightGBM;Bitcoin,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11176580,10.1109/ICCPCT65132.2025.11176580,Smart Finance Investment Management and Community Powered by Generative AI,"The smart Finance Investment Management and Community powered by using Generative AI is a revolutionary platform that leverages AI-pushed insights to help clients make knowledgeable economic selections. At the center of our device is FinLit, a generative AI model making use of prolonged quicktime period memory (LSTM) networks to offer customized funding tips based on individual demographics, together with gender, age, financial expertise, income, and investment period. The platform is educated and examined with the aid of the usage of an IBM economic dataset to make certain accuracy and reliability. Moreover, we combine a cost Tracker that visually represents customers’ spending patterns through a pie chart categorizing expenses (e.g., lease $30 \%$, financial savings $20 \%$). FinLit, similarly, analyzes these styles to imply regions in which customers can optimize their spending. To foster a collaborative financial environment, we introduce a network discussion board wherein clients can present insights, interact in discussions, and interact via likes and replies. Moreover, our financial sources phase offers direct links to numerous investment schemes, which include Public Provident Fund (PPF), steady Deposits (FD), countrywide savings certificate (NSC), and United States of America-huge Pension device (NPS), among others. Finally, to beautify financial literacy, we’ve got an amusing Quiz designed to educate and interact with users, helping them in improving their understanding of economic thoughts interactively. productivity and task delight.",Productivity;Computers;Costs;Generative AI;Finance;Mutual funds;Pensions;Reliability;Long short term memory;Investment;Generative AI;Investment Recommendation;LSTM;Expense Tracker;Financial Literacy;Community Forum;Mutual Funds;Equity Market;Financial Resources;IBM Datasets;Smart Finance,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10982029,10.1109/BigData62323.2024.10982029,CryptoPulse: Short-Term Cryptocurrency Forecasting with Dual-Prediction and Cross-Correlated Market Indicators,"Cryptocurrencies fluctuate in markets with high price volatility, which becomes a great challenge for investors. To aid investors in making informed decisions, systems predicting cryptocurrency market movements have been developed, commonly framed as feature-driven regression problems that focus solely on historical patterns favored by domain experts. However, these methods overlook three critical factors that significantly influence the cryptocurrency market dynamics: 1) the macro investing environment, reflected in major cryptocurrency fluctuations, which can affect investors collaborative behaviors, 2) overall market sentiment, heavily influenced by news, which impacts investors strategies, and 3) technical indicators, which offer insights into overbought or oversold conditions, momentum,and market trends are often ignored despite their relevance in shaping short-term price movements. In this paper, we propose a dual prediction mechanism that enables the model to forecast the next day’s closing price by incorporating macroeconomic fluctuations, technical indicators, and individual cryptocurrency price changes. Furthermore, we introduce a novel refinement mechanism that enhances the prediction through market sentimentbased rescaling and fusion. In experiments, the proposed model achieves state-of-the-art performance (SOTA), consistently outperforming ten comparison methods in most cases.",,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680204,10.1109/ICMLA52953.2021.00068,Intra-Day Price Simulation with Generative Adversarial Modelling of the Order Flow,"Intra-day price variations in financial markets are driven by the sequence of orders, called the order flow, that is submitted at high frequency by traders. This paper introduces a novel application of the Sequence Generative Adversarial Networks framework to model the order flow, such that random sequences of the order flow can then be generated to simulate the intra-day variation of prices. As a benchmark, a well-known parametric model from the quantitative finance literature is selected. The models are fitted, and then multiple random paths of the order flow sequences are sampled from each model. Model performances are then evaluated by using the generated sequences to simulate price variations, and we compare the empirical regularities between the price variations produced by the generated and real sequences. The empirical regularities considered include the distribution of the price log-returns, the price volatility, and the heavy-tail of the log-returns distributions. The results show that the order sequences from the generative model are better able to reproduce the statistical behaviour of real price variations than the sequences from the benchmark.",,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10938653,10.1109/TEM.2025.3554567,Being an Emotionally Unaffected Investor: Evidence From Bitcoin,"As one of the most prominent cryptocurrencies, Bitcoin has been at the forefront of a major revolution in the financial and technological sectors. This study utilizes data from social media to extract the emotional tendencies of investors in the Bitcoin market and analyze differences in investor behavior under various emotional features. We find that when investors exhibit reluctance (such as Sadness and Fear) to buy Bitcoin, it is the opportune moment to invest and achieve returns higher than expected. Conversely, when the emotional tone of investors becomes positive (such as Joy and Love), indicating a tendency to invest, we choose to avoid investing. Our research has also revealed that such emotional cues can assist in better predicting returns in the Bitcoin market. Analyzing market emotions contributes to a deeper understanding of market fluctuations and investor behavior. Our findings help stakeholders recognize the role of subjective emotions in the market and provide them with prudent investment advice: avoid relying excessively on the feelings of others, as this may trigger investment losses.",Bitcoin;Investment;Fluctuations;Social networking (online);Sentiment analysis;Electronic mail;Data mining;Finance;Predictive models;Blogs;BERT;bitcoin;investor behavior;large language models;machine learning;return prediction;textual analysis,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10772910,10.1109/CIFEr62890.2024.10772910,Semantic Graph Learning for Trend Prediction from Long Financial Documents,"The advent of large language models (LLMs) has initiated much research into their various financial applications. However, in applying LLMs on long documents, semantic relations are not explicitly incorporated, and a full or arbitrarily sparse attention operation is employed. In recent years, progress has been made in Abstract Meaning Representation (AMR), which is a graph-based representation of text to preserve its semantic relations. Since AMR can represent semantic relationships at a deeper level, it can be beneficially utilized by graph neural networks (GNNs) for constructing effective document-level graph representations built upon LLM embeddings to predict target metrics in the financial domain. We propose FLAG: Financial Long document classification via AMR-based GNN, an AMR graph based framework to generate document-level embeddings for long financial document classification. We construct document-level graphs from sentence-level AMR graphs, endow them with specialized LLM word embeddings in the financial domain, apply a deep learning mechanism that utilizes a GNN, and examine the efficacy of our AMR-based approach in predicting labeled target data from long financial documents. Extensive experiments are conducted on a dataset of quarterly earnings calls transcripts of companies in various sectors of the economy, as well as on a corpus of more recent earnings calls of companies in the S&P 1500 Composite Index. We find that our AMR-based approach outperforms fine-tuning LLMs directly on text in predicting stock price movement trends at different time horizons in both datasets. Our work also outperforms previous work utilizing document graphs and GNNs for text classification.",,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10725472,10.1109/ICCCNT61001.2024.10725472,Designing A Llama 2-Powered Chatbot for Enhanced College Website Support,"Most of the Colleges and universities are increasingly using artificial intelligence (AI) to improve website support and user experience in the fast-paced digital landscape of higher education. This research investigates a Natural Language Processing (NLP) based chatbot for college website support. In higher education’s digital landscape, AI-driven chatbots, particularly using the Large Language Model Meta AI Version 2 (LLaMA 2) model, are enhancing website support and user experience by addressing inquiries on admissions, courses, resources, and campus life. Another subset of research component is mainly focusing on predicting the cut-off marks for students for joining the institutions. Focusing on student/institutional cut-off mark prediction, the chatbot employs four different regression models to consider factors like joining year, quotas, previous marks, department preferences, exam difficulty, and job market demand. Evaluation metrics such as MSE, RMSE, and R-squared gauge predictive accuracy. By analyzing historical data and emphasizing academic performance, the study determines which regression models best predict student cut-off marks, ensuring a data-driven approach to decision-making. This AI-powered chatbot enhances user experience by providing comprehensive answers and accurately forecasting students’ academic performance.",Measurement;Computational modeling;Large language models;Education;Decision making;Focusing;Predictive models;Chatbots;User experience;Forecasting;LLaMA 2 Model;Cut-off Mark Prediction;Natural Language Processing (NLP);Regression;Artificial Intelligence (AI) Chatbot;Stakeholders;User-friendly Experience,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112648,10.1109/TBDATA.2025.3593370,FinMem: A Performance-Enhanced LLM Trading Agent With Layered Memory and Character Design,"We introduce FinMem, a novel Large Language Models (LLM)-based agent framework for financial trading, designed to address the need for automated systems that can transform real-time data into executable decisions. FinMem comprises three core modules: Profile for customizing agent characteristics, Memory for hierarchical financial data assimilation, and Decision-making for converting insights into investment choices. The Memory module, which mimics human traders' cognitive structure, offers interpretability and real-time tuning while handling the critical timing of various information types. It employs a layered approach to process and prioritize data based on its timeliness and relevance, ensuring that the most recent and impactful information is given appropriate weight in decision-making. FinMem's adjustable cognitive span allows retention of critical information beyond human limits, enabling it to balance historical patterns with current market dynamics. This framework facilitates self-evolution of professional knowledge, agile reactions to investment cues, and continuous refinement of trading decisions in financial environments. When compared against advanced algorithmic agents using a large-scale real-world financial dataset, FinMem demonstrates superior performance across classic metrics like Cumulative Return and Sharpe ratio. Further tuning of the agent's perceptual span and character setting enhances its trading performance, positioning FinMem as a cutting-edge solution for automated trading.",Decision making;Investment;Memory modules;Large language models;Data mining;Training;Real-time systems;Tuning;Reflection;Prediction algorithms;Deep learning;financial AI;financial technology;large language models;trading algorithms,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308192,10.1109/SSCI47803.2020.9308192,Probabilistic Analysis of Market Impact of Analysts’ Recommendation Revisions,"In this paper, we propose to model the short-term impact of recommendation revisions on stock price movements in probabilistic framework. Through the Bayesian models, we can consolidate the information of all analysts' recommendations on stocks and predict the post-recommendation price drifts of the underlying stocks. In addition, typically there are only a small number of recommendation revisions on specific stocks on each day. It implies that other analysts' views to a specific stock are unobservable. With the advantage of generative models, missing observations in the data of recommendation revisions can be accommodated easily. Secondly, we perform an empirical investigation of the Hong Kong equity market and find that the impact of recommendation revisions on stock prices is significant in the 1-day horizon, but insignificant in the longer time horizon when taking account of the transaction costs. Also, we propose trading strategies derived from the posterior probability of directions of price drifts based on the Bayesian models. In our experiment, during the out-of-sample period (1 Jan, 2019 to 21 Feb, 2020), the trading strategies gain double-digit profit returns after transaction costs.",Maximum likelihood estimation;Probabilistic logic;Indexes;Predictive models;Data models;Bayes methods;Training data;Bayesian;analyst recommendations;machine learning;trading strategy,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963106,10.1109/CAIT64506.2024.10963106,Research on Exchange Rate Prediction Driven by Multi-Source Heterogeneous Data: Based on Retrieval Augmented Generation and Explainable Machine Learning Models,"With the accelerating pace of global economic integration, exchange rate fluctuations have been influenced by various uncertain factors. The information explosion has further complicated the factors influencing exchange rate predictions. To fully utilize multi-source heterogeneous data and further optimize exchange rate prediction performance, this paper constructs an exchange rate prediction method based on Retrieval Augmented Generation (RAG) and Explainable Artificial Intelligence models. During the data processing stage, this paper first uses RAG technology to enhance the situational learning ability of Large Language Models (LLMs). By combining prompts and local sentiment databases, LLMs can perform real-time and accurate sentiment analysis on news headlines. Secondly, transfer learning is used to optimize the Inception(v3) model for sentiment analysis of news images, thereby more efficiently analyzing the sentiment variables contained in texts and images, effectively enriching the sources of multi-source heterogeneous data. Extensive experiments have shown that the multi-source heterogeneous dataset constructed in this paper can effectively improve the accuracy of exchange rate predictions and improve the predictive performance of various models across different time steps.",Exchange rates;Sentiment analysis;Accuracy;Biological system modeling;Computational modeling;Retrieval augmented generation;Transfer learning;Predictive models;Data models;Real-time systems;multi-source heterogeneous data;retrieval augmented generation;SHAP;exchange rate prediction,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073620,10.1109/NOMS57970.2025.11073620,Advancing Deep-Learning in NLP: From Network Logs to Text Classification,"This PhD Symposium Paper explores deep-learning based sequential modeling methods for textual data by investigating two applications: network security log analysis and financial forecasting. The network log analysis was performed using a hybrid approach that combines traditional pattern matching and transformer architectures. This method successfully identified common log patterns and achieved high accuracy in classifying new log types. For economic forecasting, economic news articles and retail data are used; transformer models demonstrated superior performance in sentiment analysis and item classification. Sentiment indices showed predictive power during economic downturns. These findings suggest that the integration of novel methods with traditional approaches can lead to improved models and robust applications that bridge qualitative and quantitative data.",Analytical models;Sentiment analysis;Biological system modeling;Text categorization;Predictive models;Network security;Transformers;Data models;Macroeconomics;Pattern matching;NLP;Deep Learning;Machine learning;Artifi-cial Intelligence;Network Security;Log Analysis;Macroeconomic Forecasting;LLM,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11148263,10.1049/icp.2025.2498,Mitigating market volatility impact in stock prediction: a Wasserstein GAN approach with GRU and CNN,"Stock price prediction plays a crucial role in financial decision-making, especially in volatile market conditions. Traditional forecasting methods, including statistical models and deep learning approaches, often struggle to adapt to rapid market fluctuations and unexpected events such as the COVID-19 pandemic. Moreover, many existing models require large datasets and fail to generalize well across different financial conditions. Addressing these challenges, generative models have gained attention for their ability to generate synthetic financial data and improve prediction accuracy. Here, we propose a Wasserstein Generative Adversarial Network (WGAN) with Gated Recurrent Units (GRU) as the generator and Convolutional Neural Networks (CNN) as the discriminator to enhance stock price forecasting robustness. Our model is trained using historical stock prices, trading volume, and technical indicators from four major U.S. companies—Apple, Amazon, Google, and Intel—over a period from 2014 to 2023. The dataset is split into pre-and post-COVID-19 periods to assess the model's adaptability to market anomalies. Experimental results indicate that the proposed WGAN-based model achieves an average Root Mean Square Error (RMSE) of 2.31, outperforming conventional methods such as Linear Regression and Long Short-Term Memory (LSTM) networks. Moreover, the model demonstrates minimal performance degradation when exposed to volatile periods, proving its robustness in handling market uncertainties. These findings suggest that WGAN with GRU and CNN is an effective approach to mitigating the impact of market volatility on stock price prediction. Future research will explore further optimizations, alternative generative architectures, and applications to different financial markets to refine prediction accuracy and generalizability.",,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10964288,10.1109/TCSS.2025.3557911,Enhancing Hybrid Bike-Sharing Systems Through Long-Term Inventory Management: A Generative-Model-Informed Reinforcement Learning Approach,"Hybrid bike-sharing systems (operating both bikes and ebikes) are emerging worldwide for flexibility and sustainability. Excessive rebalancing, while addressing supply-demand imbalances, causes financial burdens and resource waste. Hence, long-term daily operations (e.g., rebalancing at midnights for upcoming days) have practical economic significance, but they remain underexplored due to difficulties in tracking high within-day and between-day demand variability and the interplay between demand and daily inventory management strategies. Besides, cooperative operation of bikes and ebikes expands solution space, given their inherent demand coupling. This study is the first to explore long-term daily inventory strategies for the hybrid system (ebikes get charged at stations), determining spatial-heterogeneous inventory at midnight to maximize profits. To address the demand variability perception issue, we develop a recurrent-attentive neural process (RANP) model to predict hour-to-hour demand of the upcoming day. The RANP is integrated into a long-term optimization model, referred to as the generative-models-informed Markov decision process (GMI-MDP), where two cooperative intelligent agents determine the bike–ebike allocation based on demand perception and system rewards. A suite of numerical experiments utilizing a real-world dataset from New York is carried out, and various strategies are compared. The proposed method, through online and offline tests, demonstrates superiority over other MDP-based and rule-based methods, achieving a faster solution-seeking process and more stable rewards than MDP with exact upcoming demand. By comparing inventory volatility, we offer insights into managerial operations.",Predictive models;Inventory management;Vehicle dynamics;Resource management;Hybrid power systems;Heuristic algorithms;Shared transport;Electronic mail;Training;Systems operation;Bike–ebike allocation;generative models;long-term management;Markov decision process (MDP),IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11118821,10.1109/ICOCT64433.2025.11118821,Applications of Novel Deep Learning Algorithms for Analysing of Cryptocurrency,"With the worldwide spread of cryptocurrencies, data has become richer and more heterogeneous than before and, as a result, poses a new problem related to prediction and decision making. Although there has been recent increase in acceptance of machine learning (ML) and deep learning (DL) technologies, the current analytical models appear to have limited correspondence with cryptocurrency markets. This work directly addresses price forecasting, fraud detection, sentiment analysis, and risk management, thus illustrating the applicability of the current technologies. We implement complex and novel deep learning techniques such as long short-term memory, gated recurrent unit, Bidirectional-LSTM to explore the temporal and spatial behavior of data associated with cryptocurrencies. These models enable accurate predictions of price and market trends along with reinforcement strategies to refine trading strategies and generative models to assess the market and project what the future might require. This is used to help investors and traders spot patterns in the buying and selling of various crypto currencies, these models might have far-reaching effects on the economy. We compared the suggested model's output with that of current setups. This works findings reveal that the proposed model is more accurate than the alternatives since its prediction errors are lower.",Deep learning;Analytical models;Accuracy;Biological system modeling;Predictive models;Data models;Cryptocurrency;Fraud;Risk management;Long short term memory;Cryptocurrencies;price prediction;fraud detection;risk management;LSTM;GRU and Bi-LSTM,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10584081,10.1109/TII.2024.3417254,Efficient Deep Q-Learning for Industrial Equipment Calibration in Elevator Manufacturing,"Industrial equipment calibration is an essential element for the proper functioning of any production plant. Without frequent and proper calibration, the quality and efficiency of the overall production process are threatened. Despite its significance, it is often performed manually based on qualitative measures that may lead to suboptimal behavior. In this article, we propose a deep reinforcement learning (RL)-based methodology to automate the calibration process and evaluate it in an elevator control use case. Moreover, to overcome data scarcity we develop a simulation environment based on generative modeling that creates synthetic RL episodes. The proposed methodology relies on a minimal set of sensors and actuators, i.e., a webcam, an Arduino board, three stepper motors, and an edge computational unit. Nevertheless, experimental evaluations indicate that it can perform in real-time applications achieving accurate calibration results.",Calibration;Elevators;Webcams;Motors;Soft sensors;Q-learning;Feature extraction;Automatic calibration;deep Q-learning;parameter estimation;reinforcement learning (RL),IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6796720,10.1162/NECO_a_00007,Bayesian Online Learning of the Hazard Rate in Change-Point Problems,"Change-point models are generative models of time-varying data in which the underlying generative parameters undergo discontinuous changes at different points in time known as change points. Change-points often represent important events in the underlying processes, like a change in brain state reflected in EEG data or a change in the value of a company reflected in its stock price. However, change-points can be difficult to identify in noisy data streams. Previous attempts to identify change-points online using Bayesian inference relied on specifying in advance the rate at which they occur, called the hazard rate (h). This approach leads to predictions that can depend strongly on the choice of h and is unable to deal optimally with systems in which h is not constant in time. In this letter, we overcome these limitations by developing a hierarchical extension to earlier models. This approach allows h itself to be inferred from the data, which in turn helps to identify when change-points occur. We show that our approach can effectively identify change-points in both toy and real data sets with complex hazard rates and how it can be used as an ideal-observer model for human and animal behavior when faced with rapidly changing inputs.",,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10612494,10.1109/ICOECA62351.2024.00130,Developing an AI-Driven Chatbot for Enhanced College Website Support Using Machine Learning,"With the emerging technological revolutions, the higher education institutions are integrating Artificial Intelligence (AI) to enhance their website support and user experience. A GPT-2-based chatbot has been developed to assist students, faculty, and stakeholders in navigating the college websites easily. The objective of this research study is to support college websites by interacting with user queries and predicting the cut-off mar of the students based on their academic performance. This AI-driven chatbot employs machine learning and Natural Language Processing (NLP) techniques to address the inquiries regarding admissions, course details, academic resources, administrative procedures, and campus life. Utilizing deep learning techniques, the developed chatbot delivers comprehensive and contextually relevant responses, focusing on Q&A interactions. The chatbot, built upon the GPT -2 model by OpenAI, is skillful at generating human-like text and serves various applications, including customer support and information retrieval systems. Particularly, it specializes in predicting admission cut-off marks, employing regression models such as Linear Regression, Decision Tree Regressor, SVM Regressor, Random Forest Regressor, and XGBoost Regressor. These models consider various factors such as joining year, quotas, previous cut-off lists, department preferences, board exam difficulty, job market demands, and academic performance. The performance evaluation metrics like Mean Squared Error (MSE), Root Mean Square Error (RMSE), and R-squared are utilized to assess the predictive accuracy of the proposed chatbot. By performing a thorough analysis of historical student data, the chatbot provides users with detailed answers and accurate forecasts regarding future academic performance, thereby enhancing the overall user experience of educational websites.",Support vector machines;Accuracy;Predictive models;Chatbots;Transformers;User experience;Stakeholders;GPT-2(Generative Pre-Trained Transformer) Model;Cut-off Mark Prediction;Natural Language Processing;Regression;Artificial Intelligence Chatbot;Stakeholders;User-friendly Experience,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10594605,10.1109/ICETCI61221.2024.10594605,Fine-Tuning Gemma-7B for Enhanced Sentiment Analysis of Financial News Headlines,"In this study, we explore the application of sentiment analysis on financial news headlines to understand investor sentiment. By leveraging Natural Language Processing (NLP) and Large Language Models (LLM), we analyze sentiment from the perspective of retail investors. The FinancialPhraseBank dataset, which contains categorized sentiments of financial news headlines, serves as the basis for our analysis. We fine-tuned several models, including distilbert-base-uncased, Llama, and gemma-7b, to evaluate their effectiveness in sentiment classification. Our experiments demonstrate that the fine-tuned gemma7b model outperforms others, achieving the highest precision, recall, and F1-score. Specifically, the gemma-7b model showed significant improvements in accuracy after fine-tuning, indicating its robustness in capturing the nuances of financial sentiment. This model can be instrumental in providing market insights, risk management, and aiding investment decisions by accurately predicting the sentiment of financial news. The results highlight the potential of advanced LLMs in transforming how we analyze and interpret financial information, offering a powerful tool for stakeholders in the financial industry.",Measurement;Analytical models;Sentiment analysis;Accuracy;Predictive models;Robustness;Physiology;Sentiment Analysis;Financial News;NLP;LLM;Fine-tuning;gemma-7b,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11068814,10.1109/CVC65719.2025.00007,AI Oracle: A Blockchain-Powered Oracle for LLMs and AI Agents,"Large Language Models (LLMs) such as GPT and similar architectures have revolutionized artificial intelligence by enabling machines to understand and generate human-like text. However, these models are inherently statistical predictors rather than real-time reasoning systems, leading to fundamental limitations in accessing up-to-date information and verifying factual accuracy. This issue is particularly critical in high-stakes domains such as cryptocurrency markets, decentralized finance (DeFi), and autonomous AI agents, where real-time, verifiable, and tamper-proof information is essential for decision-making.In this paper, we introduce AI Oracle, a novel framework that integrates blockchain-powered oracles with LLMs and autonomous agents to ensure real-time access to cryptographically verified knowledge. We compare AI Oracle with both standalone LLMs and retrieval-based systems using the Model Context Protocol (MCP), highlighting significant advantages in factual reliability, adversarial robustness, and interpretability. AI Oracle combines decentralized consensus, immutable storage, and cryptographic attestation to equip AI agents with enhanced resistance to manipulation, hallucination, and misinformation.Beyond architectural improvements, we explore the broader applicability of AI Oracle across domains that require provable correctness and trust—ranging from real-world asset (RWA) tokenization to autonomous agent coordination and decentralized governance. By positioning AI Oracle as a trust-minimized epistemic infrastructure, we propose a new paradigm in AI systems: the fusion of decentralized trust with autonomous reasoning, enabling agents to operate with resilience, transparency, and embedded verifiability across dynamic environments.",Protocols;Finance;Training data;Decentralized applications;Real-time systems;Cognition;Autonomous agents;Tokenization;Cryptocurrency;Artificial intelligence;Price Oracle;Blockchain Technology;LLM;AI Agent;RWA,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11096317,10.1109/ICACI65340.2025.11096317,Beyond Single-Text Analysis: A Holistic Approach to Chinese Financial Sentiment,"Financial sentiment analysis is crucial to comprehend the functioning of markets, particularly in China, where social media significantly influences the behavior of investors. Despite the fact that sentiment analysis has progressed significantly, analyzing Chinese financial social media content remains challenging due to the lack of labeled datasets and the sophistication of Chinese social media discussions, making sentiment analysis challenging and inaccurate. Conventional approaches struggle to comprehend the subtle context, such as sarcasm and new Internet slang, and fail to fuse various sentiments from social media interactions effectively. This paper proposes a framework 11Source code is available at https://gitee.com/Monickar/Fin-Sentiment-LLM. that addresses these issues by fusing context-aware designs and integrating various sentiment signals. Our approach grasps the layered context of conversations and integrates various measurements and their interrelations into one sentiment indicator. Experiments on Chinese financial news and social media data show that our system performs better than the traditional method on both sentiment classification tasks and downstream financial applications. This provides a stronger solution for Chinese financial sentiment analysis.",Sentiment analysis;Social networking (online);Fuses;Oral communication;Solids;Real-time systems;Data models;Internet;Microstructure;Context modeling;Financial Sentiment Analysis;Chinese Social Media;Stock Forecast,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447993,10.1109/ICASSP48485.2024.10447993,Trend-Heuristic Reinforcement Learning Framework for News-Oriented Stock Portfolio Management,"Recent studies have shown that reinforcement learning (RL) methods have brought significant performance gains for stock portfolio management (PM) because they effectively utilize historical price information and directly generate portfolio weights. We found, however, that there is still great room for improvement in how to fully consider the impact of financial news and stock trends on PM while avoiding model instability caused by feature disparity and fragile convergence due to RL itself. Addressing this allows us to develop more profitable and robust PM strategies. To this end, we propose TrendTrader, a novel RL framework for news-oriented stock portfolio management with trend heuristics. Specifically, TrendTrader utilizes a large language model (LLM) to obtain sentiment scores of stock news and generates heterogeneous contexts based on global sentiment embedding, which enhances model stability in processing multimodal features. Further, TrendTrader incorporates trend heuristics into both the network architecture and the reward function, while combining supervised learning and reinforcement learning in the form of incremental training to facilitate policy network convergence. Extensive experiments in the U.S. market and the China market verify the state-of-the-art performance of TrendTrader.",Training;Supervised learning;Reinforcement learning;Signal processing;Market research;Stability analysis;Speech processing;Stock Portfolio Management;Reinforcement Learning;Incremental Learning;Multimodality,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126558,10.1109/COMPSAC65507.2025.00258,A Deep Reinforcement Learning Approach for Portfolio Optimization of Brazilian Assets Using Fundamental and Sentiment Indicators,"The Brazilian capital market presents unique challenges for portfolio optimization due to its volatility and information asymmetries. This paper proposes a Deep Reinforcement Learning (DRL) framework that integrates fundamental indicators, Portuguese-language news sentiment (via Gemini Pro), and market data (prices, volume). Five DRL algorithms (A2C, PPO, DDPG, TD3, SAC) were trained and evaluated across three feature scenarios using performance metrics such as Sharpe Ratio, Annual Return, and Maximum Drawdown. News sentiment classification and entity extraction were performed using Gemini Pro LLM. Statistical validation over 44 executions, including Shapiro-Wilk and Kruskal-Wallis tests, showed no significant differences among DRL methods. However, all DRL approaches outperformed the Ibovespa index and uniform Buy-and-Hold benchmark, highlighting the value of combining DRL with localized and diverse data sources for portfolio optimization in emerging markets.",Training;Sentiment analysis;Soft sensors;Software algorithms;Benchmark testing;Deep reinforcement learning;Performance metrics;Indexes;Portfolios;Optimization;Deep Reinforcement Learning;Portfolio Optimization;Sentiment Analysis;Fundamental Indicators;Large Language Model;Brazilian Financial Market,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167877,10.1109/CONIT65521.2025.11167877,InvestED: A Smart Financial Education Platform Using LSTM & Game Mechanics,"In the era of state-of-the-art machine learning, Long Short-Term Memory (LSTM) networks and Large Language Models (LLMs) have shown remarkable capabilities in sequence prediction and natural language comprehension respectively. Although such technologies have remade several domains, their application in financial education remains unexplored. In this research, we present InvestED, a new platform that taps the temporal dependency modeling capabilities of LSTM neural networks and contextual knowledge of LLMs to redefine financial literacy education for students. The bidirectional property of LSTM enables sophisticated market patterns to be captured by its dedicated forget, input, and output gates, while transformerbased LLMs provide natural language processing for personalized financial suggestions. Our setup utilizes the double-layer LSTM model ($\mathbf{1 0 0}$ and $\mathbf{5 0}$ units) to predict the performance of mutual funds, beating conventional statistical frameworks such as ARIMA and Prophet by $\mathbf{2 9 - 4 4 \%}$ lower error rates for all mutual fund types. The platform includes such advanced AI models within game-like interfaces such that a computation arena is availed to test investment decisions, monitor expenses, and learn financial aspects through the feedback loops produced by algorithms. Performance evaluation demonstrates the neural network’s superior potential for identifying non-linear market dependencies with mean absolute percentage errors as low as $\mathbf{2. 3 1 \%}$ for certain classes of investments in out-of-sample tests. InvestED demonstrates the potential of advanced deep learning architectures and natural language processing to redefine abstract financial education as a fun, data-driven learning experience, effectively bridging the pedagogical and technological challenges of equipping digitally-native generations with financial literacy.",Performance evaluation;Education;Neural networks;Mutual funds;Machine learning;Predictive models;Transformers;Natural language processing;Long short term memory;Investment;Gamification;Machine learning;Simulation;Financial literacy,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10363573,10.1109/HPEC58863.2023.10363573,"Energy Estimates Across Layers of Computing: From Devices to Large-Scale Applications in Machine Learning for Natural Language Processing, Scientific Computing, and Cryptocurrency Mining1","Estimates of energy usage in layers of computing from devices to algorithms have been determined and analyzed. Building on the previous analysis [3], energy needed from single devices and systems including three large-scale computing applications such as Artificial Intelligence (AI)/Machine Learning for Natural Language Processing, Scientific Simulations, and Cryptocurrency Mining have been estimated. In contrast to the bit-level switching, in which transistors achieved energy efficiency due to geometrical scaling, higher energy is expended both at the at the instructions and simulations levels of an application. Additionally, the analysis based on AI/ML Accelerators indicate that changes in architectures using an older semiconductor technology node have comparable energy efficiency with a different architecture using a newer technology. Further comparisons of the energy in computing systems with the thermodynamic and biological limits, indicate that there is a 27–36 orders of magnitude higher energy requirements for total simulation of an application. These energy estimates underscore the need for serious considerations of energy efficiency in computing by including energy as a design parameter, enabling growing needs of compute-intensive applications in a digital world.",Training;Thermodynamics;Analytical models;Computational modeling;Biological system modeling;Machine learning;Switches;Moore's law;From Bits to Architectures and Applications;Energy per Instruction;Energy per Bit;Instructions per Second;Specialized Architectures;Energy for Machine Learning and Artificial Intelligence;Natural Language Processing;ChatGPT;Energy for High Performance Scientific Computations;Energy for Crypto coin mining;Bitcoin;Thermodynamical Limit;Biological Limit;ATP;Sustainable Computing;Energy as a design parameter,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11066262,10.1109/TEM.2025.3585433,"Risk Management and Macroeconomic Disruptions in Supply Chains: The Role of Blockchain, Digital Twins, Generative AI, and Quantum Computing","The global economy faces increasing vulnerabilities from macroeconomic disruptions, such as regulatory changes, trade tensions, geopolitical conflicts, currency volatility, pandemics, and energy crises that undermine the resilience of operations and supply chain management (OSCM) systems. These disruptions exacerbate risks, including supply chain breakdowns, operational inefficiencies, and systemic weaknesses, with energy challenges emerging as a key concern due to their effects on production costs, inflation, and sustainability goals. Advanced technologies, such as blockchain, digital twins, generative artificial intelligence (AI), and quantum computing, offer transformative potential to enhance transparency, predictive accuracy, and decision-making agility. However, their adoption introduces inherent tradeoffs, as they can lead to energy-intensive operations, cybersecurity risks, and economic burdens. To make sense of these dynamics, this article develops a conceptual framework based on a multilayered information system architecture that links specific disruptions to corresponding digital responses. This framework is grounded in a thorough review of both conceptual and empirical literature, along with extensive discussions among the authors. It explores how these technologies can address the risks stemming from macroeconomic disruptions while also considering their broader economic implications and challenges. It argues that simplistic solutions fail to account for the duality of these technologies’ impacts and highlights the need for a systemic approach to integrate these technologies within OSCM. This article concludes by proposing actionable research directions for OSCM scholars and managers to navigate these complexities.",Supply chains;Macroeconomics;Blockchains;Digital twins;Risk management;Quantum computing;Organizations;Generative AI;Costs;Resilience;Blockchain;digital twins;generative artificial intelligence (AI);information system;macroeconomic disruptions;quantum computing;risk management;supply chain;TEM forum;technology management,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690672,10.1109/ICCIMS61672.2024.10690672,Self-Evolving Programs: A Novel Approach Leveraging LLMs and Quine Programs,"In an era where software systems undergo rapid evolution, the demand for self-evolving programs has received much attention. This paper introduces a groundbreaking methodology that amalgamates the predictive power of Large Language Model-Based Methods with the self-replicating nature of Quine Programs to organize self-evolving software. This innovative integration not only facilitates dynamic code adaptation to fluctuating runtime conditions but also pioneers a shift from traditional static coding paradigms. Through this approach, we aim to revolutionize software development, particularly enhancing security and performance with a focus on countering selfish mining attacks in Bitcoin. It should be noted that the suggested approach has not yet been considered in the field of software engineering, and its applications are not limited to software security. It has high potential to be used in every domain that requires adaptive programs. Since the suggested approach is novel, the proposed solution in Bitcoin is also novel. The results of simulation show the efficiency of the proposed solution.",Microwave integrated circuits;Codes;Runtime;Bitcoin;Predictive models;Software systems;Microwave theory and techniques;Security;Microwave FET integrated circuits;Software development management;Self-Evolving Programs;Language Model-based Methods;Quine Programs;Dynamic Code Optimization;Selfish Mining Defense,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10200052,10.1109/ACCAI58221.2023.10200052,Retracted: Automated AI - Equity Market Lead–Lag Prediction Based on Multivariate Time Series,"The lead-lag structure among time-series factors is the recognition that in multivariate time-series frameworks, some factor clusters significantly drive improvements in the framework, while various factors follow this development with time lags arises from. In this article, we propose a multivariate framework for the identification of lead-lag bundles in time series. We demonstrate that pairwise lead-lag interactions between time series can be viewed as a directed organization. There is a practical calculation for locating the lead-lag bundle set with significant pairwise imbalance in this instance. We investigate various options for the system's directed network clustering models and pairwise lead lag metric. Daily cost data on actual US values and the constructed generative model of the multivariate lead-lag time series framework are used to test the system. Using the pairwise lead-lag metric and directed tissue clustering computations, we offer a method for identifying lead-lag clusters in multivariate time series without a doubt. We demonstrate that the stationary tissue of pairwise lead-lag interactions between time series can be conceptualized as a directed tissue and that a suitable computation exists for locating the lead-lag groups in this type of tissue that have significant pairwise imbalances. increase.",,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10382518,10.1109/ACCESS.2024.3350638,Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering,"Blockchain technology has revolutionized the financial landscape, witnessing widespread adoption of cryptocurrencies due to their decentralized and transparent nature. As sentiments expressed on social media platforms wield substantial influence over cryptocurrency market dynamics, sentiment analysis has emerged as a crucial tool for gauging public opinion and predicting market trends. This paper explores fine-tuning techniques for large language models to enhance sentiment analysis performance. Experimental results demonstrate a significant average zero-shot performance gain of 40% on unseen tasks after fine-tuning, highlighting its potential. Additionally, the impact of instruction-based fine-tuning on models of varying scales is examined, revealing that larger models benefit from instruction tuning, achieving the highest average accuracy score of 75.16%. In contrast, smaller-scale models may experience reduced generalization due to complete model capacity utilization. To gain deeper insight into instruction effectiveness, the paper presents experimental investigations under different instruction tuning setups. Results show the model achieves an average accuracy score of 72.38% for short and simple instructions, outperforming long and complex instructions by over 12%. Finally, the paper explores the relationship between fine-tuning corpus size and model performance, identifying an optimal corpus size of 6,000 data points for the highest performance across different models. Microsoft’s MiniLM, a distilled version of BERT, excels in efficient data use and performance optimization, while Google’s FLAN-T5 demonstrates consistent and reliable performance across diverse datasets.",Cryptocurrency;Social networking (online);Analytical models;Training;Context modeling;Sentiment analysis;Transformers;Zero-shot learning;Context modeling;Supervised learning;Zero-shot learning;in-context learning;supervised fine-tuning;instruction tuned;prompt engineering,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6855483,10.1162/NECO_a_00603,Intrinsic Graph Structure Estimation Using Graph Laplacian,"A graph is a mathematical representation of a set of variables where some pairs of the variables are connected by edges. Common examples of graphs are railroads, the Internet, and neural networks. It is both theoretically and practically important to estimate the intensity of direct connections between variables. In this study, a problem of estimating the intrinsic graph structure from observed data is considered. The observed data in this study are a matrix with elements representing dependency between nodes in the graph. The dependency represents more than direct connections because it includes influences of various paths. For example, each element of the observed matrix represents a co-occurrence of events at two nodes or a correlation of variables corresponding to two nodes. In this setting, spurious correlations make the estimation of direct connection difficult. To alleviate this difficulty, a digraph Laplacian is used for characterizing a graph. A generative model of this observed matrix is proposed, and a parameter estimation algorithm for the model is also introduced. The notable advantage of the proposed method is its ability to deal with directed graphs, while conventional graph structure estimation methods such as covariance selections are applicable only to undirected graphs. The algorithm is experimentally shown to be able to identify the intrinsic graph structure.",,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10404041,10.1109/TDSC.2024.3355453,Solution Probing Attack Against Coin Mixing Based Privacy-Preserving Crowdsourcing Platforms,"Conventional crowdsourcing platforms primarily rely on a central server as the broker for information exchange. Although many efforts have been made, centralized platforms are still vulnerable to underlying security issues, such as an untrusted central server and single-point failure. Fortunately, blockchain has emerged as an alternative infrastructure for building crowdsourcing platforms. Many excellent designs of blockchain-based decentralized crowdsourcing (BDCS) solutions have been proposed. Benefiting from blockchain, BDCS can provide fascinating features, like tampering resistance and anonymity. However, a new attack surface appears in BDCS. Recently, a new attack against BDCS named solution probing attack has been identified. The solution-probing adversary can take advantage of the anonymity of BDCS to probe valid solutions using a generative model. Due to the transparency of blockchain transactions, the probing attack is effective even if solutions are encrypted. Nevertheless, we find transaction-mixing techniques effective in defending against probing attacks. In this article, we introduce the solution probing attack and an improved variant, which can attack coin mixing-based BDCS. We evaluate probing attacks on large-scale crowdsourcing tasks. Experimental results show that the adversary is capable of deceiving BDCS with a limited number of probing, even if the BDCS is protected by solution encryption and coin mixing techniques.",Crowdsourcing;Task analysis;Blockchains;Encryption;Data models;Smart contracts;Estimation;Crowdsourcing security;probing attacks;coin mixing;decentralized platform,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10763168,10.1109/ICSES63445.2024.10763168,"Artificial Intelligence Based Fraud Detection, Data Security and Privacy for Telecommunication Systems","Globally, fraud is increasing and has the potential to cost firms billions of dollars and inflict serious financial harm. Scholars hailing from several domains of application have put forth distinct methodologies. Examining these concepts can help us see the problems more clearly. Examining several approaches to fraud detection and prevention in the communications industry is the aim of this article. This paper gives a summary of the various categories of telecom fraud, problems that arise throughout the detection process, and some recommendations for how to solve them. The efficacy of the existing methodologies is documented at, succeeded by suggestions and suggestions for selecting the performance measurements that best suit the needs. There has been a notable shift in the use of advanced AI-driven solutions for fraud management in the telecom industry. The development of Generative AI is a significant breakthrough, giving CSPs powerful instruments to fight fraud. As a result of the transition from conventional to AI-based methodologies, fraud management is becoming more proactive and predictive, enabling CSPs to stay one step ahead of criminals.",Technological innovation;Consumer behavior;Banking;Media;Real-time systems;Robustness;Fraud;Telecommunications;Sensors;Internet of Things;Banking;Communication Service Providers;Consumers;Electronics;Industry;Real time Security,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11143425,10.1109/IWQoS65803.2025.11143425,LLMCatalyst: A Novel Incentive Mechanism for Client-Assisted Foundation Model Training,"Large foundation models, such as SORA and GPT-4, have emerged as a mainstream and promising trend in the deep learning community. Many evidences have showcased that the training of these large models can be facilitated by leveraging vast numbers of consumer-grade GPUs from client devices, rather than relying solely on high-end GPUs in centralized data centers. Although previous studies have primarily focused on the technical aspects of client-assisted model training, the incentive mechanisms for this scenario remain largely unexplored. Insights from P2P networks suggest that a well-designed incentive mechanism is both catalytic and indispensable for the widespread adoption of client-assisted model training. In this paper, we explore the incentive design problem of client-assisted model training and envision a novel hierarchical procurement auction that captures some properties of client-assisted model training, such as asynchronous client arrivals, synchronous training processes, and complex resource requirements. We formulate the incentive design problem as a social cost minimization problem with $l_{\infty}$-norm constraints and transform it into an approximation problem with an $l_{2}$-norm objective function which facilitates the design of an efficient approximation algorithm. Subsequently, we propose a primal-dual approximation algorithm for client selection and payment allocation, which guarantees a small competitive ratio and truthfulness. Both theoretical studies and experiments using real-world trace data are conducted to demonstrate the efficacy of our method.",Training;Procurement;Costs;Foundation models;Biological system modeling;Transforms;Quality of service;Approximation algorithms;Minimization;Resource management;LLMs;auction;client-assisted training,IEEE
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703702,10.1109/ACCAI58221.2023.10703702,Retraction Notice: Automated AI - Equity Market Lead–Lag Prediction Based on Multivariate Time Series,"The lead-lag structure among time-series factors is the recognition that in multivariate time-series frameworks, some factor clusters significantly drive improvements in the framework, while various factors follow this development with time lags arises from. In this article, we propose a multivariate framework for the identification of lead-lag bundles in time series. We demonstrate that pairwise lead-lag interactions between time series can be viewed as a directed organization. There is a practical calculation for locating the lead-lag bundle set with significant pairwise imbalance in this instance. We investigate various options for the system's directed network clustering models and pairwise lead lag metric. Daily cost data on actual US values and the constructed generative model of the multivariate lead-lag time series framework are used to test the system. Using the pairwise lead-lag metric and directed tissue clustering computations, we offer a method for identifying lead-lag clusters in multivariate time series without a doubt. We demonstrate that the stationary tissue of pairwise lead-lag interactions between time series can be conceptualized as a directed tissue and that a suitable computation exists for locating the lead-lag groups in this type of tissue that have significant pairwise imbalances. increase.",,IEEE
10.1186/s40854-025-00789-6,10.1186/s40854-025-00789-6,The power of ChatGPT in processing text: Evidence from analysis and prediction in the exchange rate markets,"This study investigates the application of large language models in analyzing sentiment features within the exchange rate markets. Traditional natural language processing methods, such as LDA and BERT, are effective in extracting topics from text; however, they fail to assess the relative importance of these topics in relation to target exchange rates. To bridge this gap, this paper employs ChatGPT to extract topics from texts and evaluate their importance scores, further enhancing exchange rate forecasting by integrating topic importance into the sentiment analysis framework. Through empirical analysis, the superiority of ChatGPT over LDA and BERT in both topic extraction and importance assessment is demonstrated. Furthermore, this study utilizes the topic importance scores generated by ChatGPT to develop a novel interval-valued sentiment index (TIS index). This index not only accounts for the relative importance of various events influencing exchange rate fluctuations but also captures the dynamic evolution of market sentiment within an interval. Empirical results highlight that the TIS Index significantly enhances the forecasting accuracy of interval models such as TARI and IMLP for exchange rates. These findings further demonstrate the advantages of ChatGPT in sentiment analysis within the foreign exchange market. These findings offer new insights into the application of ChatGPT in financial text research."," Language , Accuracy , Technological change , PSYCHOLOGY , Trends , ECONOMICS , SUSTAINABILITY , FINANCE , Text analysis , PSYCHOLOGY , Natural language processing , Chatbots , PSYCHOLOGY , ECONOMICS , ECONOMICS , Large language models;Financial Aid;Time Series Forecast;Deep Learning;Foundation Models;Large Language Models",Proquest
10.1007/s12525-025-00815-6,10.1007/s12525-025-00815-6,Wisdom of the crowd signals: Predictive power of social media trading signals for cryptocurrencies,"The emergence of cryptocurrencies and decentralized finance (DeFi) applications brings unique challenges, including high volatility, limited fundamental valuation methods, and significant informational reliance on social media. Consequently, traditional trading algorithms and decision support systems (DSS) often fall short in effectively capturing these dynamics, underscoring the need for tailored solutions. Recent research on sentiment analysis in cryptocurrency trading has provided mixed evidence regarding its predictive power, highlighting limitations in generalizability and reliability due to the inherent noise of social media content. Addressing these limitations, this study explores crowd-based trading signals, explicit buy and sell recommendations shared by users on social media platforms including X (formerly Twitter), Reddit, Stocktwits, and Telegram. We apply an event study methodology to analyze over 28,000 trading signals extracted using natural language processing (NLP) techniques based on large language models (LLMs). Our findings demonstrate that these explicit crowd-based signals significantly predict short-term cryptocurrency price movements, particularly for assets with lower market capitalization and recent negative returns. An out-of-sample trading strategy using these signals achieves superior risk-adjusted returns, outperforming both a standard cryptocurrency index (CCI30) and the S&amp;P 500. Additionally, we uncover the role of automated accounts (signal bots) actively disseminating trading recommendations. This research advances literature by introducing a precise alternative to sentiment analysis, contributing to the understanding of social media as a distributed financial information environment, and raising theoretical considerations about algorithmic agency and trust. Practical implications span investors, social media platforms, and regulators."," Social networks , FINANCE , Decentralization , PSYCHOLOGY , ECONOMICS , Financial information , SUSTAINABILITY , Digital currencies , Volatility , Risk adjustment , Algorithms , Decision support systems , SUSTAINABILITY , Large language models , PSYCHOLOGY , Sentiment analysis , SUSTAINABILITY , SUSTAINABILITY , FINANCE , Sentiment analysis , Social media , FINANCE , Neural networks , PSYCHOLOGY , Valuation , Trading , SUSTAINABILITY , Predictions , Generalizability , Reliability , Algorithms , Natural language processing , Large language models , Digital media , Decision support systems , Digital currencies , Natural language processing;Value-at-Risk;Bidirectional Generative Adversarial Networks;Financial Risk Management;Central Counterparty;Generative AI",Proquest
10.1007/s11063-025-11787-1,10.1007/s11063-025-11787-1,Detecting Bitcoin Sentiment: Leveraging Language Model Applications in Sentiment Analysis for Bitcoin Price Prediction,"As Bitcoin continues to establish itself as a global asset and discussions around relevant regulations become more active, there is an increasing demand for a comprehensive price prediction framework. To address this necessity, this study aims to enhance the accuracy of Bitcoin price predictions by integrating sentiment information with technical indicators, on-chain data, and cryptocurrency price data. Recognizing Bitcoin’s sensitivity to market sentiment, the proposed framework incorporates sentiment features derived from both lexicon-based methods and large language models. As unsupervised sentiment tools can introduce label noise particularly in domain-specific or ambiguous financial contexts, this study combines the outputs of multiple sentiment models at the feature level to construct a more stable representation. This design improves the robustness of downstream regression performance and distinguishes the framework from previous hybrid models that relied on a single sentiment source without component-wise evaluation. Experimental results using a dataset spanning 2700&#xa0;days showed that the long short-term memory (LSTM) model with a 3-day window achieves the best performance with mean absolute percentage error (MAPE) of 3.93% and R-squared value of 0.99106. Feature importance analysis further demonstrates sentiment index as the most impactful feature, as excluding it resulted in the largest decline in predictive accuracy. Additionally, the model's performance was evaluated under four major volatility periods, revealing MAPE values ranging from 1.49 to 4.03%, highlighting the framework’s practical capability in rapidly adapting to sudden market shifts. In summary, integrating sentiment information attained from multiple language models significantly enhanced prediction accuracy compared to single source approaches. These findings highlight the framework’s practical value for sentiment-informed investment strategies and risk alerts, with a modular design that enables flexible adaptation and potential integration into automated trading systems."," Language , Accuracy , Dictionaries , Deep learning , Performance evaluation , Trends , PSYCHOLOGY , ECONOMICS , Prices , SUSTAINABILITY , SUSTAINABILITY , Digital currencies , Investment strategy , PSYCHOLOGY , Accuracy , OPERATIONS , Large language models , SUSTAINABILITY , PSYCHOLOGY , Sentiment analysis , SUSTAINABILITY , FINANCE , Neural networks , SUSTAINABILITY , ECONOMICS , SUSTAINABILITY , Modular design , Natural language processing , FINANCE , Ablation , Large language models;Time Series Forecasting;Survey;Large Language Model;Deep Learning;Finance",Proquest
10.1080/1369118X.2024.2420021,10.1080/1369118X.2024.2420021,The <i>supply chain capitalism of AI</i>: a call to (re)think algorithmic harms and resistance through environmental lens,"Artificial Intelligence (AI) is woven into a supply chain of capital, commodities and human labour that has been neglected in critical debates. Given the current surge in generative AI – which is estimated to drive up the extraction of natural resources such as minerals, fossil fuels or water – it is vital to investigate its entire production line from a critical infrastructural perspective. Drawing on the supply chain capitalism , a concept coined by Anna L. Tsing in 2009, this paper contributes to critical AI studies by investigating the structure of AI supply chains, taking into account the mining, electronics, digital and e-waste industry. This paper illustrates how the supply chain capitalism of AI is precipitating geographical asymmetries connected to contested struggles in México by focusing on a key element of these chains: data centres. In times of climate emergency, this paper calls to reconsider algorithmic harms and resistance by investigating the entire capitalist production line of the AI industry from critical and environmental lens."," Artificial intelligence , Algorithms , Supply , Commodities , Resistance , Extraction , SUSTAINABILITY , Capitalism , Fossil fuels , Production lines , Resistance , Generative artificial intelligence , Modes of production , SUSTAINABILITY , Lenses , Minerals , ECONOMICS , Algorithms , Natural resources , Capitalism , Natural resources , Supply chains , Natural resources , Artificial intelligence;Sentimental Analysis;Social Media;Stock Market Change;Twitter;Large Language Models;Zero-shot Classification;Textual Entailment;Random Forest Classifier;Time-series Forecasting",Proquest
10.1007/s10614-024-10668-4,10.1007/s10614-024-10668-4,Modeling Asset Price Process: An Approach for Imaging Price Chart with Generative Diffusion Models,"Artificial Intelligence (AI) models have been recently studied to discover data patterns for prediction and forecasting tasks in finance. However, the use of deep generative models in finance remains relatively unexplored. In this paper, we investigate the potential of deep generative diffusion models to estimate unknown dynamics using multiple simulations based on stock chart images. We first demonstrate a novel pre-processing framework and synthetic image generation using opening, high, low, and closing stock chart images to train neural networks. Without assuming the specific process as the underlying asset price process, we can generate synthetic data without predetermined assumptions of the underlying movements of stock prices by trained generative diffusion models. The experimental results demonstrate that the proposed method successfully replicates well-known asset price processes. With various simulation paths, we can also accurately estimate option pricing on the S &amp;P 500. We conclude that financial simulation with AI can be a novel approach to financial decision-making."," Artificial intelligence , Finance , SUSTAINABILITY , FINANCE , Finance , Diffusion models , Deep learning , Random variables , Neural networks , SUSTAINABILITY , Simulation , Prices , SUSTAINABILITY , Neural networks , Decision making , FINANCE , Diffusion models , SUSTAINABILITY , Charts , Artificial intelligence , Image processing , Assets , Image generation , Synthetic data , Stock prices;indonesia stock exchange;multiplicative long short term memory;elitist whale optimization nonlinear parameter;improved bacterial foraging optimization;stock market trend prediction",Proquest
10.1111/1911-3846.13036,10.1111/1911-3846.13036,Can investors learn from patent documents? Evidence from textual analysis,"This paper examines the role of patent texts in the stock market valuation of patents. Utilizing the large language model BERT (Bidirectional Encoder Representations from Transformers) to summarize contextual information within patent texts, I find that patent texts explain 31.5% of the variation in the stock market valuation of patents and provide large incremental explanatory power beyond other structured patent characteristics, firm characteristics, and technological trends. Additionally, patent texts significantly predict the level, volatility, and cumulation speed of future earnings, suggesting they contain genuine information about firms' performance. However, investors do not fully incorporate such information within patent texts into stock prices, as evidenced by the predictive power of patent texts for future stock returns. This underreaction is diminished after the pre‐grant publication of patent applications is mandated. My findings underscore the value of patent texts as a source of information on internally developed intangibles and have implications for academics, practitioners, and regulators."," Earnings , Patents , Accumulation , Imposition , Prices , Textual analysis , FINANCE , Valuation , Academic staff , Power , Bidirectionality , Volatility , Securities markets , Stock prices , Contextual information;Financial Markets;Short-term Options;Option Valuation;Large Language Models;ChatGPT-3.5;ChatGPT-4;LLaMA 3.1;Bullish Prediction;Bearish Prediction;NIFTY50;Sentiment Analysis;Risk Management",Proquest
10.1371/journal.pone.0326034,10.1371/journal.pone.0326034,Enhancing stock timing predictions based on multimodal architecture: Leveraging large language models (LLMs) for text quality improvement,"This study aims to enhance stock timing predictions by leveraging large language models (LLMs), specifically GPT-4, to filter and analyze online investor comment data. Recognizing challenges such as variable comment quality, redundancy, and authenticity issues, we propose a multimodal architecture that integrates filtered comment data with stock price dynamics and technical indicators. Using data from nine Chinese banks, we compare four filtering models and demonstrate that employing GPT-4 significantly improves financial metrics like profit-loss ratio, win rate, and excess return rate. The multimodal architecture outperforms baseline models by effectively preprocessing comment data and combining it with quantitative financial data. While focused on Chinese banks, the approach can be adapted to broader markets by modifying the prompts of large language models. Our findings highlight the potential of LLMs in financial forecasting and provide more reliable decision support for investors."," FINANCE , Investments , Models , Large language models , Trends , Quality control , Language , PSYCHOLOGY , SUSTAINABILITY , Design , SUSTAINABILITY , Large language models , Investors , Redundancy , China , Economic;Wavelet;Time series;Prediction;Nonlinear System;Deep Learning",Proquest
10.1021/acs.analchem.4c05046,10.1021/acs.analchem.4c05046,Large Language Models (such as ChatGPT) as Tools for Machine Learning-Based Data Insights in Analytical Chemistry,"Artificial intelligence (AI), especially through the development of deep learning techniques like convolutional neural networks (CNNs), has revolutionized numerous fields. CNNs, introduced by Yann LeCun in the 1990s (Hubbard, W.; Jackel, L. D. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Comput. 1989, 1 (4), 541– 551. https://doi.org/10.1162/neco.1989.1.4.541), have found applications in healthcare for medical diagnostics, autonomous vehicles in transportation, stock market prediction in finance, and image recognition in computer vision to name just a few. Similarly, in analytical chemistry, deep learning has enhanced data analysis from techniques like MS spectrometry, NMR, fluorescence spectroscopy, and chromatography. Another AI branch, Natural Language Processing (NLP), has surged recently with the advent of Large Language Models (LLMs), such as OpenAI's ChatGPT. This paper demonstrates the application of an LLM via a smartphone to conduct multivariate data analyses, in an interactive conversational manner, of a hyper-spectral imaging data set from laser-induced breakdown spectroscopy (LIBS). We demonstrate the potential of LLMs to process and analyze data sets, which automatically generate and execute code in response to user queries, and anticipate their growing role in the future of analytical chemistry."," SUSTAINABILITY , Artificial intelligence , Deep learning , Analytical chemistry , Chatbots , Language , Artificial neural networks , Back propagation networks , SUSTAINABILITY , Computer vision , Machine learning , Nuclear magnetic resonance--NMR , Deep learning , SUSTAINABILITY , Chatbots , Data analysis , Datasets , Fluorescence spectroscopy , Large language models , SUSTAINABILITY , Smartphones , SUSTAINABILITY , Multivariate analysis , SUSTAINABILITY , Laser induced breakdown spectroscopy , Deep learning , Artificial intelligence , Natural language processing , Large language models , Handwriting recognition , Neural networks , Economic;Machine Learning;Stock Market;LLM;LSTM",Proquest
10.1021/acs.analchem.4c05046,10.1021/acs.analchem.4c05046,Large Language Models (such as ChatGPT) as Tools for Machine Learning-Based Data Insights in Analytical Chemistry,"Artificial intelligence (AI), especially through the development of deep learning techniques like convolutional neural networks (CNNs), has revolutionized numerous fields. CNNs, introduced by Yann LeCun in the 1990s (Hubbard, W.; Jackel, L. D. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Comput. 1989 , 1 (4), 541- 551. https://doi.org/10.1162/neco.1989.1.4.541), have found applications in healthcare for medical diagnostics, autonomous vehicles in transportation, stock market prediction in finance, and image recognition in computer vision to name just a few. Similarly, in analytical chemistry, deep learning has enhanced data analysis from techniques like MS spectrometry, NMR, fluorescence spectroscopy, and chromatography. Another AI branch, Natural Language Processing (NLP), has surged recently with the advent of Large Language Models (LLMs), such as OpenAI's ChatGPT. This paper demonstrates the application of an LLM via a smartphone to conduct multivariate data analyses, in an interactive conversational manner, of a hyper-spectral imaging data set from laser-induced breakdown spectroscopy (LIBS). We demonstrate the potential of LLMs to process and analyze data sets, which automatically generate and execute code in response to user queries, and anticipate their growing role in the future of analytical chemistry.Artificial intelligence (AI), especially through the development of deep learning techniques like convolutional neural networks (CNNs), has revolutionized numerous fields. CNNs, introduced by Yann LeCun in the 1990s (Hubbard, W.; Jackel, L. D. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Comput. 1989, 1 (4), 541- 551. https://doi.org/10.1162/neco.1989.1.4.541), have found applications in healthcare for medical diagnostics, autonomous vehicles in transportation, stock market prediction in finance, and image recognition in computer vision to name just a few. Similarly, in analytical chemistry, deep learning has enhanced data analysis from techniques like MS spectrometry, NMR, fluorescence spectroscopy, and chromatography. Another AI branch, Natural Language Processing (NLP), has surged recently with the advent of Large Language Models (LLMs), such as OpenAI's ChatGPT. This paper demonstrates the application of an LLM via a smartphone to conduct multivariate data analyses, in an interactive conversational manner, of a hyper-spectral imaging data set from laser-induced breakdown spectroscopy (LIBS). We demonstrate the potential of LLMs to process and analyze data sets, which automatically generate and execute code in response to user queries, and anticipate their growing role in the future of analytical chemistry.", Index Medicus;Stock Market Prediction;Data Augmentation;Generative Adversarial Network;Wavelet Transform,Proquest
10.1111/exsy.70018,10.1111/exsy.70018,"Generative AI for Finance: Applications, Case Studies and Challenges","Generative AI (GAI), which has become increasingly popular nowadays, can be considered a brilliant computational machine that can not only assist with simple searching and organising tasks but also possesses the capability to propose new ideas, make decisions on its own and derive better conclusions from complex inputs. Finance comprises various difficult and time‐consuming tasks that require significant human effort and are highly prone to errors, such as creating and managing financial documents and reports. Hence, incorporating GAI to simplify processes and make them hassle‐free will be consequential. Integrating GAI with finance can open new doors of possibility. With its capacity to enhance decision‐making and provide more effective personalised insights, it has the power to optimise financial procedures. In this paper, we address the research gap of the lack of a detailed study exploring the possibilities and advancements of the integration of GAI with finance. We discuss applications that include providing financial consultations to customers, making predictions about the stock market, identifying and addressing fraudulent activities, evaluating risks, and organising unstructured data. We explore real‐world examples of GAI, including Finance generative pre‐trained transformer (GPT), Bloomberg GPT, and so forth. We look closer at how finance professionals work with AI‐integrated systems and tools and how this affects the overall process. We address the challenges presented by comprehensibility, bias, resource demands, and security issues while at the same time emphasising solutions such as GPTs specialised in financial contexts. To the best of our knowledge, this is the first comprehensive paper dealing with GAI for finance."," Finance , Unstructured data , SUSTAINABILITY , Task complexity , Generative artificial intelligence;BiGRU;Stock price prediction;Attention Mechanism;Hybrid Model",Proquest
10.1021/acs.analchem.4c05046,10.1021/acs.analchem.4c05046,Large Language Models (such as ChatGPT) as Tools for Machine Learning-Based Data Insights in Analytical Chemistry,"Artificial intelligence (AI), especially through the development of deep learning techniques like convolutional neural networks (CNNs), has revolutionized numerous fields. CNNs, introduced by Yann LeCun in the 1990s (Hubbard, W.; Jackel, L. D. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Comput. 1989, 1 (4), 541– 551. https://doi.org/10.1162/neco.1989.1.4.541), have found applications in healthcare for medical diagnostics, autonomous vehicles in transportation, stock market prediction in finance, and image recognition in computer vision to name just a few. Similarly, in analytical chemistry, deep learning has enhanced data analysis from techniques like MS spectrometry, NMR, fluorescence spectroscopy, and chromatography. Another AI branch, Natural Language Processing (NLP), has surged recently with the advent of Large Language Models (LLMs), such as OpenAI’s ChatGPT. This paper demonstrates the application of an LLM via a smartphone to conduct multivariate data analyses, in an interactive conversational manner, of a hyper-spectral imaging data set from laser-induced breakdown spectroscopy (LIBS). We demonstrate the potential of LLMs to process and analyze data sets, which automatically generate and execute code in response to user queries, and anticipate their growing role in the future of analytical chemistry."," analytical chemistry , artificial intelligence , atomic absorption spectrometry , chromatography , computer vision , data analysis , data collection , diagnostic techniques , finance , fluorescence emission spectroscopy , health services , mobile telephones , prediction , stock exchange , transportation;Stock Market Prediction;Self-Attention Mechanism;Large Language Models;Information Fusion;Graph NeuralNetworks",Proquest
10.1111/exsy.13681,10.1111/exsy.13681,Integrating spotted hyena optimization technique with generative artificial intelligence for time series forecasting,"Generative artificial intelligence (AI) has developed as an effective tool for time series predicting, revolutionizing the typical methods of prediction. Different classical approaches that depend on existing approaches and assumptions, generative AI controls advanced deep learning (DL) approaches like generative adversarial networks (GANs) and recurrent neural networks (RNNs), to identify designs and connections in time series data. DL has accomplished major success in optimizing performances connected with AI. In the financial area, it can be extremely utilized for the stock market predictive, trade implementation approaches, and set of optimizers. Stock market predictive is the most important use case in this field. GANs with advanced AI approaches have become more significant in recent times. However, it can be utilized in image‐image‐translation and other computer vision (CV) conditions. GANs could not utilized greatly for stock market prediction because of their effort to establish the proper set of hyperparameters. This study develops an integrated spotted hyena optimization algorithm with generative artificial intelligence for time series forecasting (SHOAGAI‐TSF) technique. The purpose of the SHOAGAI‐TSF technique is to accomplish a forecasting process for the utilization of stock price prediction. The SHOAGAI‐TSF technique uses probabilistic forecasting with a conditional GAN (CGAN) approach for the prediction of stock prices. The CGAN model learns the data generation distribution and determines the probabilistic prediction from it. To boost the prediction results of the CGAN approach, the hyperparameter tuning can be performed by the use of the SHOA. The simulation result analysis of the SHOAGAI‐TSF technique takes place on the stock market dataset. The experimental outcomes determine the significant solution of the SHOAGAI‐TSF algorithm with other compared methods in terms of distinct metrics."," FINANCE , Optimization techniques , FINANCE , Optimization , Generative artificial intelligence , Generative adversarial networks , Recurrent neural networks , Algorithms , Computer vision , Machine learning , SUSTAINABILITY , Predictions , SUSTAINABILITY , Forecasting , Time series;Financial Reinforcement Learning;FinRL;trading agent;prompt;large language model;DeepSeek;stock market;financial news;stock price trend",Proquest
10.1109/TCSS.2025.3557911,10.1109/TCSS.2025.3557911,Enhancing Hybrid Bike-Sharing Systems Through Long-Term Inventory Management: A Generative-Model-Informed Reinforcement Learning Approach,"Hybrid bike-sharing systems (operating both bikes and ebikes) are emerging worldwide for flexibility and sustainability. Excessive rebalancing, while addressing supply-demand imbalances, causes financial burdens and resource waste. Hence, long-term daily operations (e.g., rebalancing at midnights for upcoming days) have practical economic significance, but they remain underexplored due to difficulties in tracking high within-day and between-day demand variability and the interplay between demand and daily inventory management strategies. Besides, cooperative operation of bikes and ebikes expands solution space, given their inherent demand coupling. This study is the first to explore long-term daily inventory strategies for the hybrid system (ebikes get charged at stations), determining spatial-heterogeneous inventory at midnight to maximize profits. To address the demand variability perception issue, we develop a recurrent-attentive neural process (RANP) model to predict hour-to-hour demand of the upcoming day. The RANP is integrated into a long-term optimization model, referred to as the generative-models-informed Markov decision process (GMI-MDP), where two cooperative intelligent agents determine the bike–ebike allocation based on demand perception and system rewards. A suite of numerical experiments utilizing a real-world dataset from New York is carried out, and various strategies are compared. The proposed method, through online and offline tests, demonstrates superiority over other MDP-based and rule-based methods, achieving a faster solution-seeking process and more stable rewards than MDP with exact upcoming demand. By comparing inventory volatility, we offer insights into managerial operations."," Inventory management , Perception , Solution space , Bicycles , Intelligent agents , Hybrid systems , Markov processes , OPERATIONS , MARKETING , Optimization models;Large Language Models (LLMs);Machine Learning;Stock Price Prediction",Proquest
10.1109/eScience65000.2025.00071,10.1109/eScience65000.2025.00071,CryptexLLM: How LLM Generalizability Forecasts High Volatility,"Conference Title: 2025 IEEE International Conference on eScience (eScience) Conference Start Date: 2025 Sept. 15 Conference End Date: 2025 Sept. 18 Conference Location: Chicago, IL, USA We present CryptexLLM, an approach to time series forecasting that adapts large language models (LLMs) for predicting high volatility data. We extend the TimeLLM framework with an adaptive weighted loss function, feature engineering, and sentiment analysis. Our experiments show that the approach we took outperforms traditional LSTM models and statistical methods, with our best performing model being Llama 3.1. The adaptations we made improve directional accuracy, which is particularly useful for financial applications, while still maintaining computational efficiency. Our results suggest that LLMs have the potential to effectively generalize to volatile time series domains."," Statistical methods , Large language models , SUSTAINABILITY , Sentiment analysis , Volatility , Time series , SUSTAINABILITY , Economic;Financial Stock Price Movement Prediction;Large Language Models;Information Retrieval;Retrieval Augmented Generation",Proquest
10.3390/jrfm18090475,10.3390/jrfm18090475,AI and Financial Fragility: A Framework for Measuring Systemic Risk in Deployment of Generative AI for Stock Price Predictions,"In a few years, most investment firms will deploy Generative AI (GenAI) and large language models (LLMs) for reduced-cost stock trading decisions. If GenAI-run investment decisions from most firms are heavily coordinated, they could all give a “sell” signal simultaneously, triggering market crashes. Likewise, simultaneous “buy” signals from GenAI-run investment decisions could cause market bubbles with algorithmically inflated prices. In this way, coordinated actions from LLMs introduce systemic risk into the global financial system. Existing risk analysis for GenAI focuses on endogenous risk from model performance. In comparison, exogenous risk from external factors like macroeconomic changes, natural disasters, or sudden regulatory changes, is understudied. This research fills the gap by creating a framework for measuring exogenous (systemic) risk from LLMs acting in the stock trading system. This research develops a concrete, quantitative framework to understand the systemic risk brought by using GenAI in stock investment by measuring the covariance between LLM stock price predictions across three industries (technology, automobiles, and communications) produced by eight large language models developed across the United States, Europe, and China. This paper also identifies potential data-driven technical, cultural, and regulatory mechanisms for governing AI to prevent negative financial and societal consequences."," Language , OPERATIONS , FINANCE , Accuracy , ECONOMICS , Investments , FINANCE , Proprietary , FINANCE , Neural networks , SUSTAINABILITY , Large language models , SUSTAINABILITY , Chatbots , FINANCE;Stock Market Prediction;LSTM-Transformer Hybrid;Deep Learning;Technical Indicators;Sentiment Analysis;Algorithmic Trading;Financial Forecasting;Machine Learning;Time-Series Analysis;Backtesting",Proquest
10.1109/ICCTDC64446.2025.11158803,10.1109/ICCTDC64446.2025.11158803,Temporal Data Analytics Through Reinforced LLM Architectures for Time-Series Pattern Discovery,"Conference Title: 2025 International Conference on Computing Technologies &amp; Data Communication (ICCTDC) Conference Start Date: 2025 July 4 Conference End Date: 2025 July 5 Conference Location: HASSAN, India In these modern times, where much data are involved, temporal data analysis has become a significant medium toward meaningful pattern discovery for informed decision-making in many contemporary fields such as finance, healthcare, and environmental science. Traditional methods of time-series pattern discovery often cannot adequately provide insight into complex real-world datasets due to their high dimensionality and volume. This paper introduces an innovative paradigm that relies on the power of reinforcement-enhanced architectures of LLM to further enhance the improvement of temporal data analysis in timeseries pattern discovery. Our approach integrates the knowledge from state-of-the-art LLMs with reinforcement learning to improve the detection and explanation of complex temporal patterns. We have applied our proposed approach to several real datasets, including stock market indices from the S&amp;P 500 and NOAA weather data. These results represent significant gains in the accuracy of pattern recognition and forecasting performance compared to traditional conventional methods of time-series analysis. Our further reinforced LLM architecture offers higher adaptability and scalability, making it suitable for diversified and large-scale temporal data sets. This advances not only the precision of time-series prediction but also provides deeper insights into the underlying temporal dynamics to drive more strategic and proactive decision-making processes. Our finding illustrates how reinforcement-aided LLM architectures may revolutionize temporal data analytics by opening ways to more robust and intelligent pattern-discovery systems in various real-world applications."," Data analysis , SUSTAINABILITY , Datasets , SUSTAINABILITY , Pattern analysis , SUSTAINABILITY , Data communication , PSYCHOLOGY , SUSTAINABILITY , Decision making , Pattern recognition , Time series , Meteorological data , SUSTAINABILITY , Economic;Large Language Model;Multi-Strategy;Quantitative Trading;Reinforcement Learning",Proquest
10.3389/frai.2025.1608365,10.3389/frai.2025.1608365,"Large Language Models in equity markets: applications, techniques, and insights","Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector.Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector.",,Proquest
10.1109/ISEC64801.2025.11147253,10.1109/ISEC64801.2025.11147253,Comparative Analysis of Stock Price Prediction Using LSTM and GPT-2 Models,"Conference Title: 2025 IEEE Integrated STEM Education Conference (ISEC) Conference Start Date: 2025 March 15 Conference End Date: 2025 March 15 Conference Location: Princeton, NJ, USA Stock price prediction is a challenging task in both financial and academic sectors, as stock prices often behave unpredictably and nonlinearly within complex systems. This research presents a comparative study of two models: LSTM and GPT-2 which are applied to stock price prediction using Apple Inc.’s open-source data from Yahoo Finance, covering the period from 2000 to 2024. The LSTM model produces more accurate results and is better at handling long-term dependencies compared to GPT-2. The GPT-2 model from Hugging Face struggles with temporal modeling, generating inconsistent and unpredictable outputs due to its lack of design for time series data. LSTM excels at finding patterns in the complex financial data, making it a more suitable choice for this project. The LSTM model benefits from the data preparation steps that include feature selection, normalization, handling missing values and all factors that can influence its prediction. GPT-2 shows a weakness in capturing the nonlinear time series stock prices. Its reliance on pre-trained language modeling makes it not suitable for modeling stock data without the specialized adaptations. GPT-2’s outputs often differ from the real time stock data because of its lack of temporal awareness which results in unpredictable predictions. This study shows the strengths and limitations of the two models and emphasizes LSTM’s capability in finding and producing consistent stock price predictions. While GPT-2 performs well in broader contexts, this study demonstrates that LSTM is more effective for stock price prediction. This research shows how machine learning systems can improve and help with future directions of stock price predictions. The work presented in this paper by no means provides any guidance for stock purchasing but is an effort to integrate AI and Machine learning techniques to understand the process of stock price prediction that can be improved by incorporating sophisticated techniques."," Comparative studies , OPERATIONS , Complex systems , FINANCE , Machine learning , SUSTAINABILITY , Modelling , SUSTAINABILITY , Time series , SUSTAINABILITY , Economic;Stock prediction;multi-modal deep learning;LLM;RAG;news sentiment analysis;financial data;and technical indicators",Proquest
10.1109/TENSYMP63728.2025.11144933,10.1109/TENSYMP63728.2025.11144933,LLM-Augmented Enhanced Graph Transformer for Stock Movement Prediction,"Conference Title: 2025 IEEE Region 10 Symposium (TENSYMP) Conference Start Date: 2025 July 7 Conference End Date: 2025 July 9 Conference Location: Christchurch, New Zealand Predicting stock price movements remains challenging due to the complex interactions and dynamics of financial markets. Recent deep learning advances, particularly integrating numerical data with linguistic analysis via large language models (LLMs), have shown promise. This study proposes an LLM-Augmented Enhanced Graph Transformer that combines LLM-generated financial analyses, FinBERT semantic embeddings, and a Graph Transformer to predict daily stock movements for 260 selected S&amp;P 500 stocks in 2024. We construct a static stock relationship graph based on the cosine similarity of aggregated textual embeddings, capturing long-term semantic dependencies while integrating numerical indicators. Experimental results show our approach outperforms traditional time-series models (e.g., LSTM, Transformer, Informer) and graph-based methods (e.g., GCN, GAT), demonstrating the effectiveness of multimodal fusion and graph-based attention. We also discuss computational constraints and the limitations of static graphs, highlighting future directions such as dynamic graph modeling and optimized text processing."," Semantics , Large language models , Large language models , Semantics , Economic;Global stock market prediction;Deep learning;Convolutional Neural Networks (CNNs);Long Short-Term Memory (LSTM) networks;Deep Q-Learning",Proquest
10.1109/AITest66680.2025.00018,10.1109/AITest66680.2025.00018,Hybrid LSTM-Transformer Model for Stock Market Prediction: A Deep Learning Approach,"Conference Title: 2025 IEEE International Conference on Artificial Intelligence Testing (AITest) Conference Start Date: 2025 July 21 Conference End Date: 2025 July 24 Conference Location: Tucson, AZ, USA Stock market prediction is a complex and dynamic task due to the volatile nature of financial markets, influenced by economic, social, and geopolitical factors. Traditional machine learning models, including Long Short-Term Memory (LSTM) networks, have shown potential but often fall short in capturing both short-term price fluctuations and long-term dependencies. This paper proposes a novel LSTM-Transformer hybrid model that integrates the sequential modeling capabilities of LSTM with the attention-based long-range pattern recognition of Transformers. To enhance predictive performance, we incorporate key technical indicators—Relative Strength Index (RSI), Moving Average Convergence Divergence (MACD), Bollinger Bands—as well as sentiment features derived from FinBERT, a finance-specific large language model.The model is trained on historical stock data spanning 2015 to 2024 and evaluated using an $80 \%-20 \%$ training-testing split. Performance is assessed using Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), and Sharpe Ratio to capture both prediction accuracy and risk-adjusted returns. A rolling-window backtesting approach is used to simulate real-world trading behavior across varying market conditions. Our hybrid model outperforms standalone LSTM, GRU, and Transformer baselines, achieving an MSE of 0.0021, RMSE of 0.0467, and a directional accuracy of $76.4 \%$. These findings highlight the value of combining deep learning, financial indicators, and sentiment analysis for robust stock market forecasting. A conceptual extension discussing the role of generative models like GPT for unstructured financial data is also presented."," Accuracy , SUSTAINABILITY , Deep learning , Large language models , SUSTAINABILITY , Sentiment analysis , Root-mean-square errors , FINANCE , Indicators , SUSTAINABILITY , Unstructured data , Deep learning , Artificial intelligence , Machine learning , Pattern recognition , Economic;LLM;GAT;fusion model;stock price movement prediction;LSTM",Proquest
10.1109/SIU66497.2025.11112242,10.1109/SIU66497.2025.11112242,Stock Price Prediction with Multimodal Data,"Conference Title: 2025 33rd Signal Processing and Communications Applications Conference (SIU) Conference Start Date: 2025 June 25 Conference End Date: 2025 June 28 Conference Location: Sile, Istanbul, Turkiye In today's financial markets, the influence of dynamic factors is becoming increasingly evident, and markets are affected by real-time data from various sources. In this study, a multimodal machine learning approach is adopted by integrating traditional technical analysis metrics, tweets, and news articles with historical price data. Market sentiment and investor psychology are measured through sentiment analysis of textual data using both the FinBERT and ChatGPT-4o models, and the obtained outputs are combined with financial metrics to construct an LSTM-based stock price prediction model. To enhance the model's stability, LSTM models derived from different training sessions are merged using an ensemble learning method, and the two approaches are compared. The results demonstrate that the ensemble model outperforms the standard LSTM model, and integrating financial indicators with tweet and news data, as opposed to relying solely on price data, leads to increased overall profit."," News , Machine learning , Real time , Sentiment analysis , Prediction models , Ensemble learning , SUSTAINABILITY , Economic;sentiment analysis;stock price prediction;support vector regression",Proquest
10.1109/ICCSP64183.2025.11088423,10.1109/ICCSP64183.2025.11088423,Prophetic markets: Multi-modal deep learning redefines stock market predictions,"Conference Title: 2025 11th International Conference on Communication and Signal Processing (ICCSP) Conference Start Date: 2025 June 5 Conference End Date: 2025 June 7 Conference Location: Melmaruvathur, India Stock market prediction is a vital resource for investors and financial experts looking to reduce risk and maximize profits. In this article, we propose a novel multi-modal deep learning-based method to improve predictions of stock market trends. This study uses an integrated framework of state-of-the-art machine learning techniques, deep learning with LLM, and RAG. We use data retrieval techniques, such as web scraping, to download financial reports containing corporate balance sheets. Further, our method includes real-time sentiment analysis in order to understand the investors’ current mentality which can be crucial in determining the market movements. Technical analysis uses deep learning models to interpret important indicators such as RSI, MACD, CCI, and Stochastic oscillators to uncover underlying patterns and correlations in stock trends. Our experiments demonstrate that this integrated strategy performs better than conventional single-dimensional techniques. We are combining data from corporate financial, sentiment analysis, and technical factors as well as active news sentiment analysis to improve the accuracy and reliability of market predictions by demonstrating the performance of a combined set of data sources. This work draws attention to the importance of the multifaceted integration of data by demonstrating RAG benefits for accurate financial data retrieval and multi-modal analysis in the practical applications of stock markets. The results demonstrate how these new approaches can be combined for profit maximization with better decision-making and risk reduction in financial markets."," Risk management , Deep learning , PSYCHOLOGY , Trends , Trends , Sentiment analysis , FINANCE , Modal analysis , Deep learning , Machine learning , Real time , SUSTAINABILITY , Data retrieval , Data collection , Information retrieval , Economic;machine learning;deep learning;large language model;time series;finance",Proquest
10.1109/ICOCT64433.2025.11118821,10.1109/ICOCT64433.2025.11118821,Applications of Novel Deep Learning Algorithms for Analysing of Cryptocurrency,"Conference Title: 2025 International Conference on Computing Technologies (ICOCT) Conference Start Date: 2025 June 13 Conference End Date: 2025 June 14 Conference Location: Bengaluru, India With the worldwide spread of cryptocurrencies, data has become richer and more heterogeneous than before and, as a result, poses a new problem related to prediction and decision making. Although there has been recent increase in acceptance of machine learning (ML) and deep learning (DL) technologies, the current analytical models appear to have limited correspondence with cryptocurrency markets. This work directly addresses price forecasting, fraud detection, sentiment analysis, and risk management, thus illustrating the applicability of the current technologies. We implement complex and novel deep learning techniques such as long short-term memory, gated recurrent unit, Bidirectional-LSTM to explore the temporal and spatial behavior of data associated with cryptocurrencies. These models enable accurate predictions of price and market trends along with reinforcement strategies to refine trading strategies and generative models to assess the market and project what the future might require. This is used to help investors and traders spot patterns in the buying and selling of various crypto currencies, these models might have far-reaching effects on the economy. We compared the suggested model's output with that of current setups. This works findings reveal that the proposed model is more accurate than the alternatives since its prediction errors are lower."," ECONOMICS , SUSTAINABILITY , Risk management , Deep learning , Spatial data , Deep learning , Machine learning , Sentiment analysis , Digital currencies , SUSTAINABILITY , Economic;rice export price;time series forecasting;large language models;feature selection;machine learning",Proquest
10.1109/CNIOT65435.2025.11070984,10.1109/CNIOT65435.2025.11070984,Incorporating related stock and text for stock price movement prediction based on information fusion,"Conference Title: 2025 6th International Conference on Computing, Networks and Internet of Things (CNIOT) Conference Start Date: 2025 May 23 Conference End Date: 2025 May 25 Conference Location: Shanghai, China Investors have long been concerned with the analysis of textual information related to target stocks when making stock investments. We collected and extracted stock news headlines from the Chinese stock market and utilized a Large Language Model (LLM) to identify stocks related to the target stock and the relationships among them. Based on these relationships, we constructed a related stock relationship graph. Considering the dynamic changes in the relationship weights between stocks, we employed Graph Attention Networks (GAT) to build a feature fusion model for integrating the features of related stock news. Factors influencing prediction were considered, including different methods of text concatenation, the identification of related stocks, the relationship modeling between related stocks, and the fusion of related stock features. A comparative analysis of the Long Short-Term Memory (LSTM) model, the Bidirectional Long Short-Term Memory (Bi-LSTM) model, and the Long Short-Term Memory with Attention (LSTM-Attention) model revealed that both the news headlines of the target stock and the related stocks, along with their relationships, impact stock price movement prediction. Conversely, ignoring feature fusion and textual feature extraction can negatively affect prediction accuracy."," News , Feature extraction , FINANCE , Data integration , Internet of Things , Large language models , Economic;Large language model;Foreign exchange rate;Finance;Time series;Machine learning",Proquest
10.1109/CVC65719.2025.00007,10.1109/CVC65719.2025.00007,AI Oracle: A Blockchain-Powered Oracle for LLMs and AI Agents,"Conference Title: 2025 Crypto Valley Conference (CVC) Conference Start Date: 2025 June 5 Conference End Date: 2025 June 6 Conference Location: Rotkreuz, Switzerland Large Language Models (LLMs) such as GPT and similar architectures have revolutionized artificial intelligence by enabling machines to understand and generate human-like text. However, these models are inherently statistical predictors rather than real-time reasoning systems, leading to fundamental limitations in accessing up-to-date information and verifying factual accuracy. This issue is particularly critical in high-stakes domains such as cryptocurrency markets, decentralized finance (DeFi), and autonomous AI agents, where real-time, verifiable, and tamper-proof information is essential for decision-making.In this paper, we introduce AI Oracle, a novel framework that integrates blockchain-powered oracles with LLMs and autonomous agents to ensure real-time access to cryptographically verified knowledge. We compare AI Oracle with both standalone LLMs and retrieval-based systems using the Model Context Protocol (MCP), highlighting significant advantages in factual reliability, adversarial robustness, and interpretability. AI Oracle combines decentralized consensus, immutable storage, and cryptographic attestation to equip AI agents with enhanced resistance to manipulation, hallucination, and misinformation.Beyond architectural improvements, we explore the broader applicability of AI Oracle across domains that require provable correctness and trust—ranging from real-world asset (RWA) tokenization to autonomous agent coordination and decentralized governance. By positioning AI Oracle as a trust-minimized epistemic infrastructure, we propose a new paradigm in AI systems: the fusion of decentralized trust with autonomous reasoning, enabling agents to operate with resilience, transparency, and embedded verifiability across dynamic environments."," Agents (artificial intelligence) , Large language models , SUSTAINABILITY , Reasoning , Blockchain , ECONOMICS , SUSTAINABILITY , ECONOMICS , Cryptography , Artificial intelligence , Real time , Digital currencies , Large language models , Economic;Stock Return Prediction;Deep Learning;Small Dataset Problem;Conditional Tabular Generative Adversarial Network;TabNet",Proquest
10.1109/CAI64502.2025.00032,10.1109/CAI64502.2025.00032,Graph LLM-Based Portfolio Management Algorithm,"Conference Title: 2025 IEEE Conference on Artificial Intelligence (CAI) Conference Start Date: 2025 May 5 Conference End Date: 2025 May 7 Conference Location: Santa Clara, CA, USA This paper explores the integration of large language models (LLMs) with graph-based financial networks for quantitative trading. By leveraging GPT-3 for stock network return predictions, we develop a Graph-LLM trading strategy. Experimental results demonstrate that the proposed strategy achieves lower volatility and more stable performance than traditional baselines. Our findings highlight the potential of combining LLMs with financial complex networks to enhance quantitative trading strategies."," SUSTAINABILITY , Large language models , Artificial intelligence , Economic;XGBoost algorithm;stock prediction;sentiment analysis;large language models",Proquest
10.1109/ICAISISAS64483.2025.11051550,10.1109/ICAISISAS64483.2025.11051550,Machine Learning Approaches to Picking A-Shares Stocks: A Comparative Analysis,"Conference Title: 2025 Joint International Conference on Automation-Intelligence-Safety (ICAIS) &amp; International Symposium on Autonomous Systems (ISAS) Conference Start Date: 2025 May 23 Conference End Date: 2025 May 25 Conference Location: Xi'an, China This study explores the integration of advanced machine learning (ML) techniques and large language models (LLMs) in financial modeling, focusing on the Chinese stock market. It introduces the ChatGPT Score, an LLM-driven sentiment analysis factor, and compares the traditional Fama-French five-factor (FF5) model with its augmented version, FF5+ChatGPT Score. The research evaluates linear regression models against ML models, such as Random Forests, Extreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine (LightGBM), and Category Boosting (CatBoost), within five- and six-factor frameworks. Empirical results show that the ChatGPT Score outperforms traditional sentiment tools like SnowNLP and improves the predictive accuracy of the FF5 model. Additionally, CatBoost and Random Forests demonstrate strong portfolio management capabilities. Statistical validation through retrospective analysis confirms the effectiveness of the models, while industry feedback highlights their practical value in investment strategies. However, the study acknowledges the limitations of current models and recommends future research on deep learning techniques to improve financial market analysis and predictive accuracy."," Accuracy , OPERATIONS , Large language models , Deep learning , Machine learning , Sentiment analysis , Chatbots , Statistical analysis , Regression models , Chatbots , Investment strategy , FINANCE , Economic;Large Language Model (LLM);Cancer;prompt;ROGUE score;BERTScore;Mistral 7x8B;Falcon 40b;and Llama 3-8b",Proquest
10.1109/IDS66066.2025.00016,10.1109/IDS66066.2025.00016,Enhancing FinRL Trading Agents with Advance LLM-Processed Financial News: An Improved Approach Using DeepSeek-V3,"Conference Title: 2025 IEEE 11th International Conference on Intelligent Data and Security (IDS) Conference Start Date: 2025 May 9 Conference End Date: 2025 May 11 Conference Location: New York City, NY, USA The use of AI techniques to improve stock market related operations has been benefiting traders in the stock market. FinRL is a framework that has been shown to be effective in building Reinforcement Learning (RL) based Trading Agents. Use of LLMs for performance improvement of the Agents is one of the recent initiatives. LLMs are being used to generate signals that could be combined with historical stock prices for better prediction of stock price movement trends leading to profitable trading. This paper aims to develop efficiently engineered prompts to generate DeepSeek-V3-based sentiment signals, integrate them into the FinRL environment, and improve the performance of reinforcement learning trading agents. The code, data, and trading agents are at: https://github.com/SatishChandraPhD/FinRL2025"," Performance enhancement , Economic;Contrastive learning;language model;multimodal;stock trend prediction;time series",Proquest
10.1371/journal.pone.0326034,10.1371/journal.pone.0326034,Enhancing stock timing predictions based on multimodal architecture: Leveraging large language models (LLMs) for text quality improvement,"This study aims to enhance stock timing predictions by leveraging large language models (LLMs), specifically GPT-4, to filter and analyze online investor comment data. Recognizing challenges such as variable comment quality, redundancy, and authenticity issues, we propose a multimodal architecture that integrates filtered comment data with stock price dynamics and technical indicators. Using data from nine Chinese banks, we compare four filtering models and demonstrate that employing GPT-4 significantly improves financial metrics like profit-loss ratio, win rate, and excess return rate. The multimodal architecture outperforms baseline models by effectively preprocessing comment data and combining it with quantitative financial data. While focused on Chinese banks, the approach can be adapted to broader markets by modifying the prompts of large language models. Our findings highlight the potential of LLMs in financial forecasting and provide more reliable decision support for investors.This study aims to enhance stock timing predictions by leveraging large language models (LLMs), specifically GPT-4, to filter and analyze online investor comment data. Recognizing challenges such as variable comment quality, redundancy, and authenticity issues, we propose a multimodal architecture that integrates filtered comment data with stock price dynamics and technical indicators. Using data from nine Chinese banks, we compare four filtering models and demonstrate that employing GPT-4 significantly improves financial metrics like profit-loss ratio, win rate, and excess return rate. The multimodal architecture outperforms baseline models by effectively preprocessing comment data and combining it with quantitative financial data. While focused on Chinese banks, the approach can be adapted to broader markets by modifying the prompts of large language models. Our findings highlight the potential of LLMs in financial forecasting and provide more reliable decision support for investors.", Index Medicus;commodity spot price;gated recurrent unit (GRU);generative adversarial network (GAN);time-reries forecasting;metal price prediction,Proquest
10.1109/ICASSPW65056.2025.11011079,10.1109/ICASSPW65056.2025.11011079,Hybrid Encoding-based Quantum Self Attention for Financial Time Series Analysis,"Conference Title: 2025 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW) Conference Start Date: 2025 April 6 Conference End Date: 2025 April 11 Conference Location: Hyderabad, India Self-attention mechanisms, central to Transformer architectures, have become foundational in the development of large language models (LLMs) and various advanced machine learning systems. These mechanisms are pivotal for effectively capturing complex data dependencies and relationships, which is crucial for tasks such as natural language understanding and generation. However, as dimensionality increases, self-attention mechanisms face significant challenges related to computational efficiency and scalability. This paper introduces an encoding-based quantum self-attention mechanism designed to address these issues by embedding classical data into quantum states. This approach facilitates more efficient computation and reduces model complexity. To further enhance performance for real-world applications, particularly in financial time series forecasting, we propose a hybrid model that integrates Long Short-Term Memory (LSTM) networks with quantum self-attention mechanism. Given the constraints of the Noisy Intermediate-Scale Quantum (NISQ) era, this hybrid approach represents a plausible solution, leveraging the strengths of both classical and quantum methods and focusing on achieving faster convergence. Experimental results demonstrate that our approach converges significantly quicker than traditional models, showcasing the advantages of integrating quantum techniques with classical machine learning for practical applications."," Attention , OPERATIONS , Large language models , Machine learning , SUSTAINABILITY , Task complexity , Time series , Coding , SUSTAINABILITY , SUSTAINABILITY , Speech recognition , Computational efficiency , Economic;time series;volatile;llm",Proquest
10.3390/math13101599,10.3390/math13101599,MambaLLM: Integrating Macro-Index and Micro-Stock Data for Enhanced Stock Price Prediction,"Accurate stock price prediction requires the integration of heterogeneous data streams, yet conventional techniques struggle to simultaneously leverage fine-grained micro-stock features and broader macroeconomic indicators. To address this gap, we propose MambaLLM, a novel framework that fuses macro-index and micro-stock inputs through the synergistic use of state-space models (SSMs) and large language models (LLMs). Our two-branch architecture comprises (i) Micro-Stock Encoder, a Mamba-based temporal encoder for processing granular stock-level data (prices, volumes, and technical indicators), and (ii) Macro-Index Analyzer, an LLM module—employing DeepSeek R1 7B distillation—capable of interpreting market-level index trends (e.g., S&amp;P 500) to produce textual summaries. These summaries are then distilled into compact embeddings via FinBERT. By merging these multi-scale representations through a concatenation mechanism and subsequently refining them with multi-layer perceptrons (MLPs), MambaLLM dynamically captures both asset-specific price behavior and systemic market fluctuations. Extensive experiments on six major U.S. stocks (AAPL, AMZN, MSFT, TSLA, GOOGL, and META) reveal that MambaLLM delivers up to a 28.50% reduction in RMSE compared with suboptimal models, surpassing traditional recurrent neural networks and MAMBA-based baselines under volatile market conditions. This marked performance gain highlights the framework’s unique ability to merge structured financial time series with semantically rich macroeconomic narratives. Altogether, our findings underscore the scalability and adaptability of MambaLLM, offering a powerful, next-generation tool for financial forecasting and risk management."," Language , Risk management , ECONOMICS , Large language models , PSYCHOLOGY , Summaries , SUSTAINABILITY , Multilayers , Multilayer perceptrons , Neural networks , State space models , SUSTAINABILITY , Recurrent neural networks , Indicators , SUSTAINABILITY , Data transmission , SUSTAINABILITY , Coders , Large language models , Chatbots , PSYCHOLOGY;Sentiment Analysis;Stock Price Prediction;Natural Language Processing (NLP);Large Language Models (LLMs)",Proquest
10.1109/CiFer64978.2025.10975739,10.1109/CiFer64978.2025.10975739,Leveraging Large Language Models and Retrieval-Augmented Generation for Enhanced Multi-Asset Portfolio Construction,"Conference Title: 2025 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics (CiFer) Conference Start Date: 2025, March 17 Conference End Date: 2025, March 20 Conference Location: Trondheim, Norway This study assesses the Large Language Models (LLMs) in creating investment portfolios. We implement a few-shot learning technique, followed by Retrieval Augmented Generation (RAG) enhanced with comprehensive up-to-date financial data, using Meta's latest LLM, Llama 3.1-8b. In the first phase, We assess the models' efficacy using key financial indicators, including total returns, annualized volatility, riskadjusted performance (Sharpe ratio), potential loss estimates (value-at-risk), and their pre-training knowledge with the S&amp;P 500 Index performance baseline. In the second phase, we enhance the LLM's knowledge base by RAG and the latest historical and statistical metrics (such as earnings per share (EPS), dividends per share (DPS), profit margin, and many more) for each asset from different classes. The study constrains model inputs to specific sets of financial assets, such as equities, exchangetraded funds (ETFs), commodities, cryptocurrencies, and bonds. To evaluate model performance and adaptability, we analyzed across two distinct time frames: (1) within the models' training data cutoff, and (2) from the cutoff date to the present. This approach enables the assessment of model generalization to past and present market conditions. The research quantifies LLMs’ capabilities in financial asset allocation, comparing baseline performance against RAG-augmented strategies. Our results demonstrate that RAG-enhanced LLM significantly outperforms vanilla LLM in portfolio construction across various asset classes. We contemplate that these results could influence AI-driven financial decision-making processes such as automated trading, real-time sentiment analysis, and investment management."," Performance evaluation , Knowledge bases (artificial intelligence) , Large language models , Machine learning , Real time , Sentiment analysis , Digital currencies , Large language models , SUSTAINABILITY , Retrieval , Economic;Financial Forecasting;Stock Market Prediction;Deep Learning;Deep Neural Networks;Multimodal Machine Learning;Large Language Models",Proquest
10.1109/CSICC65765.2025.10967454,10.1109/CSICC65765.2025.10967454,LoopGAN: A Novel Multi-Step Generative Architecture for Sequential Stock Forecasting,"Conference Title: 2025 29th International Computer Conference, Computer Society of Iran (CSICC) Conference Start Date: 2025, Feb. 5 Conference End Date: 2025, Feb. 6 Conference Location: Iran, Islamic Republic of This paper introduces “LoopGAN,” an advanced generative model architecture designed for sequential stock forecasting, leveraging the strengths of Conditional GAN (CGAN) and Least Squares GAN (LSGAN) to enhance prediction accuracy in highly volatile financial time series. LoopGAN's unique recursive prediction mechanism allows each output to feed back as input, creating dynamic, extended forecasts across multiple time steps. Extensive evaluation of the Dow J ones Industrial Average (DJIA) dataset, highlights LoopGAN's superior performance, achieving a Mean Absolute Percentage Error (MAP E) of 0.005739. This result surpasses traditional models, with LoopGAN outperforming LSTM and RNN models, which registered MAPE scores of 0.006803 and 0.008023, respectively. These findings underscore LoopGAN's robustness, offering a marked improvement in prediction accuracy and confirming its reliability for complex financial forecasting tasks."," Accuracy , SUSTAINABILITY , Forecasting , Task complexity , Iran , Economic;Large Language Model;Quantized Low-Rank Adaptation;Instruction Fine Tuning",Proquest
10.24425/ijet.2025.153538,10.24425/ijet.2025.153538,LLM-Based multi-agent system for individual investment in energy and natural resources,"Recent advancements in large language models and multiagent large language model based systems show that these technologies can be applied to a large number of problems. They can automate complex tasks and perform advanced analyses that would take an expert a significant amount of time. This article describes a multiagent large language model (LLM) based platform for investment advisory in the energy natural resources sector. The system integrates multiple types of investment analyses e.g. technical analysis, fundamental analysis, sentiment analysis and stock price prediction. The approach of integrating multiple types of analyses in one system allows the investor to save significant amount of time on analyzing potential investments."," Multiagent systems , Large language models , Sentiment analysis , Model-based systems , Natural resources , Task complexity , SUSTAINABILITY , SUSTAINABILITY , Large language models , SUSTAINABILITY , SUSTAINABILITY;Recommender Systems;Large Language Models;Ranking Algorithm",Proquest
10.1109/CSNT64827.2025.10967744,10.1109/CSNT64827.2025.10967744,Recommender Systems for Sector-Specific Stock Analysis,"Conference Title: 2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT) Conference Start Date: 2025, March 7 Conference End Date: 2025, March 9 Conference Location: Bhopal, India Recommender systems are essential tools that assist users in making informed decisions by providing suggestions based on their previous actions and preferences. Traditional methods like content based and collaborative filtering work well for smaller datasets but often fail to extract information from large datasets due to their limited ability to capture complex patterns. This paper introduces a novel approach for stock recommendation that leverages a large language model, Llama 3.1, fine-tuned on financial news data. Financial news headlines and summaries were collected using the FinnHub API which served as the primary dataset. The system integrates stock price forecasting, sentiment analysis, and performance indicators to generate an effective analysis for decision making. The forecasting algorithm generates the stock price predictions which were integrated with sentiment analysis and stock performance indicators to create an informative prompt-response dataset for fine-tuning. The proposed system ranks stocks based on positive developments, potential concerns, and forecasted closing prices, providing Buy or Sell recommendations. Experimental results demonstrated moderate performance for predicting Buy recommendations, while Sell predictions exhibited lower accuracy comparatively. Analysis based on sectors revealed that the consumer cyclical and healthcare sectors yielded the best performance for Buy and Sell recommendations, respectively."," Datasets , SUSTAINABILITY , Recommender systems , Large language models , PSYCHOLOGY , Sentiment analysis , Recommender systems , News , Indicators , Communications systems , Algorithms , Predictions , Forecasting , MANAGEMENT , Economic;Large language model;Bitcoin price;sentiment analysis;machine learning;market dynamics",Proquest
10.1109/ICADEIS65852.2025.10933431,10.1109/ICADEIS65852.2025.10933431,The Effect of News Sentiment on Jakarta Composite Index Prediction Using Support Vector Regression Method,"Conference Title: 2025 International Conference on Advancement in Data Science, E-learning and Information System (ICADEIS) Conference Start Date: 2025, Feb. 3 Conference End Date: 2025, Feb. 4 Conference Location: Bandung, Indonesia This research investigates the impact of news sentiment on predicting the Jakarta Composite Index (JCI) using the Support Vector Regression (SVR) method. Market sentiment, derived from news articles, has been analyzed to understand its influence on stock price movements. A dual dataset approach was employed, consisting of financial news articles from Kompas.com and historical JCI stock data. The research incorporates sentiment analysis using ChatGPT large language models (LLMs), which are then integrated as features into the prediction model. Five scenarios of sentiment integration were evaluated to identify the most effective approach. The results indicate that Scenario 4 consistently delivers the highest prediction accuracy across different evaluation metrics, with Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) values of 0.009555 and 0.007298 in the log metric evaluation, 47.616867 and 36.52605 in the absolute metric evaluation, and 85.146387 and 70.34775 in the stock closing price evaluation. While sentiment integration shows potential, its success is scenario-dependent and influenced by hyperparameter tuning. This research underscores the utility of sentiment analysis in enhancing stock price predictions and provides a foundation for further exploration of sentiment based predictive models in financial markets."," News , Large language models , PSYCHOLOGY , Support vector machines , Sentiment analysis , Prediction models , Data science , Predictions , Root-mean-square errors , SUSTAINABILITY , Jakarta Indonesia , Economic , Indonesia;Quantitative trading;Financial complex networks;Large language models;Graph-based trading strategies",Proquest
10.1109/ICADEIS65852.2025.10933440,10.1109/ICADEIS65852.2025.10933440,A Sentiment-Augmented Machine Learning Approach to Forecasting IHSG Prices Using XGBoost,"Conference Title: 2025 International Conference on Advancement in Data Science, E-learning and Information System (ICADEIS) Conference Start Date: 2025, Feb. 3 Conference End Date: 2025, Feb. 4 Conference Location: Bandung, Indonesia Stocks are a commonly used investment instrument, representing ownership in a company, and offering opportunities for investors to gain profits through the appreciation of stock value as well as dividend distribution. As one of the main financial assets, stocks are also influenced by various external factors, such as economic conditions, government policies, and market sentiment. All of these factors play a crucial role in determining stock price movements. This study integrates sentiment analysis with the XGBoost algorithm to predict IHSG stock prices. By utilizing historical stock data and sentiment derived from financial news, the study evaluates the impact of sentiment data integration on prediction accuracy. Three types of returns (absolute, relative, and logarithmic) and five sentiment scenarios were employed to assess the contribution of sentiment features to the prediction model. The results indicate that sentiment integration consistently improves the predictive performance of the model compared to using historical data alone. Among the tested scenarios, Scenario 2, 4, and 5 demonstrated the best performance, with an RMSE value of 0.009163 and an MAE value of 0.007432, using the logarithmic return type. These findings suggest that incorporating sentiment features into predictive models can enhance the accuracy of stock price predictions and highlight the potential of Natural Language Processing (NLP) and Large Language Models (LLMs) in stock market analysis."," Accuracy , Logarithms , Public policy , FINANCE , Economic conditions , Large language models , Sentiment analysis , Prediction models , Data science , Algorithms , FINANCE , Data integration , Machine learning , Natural language processing , Predictions , SUSTAINABILITY , SUSTAINABILITY , OPERATIONS , Economic;Chinese Stock Market;Financial Modeling;Fama-French Models;Machine Learning;Random Forests;XGBoost;LightGBM;CatBoost;Large Language Models;Sentiment Analysis;ChatGPT Score",Proquest
10.3390/electronics14061090,10.3390/electronics14061090,Comparative Investigation of GPT and FinBERT’s Sentiment Analysis Performance in News Across Different Sectors,"GPT (Generative Pre-trained Transformer) is a groundbreaking generative model that has facilitated substantial progress in natural language processing (NLP). As the GPT-n series has continued to evolve, its applications have garnered considerable attention across various industries, particularly in finance. In contrast, traditional financial research has primarily focused on analyzing structured data such as stock prices. However, recent trends highlight the growing importance of natural language techniques that address unstructured factors like investor sentiment and the impact of news. Positive or negative information about specific companies, industries, or the overall economy found in news or social media can influence investor behavior and market volatility, highlighting the critical need for robust sentiment analysis. In this context, we utilize the state-of-the-art language model GPT and the finance-specific sentiment analysis model FinBERT to perform sentiment and time-series analyses on financial news data, comparing the performance of the two models to demonstrate the potential of GPT. Furthermore, by examining the relationship between sentiment shifts in financial markets and news events, we aim to provide actionable insights for investment decision-making, emphasizing both the performance and interpretability of the models. To enhance the performance of GPT-4o, we employed a systematic approach to prompt design and optimization. This process involved iterative refinement, guided by insights derived from a labeled dataset. This approach emphasized the pivotal importance of prompt design in improving model accuracy, resulting in GPT-4o achieving higher performance than FinBERT. During the experiment phase, sentiment scores were generated from New York Times news data and visualized through time-series graphs for both models. Although both models exhibited similar trends, significant differences arose depending on news content characteristics across categories. According to the results, the performance of GPT-4o, optimized through prompt engineering, outperformed that of FinBERT by up to 10% depending on the sector. These findings emphasize the importance of prompt engineering and demonstrate GPT-4o’s potential to improve sentiment analysis. Furthermore, the categorized news data approach suggests potential applications in predicting the outlook of categorized financial products."," Language , OPERATIONS , Performance enhancement , Finance , ACCTAX , Investments , PSYCHOLOGY , Trends , Sentiment analysis , PSYCHOLOGY , Text analysis , News , Structured data , ECONOMICS , Prompt engineering , Design optimization , Natural language processing , Performance evaluation , Large language models , FINANCE , Chatbots , Time series , FINANCE;time series forecasting;sentiment analysis;Transformer;Informer;LLM",Proquest
10.3390/math13030487,10.3390/math13030487,LLM-Augmented Linear Transformer–CNN for Enhanced Stock Price Prediction,"Accurately predicting stock prices remains a challenging task due to the volatile and complex nature of financial markets. In this study, we propose a novel hybrid deep learning framework that integrates a large language model (LLM), a Linear Transformer (LT), and a Convolutional Neural Network (CNN) to enhance stock price prediction using solely historical market data. The framework leverages the LLM as a professional financial analyst to perform daily technical analysis. The technical indicators, including moving averages (MAs), relative strength index (RSI), and Bollinger Bands (BBs), are calculated directly from historical stock data. These indicators are then analyzed by the LLM, generating descriptive textual summaries. The textual summaries are further transformed into vector representations using FinBERT, a pre-trained financial language model, to enhance the dataset with contextual insights. The FinBERT embeddings are integrated with features from two additional branches: the Linear Transformer branch, which captures long-term dependencies in time-series stock data through a linearized self-attention mechanism, and the CNN branch, which extracts spatial features from visual representations of stock chart data. The combined features from these three modalities are then processed by a Feedforward Neural Network (FNN) for final stock price prediction. Experimental results on the S&amp;P 500 dataset demonstrate that the proposed framework significantly improves stock prediction accuracy by effectively capturing temporal, spatial, and contextual dependencies in the data. This multimodal approach highlights the importance of integrating advanced technical analysis with deep learning architectures for enhanced financial forecasting."," Language , FINANCE , Accuracy , SUSTAINABILITY , Deep learning , Wavelet transforms , SUSTAINABILITY , SUSTAINABILITY , Trends , Artificial neural networks , PSYCHOLOGY , Indicators , SUSTAINABILITY , Machine learning , Representations , FINANCE , Data analysis , OPERATIONS , Datasets , Spatial data , Large language models , PSYCHOLOGY , Summaries , FINANCE , Neural networks , Support vector machines , Standardization , Deep learning , Predictions , Large language models;Stock movement prediction;Fintech;normalizing flow;variational inference;generative models",Proquest
10.1287/ijoc.2022.0055,10.1287/ijoc.2022.0055,Let the Laser Beam Connect the Dots: Forecasting and Narrating Stock Market Volatility,"Forecasting market volatility, especially high-volatility incidents, is a critical issue in financial market research and practice. Business news as an important source of market information is often exploited by artificial intelligence–based volatility forecasting models. Computationally, deep learning architectures, such as recurrent neural networks, on extremely long input sequences remain infeasible because of time complexity and memory limitations. Meanwhile, understanding the inner workings of deep neural networks is challenging because of the largely black box nature of large neural networks. In this work, we address the first challenge by proposing a long- and short-term memory retrieval (LASER) architecture with flexible memory and horizon configurations to forecast market volatility. Then, we tackle the interpretability issue by devising a BEAM algorithm that leverages a large pretrained language model (GPT-2). It generates human-readable narratives verbalizing the evidence leading to the model prediction. Experiments on a Wall Street Journal news data set demonstrate the superior performance of our proposed LASER-BEAM pipeline in predicting high-volatility market scenarios and generating high-quality narratives compared with existing methods in the literature."," Neural networks , SUSTAINABILITY , SUSTAINABILITY , Artificial neural networks , Volatility , SUSTAINABILITY , Recurrent neural networks , Algorithms , Market research , Artificial intelligence , Machine learning , Predictions , Forecasting , Narratives , OPERATIONS , FINANCE;stock price forecasting;scenario;flow-based model",Proquest
10.1038/s41598-024-68959-7,10.1038/s41598-024-68959-7,Meta graphical lasso: uncovering hidden interactions among latent mechanisms,"In complex systems, it's crucial to uncover latent mechanisms and their context-dependent relationships. This is especially true in medical research, where identifying unknown cancer mechanisms and their impact on phenomena like drug resistance is vital. Directly observing these mechanisms is challenging due to measurement complexities, leading to an approach that infers latent mechanisms from observed variable distributions. Despite machine learning advancements enabling sophisticated generative models, their black-box nature complicates the interpretation of complex latent mechanisms. A promising method for understanding these mechanisms involves estimating latent factors through linear projection, though there's no assurance that inferences made under specific conditions will remain valid across contexts. We propose a novel solution, suggesting data, even from systems appearing complex, can often be explained by sparse dependencies among a few common latent factors, regardless of the situation. This simplification allows for modeling that yields significant insights across diverse fields. We demonstrate this with datasets from finance, where we capture societal trends from stock price movements, and medicine, where we uncover new insights into cancer drug resistance through gene expression analysis.In complex systems, it's crucial to uncover latent mechanisms and their context-dependent relationships. This is especially true in medical research, where identifying unknown cancer mechanisms and their impact on phenomena like drug resistance is vital. Directly observing these mechanisms is challenging due to measurement complexities, leading to an approach that infers latent mechanisms from observed variable distributions. Despite machine learning advancements enabling sophisticated generative models, their black-box nature complicates the interpretation of complex latent mechanisms. A promising method for understanding these mechanisms involves estimating latent factors through linear projection, though there's no assurance that inferences made under specific conditions will remain valid across contexts. We propose a novel solution, suggesting data, even from systems appearing complex, can often be explained by sparse dependencies among a few common latent factors, regardless of the situation. This simplification allows for modeling that yields significant insights across diverse fields. We demonstrate this with datasets from finance, where we capture societal trends from stock price movements, and medicine, where we uncover new insights into cancer drug resistance through gene expression analysis.", Index Medicus;Future Finance;predictive insights;chatbot consultation;stock analysis;predictive modeling;AI assistance;market guider;real-time updates;proactive decision-making;Machine Learning;LSTM;Mean Squared Error (MSE);LLM,Proquest
10.1007/s10115-024-02085-8,10.1007/s10115-024-02085-8,Multi-factor stock price prediction based on GAN-TrellisNet,"Applying deep learning, especially time series neural networks, to predict stock price, has become one of the important applications in quantitative finance. Recently, some GAN-based stock prediction models are proposed, where LSTM or GRU is used as the generator. However, these generators lack the function of feature extraction, and the prediction accuracies are slightly low. Meanwhile, these models choose some simple volume-price factors (such as OCHLV and OCHLVC) as inputs, without considering the impact of other factors on stock prices. In order to solve these problems, a stock prediction method based on multiple factors and GAN-TrellisNet is proposed. Instead of “OCHLV” or ”OCHLVC,” a multi-factor strategy with ”alpha158+OCHLVC” is introduced to enrich the stock data of inputs. The proposed generative adversarial network (GAN) is a combination of two neural networks which are TrellisNet as generative model and convolutional neural network (CNN) as discriminative model for adversarial training to forecast the stock market. TrellisNet, which integrates the feature extraction capabilities of CNN and the temporal processing capabilities of recurrent neural network (RNN), will generate new predicted results based on historical data, and then CNN will distinguish between predicted results and real stock prices. In order to demonstrate the performance of our method, we selected the decade data of different stocks from four markets (A-shares, U.S. stocks, U.K. stocks and Hong Kong stocks) as dataset and conducted two groups of comparative experiments. Compared with the state-of-the-art methods based on GAN, our method has better performance in terms of MSE, MAE, RMSE and MAPE. In addition, the multi-factor strategy with “alpha158+OCHLVC” is more effective than the original strategy with OCHLVC factors."," Recurrent neural networks , Feature extraction , FINANCE , Machine learning , Prediction models , Artificial neural networks , Neural networks , Generative adversarial networks , SUSTAINABILITY , FINANCE;Generative AI;Computational Finance;Asset Allocation;Large Language Models;Llama;Portfolio management",Proquest
10.1109/MSEC.2024.3385549,10.1109/MSEC.2024.3385549,Degenerative AI?,"It is not secret that generative AI, especially in the form of large language models (LLMs), is extremely popular today. One might go so far as to say that it’s eaten the world. It may be a bubble, or it may last—though the death of cryptocurrencies has long been predicted, as I write this Bitcoin has just reached an all-time high value against the American dollar—but for now and at least the next few years, generative AI will be with us. As people who care about security and privacy, we need to understand the implications of it: is it good or bad for our field, and if the latter, what should we do about it? Ignoring it is not an option."," Large language models , Digital currencies , Generative artificial intelligence;Large language models;Finance;Prompt engineering;Persona;Ensemble method;Portfolio management",Proquest
10.2478/mmcks-2024-0008,10.2478/mmcks-2024-0008,Emoji driven crypto assets market reactions,"In the burgeoning realm of cryptocurrency, social media platforms like Twitter have become pivotal in influencing market trends and investor sentiments. In our study, we leverage GPT-4 and a fine-tuned transformer-based BERT model for a multimodal sentiment analysis, focusing on the impact of emoji sentiment on cryptocurrency markets. By translating emojis into quantifiable sentiment data, we correlate these insights with key market indicators such as BTC Price and the VCRIX index. Our architecture’s analysis of emoji sentiment demonstrated a distinct advantage over FinBERT’s pure text sentiment analysis in such predicting power. This approach may be fed into the development of trading strategies aimed at utilizing social media elements to identify and forecast market trends. Crucially, our findings suggest that strategies based on emoji sentiment can facilitate the avoidance of significant market downturns and contribute to the stabilization of returns. This research underscores the practical benefits of integrating advanced AI-driven analyzes into financial strategies, offering a nuanced perspective on the interaction between digital communication and market dynamics in an academic context."," ECONOMICS , PSYCHOLOGY , Trends , PSYCHOLOGY;stock market analysis;agents;large language models;price prediction",Proquest
10.1109/CISCT62494.2024.11134255,10.1109/CISCT62494.2024.11134255,Transforming Financial Market Prediction Through Generative AI-Powered Data Management,"Conference Title: 2024 4th International Conference on Innovative Sustainable Computational Technologies (CISCT) Conference Start Date: 2024 Dec. 27 Conference End Date: 2024 Dec. 28 Conference Location: Dehradun, India Predicting financial markets remains essential for decision-making in trading and investment. However, traditional models often fall short due to low-quality data, market volatility, and the complexity of global economic trends. Generative AI offers a transformative approach by improving data management processes, enhancing prediction accuracy, and overcoming the limitations of current forecasting models. This research explores the potential of Generative AI to enrich financial data through techniques like data augmentation, synthetic data generation, and anomaly detection. Specifically, the study investigates how integrating Generative AI into data preprocessing can enhance predictive modeling using Long Short-Term Memory (LSTM) networks for time series forecasting, particularly in stock prices. The research also explores feature engineering techniques such as moving averages, Relative Strength Index (RSI), and volatility metrics, which are crucial for capturing market trends. Generative Adversarial Networks (GANs) are employed to create additional realistic trading scenarios, boosting model robustness. Implemented using Python, the findings reveal that the combined LSTM and GAN model improved prediction accuracy over traditional methods, achieving an RMSE of 0.096 and R-squared ( $\mathbf{R}^{\mathbf{2}}$ ) $\mathbf{0. 8 5}$ in stock price forecasts. The incorporation of synthetic data with traditional financial metrics leads to an improvement in the model's ability to predict short-term market trends. These findings suggest that the use of Generative AI can provide a more resilient and adaptive approach to financial market prediction, opening new avenues for research in the domain. Future research could focus on expanding the scope to include multi-market scenarios and incorporating real-time data streams."," Data management , Accuracy , Data augmentation , FINANCE , Trends , Trends , Prediction models , FINANCE , Volatility , Generative artificial intelligence , Generative adversarial networks , SUSTAINABILITY , Data transmission , SUSTAINABILITY , Anomalies , Real time , SUSTAINABILITY , Forecasting , Synthetic data , Economic;Large Language Model (LLM);Financial data analysis;Real-time data processing;Flask;ReactJS;Stock market information;Query processing",Proquest
10.1016/j.jfds.2025.100152,10.1016/j.jfds.2025.100152,Learning from AI-Finance: A selected synopsis,"[...]Gen-Al's information processing capability could help financial institutes in trading and asset allocation. [...]adopting AI and integrating AI into operations is becoming a competitive necessity in financial institutes. In that regard, there is a concern that Al-based trading and investment allocation can fall into the trap of Al collusion, impair market functions, and lead to a volatile asset price path. (ii) Als could possess multiple personalities, and this feature could lead to AI output containing simple biases and even scandalous behavior. [...]a careful design of regulation on Al is called for. 2. Yet, as the predictive power only lasts for two trading days, the advantage of fast and accurate information processing is very short-lived. More to the point, it shows that good news extracted by ChatGPT-3.5 from the front pages of the Wall Street Journal can predict the stock market index, even over a one-year horizon."," Language , Readability , OPERATIONS , OPERATIONS , PSYCHOLOGY , Deep learning , ACCTAX , Investments , FINANCE , PSYCHOLOGY , Neural networks , SUSTAINABILITY , PSYCHOLOGY , SUSTAINABILITY , Algorithms , Large language models , SUSTAINABILITY , SUSTAINABILITY , Chatbots;large language models;LLMs;multimodal;natural language processing;NLP",Proquest
10.1109/ICCA62237.2024.10927923,10.1109/ICCA62237.2024.10927923,Enhancing Stock Price Prediction: A Hybrid Approach Leveraging Large Language Models and Deep Learning,"Conference Title: 2024 International Conference on Computer and Applications (ICCA) Conference Start Date: 2024, Dec. 17 Conference End Date: 2024, Dec. 19 Conference Location: Cairo, Egypt Accurate stock price prediction is a challenging yet crucial goal in finance, with significant implications for investment decisions and risk management. This paper presents a comprehensive review of machine learning techniques for stock price prediction, examining traditional methods such as regression and ensemble models, as well as advanced approaches that integrate sentiment analysis and textual data sources. With the emergence of powerful Large Language Models (LLMs) such as ChatGPT, Llama and Gemini, we explore their potential for enhancing predictive accuracy using historical stock data. Key challenges are discussed, including data quality, model interpretability, and adapting to dynamic market conditions. Additionally, this paper proposes a trustworthy stock price prediction model based on LLMs enabling informed investment decision-making. Experimental results demonstrate that ChatGPT-4o model achieved a prediction accuracy of approximately 97%, which can be improved by tuning model parameters. Consequently, the paper highlights the potential of LLMs in improving stock price forecasting."," Accuracy , SUSTAINABILITY , Risk management , Large language models , Deep learning , Machine learning , Sentiment analysis , Prediction models , Chatbots , Large language models , Chatbots , SUSTAINABILITY , Economic;Stock Market Investment;Qualitative Data;Fundamental Analysis;Generative AI;Virtual Analyst",Proquest
10.1109/ICCA62237.2024.10927897,10.1109/ICCA62237.2024.10927897,Assessing the Correlation Between News Sentiment and Stock Price Movements: A Case Study of ‘WeWork’ Using Advanced NLP Techniques,"Conference Title: 2024 International Conference on Computer and Applications (ICCA) Conference Start Date: 2024, Dec. 17 Conference End Date: 2024, Dec. 19 Conference Location: Cairo, Egypt This research explores the intricate relationship between news article sentiment and stock price movements, with the company ‘WeWork’ serving as a case study. Leveraging advanced Natural Language Processing (NLP) techniques and Large Language Models (LLMs) such as Open AI, this study aims to transform unstructured textual data into actionable financial insights. Through rigorous data collection and preprocessing, sentiment scores were derived from a wide range of news sources and correlated with historical stock prices. Statistical analyses, including linear regression and correlation metrics, revealed a weak positive correlation of 16.47% between sentiment and stock prices. Although the correlation suggests that sentiment analysis can offer valuable insights into market trends, it is insufficient as a standalone predictor for investment decisions. The findings underscore the importance of integrating sentiment analysis with traditional financial metrics, and call for the development of more robust models incorporating diverse data sources in future research."," FINANCE , SUSTAINABILITY , Large language models , SUSTAINABILITY , PSYCHOLOGY , Sentiment analysis , Correlation , SUSTAINABILITY , News , Unstructured data , Natural language processing , Statistical analysis , Data collection , SUSTAINABILITY , Economic;GAN;architecture;LSGAN;CGAN;stock forecasting",Proquest
10.1109/ICDMW65004.2024.00019,10.1109/ICDMW65004.2024.00019,Leveraging Large Language Models for Predicting Stock Option Valuation and Financial Risk Mitigation,"Conference Title: 2024 IEEE International Conference on Data Mining Workshops (ICDMW) Conference Start Date: 2024, Dec. 9 Conference End Date: 2024, Dec. 9 Conference Location: Abu Dhabi, United Arab Emirates The prediction of short-term stock options with near-future expiration dates is a challenging task due to high volatility, limited information, market noise and the risk of time decay. This work focuses on the new approach to the stock options valuation by leveraging Large Language Models (LLMs) through the integration of quantitative (i.e. financial features-lagged prices, moving averages, and volatility indicators) and qualitative data (i.e. news data, including article titles, full textual content, and publication dates). More specifically, our approach fuses sentiment analysis from LLMs applied to financial news from two reputable outlets (i.e. Economic Times and Yahoo Finance India) with quantitative data on stock options, which includes stock option closing price. By conducting experiments on companies from the NIFTY 50 index using ChatGPT-3.5, ChatGPT-4, and LLaMA 3.1, we show that our method achieves superior prediction accuracy compared to other similar approaches. The paper develops a new framework to improve the valuation of short-term stock options using advanced natural language processing behaviors afforded by LLMs to achieve a more holistic capture of market dynamics and sentiment in option pricing."," Qualitative analysis , Data mining , Large language models , FINANCE , Sentiment analysis , Chatbots , Volatility , News , SUSTAINABILITY , FINANCE , Natural language processing , SUSTAINABILITY , Large language models , Chatbots , Economic;Large language model (LLM);electricity price prediction;bidding behaviors;market sentiment;spike-enhanced",Proquest
10.1109/ICCIRT59484.2024.10921844,10.1109/ICCIRT59484.2024.10921844,StockAI - Stock Analysis Tool Agent,"Conference Title: 2024 International Conference on Computing and Intelligent Reality Technologies (ICCIRT) Conference Start Date: 2024, Dec. 5 Conference End Date: 2024, Dec. 6 Conference Location: Coimbatore, India StockAI is a stock market analysis tool that integrates machine learning, traditional trading indicators, and intelligent agents to analyze live data and projections for stock investors. It does this by carrying out an analysis of the historical price trend of a stock and the ongoing stock markets from the use of mathematical indicators such as moving averages, relative strength index, and candlestick patterns. As a result, it aids in decision-making for both new and old traders. The system also leverages machine learning algorithms like random forests to generate price predictions with improved accuracy. StockAI’s interactive interface allows users to engage with the tool through natural language queries. However, challenges remain in evaluating the outputs of large language models, as current methods rely heavily on human evaluation. The ultimate goal of StockAI is to help investors make informed decisions, optimize market opportunities and mitigate risks through a combination of AI-driven analysis and traditional financial indicators."," Indicators , OPERATIONS , Algorithms , Intelligent agents , Large language models , Machine learning , SUSTAINABILITY , Decision trees , Economic;natural language processing;large language models;corporate events",Proquest
10.1109/ICDMW65004.2024.00021,10.1109/ICDMW65004.2024.00021,Sentiment Score of Bloomberg Market Wraps with ChatGPT,"Conference Title: 2024 IEEE International Conference on Data Mining Workshops (ICDMW) Conference Start Date: 2024, Dec. 9 Conference End Date: 2024, Dec. 9 Conference Location: Abu Dhabi, United Arab Emirates In this paper, we used a large dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines affect stock market movements. To make this analysis more effective, we employed ChatGPT. First, from the summary of daily financial updates, we identify top global news headlines that could have a significant influence on stock markets. Second, for each headline, we questioned ChatGPT to answer whether the news might lead to a rise, a fall in stock prices or an indecisive future. This two-stage method proves more effective than a direct question on the entire text. By gathering ChatGPT’s predictions day by day, we formed an overall market sentiment score and transform this score into a practical investment strategy in the NASDAQ index, demonstrating the significance of minimizing noise in sentiment scores by initially accumulating and then detrending them. This approach showcases that ChatGPT’s analysis of news headlines can provide valuable insights into future stock market behaviours and be a valuable tool to develop intuitive NLP-driven investment strategies leveraging news predictive power."," News , Data mining , SUSTAINABILITY , Chatbots , FINANCE , Chatbots , Investment strategy , Economic;stock prices;newspaper data;content analysis;table arrangement;ChatGPT;Regular Research Paper",Proquest
10.1109/ICICYTA64807.2024.10913442,10.1109/ICICYTA64807.2024.10913442,The Role of News Sentiment in Predicting the Jakarta Composite Index Using Long Short-Term Memory,"Conference Title: 2024 International Conference on Intelligent Cybernetics Technology &amp; Applications (ICICyTA) Conference Start Date: 2024, Dec. 17 Conference End Date: 2024, Dec. 19 Conference Location: Bali, Indonesia This paper investigates the integration of sentiment analysis and historical data to enhance the accuracy of Jakarta Composite Index (JCI) stock return predictions using a Long Short-Term Memory (LSTM) model. The dataset spans January 3, 2014, to August 6, 2024, consisting of 2,647 daily observations enriched with sentiment scores derived from over 10,000 Kompas.com news articles. Sentiment analysis, performed using a Large Language Model (LLM)-based ChatGPT model, classified sentiment into Positive, Neutral, and Negative categories, which were then integrated as predictive features. Five scenarios for incorporating sentiment data were evaluated, with Scenario 2 (sequence of past sentiment scores) yielding the best performance. Specifically, it achieved the lowest Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) across various metrics: 36.4570 and 47.5527 for Absolute Return prediction, 0.005209 and 0.006804 for Relative Return prediction, and 50,725 and 65,653 for Close Price prediction. These findings underscore the significant role of sequential sentiment data in improving prediction accuracy, offering practical recommendations for investors to leverage sentiment analysis in making more informed decisions in the JCI market."," Cybernetics , Large language models , PSYCHOLOGY , Sentiment analysis , Root-mean-square errors , Jakarta Indonesia , Indonesia , Environmental;Agricultural Price Optimization;Genetic Algorithms;Large Language Models;Mixtral 8x7B;Machine Learning;Market Efficiency;Farm Profitability;Sustainable Agriculture",Proquest
10.1109/IKT65497.2024.10892779,10.1109/IKT65497.2024.10892779,LLM-Driven Feature Extraction for Stock Market Prediction: A Case Study of Tehran Stock Exchange,"Conference Title: 2024 15th International Conference on Information and Knowledge Technology (IKT) Conference Start Date: 2024, Dec. 24 Conference End Date: 2024, Dec. 26 Conference Location: Isfahan, Iran, Islamic Republic of Stock market prediction is one of the most challenging research areas in recent years. With the emergence of deep learning and artificial intelligence, researchers have proposed various methods to predict stock market directions, considering different financial variables. One of the most significant variables influencing stock movement is user opinions and social media, which has attracted much attention from researchers in recent years. Although existing studies have introduced various methods to combine stock price and textual features, a reliable and comprehensive method has not yet been established, and there is still room for improvement. In this research, a novel method based on large language models is introduced for feature extraction from financial texts, and a self-attention mechanism is proposed to capture the internal relationships between textual and financial features. The results of the model presented in this study show a 3.10% improvement in accuracy compared to the latest competing models on a newly collected dataset"," Feature extraction , Markets , SUSTAINABILITY , Large language models , Stock exchanges , Artificial intelligence , Machine learning , FINANCE , Economic;Self-Attention;Transformers;Quantum Self-Attention;LSTM;Quantum Neural Networks",Proquest
10.1109/FMLDS63805.2024.00071,10.1109/FMLDS63805.2024.00071,Can GPT Price Options?,"Conference Title: 2024 IEEE International Conference on Future Machine Learning and Data Science (FMLDS) Conference Start Date: 2024, Nov. 20 Conference End Date: 2024, Nov. 23 Conference Location: Sydney, Australia Options are financial instruments that grant the holder the right, but not the obligation, to buy or sell an underlying asset at a predetermined price within a specified time frame. Traditional option pricing models, such as the Black-Scholes equation, depend on simplifying assumptions and struggle to effectively capture complex market dynamics. The study investigates the viability of using the Generative Pretrained Transformer (GPT) model to assess the value of stock options. We fine-tune the state-of-the-art GPT-3.5-turbo model by utilizing past option chain data and evaluate its precision in predicting option prices for well-known technology stocks including Apple (AAPL), Google (GOOG), and Microsoft (MSFT). Our model employs many features, including strike price, underlying price, days to expiry, and volatility index (VIX), to precisely predict option prices. Extensive examination undertaken at various degrees of moneyness and time horizons demonstrates that GPT models consistently surpass Black-Scholes in terms of both mean absolute error and root mean squared error. Out of all the models that were assessed, the 5-year data models exhibit the greatest overall accuracy. An error study suggests that pricing for options at the money has improved, but there are issues in appropriately pricing options that are highly in the money or out of the money. The GPT technique shows promise in leveraging transformers for computational finance applications."," FINANCE , Black-Scholes equation , Machine learning , Data science , Pricing , Economic;Temporal Data Analytics;Reinforced LLM;Time-Series Patterns;Pattern Discovery;Real- World Datasets",Proquest
10.1109/ICCCMLA63077.2024.10871633,10.1109/ICCCMLA63077.2024.10871633,Adapting Speech Models for Stock Price Prediction,"Conference Title: 2024 IEEE 6th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) Conference Start Date: 2024, Oct. 19 Conference End Date: 2024, Oct. 20 Conference Location: Hamburg, Germany Large language models (LLMs) have demonstrated remarkable success in the field of natural language processing (NLP). Despite their origins in NLP, these algorithms possess the theoretical capability to process any data type represented in an NLP-like format. In this study, we use stock data to illustrate three methodologies for processing regression data with LLMs, employing tokenization and contextualized embeddings. By leveraging the well-known LLM algorithm Bidirectional Encoder Representations from Transformers (BERT) [1], we apply quantitative stock price prediction methodologies to predict stock prices and stock price movements, showcasing the versatility and potential of LLMs in financial data analysis."," Data analysis , Algorithms , Cybernetics , Algorithms , Large language models , Machine learning , Natural language processing , Cognition , Economic;Transformer;Positional Embedding;Encoder;Autoformer;Informer;Time series;Commodity Trading",Proquest
10.1109/ISCMI63661.2024.10851487,10.1109/ISCMI63661.2024.10851487,A Comparative Study of Sequential Deep Learning Models in Financial Time Series Forecasting,"Conference Title: 2024 11th International Conference on Soft Computing &amp; Machine Intelligence (ISCMI) Conference Start Date: 2024, Nov. 22 Conference End Date: 2024, Nov. 23 Conference Location: Melbourne, Australia Time series analysis of daily stock prices is challenging due to the inherent complexity, nonlinearity, and nonstationarity of financial data. In this paper, we compare three sequential deep learning models—LSTM, Transformer, and Large Language Models (LLMs)—for stock price prediction. By transforming the regression problem of predicting daily log returns into a classification task, we evaluate the models’ classification accuracies, with the Transformer achieving the highest accuracy of 22%, followed by LSTM (15.6%) and LLM (15.3%). Regression metrics showed LSTM initially performing better, with a lower RMSE (180.92) than LLM (1739.61). However, outlier predictions in the LLM, caused by incomplete number outputs, inflated its error. After removing these outliers, LLM’s RMSE improved significantly to 33.85, surpassing LSTM. These results demonstrate the potential of Transformer and LLM models for financial time series prediction. Future work will explore incorporating self-reflection mechanisms in LLM predictions and extending the comparison to multivariate financial time series incorporating textual data and other features."," Accuracy , Comparative studies , Outliers (statistics) , FINANCE , Deep learning , Classification , Large language models , Soft computing , Root-mean-square errors , SUSTAINABILITY , Multivariate analysis , Machine learning , Deep learning , SUSTAINABILITY , Predictions , Large language models , Time series , SUSTAINABILITY , Economic;Issue Report Classification;Large Language Model;Natural Language Processing;Software Engineering;Labeling;Multi-class Classification;Empirical Study",Proquest
10.1109/ISCMI63661.2024.10851549,10.1109/ISCMI63661.2024.10851549,Foreign Exchange Rate Forecast by a Large Language Model Integrated with Trend Description,"Conference Title: 2024 11th International Conference on Soft Computing &amp; Machine Intelligence (ISCMI) Conference Start Date: 2024, Nov. 22 Conference End Date: 2024, Nov. 23 Conference Location: Melbourne, Australia In this paper, we propose a large language model to forecast the direction of change in a foreign exchange rate. The input of the proposed model is textual information as a prompt, whereas that of conventional forecast models is numerical information. A recent trend in the exchange rate is added to input textual information to enhance forecast accuracy. GPT-2 is adopted as our large language model and is fine-tuned using training data. The effectiveness of the proposed model is empirically examined using actual data."," SUSTAINABILITY , Large language models , Soft computing , Economic;FinBERT;language model;sentiment analysis;prediction;LSTM",Proquest
10.1109/BigData62323.2024.10824953,10.1109/BigData62323.2024.10824953,Large Language Models for Financial Aid in Financial Time-series Forecasting,"Conference Title: 2024 IEEE International Conference on Big Data (BigData) Conference Start Date: 2024, Dec. 15 Conference End Date: 2024, Dec. 18 Conference Location: Washington, DC, USA Considering the difficulty of financial time series forecasting in financial aid, much of the current research focuses on leveraging big data analytics in financial services. One modern approach is to utilize ""predictive analysis"", analogous to forecasting financial trends. However, many of these time series data in Financial Aid (FA) pose unique challenges due to limited historical datasets and high dimensional financial information, which hinder the development of effective predictive models that balance accuracy with efficient runtime and memory usage. Pre-trained foundation models are employed to address these challenging tasks. We use state-of-the-art time series models including pre-trained LLMs (GPT-2 as backbone), transformers, and linear models to demonstrate their ability to outperform traditional approaches, even with minimal (""few-shot"") or no fine-tuning (""zero-shot""). Our benchmark study, which includes financial aid with seven other time series tasks, shows the potential of using LLMs for scarce financial datasets."," Data analysis , OPERATIONS , Datasets , Memory tasks , Large language models , Big Data , Prediction models , SUSTAINABILITY , SUSTAINABILITY , Large language models , Forecasting , Time series , SUSTAINABILITY , SUSTAINABILITY , Economic , Environmental;Agents;Privatized Knowledge;Exchange Rate Forecasting;Experiential Learning",Proquest
10.1109/BigData62323.2024.10825449,10.1109/BigData62323.2024.10825449,Combining Financial Data and News Articles for Stock Price Movement Prediction Using Large Language Models,"Conference Title: 2024 IEEE International Conference on Big Data (BigData) Conference Start Date: 2024, Dec. 15 Conference End Date: 2024, Dec. 18 Conference Location: Washington, DC, USA Predicting financial markets and stock price movements requires analyzing a company’s performance, historic price movements, industry-specific events alongside the influence of human factors such as social media and press coverage. We assume that financial reports (such as income statements, balance sheets, and cash flow statements), historical price data, and recent news articles can collectively represent aforementioned factors.We combine financial data in tabular format with textual news articles and employ pre-trained Large Language Models (LLMs) to predict market movements. Recent research in LLMs has demonstrated that they are able to perform both tabular and text classification tasks, making them our primary model to classify the multi-modal data. We utilize retrieval augmentation techniques to retrieve and attach relevant chunks of news articles to financial metrics related to a company and prompt the LLMs in zero, two, and four-shot settings. Our dataset contains news articles collected from different sources, historic stock price, and financial report data for 20 companies with the highest trading volume across different industries in the stock market. We utilized recently released language models for our LLM-based classifier, including GPT- 3 and 4, and LLaMA- 2 and 3 models.We introduce an LLM-based classifier capable of performing classification tasks using combination of tabular (structured) and textual (unstructured) data. By using this model, we predicted the movement of a given stock’s price in our dataset with a weighted F1-score of 58.5% and 59.1% and Matthews Correlation Coefficient of 0.175 for both 3-month and 6-month periods.The dataset and codes for this paper can be found on Github. https://github.com/aliielahi/FinedFMP 1",,Proquest
10.1109/BigData62323.2024.10825946,10.1109/BigData62323.2024.10825946,Stock Price Prediction Using LLM-Based Sentiment Analysis,"Conference Title: 2024 IEEE International Conference on Big Data (BigData) Conference Start Date: 2024, Dec. 15 Conference End Date: 2024, Dec. 18 Conference Location: Washington, DC, USA This paper examines the effectiveness of recent large language model-based news sentiment estimation for stock price forecasting with the combination of latest transformer-based prediction models. To achieve a better accuracy in sentiment classification, experiments are designed to compare six different models (GPT 4, Llama 3, Gemma 2, Mistral 7b, FinBERT, VADER) in financial news sentiment classification, and it was found that recent large language models can outperform FinBERT and VADER, which are the most commonly used models in financial sentiment analysis. Based on the experiment results, Llama 3, with relatively stable performance, is chosen to classify the news sentiments of the selected companies. Informer, Transformer, TCN, LSTM, SVR, Random Forest and Naive Forecast are used to predict the stock prices with different sliding window sizes. Experiments with different scenarios are designed to evaluate the prediction ability of news sentiment. Results show that adding news sentiment data can indeed improve the stock price prediction. Informer, one of the state-of-the-art transformer models for long-term prediction tasks, yields the best performances in most cases. Ablation study of Informer suggests that the generative style decoder plays an important role in performance improvement."," News , FINANCE , Classification , Large language models , Big Data , PSYCHOLOGY , Sentiment analysis , Prediction models , Transformers , Ablation , SUSTAINABILITY , Economic;Graph neural networks;Graph Transformer;Stock movement prediction;Large Language Model",Proquest
10.3390/jrfm17120537,10.3390/jrfm17120537,Fin-ALICE: Artificial Linguistic Intelligence Causal Econometrics,"This study introduces Fin-ALICE (Artificial Linguistic Intelligence Causal Econometrics), a framework designed to forecast financial time series by integrating multiple analytical approaches including co-occurrence networks, supply chain analysis, and emotional sentiment analysis to provide a comprehensive understanding of market dynamics. In our co-occurrence analysis, we focus on companies that share the same emotion on the same day, using a much shorter horizon than our previous study of one month. This approach allows us to uncover short-term, emotion-driven correlations that traditional models might overlook. By analyzing these co-occurrence networks, Fin-ALICE identifies hidden connections between companies, sectors, and events. Supply chain analysis within Fin-ALICE will evaluate significant events in commodity-producing countries that impact their ability to supply key resources. This analysis captures the ripple effects of disruptions across industries and regions, offering a more nuanced prediction of market movements. Emotional sentiment analysis, powered by the Fin-Emotion library developed in our prior research, quantifies the emotional undertones in financial news through metrics like “emotion magnitude” and “emotion interaction”. These insights, when integrated with Temporal Convolutional Networks (TCNs), significantly enhance the accuracy of financial forecasts by capturing the emotional drivers of market sentiment. Key contributions of Fin-ALICE include its ability to perform month-by-month company correlation analysis, capturing short-term market fluctuations and seasonal patterns. We compare the performance of TCNs against advanced models such as LLMs and LSTMs, demonstrating that the Fin-ALICE model outperforms these models, particularly in sectors where emotional sentiment and supply chain dynamics are critical. Fin-ALICE provides decision-makers with predictive insights and a deeper understanding of the underlying emotional and supply chain factors that drive market behaviors."," Language , Accuracy , Deep learning , MARKETING , PSYCHOLOGY , SUSTAINABILITY , Trends , FINANCE , SUSTAINABILITY , Feature selection , SUSTAINABILITY , Linguistics , FINANCE , Correlation analysis , ECONOMICS , SUSTAINABILITY , SUSTAINABILITY , PSYCHOLOGY , Large language models;finance;quantitative stock price prediction;natural language processing;stock movement prediction;fintech;machine learning;large language models",Proquest
10.1109/BigDIA63733.2024.10808510,10.1109/BigDIA63733.2024.10808510,A Novel Wavelet Based Generative Model for Time Series Prediction,"Conference Title: 2024 10th International Conference on Big Data and Information Analytics (BigDIA) Conference Start Date: 2024, Oct. 25 Conference End Date: 2024, Oct. 28 Conference Location: Chiang Mai, Thailand Generative models have become an exciting area of research in recent years. Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs) have been utilized in various data augmentation applications. However, generative models can learn high-dimensional features of data through adversarial learning, making them suitable for nonlinear and nonstationary time series analysis, such as stock market prediction, high-frequency trading, and ocean current forecasting. In this paper, the researchers focus on using a wavelet-based GAN to predict stock market prices by generating synthetic stock market price trends. Historical stock price data from 2014 to 2024 is used for our experiments, and the results show that the wavelet-based GAN outperforms deep learning baseline models..",,Proquest
10.3390/app142411897,10.3390/app142411897,Large Language Models and the Elliott Wave Principle: A Multi-Agent Deep Learning Approach to Big Data Analysis in Financial Markets,"Traditional technical analysis methods face limitations in accurately predicting trends in today’s complex financial markets. Meanwhile, existing AI-driven approaches, while powerful in processing large datasets, often lack interpretability due to their black-box nature. This paper presents ElliottAgents, a multi-agent system that combines the Elliott wave principle with LLMs, showcasing the application of deep reinforcement learning (DRL) and natural language processing (NLP) in financial analysis. By integrating retrieval-augmented generation (RAG) and deep reinforcement learning (DRL), the system processes vast amounts of market data to identify Elliott wave patterns and generate actionable insights. The system employs a coordinated team of specialized agents, each responsible for specific aspects of analysis, from pattern recognition to investment strategy formulation. We tested ElliottAgents on both stock and cryptocurrency markets, evaluating its effectiveness in pattern identification and trend prediction across different time scales. Our experimental results demonstrate improvements in prediction accuracy when combining classical technical analysis with AI-driven approaches, particularly when enhanced by DRL-based backtesting process. This research contributes to the advancement of financial technology by introducing a scalable, interpretable framework that enhances market analysis capabilities, offering a promising new methodology for both practitioners and researchers."," ECONOMICS , SUSTAINABILITY , Accuracy , MARKETING , Trends , FINANCE , Large language models , SUSTAINABILITY , FINANCE;NLP;ChatGPT;SentimentScore;Bloomberg News",Proquest
3149090574,,Prediction of Foreign Exchange Rates by a Large Language Model,"Conference Title: 2024 SICE Festival with Annual Conference (SICE FES) Conference Start Date: 2024, Aug. 27 Conference End Date: 2024, Aug. 30 Conference Location: Kochi City, Japan This paper proposes a prompt-based method utilizing a large language model (LLM) to predict changes in foreign exchange rates based on limit order information. While traditional deep learning models for prediction utilize numerical values as input and output, LLMs use sentences and prompts. To address this, we design prompts that incorporate the numerical values. GPT-2, a widely adopted LLM, is employed and fine-tuned using a training dataset. The effectiveness of our proposed method is demonstrated through empirical analysis using actual time series data."," Prompt engineering , Large language models , Empirical analysis , Economic;Generative Pre-trained Transformer;Options;Stocks;Pricing;Black-Scholes Model;Machine Learning;Volatility;Finance Applications",Proquest
10.1109/CIFEr62890.2024.10772910,10.1109/CIFEr62890.2024.10772910,Semantic Graph Learning for Trend Prediction from Long Financial Documents,"Conference Title: 2024 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics (CIFEr) Conference Start Date: 2024, Oct. 22 Conference End Date: 2024, Oct. 23 Conference Location: Hoboken, NJ, USA The advent of large language models (LLMs) has initiated much research into their various financial applications. However, in applying LLMs on long documents, semantic relations are not explicitly incorporated, and a full or arbitrarily sparse attention operation is employed. In recent years, progress has been made in Abstract Meaning Representation (AMR), which is a graph-based representation of text to preserve its semantic relations. Since AMR can represent semantic relationships at a deeper level, it can be beneficially utilized by graph neural networks (GNNs) for constructing effective document-level graph representations built upon LLM embeddings to predict target metrics in the financial domain. We propose FLAG: Financial Long document classification via AMR-based GNN, an AMR graph based framework to generate document-level embeddings for long financial document classification. We construct document-level graphs from sentence-level AMR graphs, endow them with specialized LLM word embeddings in the financial domain, apply a deep learning mechanism that utilizes a GNN, and examine the efficacy of our AMR-based approach in predicting labeled target data from long financial documents. Extensive experiments are conducted on a dataset of quarterly earnings calls transcripts of companies in various sectors of the economy, as well as on a corpus of more recent earnings calls of companies in the S&amp;P 1500 Composite Index. We find that our AMR-based approach outperforms fine-tuning LLMs directly on text in predicting stock price movement trends at different time horizons in both datasets. Our work also outperforms previous work utilizing document graphs and GNNs for text classification."," Semantic relations , Datasets , Semantics , Classification , Graphs , Large language models , Graph neural networks , Graph representations , Documents , Effectiveness , Profits , SUSTAINABILITY , Machine learning , Deep learning , Graphical representations , Documents , Large language models , Semantics , Economic;GDP;large language model (LLM);macroeconomic indicator;natural language processing (NLP);PMI;sentiment analysis;unemployment rate",Proquest
10.3390/bdcc8110143,10.3390/bdcc8110143,"Innovative Sentiment Analysis and Prediction of Stock Price Using FinBERT, GPT-4 and Logistic Regression: A Data-Driven Approach","This study explores the comparative performance of cutting-edge AI models, i.e., Finaance Bidirectional Encoder representations from Transsformers (FinBERT), Generatice Pre-trained Transformer GPT-4, and Logistic Regression, for sentiment analysis and stock index prediction using financial news and the NGX All-Share Index data label. By leveraging advanced natural language processing models like GPT-4 and FinBERT, alongside a traditional machine learning model, Logistic Regression, we aim to classify market sentiment, generate sentiment scores, and predict market price movements. This research highlights global AI advancements in stock markets, showcasing how state-of-the-art language models can contribute to understanding complex financial data. The models were assessed using metrics such as accuracy, precision, recall, F1 score, and ROC AUC. Results indicate that Logistic Regression outperformed the more computationally intensive FinBERT and predefined approach of versatile GPT-4, with an accuracy of 81.83% and a ROC AUC of 89.76%. The GPT-4 predefined approach exhibited a lower accuracy of 54.19% but demonstrated strong potential in handling complex data. FinBERT, while offering more sophisticated analysis, was resource-demanding and yielded a moderate performance. Hyperparameter optimization using Optuna and cross-validation techniques ensured the robustness of the models. This study highlights the strengths and limitations of the practical applications of AI approaches in stock market prediction and presents Logistic Regression as the most efficient model for this task, with FinBERT and GPT-4 representing emerging tools with potential for future exploration and innovation in AI-driven financial analytics."," Language , Accuracy , FINANCE , Data analysis , OPERATIONS , FINANCE , Accuracy , Investments , SUSTAINABILITY , SUSTAINABILITY , PSYCHOLOGY , Trends , Sentiment analysis , SUSTAINABILITY , Regression models , FINANCE , PSYCHOLOGY , PSYCHOLOGY , Market research , Literature reviews , Machine learning , Natural language processing , Natural language , PSYCHOLOGY;Large Language Models (LLMs);Generative Adversarial Networks (GANs);AI-Generated Misinformation;Adversarial Learning;AI Content Moderation;Natural Language Processing (NLP);Misinformation Detection",Proquest
10.1109/AiDAS63860.2024.10730589,10.1109/AiDAS63860.2024.10730589,GPT-4 Powered Virtual Analyst for Fundamental Stock Investment by Leveraging Qualitative Data,"Conference Title: 2024 5th International Conference on Artificial Intelligence and Data Sciences (AiDAS) Conference Start Date: 2024, Sept. 3 Conference End Date: 2024, Sept. 4 Conference Location: Bangkok, Thailand This paper introduces an advanced AI-assisted tool, powered by GPT-4, for fundamental stock investment, offering human-like investment advice accompanied by supporting information to validate recommendations for users. While traditional stock market prediction tools rely heavily on quantitative data such as stock prices, volume, earnings, and dividends, the use of qualitative data for stock market analysis is an emerging trend. Recent advancements in AI, particularly with Generative AI like ChatGPT, have significantly influenced user interactions and decision-making processes. Recognizing the potential of AI across various industries, we have customized GPT-4 to perform fundamental analysis based on news, financial and annual reports of companies, government policies, and more. Our tool analyzes the above qualitative data and provide numerical scores along with logical and fact-based justifications for the short, medium, and long-term investment prospects of companies. The system delivers reliable recommendations for up to ten months without continuous monitoring, making it valuable to a wide range of users, from value investors to everyday traders. The benefits of using our tool are substantial, including significant time and cost savings."," Qualitative analysis , Data analysis , SUSTAINABILITY , Public policy , ACCTAX , Investments , SUSTAINABILITY , FINANCE , Generative artificial intelligence , Economic;stock prediction;LSTM;sentiment analysis;JCI",Proquest
10.1109/DOCS63458.2024.10704454,10.1109/DOCS63458.2024.10704454,Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach,"Conference Title: 2024 6th International Conference on Data-driven Optimization of Complex Systems (DOCS) Conference Start Date: 2024, Aug. 16 Conference End Date: 2024, Aug. 18 Conference Location: Hangzhou, China Accurate stock market predictions following earnings reports are crucial for investors. Traditional methods, particularly classical machine learning models, struggle with these predictions because they cannot effectively process and interpret extensive textual data contained in earnings reports and often overlook nuances that influence market movements. This paper introduces an advanced approach by employing Large Language Models (LLMs) instruction fine-tuned with a novel combination of instruction-based techniques and quantized low-rank adaptation (QLoRA) compression. Our methodology integrates ‘base factors‘, such as financial metric growth and earnings transcripts, with ‘external factors‘, including recent market indices performances and analyst grades, to create a rich, supervised dataset. This comprehensive dataset enables our models to achieve superior predictive performance in terms of accuracy, weighted Fl, and Matthews correlation coefficient (M CC), especially evident in the comparison with benchmarks such as GPT-4. We specifically highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases significant improvements over baseline models. The paper also discusses the potential of expanding the output capabilities to include a ‘Hold’’’’’ option and extending the prediction horizon, aiming to accommodate various investment styles and time frames. This study not only demonstrates the power of integrating cutting-edge AI with fine-tuned financial data but also paves the way for future research in enhancing AI -driven financial analysis tools."," Profits , Datasets , Complex systems , SUSTAINABILITY , FINANCE , Large language models , Performance prediction , Artificial intelligence , Machine learning , Correlation coefficients , Correlation coefficient , Economic;software testing;fairness;extreme value theory",Proquest
10.1109/CIBCB58642.2024.10702147,10.1109/CIBCB58642.2024.10702147,The Development of CanPrompt Strategy in Large Language Models for Cancer Care,"Conference Title: 2024 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB) Conference Start Date: 2024, Aug. 27 Conference End Date: 2024, Aug. 29 Conference Location: Natal, Brazil Background: The recent revolution in Large Language Models (LLMs) is transforming industries, enhancing communication, and reshaping research methodologies. LLMs have found significant applications across various sectors, notably in finance for stock market predictions, and in healthcare, where complex medical data is analyzed for diagnosis at an early stage, improving diagnostic procedures, and personalized treatment planning. In healthcare, where complex medical data is analyzed for diagnosis at an early stage. Despite the immense potential, challenges such as overwhelming Big Data, model hallucinations, and ethical concerns about patient privacy and bias persist. Method: We implemented novel strategies like CanPrompt to mitigate the accuracy and hallucination concerns to ensure responsible deployment. The CanPrompt strategy utilizes prompt engineering combined with few-shot and in-context learning to significantly enhance model accuracy by generating more relevant answers. The models were tested against a specialized dataset from MedQuAD, focusing on cancer, and evaluated using metrics like ROUGE and BERTScore to assess the semantic and syntactic accuracy of generated responses against validated ""Gold Answers"". Through this approach, the study seeks to outline the potential and limitations of LLMs in improving cancer care. Result: After applying CanPrompt with models Mistral 7x8b, Falcon 40b, and Llama 3-8b, BERTScore results showed Mistral leading with an accuracy around 84%, Falcon slightly lower, and Llama the least, with respective precision scores also reflecting a similar trend. Conclusion: The study demonstrates the promise of LLMs in cancer care through the introduction of CanPrompt."," PSYCHOLOGY , Accuracy , Data analysis , Accuracy , Strategy , Big Data , Large language models , Health care , SUSTAINABILITY , Cancer , SUSTAINABILITY , Diagnosis , Market research , Prompt engineering , Large language models , Bioinformatics , Environmental;AI-driven;risk assessment;Transformer architecture;enterprise management;natural language processing;predictive insights;real-time data;financial performance;supply chain vulnerabilities;operational disruptions",Proquest
10.1109/ACCESS.2024.3445413,10.1109/ACCESS.2024.3445413,"Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study","This paper comprehensively examines Large Language Models (LLMs) in sentiment analysis, specifically focusing on financial markets and exploring the correlation between news sentiment and Bitcoin prices. We systematically categorize various LLMs used in financial sentiment analysis, highlighting their unique applications and features. We also investigate the methodologies for effective data collection and categorization, underscoring the need for diverse and comprehensive datasets. Our research features a case study investigating the correlation between news sentiment and Bitcoin prices, utilizing advanced sentiment analysis and financial analysis methods to demonstrate the practical application of LLMs. The findings reveal a modest but discernible correlation between news sentiment and Bitcoin price fluctuations, with historical news patterns showing a more substantial impact on Bitcoin’s longer-term price than immediate news events. This highlights LLMs’ potential in market trend prediction and informed investment decision-making."," News , Impact analysis , Datasets , Data mining , Large language models , Sentiment analysis , Digital currencies , Correlation;securities;cryptocurrency;stock market;artificial intelligence;machine learning;probabilistic modelling;classification models;artificial neural network;random forests;naïve bayes",Proquest
10.1109/ICCIMS61672.2024.10690672,10.1109/ICCIMS61672.2024.10690672,Self-Evolving Programs: A Novel Approach Leveraging LLMs and Quine Programs,"Conference Title: 2024 International Conference on Computing, Internet of Things and Microwave Systems (ICCIMS) Conference Start Date: 2024, July 29 Conference End Date: 2024, July 31 Conference Location: Gatineau, QC, Canada In an era where software systems undergo rapid evolution, the demand for self-evolving programs has received much attention. This paper introduces a groundbreaking methodology that amalgamates the predictive power of Large Language Model-Based Methods with the self-replicating nature of Quine Programs to organize self-evolving software. This innovative integration not only facilitates dynamic code adaptation to fluctuating runtime conditions but also pioneers a shift from traditional static coding paradigms. Through this approach, we aim to revolutionize software development, particularly enhancing security and performance with a focus on countering selfish mining attacks in Bitcoin. It should be noted that the suggested approach has not yet been considered in the field of software engineering, and its applications are not limited to software security. It has high potential to be used in every domain that requires adaptive programs. Since the suggested approach is novel, the proposed solution in Bitcoin is also novel. The results of simulation show the efficiency of the proposed solution."," ECONOMICS , Software engineering , Internet of Things , Large language models , Digital currencies , Cybersecurity , Software development , Economic;Fin Bert;LLMs;BERT;Financial Sentimental Analysis;FSA;Financial Datasets;Data preprocessing",Proquest
10.1109/ICoDSA62899.2024.10652178,10.1109/ICoDSA62899.2024.10652178,Estimating Value at Risk for Central Counterparties: A Generative AI Approach,"Conference Title: 2024 International Conference on Data Science and Its Applications (ICoDSA) Conference Start Date: 2024, July 10 Conference End Date: 2024, July 11 Conference Location: Kuta, Bali, Indonesia Central counterparties (CCPs) play an important role in the stability of financial markets by helping to mitigate systemic risk. It is important that CCPs have robust risk management tools in order to protect themselves from failing due to a defaulting member. In this paper a new model using a Bidirectional Generative Adversarial Network (BiGAN), a type of generative AI model, is proposed to estimate Value at Risk (VaR), a common metric used to compute initial margin for CCPs. Fifteen years of closing prices from the S&amp;P 500 index was used as the dataset. The model was backtested for a period of four years. The results were evaluated using the number of breaches, Kupiec test, excess margin as well as two procyclicality measures: the standard deviation and peak to trough ratio of margin. The results were compared against three widely used models: filtered historical simulation method, historical VaR and parametric VaR. The results from this study showed that VaR computed using the BiGAN model produced 19 breaches on average for the four-year test period. While the experimental results show the proposed model is comparable with other models in terms of accuracy, its standard deviation for margin calls is lower which results in more short-term stability and a lower excess margin compared to the traditional models. The results of this research encourage further research on using BiGAN to estimate VAR."," Standard deviation , SUSTAINABILITY , Risk management , SUSTAINABILITY , Stability , SUSTAINABILITY , Generative artificial intelligence , Standard deviation , Generative adversarial networks , Economic;Financial Prediction;Large Language Models;Sentiment Analysis;Market Forecasting;Machine Learning;Quantum AI",Proquest
10.1038/s41598-024-68959-7,10.1038/s41598-024-68959-7,Meta graphical lasso: uncovering hidden interactions among latent mechanisms,"In complex systems, it’s crucial to uncover latent mechanisms and their context-dependent relationships. This is especially true in medical research, where identifying unknown cancer mechanisms and their impact on phenomena like drug resistance is vital. Directly observing these mechanisms is challenging due to measurement complexities, leading to an approach that infers latent mechanisms from observed variable distributions. Despite machine learning advancements enabling sophisticated generative models, their black-box nature complicates the interpretation of complex latent mechanisms. A promising method for understanding these mechanisms involves estimating latent factors through linear projection, though there’s no assurance that inferences made under specific conditions will remain valid across contexts. We propose a novel solution, suggesting data, even from systems appearing complex, can often be explained by sparse dependencies among a few common latent factors, regardless of the situation. This simplification allows for modeling that yields significant insights across diverse fields. We demonstrate this with datasets from finance, where we capture societal trends from stock price movements, and medicine, where we uncover new insights into cancer drug resistance through gene expression analysis."," Medical research , Gene expression , SUSTAINABILITY , Observational learning , Drug resistance , Drug resistance , Drug resistance , SUSTAINABILITY;Generative Models;Discriminative Models;Stacked Generalization;Xgboost;LightGBM;Bitcoin",Proquest
10.1109/ACCESS.2024.3350638,10.1109/ACCESS.2024.3350638,Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering,"Blockchain technology has revolutionized the financial landscape, witnessing widespread adoption of cryptocurrencies due to their decentralized and transparent nature. As sentiments expressed on social media platforms wield substantial influence over cryptocurrency market dynamics, sentiment analysis has emerged as a crucial tool for gauging public opinion and predicting market trends. This paper explores fine-tuning techniques for large language models to enhance sentiment analysis performance. Experimental results demonstrate a significant average zero-shot performance gain of 40% on unseen tasks after fine-tuning, highlighting its potential. Additionally, the impact of instruction-based fine-tuning on models of varying scales is examined, revealing that larger models benefit from instruction tuning, achieving the highest average accuracy score of 75.16%. In contrast, smaller-scale models may experience reduced generalization due to complete model capacity utilization. To gain deeper insight into instruction effectiveness, the paper presents experimental investigations under different instruction tuning setups. Results show the model achieves an average accuracy score of 72.38% for short and simple instructions, outperforming long and complex instructions by over 12%. Finally, the paper explores the relationship between fine-tuning corpus size and model performance, identifying an optimal corpus size of 6,000 data points for the highest performance across different models. Microsoft’s MiniLM, a distilled version of BERT, excels in efficient data use and performance optimization, while Google’s FLAN-T5 demonstrates consistent and reliable performance across diverse datasets."," Accuracy , Data mining , Cryptography , Large language models , PSYCHOLOGY , Sentiment analysis , Digital currencies , Scale models , Data points , Prompt engineering;Generative AI;Investment Recommendation;LSTM;Expense Tracker;Financial Literacy;Community Forum;Mutual Funds;Equity Market;Financial Resources;IBM Datasets;Smart Finance",Proquest
10.1080/14765284.2023.2245279,10.1080/14765284.2023.2245279,From fiction to fact: the growing role of generative AI in business and finance,"Generative Artificial Intelligence (AI), such as ChatGPT by OpenAI, has revolutionized the business world, with benefits including improved accessibility, efficiency, and cost reduction. This article reviews recent developments of generative AI in business and finance, summarizes its practical applications, provides examples of the latest generative AI tools, and demonstrates that generative AI can revolutionize data analysis in industry and academia. To test the ability of generative AI to support decision-making in financial markets, we use the ChatGPT to capture corporate sentiments towards environmental policy by inputting text extracted from corporate financial statements. Our results demonstrate that the sentiment scores generated by ChatGPT can predict firms’ risk-management capabilities and stock return performance. This study also highlights the potential challenges and limitations associated with generative AI. Finally, we propose several questions for future research at the intersection of generative AI with business and finance.",,Proquest
10.1007/s44196-023-00212-x,10.1007/s44196-023-00212-x,An Efficient GAN-Based Multi-classification Approach for Financial Time Series Volatility Trend Prediction,"Deep learning has achieved tremendous success in various applications owing to its robust feature representations of complex high-dimensional nonlinear data. Financial time-series prediction is no exception. Hence, the volatility trend prediction in financial time series (FTS) has been an active topic for several decades. Inspired by generative adversarial networks (GAN), which have been studied extensively in image processing and have achieved excellent results, we present the ordinal regression GAN for financial volatility trends (ORGAN-FVT) method for the end-to-end multi-classification task of FTS. An improved generative model based on convolutional long short-term memory (ConvLSTM) and multilayer perceptron (MLP) is proposed to capture temporal features effectively and mine the data distribution of volatility trends (short, neutral, and long) from given FTS data. Meanwhile, ordinal regression is leveraged for the discriminator to improve the multi-classification performance, making the model more practical. Finally, we empirically compare ORGAN-FVT with several state-of-the-art approaches on three real-world stock datasets: MICROSOFT(MSFT), Tesla(TSLA), and The People’s Insurance Company of China(PAICC). ORGAN-FVT demonstrated significantly better AUC and F1 scores, at most 20.81% higher than its competitors.",,Proquest
10.1109/BigDIA60676.2023.10429428,10.1109/BigDIA60676.2023.10429428,A Wavelet Based Method for Un-Stationary Complex System,"Conference Title: 2023 9th International Conference on Big Data and Information Analytics (BigDIA) Conference Start Date: 2023, Dec. 15 Conference End Date: 2023, Dec. 17 Conference Location: Haikou, China It is known that stock system is chaotic, nonlinear and un-stationary system. Stock market analysis system including deep learning method and generative models usually utilize historical datasets to get the stock market features to predict the future trend. The nonlinearity of the stock market system have determined that although the features can be acquired by deep learning and generative models, it consume considerable resources including labelled cost and computing. In order to analyze such system, researchers have proposed a novel wavelet based nonlinear model, along with the interpretable feature from nonlinear and unstationary series data. Wavelet based OLS method is able to get the features of nonlinear system in a relative low cost with the acceptable result accuracy decline. What’s more, it will give an interpretability analysis form the model analysis. To sum up, the Comprehensive performance shows that the predictive power of nonlinear wavelet models outperforms than other baseline methods."," Complex systems , Deep learning , Cost analysis , Big Data , Nonlinear systems , Deep learning , Chaos theory , Wavelet analysis , FINANCE , Nonlinearity , Economic;BERT;bitcoin;investor behavior;large language models;machine learning;return prediction;textual analysis",Proquest
10.3390/math11132883,10.3390/math11132883,"Price, Complexity, and Mathematical Model","The whole world has entered the era of the Vuca. Some traditional methods of problem analysis begin to fail. Complexity science is needed to study and solve problems from the perspective of complex systems. As a complex system full of volatility and uncertainty, price fluctuations have attracted wide attention from researchers. Therefore, through a literature review, this paper analyzes the research on complex theories on price prediction. The following conclusions are drawn: (1) The price forecast receives widespread attention year by year, and the number of published articles also shows a rapid rising trend. (2) The hybrid model can achieve higher prediction accuracy than the single model. (3) The complexity of models is increasing. In the future, the more complex methods will be applied to price forecast, including AI technologies such as LLM. (4) Crude-oil prices and stock prices will continue to be the focus of research, with carbon prices, gold prices, Bitcoin, and others becoming new research hotspots. The innovation of this research mainly includes the following three aspects: (1) The whole analysis of all the articles on price prediction using mathematical models in the past 10 years rather than the analysis of a single field such as oil price or stock price. (2) Classify the research methods of price forecasting in different fields, and found the common problems of price forecasting in different fields (including data processing methods and model selection, etc.), which provide references for different researchers to select price forecasting models. (3) Use VOSviewer to analyze the hot words appearing in recent years according to the timeline, find the research trend, and provide references for researchers to choose the future research direction.",,Proquest
10.7717/peerj-cs.1377,10.7717/peerj-cs.1377,Evaluation of transformer models for financial targeted sentiment analysis in Spanish,"Nowadays, financial data from social media plays an important role to predict the stock market. However, the exponential growth of financial information and the different polarities of sentiment that other sectors or stakeholders may have on the same information has led to the need for new technologies that automatically collect and classify large volumes of information quickly and easily for each stakeholder. In this scenario, we conduct a targeted sentiment analysis that can automatically extract the main economic target from financial texts and obtain the polarity of a text towards such main economic target, other companies and society in general. To this end, we have compiled a novel corpus of financial tweets and news headlines in Spanish, constituting a valuable resource for the Spanish-focused research community. In addition, we have carried out a performance comparison of different Spanish-specific large language models, with MarIA and BETO achieving the best results. Our best result has an overall performance of 76.04%, 74.16%, and 68.07% in macro F1-score for the sentiment classification towards the main economic target, society, and other companies, respectively, and an accuracy of 69.74% for target detection. We have also evaluated the performance of multi-label classification models in this context and obtained a performance of 71.13%.Nowadays, financial data from social media plays an important role to predict the stock market. However, the exponential growth of financial information and the different polarities of sentiment that other sectors or stakeholders may have on the same information has led to the need for new technologies that automatically collect and classify large volumes of information quickly and easily for each stakeholder. In this scenario, we conduct a targeted sentiment analysis that can automatically extract the main economic target from financial texts and obtain the polarity of a text towards such main economic target, other companies and society in general. To this end, we have compiled a novel corpus of financial tweets and news headlines in Spanish, constituting a valuable resource for the Spanish-focused research community. In addition, we have carried out a performance comparison of different Spanish-specific large language models, with MarIA and BETO achieving the best results. Our best result has an overall performance of 76.04%, 74.16%, and 68.07% in macro F1-score for the sentiment classification towards the main economic target, society, and other companies, respectively, and an accuracy of 69.74% for target detection. We have also evaluated the performance of multi-label classification models in this context and obtained a performance of 71.13%.",,Proquest
10.1007/s10994-022-06250-4,10.1007/s10994-022-06250-4,Lead–lag detection and network clustering for multivariate time series with an application to the US equity market,"In multivariate time series systems, it has been observed that certain groups of variables partially lead the evolution of the system, while other variables follow this evolution with a time delay; the result is a lead–lag structure amongst the time series variables. In this paper, we propose a method for the detection of lead–lag clusters of time series in multivariate systems. We demonstrate that the web of pairwise lead–lag relationships between time series can be helpfully construed as a directed network, for which there exist suitable algorithms for the detection of pairs of lead–lag clusters with high pairwise imbalance. Within our framework, we consider a number of choices for the pairwise lead–lag metric and directed network clustering model components. Our framework is validated on both a synthetic generative model for multivariate lead–lag time series systems and daily real-world US equity prices data. We showcase that our method is able to detect statistically significant lead–lag clusters in the US equity market. We study the nature of these clusters in the context of the empirical finance literature on lead–lag relations, and demonstrate how these can be used for the construction of predictive financial signals."," Algorithms , Time lag , Evolution , Lag time , Response time , Time series , Clustering , Time series , Multivariate analysis , United States--US;Deep learning;financial AI;financial technology;large language models;trading algorithms",Proquest
10.1016/j.knosys.2022.108712,10.1016/j.knosys.2022.108712,A self-regulated generative adversarial network for stock price movement prediction based on the historical price and tweets,"Stock price movement prediction is an important task of the financial prediction field. The current mainstream approaches usually apply financial texts and some corresponding stock price information to predict the stock price movement. However, the current methods usually suffer from two shortcomings: (1) To reduce the stochasticity in the stock price and financial text information, some researchers adopt generative models to better treat the stochasticity while enduring the overfitting problem during training. (2) Although the current state-of-the-art methods based on the generative adversarial network have been proposed to reduce the overfitting, they only concentrate on the overfitting problem of the stock price information and neglect the above problem of financial text information with higher stochasticity. In this paper, we propose a self-regulated generative adversarial network by combining the generative adversarial network and cooperative network for the stock price movement prediction. Furthermore, the proposed model can effectively reduce the stochasticity and overfitting problems simultaneously for the stock price and the financial text information. The experimental results on the currently commonly used stock dataset based on tweets confirm that the proposed method can achieve the novelly state-of-the-art performance compared with some current advances."," Generative adversarial networks , Stock prices , Stochastic models;Bayesian;analyst recommendations;machine learning;trading strategy",Proquest
10.1109/ICCWAMTIP56608.2022.10016580,10.1109/ICCWAMTIP56608.2022.10016580,Tabnet With Data Augmentation Apporach in Stock Return Prediction Task,"Conference Title: 2022 19th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP) Conference Start Date: 2022, Dec. 16 Conference End Date: 2022, Dec. 18 Conference Location: Chengdu, China Despite the advent of deep learning, stock return prediction task still has many challenges. Due to the scarcity of stock data, we adopt a GAN-based deep generative model to create synthetic data samples. To deal with the intrinsic low signal-to-noise ratio property of stock price time series, we formulate the return prediction as a supervised learning problem with tabular dataset, where we do feature engineering before training with a TabNet model. We conduct extensive experiments on real Chinese stock market with 6 different models, which proves that our proposed model makes larger profit and remains stability."," Data processing , Deep learning , Machine learning , Supervised learning , Signal to noise ratio , Data augmentation , Economic;multi-source heterogeneous data;retrieval augmented generation;SHAP;exchange rate prediction",Proquest
10.1007/s11042-021-11670-w,10.1007/s11042-021-11670-w,Generative adversarial network (GAN) and enhanced root mean square error (ERMSE): deep learning for stock price movement prediction,"The prediction of stock price movement direction is significant in financial circles and academic. Stock price contains complex, incomplete, and fuzzy information which makes it an extremely difficult task to predict its development trend. Predicting and analysing financial data is a nonlinear, time-dependent problem. With rapid development in machine learning and deep learning, this task can be performed more effectively by a purposely designed network. This paper aims to improve prediction accuracy and minimizing forecasting error loss through deep learning architecture by using Generative Adversarial Networks. It was proposed a generic model consisting of Phase-space Reconstruction (PSR) method for reconstructing price series and Generative Adversarial Network (GAN) which is a combination of two neural networks which are Long Short-Term Memory (LSTM) as Generative model and Convolutional Neural Network (CNN) as Discriminative model for adversarial training to forecast the stock market. LSTM will generate new instances based on historical basic indicators information and then CNN will estimate whether the data is predicted by LSTM or is real. It was found that the Generative Adversarial Network (GAN) has performed well on the enhanced root mean square error to LSTM, as it was 4.35% more accurate in predicting the direction and reduced processing time and RMSE by 78&#xa0;s and 0.029, respectively. This study provides a better result in the accuracy of the stock index. It seems that the proposed system concentrates on minimizing the root mean square error and processing time and improving the direction prediction accuracy, and provides a better result in the accuracy of the stock index."," Mean square errors , Time dependence , Accuracy , Deep learning , Mean square values , Root-mean-square errors , Artificial neural networks , Neural networks , Generative adversarial networks , Mathematical models , Deep learning , Economic forecasting , Machine learning;NLP;Deep Learning;Machine learning;Artifi-cial Intelligence;Network Security;Log Analysis;Macroeconomic Forecasting;LLM",Proquest
10.1109/LSP.2021.3135793,10.1109/LSP.2021.3135793,Learning Sentimental and Financial Signals With Normalizing Flows for Stock Movement Prediction,"Stockmovement prediction using Tweets (text) and historical price signals (time series) remains a challenging task due to the complex, noisy and dynamic nature of the stock market. The key to improve prediction performance is effectively capturing the complementarity between market sentiment signal from Tweets and time-series signal from the stock price. In this paper, we contribute a new solution StockNF by exploiting a deep generative model technique, Normalizing Flow (NF), to learn more flexible and expressive posterior distributions of latent variables of Tweets and price signals, which can largely ameliorate the bias inference problem in existing methods. We empirically evaluate the NF technique on a public stock movement prediction dataset and show that StockNF outperforms the state-of-the-art baselines.",,Proquest
10.1016/j.eswa.2020.114444,10.1016/j.eswa.2020.114444,Forecasting daily stock trend using multi-filter feature selection and deep learning,"Stock market forecasting has attracted significant attention mainly due to the potential monetary benefits. Predicting these markets is a challenging task due to numerous interrelated factors, and needs a complete and efficient feature selection process to identify the most informative factors. As a time series problem, stock price movements are also dependent on movements on its previous trading days. Feature selection techniques have been widely applied in stock forecasting, but existing approaches usually use a single feature selection technique, which may overlook some important assumptions about the underlying regression function linking the input and output variables. In this study, we combine features selected by multiple feature selection techniques to generate an optimal feature subset and then use a deep generative model to predict future price movements. First, we compute an extended set of forty-four technical indicators from daily stock data of eighty-eight stocks and then compute their importance by independently training logistic regression model, support vector machine and random forests. Based on a prespecified threshold, the lowest ranked features are dropped and the rest are grouped into clusters. The variable importance measure is reused to select the most important feature from each cluster to generate the final subset. The input is then fed to a deep generative model comprising of a market signal extractor and an attention mechanism. The market signal extractor recurrently decodes market movement from the latent variables to deal with stochastic nature of the stock data and the attention mechanism discriminates between predictive dependencies of different temporal auxiliary outputs. The results demonstrate that combining features selected by multiple feature selection approaches and using them as input into a deep generative model outperforms state-of-the-art approaches."," Feature selection , Economic forecasting , Support vector machines , Regression models , Deep learning;Bike–ebike allocation;generative models;long-term management;Markov decision process (MDP)",Proquest
10.1007/s41109-021-00357-8,10.1007/s41109-021-00357-8,On the challenges of predicting microscopic dynamics of online conversations,"To what extent can we predict the structure of online conversation trees? We present a generative model to predict the size and evolution of threaded conversations on social media by combining machine learning algorithms. The model is evaluated using datasets that span two topical domains (cryptocurrency and cyber-security) and two platforms (Reddit and Twitter). We show that it is able to predict both macroscopic features of the final trees and near-future microscopic events with moderate accuracy. However, predicting the macroscopic structure of conversations does not guarantee an accurate reconstruction of their microscopic evolution. Our model’s limited performance in long-range predictions highlights the challenges faced by generative models due to the accumulation of errors."," Algorithms , Evolution , Trees , Machine learning , Digital currencies , Digital media , Cybersecurity;Cryptocurrencies;price prediction;fraud detection;risk management;LSTM;GRU and Bi-LSTM",Proquest
10.1109/ICNSC52481.2021.9702208,10.1109/ICNSC52481.2021.9702208,Stock Price Prediction Based on Conditional Flows Scenario Generation,"Conference Title: 2021 IEEE International Conference on Networking, Sensing and Control (ICNSC) Conference Start Date: 2021, Dec. 3 Conference End Date: 2021, Dec. 5 Conference Location: Xiamen, China Stock price forecasting is an important issue in the financial field. However, most of the existing studies were focused on the prediction of a single stock, ignoring the correlation among different assets. A possible way to solve the above problem is to provide a set of scenarios which include the future returns of several stocks, instead of a single one. The flow-based model is a kind of deep learning model proposed in recent years, which has powerful data generation abilities. In this paper, we use a flow-based conditional generative model to forecast the stock price scenario. We use real stock market data to verify the proposed method. The simulation results show that the model based on the proposed method can capture the complex dependence of the future stock relationship and provide more accurate and diversified forecasting results."," Mathematical models , Economic forecasting , Scenario generation , Economic;Automatic calibration;deep Q-learning;parameter estimation;reinforcement learning (RL)",Proquest
10.1109/SMC52423.2021.9659283,10.1109/SMC52423.2021.9659283,Stock Price Prediction Using Sentiment Analysis,"Conference Title: 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC) Conference Start Date: 2021, Oct. 17 Conference End Date: 2021, Oct. 20 Conference Location: Melbourne, Australia We investigate the influence of financial news headline sentiment on the predictability of stock prices using Long Term Short Term Memory (LSTM) networks. The investigation is performed on intraday data with specific lag-times between published article headlines and realised stock prices. FinBERT, a natural language processing model which is fine-tuned specifically for financial news is used to perform sentiment analysis on the company related news headlines. Two base models, one with only historical stock price data as inputs and the other with both historical stock price data and sentiment data from the original BERT model is tested. An alternative model with have both historical stock price data and sentiment data from the fine tuned FinBERT model as additional features. A comparison is performed on both the base and alternative models using Root Mean Square Error (RMSE) and mean absolute error (MAE) as performance metrics. The results suggest that the use of news headline sentiment features from FinBERT significantly improve the predictive performance of LSTM networks in intraday stock price prediction. FinBERT features are also found to outperform features based BERT model trained on a general corpus, illustrating the positive effect of domain specific fine tuning for Large Language models.",,Proquest
10.1109/CAIDA51941.2021.9425223,10.1109/CAIDA51941.2021.9425223,A Methodology for Securities and Cryptocurrency Trading Using Exploratory Data Analysis and Artificial Intelligence,"Conference Title: 2021 1st International Conference on Artificial Intelligence and Data Analytics (CAIDA) Conference Start Date: 2021, April 6 Conference End Date: 2021, April 7 Conference Location: Riyadh, Saudi Arabia This paper discusses securities and cryptocurrency trading using artificial intelligence (AI) in the sense that it focuses on performing Exploratory Data Analysis (EDA) on selected technical indicators before proceeding to modelling, and then to develop more practical models by introducing new reward loss function that maximizes the returns during training phase. The results of EDA reveal that the complex patterns within the data can be better captured by discriminative classification models and this was endorsed by performing back-testing on two securities using Artificial Neural Network (ANN) and Random Forests (RF) as discriminative models against their counterpart Naïve Bayes as a generative model. To enhance the learning process, the new reward loss function is utilized to retrain the ANN with testing on AAPL, IBM, BRENT CRUDE and BTC using auto-trading strategy that serves as the intelligent unit, and the results indicate this loss superiorly outperforms the conventional cross-entropy used in predictive models. The overall results of this work suggest that there should be larger focus on EDA and more practical losses in the research of machine learning modelling for stock market prediction applications."," ECONOMICS , Data analysis , Learning theory , SUSTAINABILITY , Machine learning , Artificial intelligence , Prediction models , Digital currencies , Modelling , Artificial neural networks , SUSTAINABILITY , SUSTAINABILITY , SUSTAINABILITY , Economic;GPT-2(Generative Pre-Trained Transformer) Model;Cut-off Mark Prediction;Natural Language Processing;Regression;Artificial Intelligence Chatbot;Stakeholders;User-friendly Experience",Proquest
10.1016/j.eneco.2019.104624,10.1016/j.eneco.2019.104624,Geopolitical risk uncertainty and oil future volatility: Evidence from MIDAS models,"Using a textual analysis based geopolitical risk (GPR) index, this paper exploits the effects of geopolitical risk uncertainty on oil futures price volatility within a mixed data sampling (MIDAS) modeling framework. With a variety of MIDAS specifications, our in-sample estimation results suggest that the short-term (e.g. one-day-ahead) oil realized volatility is positively associated with GPR uncertainty, and our out-of-sample forecasting exercise indicates that the GPR index is useful for improving short-term oil futures volatility prediction. In addition, we find that the categorical GPR index: GPR action related index (GPA), contributes more to the long-term oil volatility forecasting, compared with GPR threat related index (GPT)."," Indexes , Uncertainty , Petroleum , Sampling , SUSTAINABILITY , Textual analysis , Data sampling , Volatility , International relations , Petroleum , Mathematical models , Estimation , Short term , Risk , Sampling , Uncertainty , Geopolitics , Oil , Forecasting , SUSTAINABILITY , ECONOMICS , Predictions , Uncertainty , Economic;Sentiment Analysis;Financial News;NLP;LLM;Fine-tuning;gemma-7b",Proquest
10.1109/SSCI47803.2020.9308192,10.1109/SSCI47803.2020.9308192,Probabilistic Analysis of Market Impact of Analysts’ Recommendation Revisions,"Conference Title: 2020 IEEE Symposium Series on Computational Intelligence (SSCI) Conference Start Date: 2020, Dec. 1 Conference End Date: 2020, Dec. 4 Conference Location: Canberra, Australia In this paper, we propose to model the short-term impact of recommendation revisions on stock price movements in probabilistic framework. Through the Bayesian models, we can consolidate the information of all analysts’ recommendations on stocks and predict the post-recommendation price drifts of the underlying stocks. In addition, typically there are only a small number of recommendation revisions on specific stocks on each day. It implies that other analysts’ views to a specific stock are unobservable. With the advantage of generative models, missing observations in the data of recommendation revisions can be accommodated easily. Secondly, we perform an empirical investigation of the Hong Kong equity market and find that the impact of recommendation revisions on stock prices is significant in the 1-day horizon, but insignificant in the longer time horizon when taking account of the transaction costs. Also, we propose trading strategies derived from the posterior probability of directions of price drifts based on the Bayesian models. In our experiment, during the out-of-sample period (1 Jan, 2019 to 21 Feb, 2020), the trading strategies gain double-digit profit returns after transaction costs."," FINANCE , Impact analysis , Conditional probability , Bayesian analysis , Empirical analysis , Probabilistic analysis , Revisions , Artificial intelligence , Statistical analysis , Pricing , Economic;Price Oracle;Blockchain Technology;LLM;AI Agent;RWA",Proquest
10.1587/transinf.2016IIP0016,10.1587/transinf.2016IIP0016,Stock Price Prediction by Deep Neural Generative Model of News Articles,"In this study, we propose a deep neural generative model for predicting daily stock price movements given news articles. Approaches involving conventional technical analysis have been investigated to identify certain patterns in past price movements, which in turn helps to predict future price movements. However, the financial market is highly sensitive to specific events, including corporate buyouts, product releases, and the like. Therefore, recent research has focused on modeling relationships between these events that appear in the news articles and future price movements; however, a very large number of news articles are published daily, each article containing rich information, which results in overfitting to past price movements used for parameter adjustment. Given the above, we propose a model based on a generative model of news articles that includes price movement as a condition, thereby avoiding excessive overfitting thanks to the nature of the generative model. We evaluate our proposed model using historical price movements of Nikkei 225 and Standard &amp; Poor's 500 Stock Index, confirming that our model predicts future price movements better than such conventional classifiers as support vector machines and multilayer perceptrons. Further, our proposed model extracts significant words from news articles that are directly related to future stock price movements."," News , Mathematical models , Support vector machines , Predictions , Multilayer perceptrons , Finished goods , Stock market indexes;Financial Sentiment Analysis;Chinese Social Media;Stock Forecast",Proquest
0090-5364,,Estimating time-changes in noisy Lévy models,"In quantitative finance, we often model asset prices as a noisy Ito semimartingale. As this model is not identifiable, approximating by a time-changed Levy process can be useful for generative modelling. We give a new estimate of the normalised volatility or time change in this model, which obtains minimax convergence rates, and is unaffected by infinite-variation jumps. In the semimartingale model, our estimate remains accurate for the normalised volatility, obtaining convergence rates as good as any previously implied in the literature."," Probability distribution , SUSTAINABILITY , Estimating techniques , Studies , FINANCE , SUSTAINABILITY , Approximation;Stock Portfolio Management;Reinforcement Learning;Incremental Learning;Multimodality",Proquest
10.1162/NECO_a_00007,10.1162/NECO_a_00007,Bayesian Online Learning of the Hazard Rate in Change-Point Problems,"Change-point models are generative models of time-varying data in which the underlying generative parameters undergo discontinuous changes at different points in time known as change points. Change-points often represent important events in the underlying processes, like a change in brain state reflected in EEG data or a change in the value of a company reflected in its stock price. However, change-points can be difficult to identify in noisy data streams. Previous attempts to identify change-points online using Bayesian inference relied on specifying in advance the rate at which they occur, called the hazard rate (h). This approach leads to predictions that can depend strongly on the choice of h and is unable to deal optimally with systems in which h is not constant in time. In this letter, we overcome these limitations by developing a hierarchical extension to earlier models. This approach allows h itself to be inferred from the data, which in turn helps to identify when change-points occur. We show that our approach can effectively identify change-points in both toy and real data sets with complex hazard rates and how it can be used as an ideal-observer model for human and animal behavior when faced with rapidly changing inputs."," Learning , Mathematical models , Data processing , Bayesian analysis , Brain , EEG , Internet , Models;Deep Reinforcement Learning;Portfolio Optimization;Sentiment Analysis;Fundamental Indicators;Large Language Model;Brazilian Financial Market",Proquest
10.1162/NECO_a_00007,10.1162/NECO_a_00007,Bayesian online learning of the hazard rate in change-point problems,"Change-point models are generative models of time-varying data in which the underlying generative parameters undergo discontinuous changes at different points in time known as change points. Change-points often represent important events in the underlying processes, like a change in brain state reflected in EEG data or a change in the value of a company reflected in its stock price. However, change-points can be difficult to identify in noisy data streams. Previous attempts to identify change-points online using Bayesian inference relied on specifying in advance the rate at which they occur, called the hazard rate (h). This approach leads to predictions that can depend strongly on the choice of h and is unable to deal optimally with systems in which h is not constant in time. In this letter, we overcome these limitations by developing a hierarchical extension to earlier models. This approach allows h itself to be inferred from the data, which in turn helps to identify when change-points occur. We show that our approach can effectively identify change-points in both toy and real data sets with complex hazard rates and how it can be used as an ideal-observer model for human and animal behavior when faced with rapidly changing inputs.Change-point models are generative models of time-varying data in which the underlying generative parameters undergo discontinuous changes at different points in time known as change points. Change-points often represent important events in the underlying processes, like a change in brain state reflected in EEG data or a change in the value of a company reflected in its stock price. However, change-points can be difficult to identify in noisy data streams. Previous attempts to identify change-points online using Bayesian inference relied on specifying in advance the rate at which they occur, called the hazard rate (h). This approach leads to predictions that can depend strongly on the choice of h and is unable to deal optimally with systems in which h is not constant in time. In this letter, we overcome these limitations by developing a hierarchical extension to earlier models. This approach allows h itself to be inferred from the data, which in turn helps to identify when change-points occur. We show that our approach can effectively identify change-points in both toy and real data sets with complex hazard rates and how it can be used as an ideal-observer model for human and animal behavior when faced with rapidly changing inputs.", Index Medicus;Gamification;Machine learning;Simulation;Financial literacy,Proquest
0899-7667,,Bayesian Online Learning of the Hazard Rate in Change-Point Problems,"Change-point models are generative models of time-varying data in which the underlying generative parameters undergo discontinuous changes at different points in time known as change points. Change-points often represent important events in the underlying processes, like a change in brain state reflected in EEG data or a change in the value of a company reflected in its stock price. However, change-points can be difficult to identify in noisy data streams. Previous attempts to identify change-points online using Bayesian inference relied on specifying in advance the rate at which they occur, called the hazard rate (h). This approach leads to predictions that can depend strongly on the choice of h and is unable to deal optimally with systems in which h is not constant in time. In this letter, we overcome these limitations by developing a hierarchical extension to earlier models. This approach allows h itself to be inferred from the data, which in turn helps to identify when change-points occur. We show that our approach can effectively identify change-points in both toy and real data sets with complex hazard rates and how it can be used as an ideal-observer model for human and animal behavior when faced with rapidly changing inputs. [PUBLICATION ABSTRACT]"," Bayesian analysis , Online instruction , Distance learning , Brain , Information processing , Electroencephalography;Moore's law;From Bits to Architectures and Applications;Energy per Instruction;Energy per Bit;Instructions per Second;Specialized Architectures;Energy for Machine Learning and Artificial Intelligence;Natural Language Processing;ChatGPT;Energy for High Performance Scientific Computations;Energy for Crypto coin mining;Bitcoin;Thermodynamical Limit;Biological Limit;ATP;Sustainable Computing;Energy as a design parameter",Proquest
10.1108/02686900610705037,10.1108/02686900610705037,The stock market reaction to Ernst & Young's sale of its consulting unit to Cap Gemini,"Purpose - The purpose of this paper is to investigate how the stock prices of Ernst & Young's (E&Y's) audit clients reacted to the sale of the accounting firm's consulting unit to Cap Gemini. The study is motivated by the debate on how the provision of non-audit services by auditors affects investor perceptions of auditor independence. Design/methodology/approach - This paper uses the event study approach and examines market model prediction errors around relevant dates. Findings - E&Y client firms' mean and median abnormal stock returns are significantly positive for two events, the approval of the sale by E&Y's partners, and the approval of the transaction by Cap Gemini stockholders. Research limitations/implications - This study is limited to one major audit firm for reasons discussed in the paper. Originality/value - This study offers evidence on investor perceptions of auditor independence without relying on an earnings management model as is common in the literature. This study's evidence suggests that investors view the separation of auditing and consulting favorably."," Raw materials , Consulting , Mathematical models , Sales , Perception , Marketing , Clients , Accounting , Error analysis , Management , Separation , Methodology;Blockchain;digital twins;generative artificial intelligence (AI);information system;macroeconomic disruptions;quantum computing;risk management;supply chain;TEM forum;technology management",Proquest
10.1108/02686900610705037,10.1108/02686900610705037,The stock market reaction to Ernst & Young's sale of its consulting unit to Cap Gemini,"Purpose - The purpose of this paper is to investigate how the stock prices of Ernst & Young's (E&Y's) audit clients reacted to the sale of the accounting firm's consulting unit to Cap Gemini. The study is motivated by the debate on how the provision of non-audit services by auditors affects investor perceptions of auditor independence. Design/methodology/approach - This paper uses the event study approach and examines market model prediction errors around relevant dates. Findings - E&Y client firms' mean and median abnormal stock returns are significantly positive for two events, the approval of the sale by E&Y's partners, and the approval of the transaction by Cap Gemini stockholders. Research limitations/implications - This study is limited to one major audit firm for reasons discussed in the paper. Originality/value - This study offers evidence on investor perceptions of auditor independence without relying on an earnings management model as is common in the literature. This study's evidence suggests that investors view the separation of auditing and consulting favorably."," Raw materials , Consulting , Mathematical models , Sales , Marketing , Clients , Accounting , Error analysis , Management , Separation;Self-Evolving Programs;Language Model-based Methods;Quine Programs;Dynamic Code Optimization;Selfish Mining Defense",Proquest
