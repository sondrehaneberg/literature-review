ID;Title;Reference;Reviewer;Include?;File;Input enhancement?;Prediction engine?;Multi-agent?;News Sentiment;Social Media Sentiment;Corporate Communication Sentiment;Input Enhancement Beyond Sentiment;Type Prediction Engine;Survey?;Instrument;DOI;Link;Results;Model(s);Financial Instrument
10.18653/v1/2023.emnlp-industry.69;Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting;\textcite{yu_chen_lu_2023};Olav;Yes;Literature%20Database/2023.emnlp-industry.69.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input, Financial Text Input, Multimodal Input;‚ùå;Stocks;10.18653/v1/2023.emnlp-industry.69;https://doi.org/10.18653/v1/2023.emnlp-industry.69;"Yu et al. (2023) investigated stock return prediction for the NASDAQ-100 using GPT-4 and Open LLaMA.
Their results show that both GPT-4 and Open LLaMA outperformed traditional models such as ARMA-GARCH
and gradient boosting trees, particularly when incorporating step-by-step reasoning through the COT approach.
Regarding predictive accuracy, the Mean Squared Error (MSE) for GPT-4 Few-Shot w/ COT and Open LLaMA
(13B) Fine-Tuned w/ COT was 50.5% and 63.5%, respectively, compared to 90.1% for the ARMA-GARCH
model in monthly predictions. Furthermore, the models generated textual explanations for their predictions,
evaluated using ROUGE-1 and ROUGE-2 scores. GPT-4 Few-Shot with COT achieved the highest scores, while
Open LLaMA, after COT fine-tuning, also demonstrated strong explanatory performance comparable to GPT-4
without COT.";GPT-4, Open LLaMA 13B;Stock
10.1007/s43546-021-00106-0;Construction of a news article evaluation model utilizing high-frequency data and a large-scale language generation model;;Sondre;Tja;Literature%20Database/s43546-021-00106-0.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1007/s43546-021-00106-0;https://doi.org/10.1007/s43546-021-00106-0;The study by Nish et al. (2021) developed a deep learning-based classification model combining LSTM, BiLSTM and RoBERTa. Incorporating ChatGPT-2 generated news significantly improved both accuracy and AUC scores in predicting stock direction.;GPT-2;Stock
10.1007/978-3-030-58790-1_7;News Articles Evaluation Analysis in Automotive Industry Using GPT-2 and Co-occurrence Network;;Sondre;Tja;Literature%20Database/978-3-030-58790-1.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1007/978-3-030-58790-1_7;https://doi.org/10.1007/978-3-030-58790-1_7;Nishi, Suge, and Takahashi (2020) develop an LSTM-based model enhanced with GPT-2-generated financial news to evaluate how news impacts short-term stock price movements in the Japanese automotive industry. Their results show that incorporating synthetic news improves classification accuracy compared to a baseline model trained solely on authentic Reuters articles. (Builds on earlier paper);GPT-2;Stock
10.1109/ICCA62237.2024.10927897;Assessing the Correlation Between News Sentiment and Stock Price Movements: A Case Study of 'WeWork' Using Advanced NLP Techniques;\textcite{alnahyan_shuhaiber_2024};Sondre;Yes;Literature%20Database/Assessing_the_Correlation_Between_News_Sentiment_and_Stock_Price_Movements__A_Case_Study_of_x2018WeWorkx2019_Using_Advanced_NLP_Techniques.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stocks;10.1109/icca62237.2024.10927897;https://doi.org/10.1109/icca62237.2024.10927897;Al Nahyan and Shuhaiber (2024) examine the relationship between news sentiment and stock price movements for WeWork using advanced NLP methods and OpenAI‚Äôs large language models. By correlating sentiment scores derived from Refinitiv news articles with historical stock data, they find a weak positive correlation (16.47%), suggesting that sentiment analysis offers useful but insufficient predictive power when used alone for financial forecasting.;ChatGPT;Stock
2-s2.0-85195171155;Modal-adaptive Knowledge-enhanced Graph-based Financial Prediction from Monetary Policy Conference Calls with LLM;;Olav;Tja;Literature%20Database/Modal-adaptive_Knowledge-enhanced_Graph-based_Financial_Prediction_from_Monetary_Policy_Conference_Calls_with_LLM.pdf;‚úîÔ∏è;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Multiple assets;;https://doi.org/10.48550/arXiv.2403.16055;"Tja usikker. 
BERT/ andre Encoders brukes for √• lese, forst√• og strukturere informasjon (som tekst, lyd og video)
LLM brukes for √• predicte.

Zhang et al. (2025) investigate financial forecasting from Monetary Policy Conference (MPC) calls by integrating textual, visual, and audio modalities through a multimodal, knowledge-enhanced framework named MANAGER. The model combines external financial knowledge (FinDKG), modality-specific encoders (BEiT-3 for video, HuBERT for audio, and text embeddings), and a knowledge-enhanced graph network with ChatGLM2 serving as the large language model backbone. This architecture enables the model to jointly capture semantic, tonal, and visual cues from MPC meetings while leveraging financial context.
Compared to traditional deep learning baselines such as LSTM, GRU, and multimodal transformers without LLM integration, MANAGER achieves significantly improved performance in both price movement and volatility prediction tasks. Specifically, the model attains the highest F1-scores for directional prediction (‚âà0.67‚Äì0.70) and the lowest Mean Squared Error (‚âà0.033‚Äì0.035) for volatility estimation, outperforming all ablated versions. These results highlight that incorporating an LLM (ChatGLM2) with external knowledge and multimodal reasoning substantially enhances predictive accuracy and interpretability, as the model can also generate coherent textual explanations for its forecasts.";;
10.2478/mmcks-2024-0008;Emoji driven crypto assets market reactions;;Sander;Tja;Literature%20Database/Emoji_driven_crypto_assets_market_reactions.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Cryptocurrencies;10.2478/mmcks-2024-0008;https://doi.org/10.2478/mmcks-2024-0008;Tenker nei, virker som GPT brukes til √• konvertere emojis til tekst, s√• brukes BERT derfra;;
10.1109/ICADEIS65852.2025.10933431;The Effect of News Sentiment on Jakarta Composite Index Prediction Using Support Vector Regression Method;\textcite{dwiyanti_aquarini_gunawan_2025};Sander;Yes;Literature%20Database/The_Effect_of_News_Sentiment_on_Jakarta_Composite_Index_Prediction_Using_Support_Vector_Regression_Method.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stock index (JCI);10.1109/icadeis65852.2025.10933431;https://doi.org/10.1109/icadeis65852.2025.10933431;;ChatGPT;Index
10.14569/IJACSA.2025.0160402;Comparing Vision-Instruct LLMs, Vision-Based Deep Learning, and Numeric Models for Stock Movement Prediction;\textcite{chen_2025};Olav;Yes;Literature%20Database/Comparing_Vision-Instruct_LLMs_Vision-Based_Deep_Learning_and_Numeric_Models_for_Stock_Movement_Prediction.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Image Input;‚ùå;Stock;10.14569/ijacsa.2025.0160402;https://doi.org/10.14569/ijacsa.2025.0160402;"Tja tenker det.

The study investigates a prompt-based Large Language Model (LLM) framework designed to analyze candlestick charts, comparing its performance with image-based models such as MobileNetV2, Vision Transformer, and Convolutional Neural Network (CNN), as well as numerical models including Support Vector Machine (SVM), Random Forest, LSTM, and CNN-LSTM. While LLMs have shown promising potential in stock price prediction, their direct application to visual data poses challenges compared to traditional numerical methods. To address this, the study employs post-hoc calibration techniques such as Platt Scaling to enhance prediction reliability and mitigate bias. The results demonstrate that calibration significantly improves performance ‚Äî for instance, the LLaMA model‚Äôs accuracy increases from 0.70 to 0.86 after calibration. Overall, the findings indicate that LLMs like LLaMA and Qwen can effectively predict stock price movements using candlestick charts when properly calibrated, making them competitive with established financial forecasting models.";LLaMA-3.2-11B, Qwen-2-7B;Stock
10.1109/ICDMW65004.2024.00021;Sentiment Score of Bloomberg Market Wraps with ChatGPT;\textcite{lefort_benhamou_ohana_guez_saltiel_2024};Sondre;Yes;Literature%20Database/Sentiment_Score_of_Bloomberg_Market_Wraps_with_ChatGPT.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Equity index;10.1109/icdmw65004.2024.00021;https://doi.org/10.1109/icdmw65004.2024.00021;Lefort et al. (2024) propose a two-step ChatGPT-based framework for sentiment analysis of Bloomberg Market Wraps to assess how global financial news impacts stock market movements. Their detrended cumulative sentiment score outperforms a passive NASDAQ benchmark with a 57.7% higher Sharpe ratio, 53.9% higher Sortino ratio, and 76.4% higher Calmar ratio, demonstrating ChatGPT‚Äôs potential for zero-shot financial forecasting. (Uses LLM sentiment exclusively as investment strategy);GPT-3.5-Turbo;Index
10.18653/v1/2024.emnlp-industry.77;Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow;\textcite{guo_hauptmann_2024};Sondre;Yes;Literature%20Database/2024.emnlp-industry.77.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Text Input;‚ùå;Stocks;10.18653/v1/2024.emnlp-industry.77;https://doi.org/10.18653/v1/2024.emnlp-industry.77;Guo and Hauptmann (2024) fine-tune large language models such as DeBERTa, Mistral, and LLaMA3 to directly predict stock returns from financial news, replacing conventional sentiment extraction methods. Their results show that LLM-based return predictions significantly outperform sentiment-based baselines (FinBERT and FinVADER), with models like LLaMA3 and Mistral achieving the highest portfolio Sharpe ratios (up to 1.49) in both long-only and long-short strategies. (LLM sentiment as investment strategy);LLama-3-8B, Mistral-7B;Stock
10.1016/j.frl.2025.107472;Decoding risk sentiment in 10-K filings: Predictability for U.S. stock indices;\textcite{manella_2025};Olav;Yes;Literature%20Database/Decoding_risk_sentiment_in_10-K_filings-_Predictability_for_U.S._stock_indices.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;TRUE;;;‚ùå;Stock index;10.1016/j.frl.2025.107472;https://doi.org/10.1016/j.frl.2025.107472;The study examines whether the language used in the risk factors section of 10-K filings by U.S.-listed firms contains predictive information about future market movements, specifically the one-week-ahead returns of major stock indices such as the S&P 500, Nasdaq, Russell 2000, and Dow Jones. To quantify sentiment, the researchers applied the traditional LM dictionary and constructed four additional tone indicators based on AI-generated lexicons developed using ChatGPT. The AI-calibrated approaches, particularly those using GPT-4 and GPT-4o-mini, delivered superior predictive accuracy compared to conventional dictionary-based methods in both in-sample and out-of-sample evaluations. Moreover, results show that sentiment has a stronger impact on the S&P 500 than on the Dow Jones, suggesting that the sensitivity of market segments to linguistic tone varies across indices.;GPT-3.5, GPT-4, GPT-4o, GPT-4o-mini;Index
10.1016/j.frl.2024.105227;Sentiment trading with large language models;\textcite{kirtac_germano_2024};Sander;Yes;Literature%20Database/S1544612324002575.html;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stocks;10.1016/j.frl.2024.105227;https://doi.org/10.1016/j.frl.2024.105227;;OPT;Stock
10.1109/DOCS63458.2024.10704454;Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach;;Olav;No;Literature%20Database/Harnessing_Earnings_Reports_for_Stock_Predictions-_A_QLoRA-Enhanced_LLM_Approach.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Stocks;10.1109/docs63458.2024.10704454;https://doi.org/10.1109/docs63458.2024.10704454;The study presents an enhanced approach to stock market prediction by utilizing instruction-based fine-tuning LLMs to improve contextual understanding while using Quantized Low-Rank Adaptation (QLoRA) to optimize computational efficiency without compromising model accuracy. By integrating both base factors (such as financial metric growth and earnings call transcripts) and external factors (including recent market indices, stock performance, and analyst ratings), the researchers created a comprehensive dataset capturing the multifaceted dynamics of financial data. Among the evaluated models, the Llama-3-8B-Instruct-4bit‚Äîa highly optimized, instruction-oriented LLM‚Äîachieved the strongest overall performance on the Full dataset, outperforming GPT-4 by 16% in accuracy and 10% in weighted F1 score.;GPT-4, LLaMA 3;Stock
10.1109/IKT65497.2024.10892779;LLM-Driven Feature Extraction for Stock Market Prediction: A case study of Tehran Stock Exchange;\textcite{hosseinpour_haratizadeh_2024};Sander;Yes;Literature%20Database/LLM-Driven_Feature_Extraction_for_Stock_Market_Prediction_A_Case_Study_of_Tehran_Stock_Exchange.pdf;‚úîÔ∏è;‚ùå;‚ùå;;TRUE;;;;‚ùå;Stocks;10.1109/ikt65497.2024.10892779;https://doi.org/10.1109/ikt65497.2024.10892779;;GPT Text-Embedding 3 Small, LLaMA 3;Stock
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11009071;Leveraging Automatically Optimized Forecasters and Large Language Model for Predicting Vietnamese Rice Export Price;;Sondre;No;Literature%20Database/Leveraging_Automatically_Optimized_Forecasters_and_Large_Language_Model_for_Predicting_Vietnamese_Rice_Export_Price.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Export Price Vietnam Rice;10.1109/rivf64335.2024.11009071;https://doi.org/10.1109/rivf64335.2024.11009071;"Phan et al., 2024 combines macroeconomic indicators with GPT-4-based news sentiment analysis to forecast Vietnam‚Äôs rice export price using machine learning models such as CatBoost.
It is excluded from this analysis since it focuses on predicting a macroeconomic variable (export price) rather than firm-level or stock market movements.";GPT-4;Macroeconomic number
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181526;CryptexLLM: How LLM Generalizability Forecasts High Volatility;\textcite{tran_et_al_2025};Olav;Yes;Literature%20Database/CryptexLLM-_How_LLM_Generalizability_Forecasts_High_Volatility_.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input, Financial Text Input, Multimodal Input;‚ùå;Cryptocurrency (Bitcoin);10.1109/escience65000.2025.00071;https://doi.org/10.1109/escience65000.2025.00071;"Kort Conference Paper som ikke kommer med noen tydelige svar resultater av hvor mye bedre de ulike LLM-ene leverer, emn er tydelig p√• at det gir gode resultater og at LLaMA 3.1 gir best.

The authors introduce CryptexLLM, a framework designed to adapt LLMs for time series forecasting in highly volatile environments. Building on the TimeLLM architecture, the model incorporates feature engineering, sentiment integration, and an adaptive weighted loss function to better capture complex market dynamics. Through experiments on Bitcoin price prediction, the study demonstrates that CryptexLLM consistently outperforms conventional deep learning and statistical baselines such as LSTM, with LLaMA 3.1 achieving the highest overall predictive performance.";DeepSeek R1 7B, Gemma 3, LLaMA 3.1 8B, LLaMA 7B, Mistral-7B, Qwen 3;Cryptocurrency
10.1016/j.knosys.2025.114449;Enhancing large language models for bitcoin time series forecasting;\textcite{chaffard_molla_cavazza_prendinger_2025};Sondre;Yes;Literature%20Database/Enhancing_large_language_models_for_bitcoin_time_series_forecasting.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input;‚ùå;Cryptocurrency (Bitcoin);10.1016/j.knosys.2025.114449;https://doi.org/10.1016/j.knosys.2025.114449;This article by Chaffard et al. (2025) presents an improved Time-LLM model for forecasting Bitcoin prices, adapting large language models for complex, non-stationary financial time series. The authors introduce structural modifications, including an inverted embedding method and PCA-based dimensionality reduction, and propose fractional differencing to handle non-stationarity. Their enhanced model achieves a 50 % improvement in SMAPE and 5 % higher directional accuracy compared to state-of-the-art baselines such as Time-LLM, GPT4TS, and PatchTST. The study concludes that reprogrammed LLMs can effectively model financial time series lacking clear seasonality while maintaining computational efficiency.;GPT-2, LLaMA-2-7B, LLaMA2-13B;Cryptocurrency
WOS:001540598500049;LLM-Driven Stock Prediction: Capturing Market Trends with LLaMA;\textcite{tak_pele_2025};Olav;Yes;Literature%20Database/LLM-Driven_Stock_Prediction-_Capturing_Market_Trends_with_LLaMA.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input, Financial Text Input, Multimodal Input;‚ùå;Stocks;10.2478/picbe-2025-0043;https://doi.org/10.2478/picbe-2025-0043;Li et al. (2025) compares LLaMA 3.3 with LLaMA 3.1 and the ARIMA benchmark to evaluate their ability to model both temporal and textual dependencies in financial data. Results show that the zero-shot, news-aware LLaMA 3.3 70B Instruct model consistently outperforms ARIMA across all assets, while the multi-shot LLaMA 3.1 8B variant achieves superior results in most cases. The authors highlight that instruction-tuned LLMs specifically trained on time series data, or integrated with embeddings from specialized time series models, could further enhance predictive accuracy.;LLaMA 3.1 8B, LLaMA 3.3 70B;Cryptocurrency, Index, Stock
10.1016/j.econlet.2025.112404;Predicting stock price trends using language models to extract the sentiment from analyst reports: Evidence from IBEX 35-listed companies;;Sander;No;Literature%20Database/1-s2.0-S0165176525002411-main.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Text Input;‚ùå;Stock;10.1016/j.econlet.2025.112404;https://doi.org/10.1016/j.econlet.2025.112404;;GPT-4;Stock
WOS:001551945700001;Toward profitable energy futures trading strategies using reinforcement learning incorporating disagreement and connectedness methods enabled by large language models;;Olav;Tja;Literature%20Database/Toward_profitable_energy_futures_trading_strategies_using_reinforcement_learning_incorporating_disagreement_and_connectedness_methods_enabled_by_large_language_models-compressed.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Crude oil futures;10.1016/j.egyai.2025.100562;https://doi.org/10.1016/j.egyai.2025.100562;"Portef√∏ljeoptimalisering

LLMs are used in this study as signal extractors, not as trading agents. They classify and interpret financial news and social media text to generate sentiment and disagreement indicators, which are then combined with market connectedness metrics and price features. These enriched signals serve as inputs to a reinforcement learning (RL) framework that optimizes trading decisions for WTI crude oil futures.
Thus, the approach constitutes a form of portfolio optimization through reinforcement learning, where the RL agent dynamically adjusts its position (buy, hold, sell) to maximize portfolio returns and risk-adjusted performance rather than solving a static mean‚Äìvariance problem.";;
10.3389/frai.2025.1608365;Large Language Models in equity markets: applications, techniques, and insights;;Olav;No;Literature%20Database/Large_Language_Models_in_equity_markets-_applications_techniques_and_insights.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;?;10.3389/frai.2025.1608365;https://doi.org/10.3389/frai.2025.1608365;The article is a systematic review of 84 research studies published between 2022 and 2025, examining how large language models (LLMs) are applied within equity and capital markets.;;
10.1007/978-981-96-7178-6_2;Stock Trend Prediction Based on Complex Network and Sentiment Analysis;\textcite{wang_he_2025};Sondre;Yes;Literature%20Database/978-981-96-7178-6.pdf;‚úîÔ∏è;‚ùå;‚ùå;;TRUE;;;;‚ùå;Stock;10.1007/978-981-96-7178-6_2;https://doi.org/10.1007/978-981-96-7178-6_2;Wang and He (2025) develop a model to predict, on a monthly basis, the direction of stock movements in China‚Äôs semiconductor industry chain market. First, they construct a complex network of the industry based on correlations in stock returns to identify structural connections in the industry chain market. Then, they use a GPT model in combination with a KNN classifier to analyze investor comments and generate a sentiment score. Both the network features and sentiment score are fed into an LSTM model that predicts whether the stock prices will rise or not. The GPT-KNN method achieves an accuracy of 77.59%, outperforming the comparison algorithm.;GPT;Stock
10.1145/3652037.3652076;Stock Price Trend Prediction using Emotion Analysis of Financial Headlines with Distilled LLM Model;;Olav;Tja;Literature%20Database/Stock_Price_Trend_Prediction_using_Emotion_Analysis_of_Financial_Headlines_with_Distilled_LLM_Model.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1145/3652037.3652076;https://doi.org/10.1145/3652037.3652076;"Bruker BERT (DistilRoBERTa - Distilled LLM)

Distilled models are lightweight versions of large LLMs

The paper explores whether emotion analysis of financial news headlines alone can be used to predict stock price direction ‚Äî specifically whether a stock will go up or down the following day ‚Äî without using any numerical financial data (like prices, volumes, etc.).";;
10.1109/ISCMI63661.2024.10851549;Foreign Exchange Rate Forecast by a Large Language Model Integrated with Trend Description;\textcite{peng_iima_2024};Sondre;Yes;Literature%20Database/Foreign_Exchange_Rate_Forecast_by_a_Large_Language_Model_Integrated_with_Trend_Description.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input;‚ùå;Foreign exchange;10.1109/iscmi63661.2024.10851549;https://doi.org/10.1109/iscmi63661.2024.10851549;Peng & Iima (2024) uses a fine-tuned GPT-2 model to predict foreign exchange rate movements by converting numerical market data into text-based prompts that describe recent trends. The model is trained to output whether the exchange rate will increase or decrease, using trend descriptions as contextual input. Results show an accuracy of up to 56.4% and a profit ratio of 1.03√ó, outperforming traditional LSTM and CNN models.;GPT-2;Forex
10.1145/3677052.3698688;FinVision: A Multi-Agent Framework for Stock Market Prediction;\textcite{fatemi_hu_2024};Sondre;Yes;Literature%20Database/FinVision__A_Multi-Agent_Framework_for_Stock_Market_Prediction.pdf;‚úîÔ∏è;‚úîÔ∏è;‚úîÔ∏è;;;;;Financial Numerical Input, Financial Text Input;‚ùå;Stocks;10.1145/3677052.3698688;https://doi.org/10.1145/3677052.3698688;Fatemi & Hu, (2024) presents a multi-agent GPT-based system that integrates news sentiment, technical chart analysis, and historical reflections to predict stock movements and make trading decisions. Using GPT-4o-mini and o1-mini, the system achieved annualized returns of 14.79% for Apple, 25.57% for Microsoft, and 42.14% for Amazon, outperforming Buy & Hold baselines. Overall, FinVision delivered higher Sharpe ratios (up to 1.72) and lower drawdowns (‚âà12‚Äì14%), demonstrating improved risk-adjusted performance over traditional and reinforcement learning models.;GPT-4o-mini, GPT-o1-mini;Stock
2-s2.0-85107149696;Stock trend prediction using financial market news and bert;;Sondre;Tja;Literature%20Database/101721.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Stocks;10.5220/0010172103250332;https://doi.org/10.5220/0010172103250332;Wei & Nguyen (2020) fine-tunes a BERT model to predict next-day stock price movements based on financial news articles and market data. The model incorporates additional semantic features such as sentiment polarity, event categories, and stock correlation networks to enhance prediction accuracy. Results show that the proposed BERT-based model achieves 58.4% accuracy, outperforming previous methods by 2.9%.;BERT;Stock
10.1186/s40854-025-00789-6;The power of ChatGPT in processing text: Evidence from analysis and prediction in the exchange rate markets;\textcite{yang_et_al_2025};Olav;Yes;Literature%20Database/The_power_of_ChatGPT_in_processing_text-_Evidence_from_analysis_and_prediction_in_the_exchange_rate_markets.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Exchange rate;10.1186/s40854-025-00789-6;https://doi.org/10.1186/s40854-025-00789-6;"Yang et al. (2025) investigate the use of ChatGPT-3.5 for sentiment and topic analysis in the foreign exchange
market. From these outputs, the authors construct a Topic Importance-based Sentiment (TIS) index that captures
both the polarity and significance of market events. The TIS index is then integrated into interval-valued
forecasting models‚ÄîIMLP, IELM, ACI, and TARI‚Äîto evaluate its predictive impact. Empirical results show
that all models using the TIS index achieve lower prediction errors and higher explanatory power than their
baselines across every evaluation metric, including MAPE, IMSE, RMSE, and ùëÖ2. ChatGPT reaches a sentiment
classification accuracy of 98.27 percent and an F1-score of 0.98, while BERT attains 94.79 percent accuracy
with an F1-score of 0.94, and LDA performs considerably worse with 68.21 percent accuracy and an F1-score
of 0.63.";GPT-3.5;Forex
10.1007/s10614-024-10835-7;Forecasting Brazilian Stock Market Using Sentiment Indices from Textual Data, Chat-GPT-Based and Technical Indicators;\textcite{souza_et_al_2025};Olav;Yes;Literature%20Database/Forecasting_Brazilian_Stock_Market_Using_Sentiment_Indices_from_Textual_Data_Chat-GPT-Based_and_Technical_Indicators.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stock index;10.1007/s10614-024-10835-7;https://doi.org/10.1007/s10614-024-10835-7;This research explores whether sentiment information derived from textual sources can enhance forecasts of daily returns in the Brazilian stock market (Ibovespa). The approach integrates conventional technical indicators with sentiment measures obtained from financial news, Twitter posts, and ChatGPT-generated analyses. The findings indicate that the ChatGPT-based sentiment index fails to improve out-of-sample predictive performance, whereas sentiment extracted from financial news‚Äîconstructed using a time-varying dictionary‚Äîprovides a notable increase in forecasting accuracy. Among the examined technical indicators, the Accumulation‚ÄìDistribution (AD) variable delivers the strongest results, surpassing the historical average benchmark.;ChatGPT;ETF
10.1002/fut.22568;ChatGPT and Commodity Return;\textcite{gao_wang_wang_zhang_2025};Olav;Yes;Literature%20Database/ChatGPT_and_Commodity_Return.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Commodity futures index;10.1002/fut.22568;https://doi.org/10.1002/fut.22568;The study examines whether ChatGPT can be employed to predict expected returns on commodity futures. The authors collect 2.5 million news articles from nine major U.S. and international newspapers, classifying each as UP or DOWN depending on whether it implies rising or falling global commodity prices. For 18 commodities, a monthly Commodity News Ratio (CNR) is computed as the net share of positive versus negative news. Using Partial Least Squares (PLS), these ratios are aggregated into a single Commodity News Ratio Index (CNRI) representing the overall market sentiment. Regression analyses show that the ChatGPT-based CNRI significantly predicts 1‚Äì12-month excess returns on the commodity index. The benchmark model is the historical average return, and ChatGPT delivers substantial improvements, with an in-sample R2R^2R2 of 23.6% after 2004 and an out-of-sample R2R^2R2 of 5.84%. Finally, ChatGPT outperforms both the traditional Bag-of-Words method and the BERT encoder model, confirming its superior capability in extracting predictive semantic information from financial text.;GPT-3.5;Derivatives
10.1109/ICICYTA64807.2024.10913442;The Role of News Sentiment in Predicting the Jakarta Composite Index Using Long Short-Term Memory;\textcite{purwanto_et_al_2025};Olav;Yes;Literature%20Database/The_Role_of_News_Sentiment_in_Predicting_the_Jakarta_Composite_Index_Using_Long_Short-Term_Memory.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Equity index;10.1109/icicyta64807.2024.10913442;https://doi.org/10.1109/icicyta64807.2024.10913442;"Purwanto et al. (2025) explore whether incorporating news sentiment can enhance forecasts of the Jakarta
Composite Index (JCI) when combined with historical price data using a Long Short-Term Memory (LSTM)
model. They construct a daily sentiment index from financial news articles and experiment with five different
approaches to embed this information into the time series model. Among these, Scenario 2, which utilizes a
sequence of historical sentiment scores, consistently delivers the most accurate results across several evaluation
metrics, including MAE and RMSE. This outcome suggests that temporal patterns in sentiment provide valuable
predictive information, underscoring the significance of capturing sentiment dynamics rather than relying solely
on single-day values. However, the effect of sentiment integration is not uniform across all forecasting tasks. In
particular, for relative return predictions, the inclusion of sentiment features occasionally reduced performance,
implying that the predictive value of sentiment depends on the target variable and must be adapted to the
modeling context.";GPT-4o-mini;Index
10.1016/j.fraope.2025.100359;LLM-guided semantic feature selection for interpretable financial market forecasting in low-resource financial markets;;Sander;Tja;Literature%20Database/1-s2.0-S2773186325001471-main.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock index;10.1016/j.fraope.2025.100359;https://doi.org/10.1016/j.fraope.2025.100359;LLM brukt til feature selection;;
2-s2.0-85195934691;AlphaFin: Benchmarking Financial Analysis with Retrieval-Augmented Stock-Chain Framework;;Sondre;No;Literature%20Database/AlphaFin__Benchmarking_Financial_Analysis_with_Retrieval-Augmented_Stock-Chain_Framework.pdf;‚úîÔ∏è;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Stocks;10.48550/ARXIV.2403.12582;https://doi.org/10.48550/arXiv.2403.12582;Li et al. (2024) introduces a Stock-Chain framework that integrates a fine-tuned LLM (StockGPT) with Retrieval-Augmented Generation (RAG) and Chain-of-Thought reasoning to predict stock price trends and explain financial outcomes. The model analyzes financial news, reports, and market data to forecast whether a stock will rise or fall in the following month. Results show a prediction accuracy of 55.7%, an annualized return of 30.8%, and a Sharpe ratio of 1.57, outperforming ChatGPT, FinGPT, and traditional LSTM models.;StockGPT;Stock
10.1145/3724154.3724240;Optimizing Stock Market Return Forecasts with Uncertainty Sentiment: Leveraging LLM-based Insights;;Sander;No;;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock;10.1145/3724154.3724240;https://doi.org/10.1145/3724154.3724240;;;
10.1007/s10844-025-00971-3;From news to trends: a financial time series forecasting framework with LLM-driven news sentiment analysis and selective state spaces;\textcite{wang_sun_wang_2025};Sondre;Yes;Literature%20Database/s10844-025-00971-3.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stock;10.1007/s10844-025-00971-3;https://doi.org/10.1007/s10844-025-00971-3;"Y. Wang et al. (2025) propose MambaMoE, a model that combines historical stock price data with news
sentiment derived from a fine-tuned DeepSeek large language model. The DeepSeek component extracts
sentiment features from financial news, which are then integrated into the MambaMoE forecasting framework.
The results show that MambaMoE achieves notably higher accuracy than both LSTM and Transformer models,
with performance gains of roughly 24% and 6%, respectively, in short-term stock forecasting.";DeepSeek-R1-7B, LLaMA 3.1 8B, Qwen;Stock
10.1007/978-981-96-4589-3_9;Rationale-Driven Predictions for¬†Stock Movements: A Multi-model Integration and¬†Stack Generalization Approach;;Sander;Tja;;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Stock;10.1007/978-981-96-4589-3_9;https://doi.org/10.1007/978-981-96-4589-3_9;"
‚Ä¢  Mostly explaining rationale";;
10.1109/ISCMI63661.2024.10851487;A Comparative Study of Sequential Deep Learning Models in Financial Time Series Forecasting;\textcite{fang_et_al_2024};Sondre;Yes;Literature%20Database/A_Comparative_Study_of_Sequential_Deep_Learning_Models_in_Financial_Time_Series_Forecasting.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input;‚ùå;Stocks;10.1109/iscmi63661.2024.10851487;https://doi.org/10.1109/iscmi63661.2024.10851487;"Fang et al. (2024) compare three sequential deep learning models for stock price prediction. In this study,
the LLM model is used directly to classify and predict stock prices. The three models evaluated are an LSTM
network, a Transformer architecture, and GPT-3.5-Turbo applied in a zero-shot setting. The time series data are
converted into strings and given to the LLM through a prompt instructing it to predict the next observation. The
model‚Äôs textual output is converted back to numerical form for evaluation. The three models were compared
both through classification accuracy and regression metrics. For classification, the continuous log returns were
divided into seven categories, which makes the accuracy values relatively low. Results show that the Transformer
achieved the highest classification accuracy (22%), followed by LSTM (15.6%) and GPT-3.5-Turbo (15.3%). In
regression analysis, the LLM initially produced large errors due to incomplete outputs, but after outlier removal
its RMSE dropped to 33.85, outperforming the LSTM (125.72).";GPT-3.5-Turbo;Stock
10.22495/rgcv15i2p13;CAN CHATGPT PREDICT STOCK PRICES? EVALUATING ARTIFICIAL INTELLIGENCE-DRIVEN FINANCIAL FORECASTING AND RISK MANAGEMENT;;Sondre;No;Literature%20Database/Can_ChatGPT_predict_stock_prices__Evaluating_artificial_intelligence-driven_financial_forecasting_and_risk_management.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;?;10.22495/rgcv15i2p13;https://doi.org/10.22495/rgcv15i2p13;Akpan (2025) evaluates whether ChatGPT-4, Claude 3.5, and Gemini 1.0 can forecast companies‚Äô financial metrics such as revenue and net income using historical data from 2020‚Äì2022. The models are tested in a zero-shot setting and compared against actual 2023 results, with ChatGPT-4 achieving the highest accuracy (90.4%). This paper is excluded from the analysis because it focuses on financial performance prediction, not stock price or market trend forecasting.;Claude-3.5, GPT-4, Gemini-1.0;None
10.1016/j.procs.2024.08.258;ChatGPT-based Sentiment Analysis and Risk Prediction in the Bitcoin Market;\textcite{kang_yuan_zhang_chen_li_2024};Sondre;Yes;Literature%20Database/main.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Bitcoin;10.1016/j.procs.2024.08.258;https://doi.org/10.1016/j.procs.2024.08.258;Kang et al. (2024) uses ChatGPT to classify cryptocurrency news headlines as positive, neutral, or negative to generate a sentiment index. This sentiment data is then incorporated into KNN and GARCH models to predict Value-at-Risk (VaR) for Bitcoin. Results show that including ChatGPT-based sentiment improves explanatory power by 33% (R¬≤ increasing from 0.417 to 0.554) and reduces prediction error, demonstrating that sentiment significantly enhances Bitcoin risk forecasting.;ChatGPT;Cryptocurrency
10.1007/s10614-025-11024-w;Stock Market Forecasting: From Traditional Predictive Models to Large Language Models;;Sondre;Tja;Literature%20Database/s10614-025-11024-w.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;?;10.1007/s10614-025-11024-w;https://doi.org/10.1007/s10614-025-11024-w;Darwish et al. (2025) provides a comprehensive survey of methods used for stock market forecasting. It compares traditional models, deep learning architectures, and LLM-based approaches such as GPT-4, FinBERT, and BloombergGPT, analyzing their predictive performance and interpretability. The study concludes that LLMs enhance accuracy and reasoning in stock prediction, though challenges remain regarding transparency, cost, and generalization across markets.;;
10.1109/IDCIOT64235.2025.10914764;Comparative Advances in Financial Sentiment Analysis:A Review of BERT,FinBert, and Large Language Models;;Sondre;Tja;Literature%20Database/Comparative_Advances_in_Financial_Sentiment_Analysis_A_Review_of_BERTFinBert_and_Large_Language_Models.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;;10.1109/idciot64235.2025.10914764;https://doi.org/10.1109/idciot64235.2025.10914764;Mahendran et al. (2025) presents a survey comparing transformer-based models used for financial sentiment analysis. It reviews the performance of BERT, FinBERT, DistilBERT, DistilRoBERTa, and discusses the potential of GPT-based LLMs for few-shot and zero-shot financial text classification. The study finds that FinBERT provides the most accurate and domain-adapted results, while GPT models offer strong theoretical potential but were not empirically tested in the paper.;;
10.1145/3589334.3645611;Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models;\textcite{koa_ma_ng_chua_2024};Sander;Yes;Literature%20Database/3589334.3645611.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Text Input;‚ùå;Stocks;10.1145/3589334.3645611;https://doi.org/10.1145/3589334.3645611;;GPT-3.5-Turbo, Vicuna;Stock
10.1016/j.procs.2025.08.073;Crude oil risk forecasting using time series foundation model;;Sondre;No;Literature%20Database/main2.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;?;10.1016/j.procs.2025.08.073;https://doi.org/10.1016/j.procs.2025.08.073;He, Yu & Zou (2025) applies Chronos, an LLM-based time series foundation model built on the T5 architecture, to forecast Value-at-Risk (VaR) for crude oil futures. The model analyzes price data from the Shanghai International Energy Exchange (2018‚Äì2023) using a zero-shot approach to assess market risk. Results show that Chronos achieves higher reliability at the 97.5% and 99% confidence levels than traditional ARMA-GARCH and historical simulation methods, providing more balanced and accurate risk forecasts.;Chronos;VaR
10.3390/math11132883;Price, Complexity, and Mathematical Model;;Sander;No;;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;?;10.3390/math11132883;https://doi.org/10.3390/math11132883;Survey. Although the study highlights Large Language Models (LLMs) as an emerging direction for future research, it does not empirically examine their application or performance in price prediction.;;
10.1145/3708036.3708236;Enhancing Stock Prediction with Sentimental and Relational InformationDistilled from Large Models;\textcite{2_liu_et_al_2024};Sondre;Yes;Literature%20Database/Enhancing_Stock_Prediction_with_Sentimental_and_Relational_InformationDistilled_from_Large_Models.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stock;10.1145/3708036.3708236;https://doi.org/10.1145/3708036.3708236;Liu et al. (2024) uses ChatGPT to extract sentiment and inter-company relationships from financial news through a Chain-of-Thought-based distillation process. These LLM-derived features are integrated into a Graph Neural Network (GNN) to improve stock trend prediction. Results show that incorporating ChatGPT-generated sentiment and relational information increases prediction accuracy by up to 3.23% compared to baseline models.;ChatGPT;Stock
10.1109/BigData62323.2024.10825946;Stock Price Prediction Using LLM-Based Sentiment Analysis;;Sander;Tja;Literature%20Database/Stock_Price_Prediction_Using_LLM-Based_Sentiment_Analysis.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1109/bigdata62323.2024.10825946;https://doi.org/10.1109/bigdata62323.2024.10825946;Se p√• torsdag;;
10.1007/978-3-031-97564-6_24;Predicting Stock Prices with¬†ChatGPT-Annotated Reddit Sentiment: Hype or¬†Reality?;;Olav;Tja;Literature%20Database/Predicting_Stock_Prices_with_ChatGPT-Annotated_Reddit_Sentiment-_Hype_or_Reality.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock;10.1007/978-3-031-97564-6_24;https://doi.org/10.1007/978-3-031-97564-6_24;"I denne artikkelen brukes kun en encoder-basert modell (RoBERTa). ChatGPT brukes bare til annotering, ikke som treningsmodell



Studien unders√∏ker om sentiment (f√∏lelser og meninger) fra sosiale medier ‚Äì spesielt Reddit ‚Äì kan brukes til √• forutsi aksjepriser.

Forskerne fokuserer p√• to kjente aksjer fra ‚Äúmeme stock‚Äù-b√∏lgen: GameStop (GME) og AMC Entertainment (AMC).

De bruker ChatGPT for √• annotere (merke) innlegg fra Reddit med positiv, negativ eller n√∏ytral tone, og deretter trener de en finjustert RoBERTa-modell for sentimentanalyse.
Form√•let er √• finne ut om:
‚Ä¢ ChatGPT-annotert sentiment fra Reddit kan forklare eller forutsi aksjeprisbevegelser, og
‚Ä¢ om slike signaler er sterkere enn enklere m√•l som antall kommentarer eller Google-s√∏k.";RoBERTa;Stock
10.1109/AiDAS63860.2024.10730589;GPT-4 Powered Virtual Analyst for Fundamental Stock Investment by Leveraging Qualitative Data;;Olav;No;Literature%20Database/GPT-4_Powered_Virtual_Analyst_for_Fundamental_Stock_Investment_by_Leveraging_Qualitative_Data.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;?, Stocks;10.1109/aidas63860.2024.10730589;https://doi.org/10.1109/aidas63860.2024.10730589;This study introduces an AI-based investment tool powered by GPT-4, designed to act as a virtual financial analyst. The system interprets qualitative information, such as company reports and news, and produces numerical ratings with fact-based explanations for short-, medium-, and long-term investment prospects. The findings indicate that its recommendations remain accurate and reliable for up to ten months without continuous updates.;GPT-4, GPT-4 Turbo;Stock
10.3905/jpm.2024.1.645;Large Language Models for Financial and Investment Management: Applications and Benchmarks;;Sander;Tja;Literature%20Database/JPM-2024-Kong-162-210.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;?;10.3905/jpm.2024.1.645;https://doi.org/10.3905/jpm.2024.1.645;Survey;;
10.1109/TENSYMP63728.2025.11144933;LLM-Augmented Enhanced Graph Transformer for Stock Movement Prediction;;Sondre;Tja;Literature%20Database/LLM-Augmented_Enhanced_Graph_Transformer_for_Stock_Movement_Prediction.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock;10.1109/tensymp63728.2025.11144933;https://doi.org/10.1109/tensymp63728.2025.11144933;Zhou et al. (2025) introduces a model that combines LLM-generated financial text with graph-based numerical analysis to predict daily stock price movements in the S&P 500. The authors use DeepSeek-R1-Distill-Qwen-14B to generate concise market summaries, which are embedded with FinBERT and integrated into a Graph Transformer alongside technical indicators. The proposed model achieves 70.1% accuracy and an AUC of 0.7865, outperforming traditional graph and time-series baselines by up to 18%. (LLM used to generate summaries and FinBERT used to derive sentiment);DeepSeek, Qwen;Stock
10.1109/SIU66497.2025.11112242;"Stock Price Prediction with Multimodal Data; √áok Modlu Veri Ile Hisse Senedi Fiyati Tahmini";;Olav;No;Literature%20Database/Stock_Price_Prediction_with_Multimodal_Data.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock;10.1109/siu66497.2025.11112242;https://doi.org/10.1109/siu66497.2025.11112242;"Artikkel p√• tyrkisk.
Engelsk versjon av forskningsarbeidet med navn ‚ÄúMultimodal Stock Price Prediction‚Äù er med i Literature Database.";;
10.5220/0013191200003890;Integrating Traditional Technical Analysis with AI: A Multi-Agent LLM-Based Approach to Stock Market Forecasting;;Olav;Tja;Literature%20Database/Integrating_Traditional_Technical_Analysis_with_AI-_A_Multi-Agent_LLM-Based_Approach_to_Stock_Market_Forecasting.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.5220/0013191200003890;https://doi.org/10.5220/0013191200003890;"LLM som agentModus. Gi r√•d osv. usikker p√• om den skal med.

LLM-en brukes som flere spesialiserte ‚Äúagenter‚Äù som samarbeider om √• analysere, tolke og foresl√• handelsstrategier.
Den er alts√• ikke trent direkte p√• aksjedata, men styrer arbeidsflyten, gjenkjenner m√∏nstre, og lager forklarbare beslutninger.

Artikkelen presenterer ElliottAgents ‚Äì et fleragentsystem som kombinerer klassisk teknisk analyse (Elliott Wave-prinsippet) med moderne KI-teknikker (LLM-agenter, RAG og dyp forsterkningsl√¶ring/DRL) for √• gjenkjenne b√∏lgem√∏nstre og lage handelsanbefalinger i aksjemarkedet. Studien demonstrerer arkitekturen, beskriver arbeidsflyten mellom agentene og viser eksperimenter p√• historiske data for store amerikanske selskaper (f.eks. Apple, Amazon, Google).

Elliott Wave-prinsippet (EWP) er popul√¶rt blant tradere, men manuelt og subjektivt. Forfatterne hevder at LLM-agenter kan gj√∏re m√∏nstergjenkjenningen mer skalerbar og forklarbar, og at DRL-basert backtesting kan gi l√¶rende og mer robuste beslutninger.

";;
10.18653/v1/2024.findings-acl.233;Can Large Language Models Mine Interpretable Financial Factors More Effectively? A Neural-Symbolic Factor Mining Agent Model;;Olav;Tja;Literature%20Database/Can_Large_Language_Models_Mine_Interpretable_Financial_Factors_More_Effectively_A_Neural-Symbolic_Factor_Mining_Agent_Model.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.18653/v1/2024.findings-acl.233;https://doi.org/10.18653/v1/2024.findings-acl.233;"Har lagt den inn, men useri√∏st gode resultater p√• Annuilized return og SHarpe Ratio? 

Z. Li et al. (2024) present FAMA (FActor Mining Agent), a new approach that applies Large Language
Models (LLMs) to the task of financial factor discovery. The idea is to let LLMs act as a bridge between
symbolic methods, which are interpretable, and neural approaches, which are efficient but often opaque. FAMA
integrates two complementary mechanisms. The first, Cross-Sample Selection (CSS), ensures that the model
is exposed to a wide set of diverse factor examples, helping it avoid producing similar or repetitive outputs.
The second, Chain-of-Experience (CoE), allows the system to build on previously effective patterns, effectively
‚Äúlearning from experience‚Äù to improve the search for high-quality factors. When tested on real S&P 500 stock
market data, FAMA outperformed earlier models. The method improved RankIC by 0.006 and RankICIR by
0.105 compared to the previous state of the art. In simulated investments, it also achieved an annualized return
of 38.4% and an exceptionally high Sharpe ratio of 667.2, indicating both strong performance and low risk.";GPT-3.5;Stock
10.1145/3652037.3652047;Assessment of the Applicability of Large Language Models for Quantitative Stock Price Prediction;;Olav;Tja;Literature%20Database/Assessment_of_the_Applicability_of_Large_Language_Models_for_Quantitative_Stock_Price_Prediction.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;?;10.1145/3652037.3652047;https://doi.org/10.1145/3652037.3652047;"Tja. Bruker ikke LLM direkte her

Forfatterne bruker ikke ferdige LLM-er som GPT, men overf√∏rer prinsippene bak dem ‚Äì som Transformer-arkitektur og pre-training-teknikker ‚Äì til numeriske tidsserier. De bygger egne modeller (Stock2Vec og Stock Transformer) som etterligner hvordan LLM-er l√¶rer m√∏nstre i spr√•k.";;
10.1016/j.jfds.2025.100152;Learning from AI-Finance: A selected synopsis;;Olav;No;Literature%20Database/Learning_from_AI-Finance-_A_selected_synopsis.pdf;‚úîÔ∏è;‚úîÔ∏è;‚ùå;;;;;;‚úîÔ∏è;Stock market index;10.1016/j.jfds.2025.100152;https://doi.org/10.1016/j.jfds.2025.100152;"Conference based survey.

Mange interessante funn presentert i artikkelen fra konferansen.
Artikkelen oppsummerer hovedfunnene fra den 2. √•rlige konferansen ‚ÄúCapital Market Research in the Era of AI‚Äù (2024), der forskere presenterte hvordan generativ kunstig intelligens (Gen-AI) p√•virker finanssektoren. Forfatterne (Huang, Lee og Yeung) √∏nsker √• vise hvordan AI-drevet databehandling, prediksjon og beslutningsst√∏tte endrer finansmarkedene, bedriftsstrategi, og regulering.";;
10.1007/978-3-031-72393-3_5;SARF: Stock Market Prediction with Sentiment-Augmented Random Forest;\textcite{talazadeh_perakovic_2025};Sondre;Yes;Literature%20Database/978-3-031-72393-3_5.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stock;10.1007/978-3-031-72393-3_5;https://doi.org/10.1007/978-3-031-72393-3_5;Talazadeh & Perakoviƒá (2025) presents a hybrid model that integrates FinGPT-based sentiment analysis with a Random Forest algorithm to predict stock market direction. The model combines financial news sentiment scores with 15 technical indicators across the S&P 500, NASDAQ, and Dow Jones indices. Results show that the proposed SARF model achieves up to 85% accuracy, improving prediction performance by approximately 9% over traditional Random Forest and LSTM models.;FinGPT;Index
10.12785/ijcds/1571026011;Enhancing Bitcoin Forecast Accuracy by Integrating AI, Sentiment Analysis, and Financial Models;\textcite{elabaji_haraty_2025};Sander;Yes;Literature%20Database/1571026011.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Cryptocurrency (Bitcoin);10.12785/ijcds/1571026011;https://doi.org/10.12785/ijcds/1571026011;;LLaMA2;Cryptocurrency
10.3389/fbloc.2025.1627769;Short-term cryptocurrency price forecasting based on news headline analysis;;Olav;Tja;Literature%20Database/Short-term_cryptocurrency_price_forecasting_based_on_news_headline_analysis.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Cryptocurrency;10.3389/fbloc.2025.1627769;https://doi.org/10.3389/fbloc.2025.1627769;"Tja - GPT i form av LLM-arkitektur 
Bruker ikke LLM‚Äôer direkte men hller GPT i form av en LLM Arkiteektur(Transformer arkitektur)
De vil fremover i neste studie bruke ¬´ekte LLM-er¬ª som resonnerer.

‚Äúclassifier architectures founded on more recent transformer-based models ‚Äî specifically BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer). This comparative approach allows for a systematic assessment of how different embedding technologies capture the nuanced semantic content of financial news headlines.Dette viser at GPT brukes som en klassifikasjonsmodell for embeddings ‚Äî alts√• et ‚Äúlag av vektorer‚Äù som representerer tekst.Det st√•r ingen steder at de ‚Äúpromptet‚Äù eller ‚Äúspurte‚Äù GPT om noe, eller at modellen genererte tekst.   ";;
10.1109/IDS66066.2025.00016;Enhancing FinRL Trading Agents with Advance LLM-Processed Financial News: An Improved Approach Using DeepSeek-V3;\textcite{chandra_balakrishna_2025};Olav;Yes;Literature%20Database/LLM-Processed_Financial_News-_An_Improved_Approach_Using_DeepSeek-V3.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stock;10.1109/ids66066.2025.00016;https://doi.org/10.1109/ids66066.2025.00016;This study investigates whether sentiment inputs generated by a Large Language Model (LLM) can enhance the performance of reinforcement learning (RL)-based trading agents within the FinRL framework. The results demonstrate that sentiment features produced by DeepSeek-V3 significantly improve the agents‚Äô trading performance across multiple financial metrics. The findings highlight the critical role of prompt engineering in determining the quality and usefulness of LLM-derived features. In other words, how the LLM is instructed has a greater impact on performance than the choice of model itself. Among the evaluated prompting strategies ‚Äî Few-Shot, Counterfactual, Chain-of-Thought (CoT), and Role-Based (baseline) ‚Äî the Few-Shot approach yielded the most consistent gains, delivering superior risk-adjusted returns, higher cumulative profitability, and more stable trading behavior over time.;DeepSeek-V3;Stock
10.1109/ICAISISAS64483.2025.11051550;Machine Learning Approaches to Picking A-Shares Stocks: A Comparative Analysis;\textcite{wu_you_2025};Sondre;Yes;Literature%20Database/Machine_Learning_Approaches_to_Picking_A-Shares_Stocks__A_Comparative_Analysis.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;TRUE;;;‚ùå;Stock;10.1109/icaisisas64483.2025.11051550;https://doi.org/10.1109/icaisisas64483.2025.11051550;Wu & You (2025) uses ChatGPT to generate a sentiment-based factor, the ‚ÄúChatGPT Score,‚Äù from Chinese company announcements. This score is integrated into both the Fama-French 5-Factor model and several machine learning models (Random Forest, XGBoost, LightGBM, CatBoost) to improve stock return prediction in the Chinese A-shares market. Results show that incorporating ChatGPT sentiment increases annual returns by up to 20.2% and boosts the Sharpe ratio to 1.60, outperforming traditional models.;ChatGPT;Stock
10.1007/978-981-97-5934-7_19;News that Moves the Market: DSEX-News Dataset for Forecasting DSE Using BERT;;Olav;Tja;Literature%20Database/News_that_Moves_the_Market-_DSEX-News_Dataset_for_Forecasting_DSE_Using_BERT.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Equity index;10.1007/978-981-97-5934-7_19;https://doi.org/10.1007/978-981-97-5934-7_19;"Tja, Bruker BERT.


Khan et al. (2024) fine-tune a BERT-base-uncased model to forecast stock market movements on the Dhaka Stock Exchange (DSE) using a newly created DSEX-News dataset of 14,721 manually labeled financial headlines. The method involves extensive data cleaning, expert validation, and feature extraction through BERT embeddings for binary sentiment classification. Results show that the proposed BERT-based model achieves 99% accuracy, outperforming traditional ML, deep learning, FinBERT, and RoBERTa models. The authors conclude that BERT effectively captures contextual financial sentiment, making it highly suitable for market prediction in emerging economies.";;
10.1109/ICDMW65004.2024.00019;Leveraging Large Language Models for Predicting Stock Option Valuation and Financial Risk Mitigation;\textcite{dsouza_et_al_2024};Sondre;Yes;Literature%20Database/Leveraging_Large_Language_Models_for_Predicting_Stock_Option_Valuation_and_Financial_Risk_Mitigation.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stock options;10.1109/icdmw65004.2024.00019;https://doi.org/10.1109/icdmw65004.2024.00019;Dsouza et al. (2024) combines LLM-based sentiment and trend analysis with quantitative financial indicators to predict stock option valuations in the NIFTY 50 market. The study employs ChatGPT-3.5, ChatGPT-4, and LLaMA 3.1 to extract sentiment and classify market trends (bullish, bearish, neutral) from financial news, integrating these features into a hybrid predictive framework. Results show that ChatGPT-4 achieved the highest accuracy (54%), while LLaMA 3.1 performed best in recall (0.576) and F1-score (0.082), demonstrating the potential of LLMs for option valuation and risk forecasting.;GPT-3.5, GPT-4, LLaMA-3.1;Derivatives
10.3390/jrfm18020099;A First Look at Financial Data Analysis Using ChatGPT-4o;;Olav;No;Literature%20Database/A_First_Look_at_Financial_Data_Analysis_Using_ChatGPT-4o.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.3390/jrfm18020099;https://doi.org/10.3390/jrfm18020099;Chou et al. (2025) employ ChatGPT-4o as an integrated analytical tool that both performs financial data analyses and interprets their results, comparing its outputs with those from traditional software such as Stata. They analyze daily stock data for 30 companies in the Dow Jones Industrial Average, combined with market returns and the risk-free rate. The study performs several tests, including zero-shot prompting, time-series analysis, risk-return evaluation, and ARMA--GARCH modeling. Results show that ChatGPT-4o performs on par with traditional statistical software such as Stata, with only minor discrepancies arising from implementation differences. However, the findings emphasize that ChatGPT-4o's outputs require human validation and expert oversight to ensure analytical soundness. The authors conclude that ChatGPT-4o should serve as a complementary analytical tool rather than a replacement for professional financial analysts.;GPT-4o;Stock
10.1016/j.eswa.2025.127864;Investigating the impact of sentiments on stock market using digital proxies: Current trends, challenges, and future directions;;Sondre;Tja;Literature%20Database/Investigating_the_impact_of_sentiments_on_stock_market_using_digital_proxies__Current_trends_challenges_and_future_directions-compressed_(1).pdf;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;?;10.1016/j.eswa.2025.127864;https://doi.org/10.1016/j.eswa.2025.127864;Gupta et al. (2025) is a comprehensive survey reviewing how digital sentiment data from social media, news, and online forums influence stock market behavior. It analyzes 108 prior studies, comparing traditional machine learning, deep learning, and LLM-based sentiment analysis methods. The study identifies key trends, datasets, and challenges, providing future research directions for improving sentiment-driven stock market forecasting. (A very strong survey);;
10.1109/FMLDS63805.2024.00071;Can GPT Price Options?;\textcite{pawar_chaudhary_2024};Sander;Yes;Literature%20Database/Can_GPT_Price_Options.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input;‚ùå;Stock options;10.1109/fmlds63805.2024.00071;https://doi.org/10.1109/fmlds63805.2024.00071;;GPT-3.5-Turbo;Derivatives
10.1109/SMC52423.2021.9659283;Stock Price Prediction Using Sentiment Analysis;;Sander;Tja;;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1109/smc52423.2021.9659283;https://doi.org/10.1109/smc52423.2021.9659283;Tenker Nei, BERT only;;
10.3905/jfds.2023.1.143;Assessing Look-Ahead Bias in Stock Return Predictions Generated by GPT Sentiment Analysis;\textcite{glasserman_lin_2024};Sondre;Yes;Literature%20Database/Assessing_Look-Ahead_Bias_in_Stock_Return_Predictions_Generated_by_GPT_Sentiment_Analysis.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.3905/jfds.2023.1.143;https://doi.org/10.3905/jfds.2023.1.143;Glasserman & Lin (2024) examines whether GPT-3.5-based sentiment models inadvertently use future or biased information when predicting stock returns from financial news. The authors anonymize company names and product references in headlines to test if GPT‚Äôs prior knowledge affects prediction accuracy. Results show that anonymized inputs improve performance by 5.9 basis points per day, indicating that GPT‚Äôs background knowledge introduces distraction rather than look-ahead bias. (Very interesting paper. Could be used in discussion);GPT-3.5-Turbo;Stock
10.3390/jrfm18090475;AI and Financial Fragility: A Framework for Measuring Systemic Risk in Deployment of Generative AI for Stock Price Predictions;;Sander;No;;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Stock;10.3390/jrfm18090475;https://doi.org/10.3390/jrfm18090475;;;
10.1145/3583780.3614886;Follow the Will of the Market: A Context-Informed Drift-Aware Method for Stock Prediction;;Olav;Tja;Literature%20Database/Follow_the_Will_of_the_Market-_A_Context-Informed_Drift-Aware_Method_for_Stock_Prediction.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1145/3583780.3614886;https://doi.org/10.1145/3583780.3614886;"Tja - LLM i form av LLM-arkitektur
De bruker ikke en LLM direkte, men heller ideen bak.

Dette kalles in-context learning ‚Äì modellen l√¶rer p√• stedet ut fra konteksteksempler uten √• trene p√• nytt.
Song et al. overf√∏rer denne id√©en til finans:
‚Ä¢ De lager ‚Äúdemonstrasjoner‚Äù av markedet ‚Äî oppsummeringer av hva som nylig har g√•tt opp eller ned.
‚Ä¢ Disse demonstrasjonene blir som prompten i en LLM.
‚Ä¢ Deretter lager de en egen nettverksarkitektur som endrer vektene sine dynamisk ut fra denne konteksten.
Dermed imiterer de LLM-ens evne til √• l√¶re fra kontekst, men med et spesialbygd nettverk for aksjedata.

To alleviate this issue, the recently popularized concept of In-Context learning has provided
us with valuable insights. In this approach, large language models
(LLMs) are exposed to multiple examples of input-label pairs, also
known as demonstrations, as part of the prompt before performing a task on an unseen example. By thoroughly analyzing these
demonstrations, LLMs can uncover potential patterns and effectively adapt to new tasks. Building upon this concept, we propose a
Context-Informed drift-aware method for Stock Prediction (CISP),
which continually adjusts to the latest market styles and offers
more accurate predictions. ";;
10.1109/ACCESS.2024.3445413;Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study;;Olav;Tja;Literature%20Database/Large_Language_Models_and_Sentiment_Analysis_in_Financial_Markets-_A_Review_Datasets_and_Case_Study.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;?;10.1109/access.2024.3445413;https://doi.org/10.1109/access.2024.3445413;"Survey - Systematic Litterature Review

Artikkelen konkluderer med at LLM-er forbedrer sentimentanalyse betydelig i finans,
det finnes en svak men reell sammenheng mellom nyhetssentiment og Bitcoin-pris og fremtidig forskning b√∏r fokusere p√• multimodale data, forklarbarhet og ressursoptimalisering.
Survey + Empirisk studie.

Vanskelig √• forst√• beslutningene (‚Äúblack box‚Äù) ‚Üí reduserer tillit i finans. LLM-er krever enorme mengder GPU-tid og energi (GPT-3 ‚âà 175 mrd. parametere).";;
10.1007/978-981-97-0837-6_4;Forecasting Chinese Overnight Stock Index Movement Using Large Language Models with¬†Market Summary;;Olav;Tja;Literature%20Database/Forecasting_Chinese_Overnight_Stock_Index_Movement_Using_Large_Language_Models_with_Market_Summary.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Equity index;10.1007/978-981-97-0837-6_4;https://doi.org/10.1007/978-981-97-0837-6_4;"Tja - Mye BERT modeller
Rundt 73 % av modellene i artikkelen er encoder-baserte, 18 % decoder-baserte, og 9 % encoder‚Äìdecoder

GPT-3.5 og GPT-4 brukes ikke som trenbare modeller, men som eksterne sammenligningsverkt√∏y ‚Äî alts√• som et benchmark-grunnlag for √• vurdere hvor godt de fintunede kinesiske LLM-ene (som BERT, MacBERT osv.) presterer. GPT brukes til √• generere prediksjoner via prompt-sp√∏rringer (API-kall), ikke til √• trene eller finjustere modellen.";;
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963060;FN-Agents: Analysis of Exchange Rate Volatility Prediction Based on Multi-Agent Systems;;Sondre;Tja;Literature%20Database/FN-Agents__Analysis_of_Exchange_Rate_Volatility_Prediction_Based_on_Multi-Agent_Systems.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Foreign exchange;10.1109/cait64506.2024.10963060;https://doi.org/10.1109/cait64506.2024.10963060;;;
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447993;Trend-Heuristic Reinforcement Learning Framework for News-Oriented Stock Portfolio Management;;Sander;Tja;;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;;10.1109/icassp48485.2024.10447993;https://doi.org/10.1109/icassp48485.2024.10447993;Tenker nei, Portef√∏lje agent. F√•r eventuelt se;;
10.3390/e27060550;Artificial Intelligence Models for Predicting Stock Returns Using Fundamental, Technical, and Entropy-Based Strategies: A Semantic-Augmented Hybrid Approach;;Sander;No;Literature%20Database/entropy-27-00550-v2.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock;10.3390/e27060550;https://doi.org/10.3390/e27060550;Weird, se p√• senere;;
10.3390/bdcc8110143;Innovative Sentiment Analysis and Prediction of Stock Price Using FinBERT, GPT-4 and Logistic Regression: A Data-Driven Approach;\textcite{shobayo_et_al_2024};Sondre;Yes;Literature%20Database/BDCC-08-00143.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stock index (NGX All-Share);10.3390/bdcc8110143;https://doi.org/10.3390/bdcc8110143;Shobayo et al. (2024) compares FinBERT, GPT-4, and Logistic Regression for predicting stock index movements in the Nigerian market. FinBERT and GPT-4 are used to extract sentiment from financial news, while Logistic Regression serves as the main predictive engine combining sentiment and market data. Results show that Logistic Regression achieved the highest accuracy (81.83%) and ROC-AUC (89.76%), outperforming both FinBERT (63.33%) and GPT-4 (54.19%).;GPT-4;Index
10.1109/BigData62323.2024.10825449;Combining Financial Data and News Articles for Stock Price Movement Prediction Using Large Language Models;\textcite{elahi_taghvaei_2024};Sondre;Yes;Literature%20Database/Combining_Financial_Data_and_News_Articles_for_Stock_Price_Movement_Prediction_Using_Large_Language_Models.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Stocks;10.1109/bigdata62323.2024.10825449;https://doi.org/10.1109/bigdata62323.2024.10825449;\textcite{elahi_taghvaei_2024} evaluate the performance of several large language models in predicting stock price movements by combining financial indicators with textual information from news articles. Using a retrieval-augmented generation (RAG) framework, the authors test GPT-3.5, GPT-4, LLaMA 2, and LLaMA 3 under zero-, two-, and four-shot settings to classify whether stock prices will rise or fall over three- and six-month horizons. The dataset includes financial reports, historical prices, and news articles for 20 highly traded U.S. companies collected between October 2021 and January 2024. For the three-month task, GPT-3.5 in the zero-shot setting achieves the best weighted F1-score of 0.592, while GPT-4 in the two-shot setting performs best for the six-month horizon with a score of 0.591. The other models perform slightly worse, with LLaMA 3 reaching 0.573 and LLaMA 2 0.556 at best.;GPT-3.5, GPT-4, LLaMA 3, LLaMA2;Stock
10.1080/23322039.2025.2468387;A systematic approach to predicting NFT prices using time series forecasting and macroeconomic factors in digital assets;;Sander;No;;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;NFTs (digital assets);10.1080/23322039.2025.2468387;https://doi.org/10.1080/23322039.2025.2468387;;;
10.1016/j.inffus.2024.102616;Data-driven stock forecasting models based on neural networks: A review;;Sander;Tja;;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;?;10.1016/j.inffus.2024.102616;https://doi.org/10.1016/j.inffus.2024.102616;Survey. While Large Language Models (LLMs) are not directly analyzed, the authors highlight them as a promising future direction for integrating textual and multimodal data into stock forecasting.;;
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10981791;Pleno-Alignment Framework for Stock Trend Prediction;\textcite{zhang_pleno_2024};Sander;Yes;Literature%20Database/Pleno-Alignment_Framework_for_Stock_Trend_Prediction.pdf;‚úîÔ∏è;‚ùå;‚ùå;;TRUE;;;;‚ùå;Stocks;10.1109/tnnls.2025.3561811;https://doi.org/10.1109/tnnls.2025.3561811;;Alpaca-LoRA, GPT-2, GPT-Neo, Vicuna;Stock
10.1007/s10614-024-10811-1;MoF: A Background-Aware Multi-source Fusion Financial Trend Forecasting Mechanism;;Sander;Tja;;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1007/s10614-024-10811-1;https://doi.org/10.1007/s10614-024-10811-1;Tenker Nei, BERT only;;
10.1109/CSCE60160.2023.00302;Content Analysis of Items in Newspaper Data Using Table Arrangement Technology and ChatGPT for Stock Price Prediction;;Sander;Tja;;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1109/csce60160.2023.00302;https://doi.org/10.1109/csce60160.2023.00302;Tenker nei, var ikke helt prediction;;
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10594605;Fine-Tuning Gemma-7B for Enhanced Sentiment Analysis of Financial News Headlines;;Olav;No;Literature%20Database/Fine-Tuning_Gemma-7B_for_Enhanced_Sentiment_Analysis_of_Financial_News_Headlines.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;;10.1109/icetci61221.2024.10594605;https://doi.org/10.1109/icetci61221.2024.10594605;Mo et al. (2024) investigate the enhancement of financial news headline sentiment analysis through the application of Large Language Models (LLMs), including DistilBERT, LLaMA, and particularly a fine-tuned version of Gemma-7B. The authors analyze sentiment from the perspective of retail investors, aiming to capture how individual market participants interpret financial news. The fine-tuned Gemma-7B model achieves an overall accuracy of 0.874 and an F1-score of 0.876, outperforming both DistilBERT (0.824 / 0.829) and the fine-tuned LLaMA model (0.872 / 0.872). The study demonstrates that modern LLMs can revolutionize financial data interpretation and serve as an effective decision-support tool.;DistillBERT, Gemma-7B, LLaMA;None
10.1109/CSNT64827.2025.10967744;Recommender Systems for Sector-Specific Stock Analysis;\textcite{shah_et_al_2025};Sondre;Yes;Literature%20Database/Recommender_Systems_for_Sector-Specific_Stock_Analysis.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input, Financial Text Input, Multimodal Input;‚ùå;Stock;10.1109/csnt64827.2025.10967744;https://doi.org/10.1109/csnt64827.2025.10967744;Shah et al. (2025) develops a sector-based stock recommendation system using a fine-tuned LLaMA 3.1 model trained on financial news and price data from the FinnHub API. The LLM analyzes company news to generate buy/sell recommendations and sentiment-based insights across different market sectors. Results show that the model achieved an F1-score of 0.69 for Buy and 0.24 for Sell, performing best in the Consumer Cyclical and Healthcare sectors.;LLaMA-3.1;Stock
10.1016/j.iref.2025.104281;A multifactor model using large language models and multimodal investor sentiment;;Sondre;Tja;Literature%20Database/A_multifactor_model_using_large_language_models_and_multimodal_investor_sentiment.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock;10.1016/j.iref.2025.104281;https://doi.org/10.1016/j.iref.2025.104281;Zhang et al. (2025) proposes a multifactor stock prediction framework that integrates textual and visual investor sentiment. It employs RoBERTa for text-based sentiment extraction and Inception V3 for image-based sentiment, combining them through a multimodal semantic correlation model. Results show that the multimodal sentiment factors improve prediction accuracy by 8.6% and significantly enhance portfolio returns in the CSI 300 market.;RoBERTa;Stock
10.18653/v1/2024.findings-acl.185;LLMFactor: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction;\textcite{wang_izumi_sakaji_2024};Olav;Yes;Literature%20Database/LLMFactor-_Extracting_Profitable_Factors_through_Prompts_for_Explainable_Stock_Movement_Prediction.pdf;‚úîÔ∏è;‚úîÔ∏è;‚ùå;;;;TRUE;;‚ùå;Stocks;10.18653/v1/2024.findings-acl.185;https://doi.org/10.18653/v1/2024.findings-acl.185;Wang et al. (2024) compare four methodological approaches for stock movement prediction based on textual and historical market data. While earlier research has relied on time-based,  keyphrase extraction and sentiment analysis to infer market-driving factors, this study introduces LLMFactor, a novel framework that enables LLMs to autonomously identify and formulate explanatory factors from financial news. The model leverages GPT-3.5-turbo, GPT-4, and GPT-4-turbo within the proposed Sequential Knowledge-Guided Prompting (SKGP) strategy. Empirical results across four benchmark datasets---StockNet, CMIN-US, CMIN-CN, and EDT---demonstrate that LLMFactor outperforms existing state-of-the-art models, achieving improvements of 2.9\%, 0.4\%, 11\%, and 4.8\% in MCC, respectively. The accuracy scores similarly confirm that the factor-based approach substantially exceeds the time, keyphrase- and sentiment-based baselines.;GPT-3.5-Turbo, GPT-4, GPT-4 Turbo;Stock
2-s2.0-85204874765;Enhanced Financial Sentiment Analysis and Trading Strategy Development Using Large Language Models;;Olav;No;Literature%20Database/Enhanced_financial_sentiment_analysis_and_trading_strategy_development_using_large_language_models.pdf;‚úîÔ∏è;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Stocks;https://doi.org/10.18653/v1/2024.wassa-1.1;https://aclanthology.org/2024.wassa-1.1/;"Sander hadde samme artikkelen med annet navn. Denen er fjerna fra OverLeafen.

Kƒ±rtac and Germano (2024) compares large language models (OPT, LLaMA, FinBERT, BERT, and RoBERTa) with the traditional Loughran‚ÄìMcDonald dictionary in generating sentiment scores for stock movement analysis. Using financial news from 2010‚Äì2023, each article is linked to a stock and labeled by its three-day excess return,
scaled between 0 and 1. These sentiment scores are used in a panel regression to predict next-day returns. Results show that complex models outperform simpler ones: OPT achieves the highest accuracy (0.744) and F1-score (0.754), surpassing LLaMA (0.632, 0.691), FinBERT (0.722, 0.722), BERT (0.725, 0.734), RoBERTa (0.671, 0.678), and Loughran‚ÄìMcDonald (0.501, 0.508).";BERT, FinBERT, LLaMA 3, Loughran-McDonalds dictionary, OPT, RoBERTa;Stock
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825362;Leveraging Large Language Models for Institutional Portfolio Management: Persona-Based Ensembles;\textcite{abe_et_al_2024};Sondre;Yes;Literature%20Database/Leveraging_Large_Language_Models_for_Institutional_Portfolio_Management__Persona-Based_Ensembles.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input;‚ùå;Stocks & bonds;10.1109/bigdata62323.2024.10825362;https://doi.org/10.1109/bigdata62323.2024.10825362;Abe et al. (2024) uses GPT-4 as a predictive engine to forecast stock and bond price movements for institutional-level portfolio management. The model simulates different investor personas‚Äîshort-, medium-, and long-term‚Äîand combines their forecasts through an ensemble approach to improve decision robustness. Results show that the GPT-4 ensemble achieves 37.8% prediction accuracy and an F1-score of 0.484, outperforming traditional buy-and-hold strategies in periods of rising inflation.;GPT-4;Bond, Stock
2-s2.0-85216409938;Prediction of Foreign Exchange Rates by a Large Language Model;\textcite{peng_iima_kitamura_2024};Sander;Yes;Literature%20Database/Prediction_of_Foreign_Exchange_Rates_by_a_Large_Language_Model.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input;‚ùå;Foreign exchange;;;;GPT-2;Forex
10.1007/978-3-031-96235-6_23;Enhancing Cryptocurrency Sentiment Analysis with¬†GPT-4: A Comparative Study;;Sander;No;Literature%20Database/978-3-031-96235-6_23.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;?;10.1007/978-3-031-96235-6_23;https://doi.org/10.1007/978-3-031-96235-6_23;;ALBERT, FinBERT, Flan-T5, GPT-4, Gemma-7B;Cryptocurrency
10.1007/s12525-025-00815-6;Wisdom of the crowd signals: Predictive power of social media trading signals for cryptocurrencies;;Sondre;No;Literature%20Database/s12525-025-00815-6.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Cryptocurrency;10.1007/s12525-025-00815-6;https://doi.org/10.1007/s12525-025-00815-6;LLM not used;;
10.1109/ICCCMLA63077.2024.10871633;Adapting Speech Models for Stock Price Prediction;;Sander;Tja;;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Stocks;10.1109/icccmla63077.2024.10871633;https://doi.org/10.1109/icccmla63077.2024.10871633;Tenker Nei, BERT only;;
10.1080/23270012.2024.2306929;Dividend announcement and the value of sentiment analysis;;Sander;Tja;Literature%20Database/Dividend_announcement_and_the_value_of_sentiment_analysis.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1080/23270012.2024.2306929;https://doi.org/10.1080/23270012.2024.2306929;Var litt weird √• bruke resultatene. Mer korrelasjon og p-verdier;;
10.24425/ijet.2025.153538;LLM-Based multi-agent system for individual investment in energy and natural resources;;Sander;Tja;;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.24425/ijet.2025.153538;https://doi.org/10.24425/ijet.2025.153538;Er mer en bot/plattform som skreddersyr investeringsforslag basert p√• real-time og brukers √∏snker.;;
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108638;Investigating the Predictive Capabilities of Large Language Models in Day Trading by Leveraging Multimodal Data;\textcite{horn_schlippe_2025};Olav;Yes;Literature%20Database/Investigating_the_Predictive_Capabilities_of_Large_Language_Models_in_Day_Trading_by_Leveraging_Multimodal_Data.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input, Financial Text Input, Multimodal Input;‚ùå;Stocks;10.1109/icnlp65360.2025.11108638;https://doi.org/10.1109/icnlp65360.2025.11108638;"Horn and Schlippe (2025) examine how six large language models‚ÄîGPT-4, GPT-4o, Llama 3, Claude 3.5,
Mistral 0.3, and Gemma 2‚Äîcan predict short-term stock movements in a day-trading setting by processing
multimodal data. Their experiments were conducted on Apple‚Äôs stock over a period of roughly 30 trading days.
The models were prompted with different types of input, including textual price histories, news articles, and
graphical price charts. The best price-prediction accuracy, measured by a Mean Absolute Percentage Error
of 1.4 percent, was achieved by Claude 3.5 and Gemma 2 when provided with textual price history and news
information. Moreover, Llama 3 obtained the highest directional accuracy, reaching an F1-score of 83 percent
when classifying market movements using combined textual data from price and news histories.";Claude-3.5, GPT-4, GPT-4o, Gemma 2, LLaMA 3, Mistral 0.3;Stock
10.1080/14765284.2023.2245279;From fiction to fact: the growing role of generative AI in business and finance;;Sondre;No;Literature%20Database/From_fiction_to_fact__the_growing_role_of_generative_AI_in_business_and_finance_compressed.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1080/14765284.2023.2245279;https://doi.org/10.1080/14765284.2023.2245279;The study does not involve direct stock price forecasting or market trend prediction.;;
10.1007/978-981-96-1758-6_20;Forex Price Prediction: A Multi-model Approach Integrating Sentiment Analysis Using LLMs with LSTM, XGBoost, Transformer Models;\textcite{dave_varastehpour_shakiba_2025};Olav;Yes;Literature%20Database/Forex_Price_Prediction-_A_Multi-model_Approach_Integrating_Sentiment_Analysis_Using_LLMs_with_LSTM_XGBoost_Transformer_Models_.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Exchange rate;10.1007/978-981-96-1758-6_20;https://doi.org/10.1007/978-981-96-1758-6_20;This study explores foreign exchange (forex) price prediction by integrating historical price data, macroeconomic indicators, and news-based market sentiment. Large Language Models (LLMs) ‚Äî GPT-4 (decoder-only) and Gemini Advanced (encoder-decoder) ‚Äî were employed for zero-shot sentiment classification of financial news headlines. Using a standardized prompt, the models assigned daily sentiment scores of +1 (positive), 0 (neutral), or ‚Äì1 (negative), which were then aggregated and aligned with a Rate of Change (ROC‚Çâ) indicator capturing price movements over a 36-hour horizon. The predictive framework combined these sentiment scores with traditional features and tested three models: LSTM, XGBoost, and Transformer. Results showed that GPT-4 achieved the strongest correlation between sentiment and price movements for EUR/USD (œÅ = 0.26) and NZD/USD (œÅ = 0.21), while Gemini Advanced performed best for EUR/NZD (œÅ = 0.19).;GPT-4;Forex
10.1117/12.3071166;Modality-aligned fine-tuning of large models for stock prediction;\textcite{zhang_2025_llama_ttpt};Olav;Yes;Literature%20Database/Modality-aligned_fine-tuning_of_large_models_for_stock_prediction.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input, Financial Text Input, Multimodal Input;‚ùå;Stock;10.1117/12.3071166;https://doi.org/10.1117/12.3071166;1.  Zhang (2025) propose LLaMA-TTPT, an efficient adaptation framework that enables frozen large language models to handle the low signal-to-noise ratio and complex dynamics of financial time-series data. The method combines a temporal-text prompt tuning mechanism to align numerical and textual modalities, a cross-attention module for multimodal fusion, and a hierarchical soft prompt propagation structure to capture both short- and long-term dependencies. Experiments on the India Nifty 50 stock market dataset demonstrate that LLaMA-TTPT surpasses mainstream temporal models, including CNN, LSTM, CNN-LSTM, and Transformer architectures, achieving the lowest MAE (62.6) and highest DPA (93.3%), compared with Transformer (135.5, 90.5%), CNN-LSTM (153.4, 90.1%), LSTM (157.8, 88.6%), and CNN (172.5, 85.7%).;LLaMA;Stock
10.5220/0013174500003890;Multimodal Stock Price Prediction;\textcite{karadas_eravci_ozbayoglu_2025};Sondre;Yes;Literature%20Database/2502.05186.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;TRUE;;;;‚ùå;Stocks;10.5220/0013174500003890;https://doi.org/10.5220/0013174500003890;Karada≈ü et al. (2025) proposes a framework that combines financial indicators, social media sentiment, and news sentiment to predict stock closing prices. ChatGPT-4o and FinBERT are used to extract sentiment features from tweets and financial articles, which are then integrated into an LSTM-based predictive model. Results show that including sentiment data improves accuracy by up to 5%, achieving an R¬≤ of 0.964 and simulated returns of 42.1%.;GPT-4o;Stock
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10881868;Comparative Analysis of LLM-based Market Prediction and Human Expertise with Sentiment Analysis and Machine Learning Integration;;Olav;Tja;Literature%20Database/Comparative_Analysis_of_LLM-based_Market_Prediction_and_Human_Expertise_with_Sentiment_Analysis_and_Machine_Learning_Integration.pdf;‚úîÔ∏è;‚úîÔ∏è;‚ùå;;;;;;‚ùå;?;10.1109/dsit61374.2024.10881868;https://doi.org/10.1109/dsit61374.2024.10881868;"Tja, fordi den baserer seg p√• BERT slik jeg tolker det.
Sammenligner Quantum (bygget p√• Transformer arkitektur inspirert av BERT og FinBERT) mot mneneskelige analytikere og mot andre LLM-er (GPT-3, GPT-4, FinGPT, FinBERT) p√• oppgaver i markeds¬≠prediksjon.
Hovedp√•standen er at Quantum sl√•r de andre modellene og (s√•vidt) menneskene, s√¶rlig i raske, data-tette situasjoner";;
10.1109/ICCA62237.2024.10927923;Enhancing Stock Price Prediction: A Hybrid Approach Leveraging Large Language Models and Deep Learning;\textcite{ahmed_ebrahim_abdelaal_2024};Sander;Yes;Literature%20Database/Enhancing_Stock_Price_Prediction_A_Hybrid_Approach_Leveraging_Large_Language_Models_and_Deep_Learning.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;;‚ùå;Stocks;10.1109/icca62237.2024.10927923;https://doi.org/10.1109/icca62237.2024.10927923;;GPT-4;Stock
10.1016/j.frl.2024.106487;Intelligent forecasting in bitcoin markets;;Sondre;No;Literature%20Database/Intelligent_forecasting_in_bitcoin_markets.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Cryptocurrency (Bitcoin);10.1016/j.frl.2024.106487;https://doi.org/10.1016/j.frl.2024.106487;\textcite{cohen_aiche_2025} explore how large language models can be applied to algorithmic trading in cryptocurrency markets. In this study, ChatGPT-01 Preview is not used to generate forecasts directly, but rather to write and refine the Python code implementing the trading algorithm. This AI-driven approach is compared with an XGBoost model and a traditional Buy-and-Hold strategy. Results show that the ChatGPT-based strategy achieved a total return of 944.85%, significantly outperforming both benchmarks.;;
10.1007/s11063-025-11787-1;Detecting Bitcoin Sentiment: Leveraging Language Model Applications in Sentiment Analysis for Bitcoin Price Prediction;\textcite{jung_lee_kim_2025};Sander;Yes;Literature%20Database/s11063-025-11787-1.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Cryptocurrency (Bitcoin);10.1007/s11063-025-11787-1;https://doi.org/10.1007/s11063-025-11787-1;;LLaMA-2-7B, LLama-3-8B;Cryptocurrency
10.3390/math13101599;MambaLLM: Integrating Macro-Index and Micro-Stock Data for Enhanced Stock Price Prediction;;Olav;Tja;Literature%20Database/MambaLLM-_Integrating_Macro-Index_and_Micro-Stock_Data_for_Enhanced_Stock_Price_Prediction.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock;10.3390/math13101599;https://doi.org/10.3390/math13101599;"Tja - Mest Encoder, Decoder kun til generering av tekstrapport av S&P500.

LLM¬† bruesk kun til genereringen av dataen hvor DeepSeek genrerer daglige tekstrapporter om S&P500. Det er kun denne delen Decoder brukes til.Eller er det Encoder etter at tekstrapporten er genrert.Teksten sendes inn i FinBERT, som lager en embedding-vektor (768 tall). Denne vektoren blir en numerisk oppsummering av markedsstemningen ‚Äì og kan derfor mates inn sammen med aksjedata i Mamba-modellen.";;
10.1007/s00521-025-11432-x;Multimodal deep learning model for bitcoin price prediction with news and market prices;;Sander;Tja;;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Cryptocurrency (Bitcoin);10.1007/s00521-025-11432-x;https://doi.org/10.1007/s00521-025-11432-x;Bruker gpt til summarize, s√• inn i ada002.;;
10.1007/978-3-031-96235-6_21;Comparative Analysis and¬†Evaluation of¬†SLMs and¬†LLMs for¬†Stock Price Movement Prediction;\textcite{van_der_leij_et_al_2025};Olav;Yes;Literature%20Database/Comparative_Analysis_and_Evaluation_of_SLMs_and_LLMs_for_Stock_Price_Movement_Prediction.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Text Input;‚ùå;Stock;10.1007/978-3-031-96235-6_21;https://doi.org/10.1007/978-3-031-96235-6_21;"Sammenligner SLM med LLM.
NB: Lagt inn i teksten

Van der Leij et al. (2025) investigate performance differences between a fine-tuned SLM, Phi-2, and a general LLM, GPT-4, in predicting stock price movements. The study uses news and tweet datasets, labelling each item UP or DOWN based on next-day price changes. Phi-2 is fine-tuned using QLoRA (Quantized Low-Rank Adaptation), while GPT-4 serves as a general model without fine-tuning. Both GPT-4 and Phi-2 with a trained adapter achieve accuracy scores exceeding random guessing (0.540). The study finds no significant performance difference between using news or tweet data individually, but combining the two datasets decreases the performance of both GPT-4 and the base Phi-2 models, while the quantized Phi-2 + trained adapter maintains similar performance across datasets";GPT-4, Phi-2;Stock
10.1371/journal.pone.0326034;Enhancing stock timing predictions based on multimodal architecture: Leveraging large language models (LLMs) for text quality improvement;\textcite{chen_et_al_2025};Sander;Yes;Literature%20Database/journal.pone.0326034.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;TRUE;;‚ùå;Stock;10.1371/journal.pone.0326034;https://doi.org/10.1371/journal.pone.0326034;;GPT-4;Stock
WOS:001431695500063;CryptoTrade: A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading;\textcite{1_li_et_al_2024};Sander;Yes;Literature%20Database/2024.emnlp-main.63.pdf;‚úîÔ∏è;‚úîÔ∏è;‚úîÔ∏è;;;;;Financial Numerical Input, Financial Text Input;‚ùå;Cryptocurrencies;;;;GPT-3.5-Turbo, GPT-4, GPT-4o;Cryptocurrency
WOS:001221698100004;Transforming sentiment analysis in the financial domain with ChatGPT;\textcite{fatouros_soldatos_kouroumali_makridis_kyriazis_2023};Sander;Yes;Literature%20Database/1-s2.0-S2666827023000610-main.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;?;10.1016/j.mlwa.2023.100508;https://doi.org/10.1016/j.mlwa.2023.100508;;GPT-3.5-Turbo;Forex
10.3390/math13030487;LLM-Augmented Linear Transformer‚ÄìCNN for Enhanced Stock Price Prediction;\textcite{zhou_zhang_yu_wang_liu_yongchareon_wang_2025};Sander;Yes;Literature%20Database/mathematics-13-00487-v2.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;TRUE;;‚ùå;Stock;10.3390/math13030487;https://doi.org/10.3390/math13030487;;GPT-4o;Stock
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963106;Research on Exchange Rate Prediction Driven by Multi-Source Heterogeneous Data: Based on Retrieval Augmented Generation and Explainable Machine Learning Models;;Sander;Tja;;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Foreign exchange;10.1109/cait64506.2024.10963106;https://doi.org/10.1109/cait64506.2024.10963106;Bruker RAG;;
10.1109/CAI64502.2025.00032;Graph LLM-Based Portfolio Management Algorithm;\textcite{qin_yi_kuruoglu_2025};Olav;Yes;Literature%20Database/Graph_LLM-Based_Portfolio_Management_Algorithm.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Text Input;‚ùå;Stock;10.1109/cai64502.2025.00032;https://doi.org/10.1109/cai64502.2025.00032;"Qin et al(2025) combines LLMs with graph-based financial networks to predict the next-day return of individual stocks. Information extracted from the financial graph is transformed into text and merged with historical return data, allowing the LLM to process it as natural language and generate a predicted return for each stock.
The proposed Graph-LLM strategy is compared against three baseline approaches: the Moving Average Cross-Over Strategy, the Momentum Strategy, and the Random Forest Strategy. Results demonstrate that the proposed Graph-LLM strategy achieves a mean cumulative return and standard deviation of (1.8658, 0.0731), outperforming traditional approaches such as Random Forest (2.1360, 0.4621), Momentum (1.65, N/A), and Moving Average (1.11, N/A) in terms of stability and consistency over time.";GPT-3;Stock
10.1016/j.iswa.2025.200496;Emulating fundamental analysts: Analytical stage-based multi-agent framework enhanced with expert guidance and Preference-Anchored Likelihood Adjustment;\textcite{xu_et_al_2025};Sondre;Yes;Literature%20Database/Emulating_fundamental_analysts__Analytical_stage-based_multi-agent_framework_enhanced_with_expert_guidance_and_Preference-Anchored_Likelihood_Adjustment.pdf;‚úîÔ∏è;‚úîÔ∏è;‚úîÔ∏è;;;;;Financial Numerical Input, Financial Text Input;‚ùå;Stock;10.1016/j.iswa.2025.200496;https://doi.org/10.1016/j.iswa.2025.200496;Xu et al. (2025) develops a multi-agent LLM framework that replicates the step-by-step reasoning of human financial analysts. Multiple LLMs (GPT-4o mini, Qwen2-7B, etc.) analyze corporate financial reports and qualitative data to produce Buy, Hold, or Sell recommendations, serving as both a predictive engine and an explainable reasoning system. Results show that the proposed framework achieves a Macro-F1 of 0.583 and MCC of 0.18, outperforming single-agent baselines in both accuracy and interpretability.;GPT-4o-mini, LLama-3-8B, Qwen-2-7B;Stock
10.1007/s11156-025-01437-x;Using Generative AI to predict the weather impact on future stock returns;;Olav;No;Literature%20Database/Using_Generative_AI_to_predict_the_weather_impact_on_future_stock_returns.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock;10.1007/s11156-025-01437-x;https://doi.org/10.1007/s11156-025-01437-x;"Y. Zhou (2025) investigates how weather events influence stock returns by leveraging ChatGPT, most likely
the GPT-4 version. Instead of using numerical data alone, the authors prompt ChatGPT to interpret written
descriptions of storms and assess whether these events are likely to impact a company‚Äôs future share price. The
findings demonstrate that ChatGPT is able to anticipate negative abnormal returns following severe weather
conditions. The results also indicate that ChatGPT‚Äôs forecasts are particularly accurate for large and financially
robust firms‚Äîthose with strong profitability, low debt levels, and high liquidity‚Äîwhich tend to experience
the sharpest price drops after extreme weather events. This pattern implies that investors often underreact to
weather-related risks, especially in larger corporations. Additionally, ChatGPT‚Äôs predictive ability appears to
be most effective in strong macroeconomic environments, including market upswings, periods of low volatility,
and high employment. This suggests that when general market optimism prevails, investors may fail to account
for the financial consequences of adverse weather events.";GPT-4;Stock
WOS:001441835400001;AT-FinGPT: Financial risk prediction via an audio-text large language model;\textcite{liu_bu_li_zhang_zhao_2025};Olav;Yes;Literature%20Database/AT-FinGPT-_Financial_risk_prediction_via_an_audio-text_large_language_model.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Audio Input, Financial Text Input, Multimodal Input;‚ùå;?;10.1016/j.frl.2025.106967;https://doi.org/10.1016/j.frl.2025.106967;\textcite{ liu_bu_li_zhang_zhao_2025}introduces AT-FinGPT, a multimodal large language model that combines audio and text data from CEO presentations and quarterly earnings calls. The audio captures tone, emotion, and tempo, which provide insights beyond the spoken words. Using a ChatGPT-based preprocessing step, the information is structured and fed into FinGPT, which is then fine-tuned to predict volatility variation and Value-at-Risk (VaR). Results show that AT-FinGPT achieves the best predictive accuracy, with an MSE of 0.192 for the CSI 300 stock pool, compared to 0.336 for FinGPT and 2.037 for GPT-3.5-Turbo. This demonstrates that integrating audio and text substantially reduces prediction errors and improves market risk assessment.;FinGPT, GPT-3.5-Turbo;Index, Stock
2-s2.0-85204009784;COMPARISON OF LEXICON-BASED METHOD, MACHINE LEARNING AND CHATGPT ON SENTIMENT ANALYSIS OF BIG CAP AND SMALL CAP COMPANIES IN UNITED STATE INDEXES;\textcite{kamil_shah_2024};Olav;Yes;Literature%20Database/COMPARISON_OF_LEXICON-BASED_METHOD_MACHINE_LEARNING_AND_CHATGPT_ON_SENTIMENT_ANALYSIS_OF_BIG_CAP_AND_SMALL_CAP_COMPANIES_IN_UNITED_STATE_INDEXES_.pdf;‚úîÔ∏è;‚ùå;‚ùå;;TRUE;;;;‚ùå;;;https://doi.org/10.48550/arXiv.2311.06221;\textcite{ kamil_shah_2024} compares the performance of three sentiment analysis approaches---lexicon-based, machine learning (Random Forest), and ChatGPT---on tweets about U.S. big-cap and small-cap companies. After data cleaning and preprocessing (removing noise, stop words, and other irrelevant elements), the refined Twitter data were analyzed using the three models to estimate tweet sentiment. Each model produced sentiment labels for all tweets, which were then compared to manually assigned ``ground truth'' labels. Random Forest achieved the highest accuracy (83.6\% for big caps and 78.8\% for small caps), followed by ChatGPT (77.4\% and 72.4\%), while the lexicon-based method performed weakest (46.5\% and 43.6\%).;GPT-3.5;Stock
10.1007/s40745-025-00637-5;Dynamic Bayesian Networks for Predicting Cryptocurrency Price Directions: Uncovering Causal Relationships;;Sondre;No;Literature%20Database/s40745-025-00637-5.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;Cryptocurrency;10.1007/s40745-025-00637-5;https://doi.org/10.1007/s40745-025-00637-5;The paper is excluded because it uses a Dynamic Bayesian Network (DBN) as the primary predictive model, with GPT-2 only serving as a weak baseline, meaning the study does not utilize an LLM as the core predictive engine.;;
10.1111/jifm.70004;Carbon Neutrality Uncertainty and the Cross-Section of Stock Returns: Evidence From China;;Sander;No;;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;?;10.1111/jifm.70004;https://doi.org/10.1111/jifm.70004;Virker ikke som brukt i prediction;;
10.3390/electronics14061090;Comparative Investigation of GPT and FinBERT‚Äôs Sentiment Analysis Performance in News Across Different Sectors;;Sander;No;Literature%20Database/electronics-14-01090.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;?;10.3390/electronics14061090;https://doi.org/10.3390/electronics14061090;Har inkludert den n√•, men litt usikker. Er ikke helt sikker p√• financila instrument;FinBERT, GPT-4o;
10.1109/ICCSP64183.2025.11088423;Prophetic markets: Multi-modal deep learning redefines stock market predictions;\textcite{chidambaram_et_al_2025};Olav;Yes;Literature%20Database/Prophetic_markets-_Multi-modal_deep_learning_redefines_stock_market_predictions.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;TRUE;;;‚ùå;Stock;10.1109/iccsp64183.2025.11088423;https://doi.org/10.1109/iccsp64183.2025.11088423;\textcite{ chidambaram_et_al_2025} introduces a novel deep learning model for stock market prediction that integrates Retrieval-Augmented Generation (RAG), LLaMA, and LSTM into a single, real-time prediction framework. RAG is employed to continuously retrieve up-to-date information about companies and market conditions, ensuring that the model is contextually current. The LLaMA model analyzes unstructured textual data‚Äîsuch as financial reports, news, and market analyses‚Äîto classify each company as positive or negative based on sentiment and contextual cues, providing a qualitative assessment. Meanwhile, the LSTM model performs a quantitative evaluation, capturing temporal patterns in technical indicators such as RSI and MACD. While the LSTM model alone achieves an accuracy of 0.65, integrating LLaMA‚Äôs textual analysis and sentiment information increases the overall system accuracy to 0.83, demonstrating that incorporating large language models significantly enhances predictive performance.;LLaMA;Stock
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11158803;Temporal Data Analytics Through Reinforced LLM Architectures for Time-Series Pattern Discovery;;Olav;No;Literature%20Database/Temporal_Data_Analytics_Through_Reinforced_LLM_Architectures_for_Time-Series_Pattern_Discovery.pdf;?;‚úîÔ∏è;‚ùå;;;;;;‚ùå;?;10.1109/icctdc64446.2025.11158803;https://doi.org/10.1109/icctdc64446.2025.11158803;Brukes kun Encoder-basert arkitektur BERT   ;;
10.1109/CIFER62890.2024.10772910;Semantic Graph Learning for Trend Prediction from Long Financial Documents;;Sondre;Tja;Literature%20Database/Semantic_Graph_Learning_for_Trend_Prediction_from_Long_Financial_Documents.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1109/cifer62890.2024.10772910;https://doi.org/10.1109/cifer62890.2024.10772910;Xia et al. (2024) proposes FLAG, a framework that predicts stock price trends based on earnings call transcripts. The model combines Abstract Meaning Representation (AMR) graphs with FinBERT embeddings to capture both semantic structure and contextual meaning from long financial texts. Using a Graph Attention Network (GATv2) for classification, FLAG achieves an accuracy of 63.7% and F1-score of 0.635, outperforming FinBERT and StockGNN baselines.;FinBERT;Stock
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11129507;Stock Market Forecasting with Pretrained Deep Learning Models;;Olav;No;Literature%20Database/Stock_Market_Forecasting_with_Pretrained_Deep_Learning_Models.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stock indices;10.1109/bigdataservice65758.2025.00026;https://doi.org/10.1109/bigdataservice65758.2025.00026;\textcite{do_chu_zhao_li_2025} investigate whether information from social media influences market movements, and whether large language models (LLMs) can utilize market sentiment in a zero-shot manner, that is, without additional training data, to improve forecasting accuracy. They employ two sentiment analysis models: the encoder‚Äìdecoder model BART-large-MNLI, used to extract detailed sentiment signals from tweets, and ChatGPT-3.5-turbo, a decoder-only model serving as a baseline for comparison. The extracted sentiment features are then fed into three different prediction models: Random Forest and Histogram-based Gradient Boosting, representing traditional machine learning methods, and TimesFM, a decoder-only LLM designed for time-series forecasting. The results demonstrate that TimesFM achieves dramatically higher predictive accuracy, approaching 100 percent when combined with BART-based sentiment, while TimesFM with ChatGPT sentiment performs slightly worse but still highly accurately. In contrast, the traditional machine learning models reach only about 50 percent accuracy using ChatGPT sentiment data. Overall, TimesFM effectively captures the temporal relationships between market reactions and social media sentiment, outperforming the classical models by a wide margin.;GPT 3.5 Turbo;Index
10.1016/j.eswa.2025.128676;In the beginning was the Word: LLM-VaR and LLM-ES;\textcite{pele_et_al_2025};Sondre;Yes;Literature%20Database/In_the_beginning_was_the_Word__LLM-VaR_and_LLM-ES_compressed.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input;‚ùå;?;10.1016/j.eswa.2025.128676;https://doi.org/10.1016/j.eswa.2025.128676;Pele et al. (2025) introduces LLM-VaR and LLM-ES, two novel methods that use GPT-3.5, GPT-4, and GPT-4o as predictive engines for financial risk forecasting. The models take historical return data as text input in a zero-shot setting to directly estimate Value-at-Risk (VaR) and Expected Shortfall (ES) without retraining. Results show that GPT-3.5 outperforms traditional models like GARCH and EWMA, achieving the most accurate short-term risk predictions, particularly in volatile markets.;GPT-3.5, GPT-4, GPT-4o;Bond, Cryptocurrency, ETF, Index
10.3390/app142411897;Large Language Models and the Elliott Wave Principle: A Multi-Agent Deep Learning Approach to Big Data Analysis in Financial Markets;;Sander;Tja;Literature%20Database/applsci-14-11897.pdf;?;?;‚ùå;;;;;;‚ùå;Stocks & cryptocurrencies;10.3390/app142411897;https://doi.org/10.3390/app142411897;Tror kanskje ja, men werid√¶,: Elliot-Wave agent;;
10.1145/3677052.3698689;ECC Analyzer: Extracting Trading Signal from Earnings Conference Calls using Large Language Model for Stock Volatility Prediction;\textcite{cao_et_al_2024};Sondre;Yes;Literature%20Database/ECC_Analyzer__Extracting_Trading_Signal_from_Earnings_Conference_Calls_using_Large_Language_Model_for_Stock_Volatility_Prediction.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;TRUE;;;‚ùå;;10.1145/3677052.3698689;https://doi.org/10.1145/3677052.3698689;Cao et al. (2024) introduces a multimodal LLM-based framework that predicts stock volatility using both the audio and text from corporate earnings calls. GPT-4 Turbo is employed in a Retrieval-Augmented Generation (RAG) pipeline to summarize transcripts and extract key financial signals, which are combined with acoustic and textual embeddings for modeling. The approach achieves a 27.7% lower MSE than previous state-of-the-art methods, demonstrating superior short-term volatility forecasting performance.;GPT-4 Turbo;Stock
WOS:000799454300035;Stock Trend Prediction using Financial Market News and BERT;;Sander;Tja;;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.5220/0010172103250332;https://doi.org/10.5220/0010172103250332;Tror bare BERT - ogs√• l√•st artikkel;;
10.1109/ACCESS.2024.3350638;Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering;;Sander;Tja;;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;?;10.1109/access.2024.3350638;https://doi.org/10.1109/access.2024.3350638;Ser p√• fine-tuning importance;;
10.1007/978-3-031-66336-9_31;Language as¬†a¬†Lens: A Hybrid Text Summarization and¬†Sentiment Analysis Approach for¬†Multiclass Stock Return Prediction;\textcite{balaneji_2024_language_as_a_lens};Olav;Yes;Literature%20Database/Language_as_a_Lens-_A_Hybrid_Text_Summarization_and_Sentiment_Analysis_Approach_for_Multiclass_Stock_Return_Prediction.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stocks;10.1007/978-3-031-66336-9_31;https://doi.org/10.1007/978-3-031-66336-9_31;The article examines how text summarization and sentiment analysis can be applied to predict hourly stock returns for six companies listed in the Dow Jones Index (2017‚Äì2020). It integrates traditional market variables such as price, volatility, and trading volume with sentiment features extracted from financial news. News data are aligned with the subsequent trading hour on the NYSE. Summaries of news articles are generated using various Natural Language Processing (NLP) tools and analyzed with VADER, FinBERT, and GPT-3.5 Turbo, where GPT is applied in a zero-shot setting. The results show that FinBERT achieves higher SHAP (Shapley Additive Explanations) values than GPT-3.5, likely due to its domain-specific training on financial texts. The authors note that the lack of optimized prompting for GPT-3.5 may have limited its performance.;GPT-3.5;Stock
10.1007/s10791-025-09573-7;Leveraging large language model as news sentiment predictor in stock markets: a knowledge-enhanced strategy;;Sander;No;;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;?;10.1007/s10791-025-09573-7;https://doi.org/10.1007/s10791-025-09573-7;;GLM2, GLM3;Sentiment Only
10.1145/3604237.3626861;Predictability of Post-Earnings Announcement Drift with Textual and Contextual Factors of Earnings Calls;;Sondre;Tja;Literature%20Database/Predictability_of_Post-Earnings_Announcement_Drift_with_Textual_and_Contextual_Factors_of_Earnings_Calls.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;Stocks;10.1145/3604237.3626861;https://doi.org/10.1145/3604237.3626861;Chung & Tanaka-Ishii (2023) examines how linguistic information from earnings call transcripts can enhance prediction of Post-Earnings Announcement Drift (PEAD). ChatGPT is used for abstractive summarization of transcripts, while Sentence-BERT generates contextual embeddings that capture semantic nuances of the discussions. These features, combined with financial and technical factors, improve predictive performance, yielding portfolio returns up to 108.5% higher than baseline models.;BERT, ChatGPT;Stock
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073620;Advancing Deep-Learning in NLP: From Network Logs to Text Classification;;Sander;Tja;Literature%20Database/Advancing_Deep-Learning_in_NLP_From_Network_Logs_to_Text_Classification.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;;;‚ùå;?;10.1109/noms57970.2025.11073620;https://doi.org/10.1109/noms57970.2025.11073620;BERT og lite results;;
2-s2.0-85209671545;LLM-Driven Knowledge Enhancement for Securities Index Prediction;\textcite{di_et_al_2025};Sander;Yes;Literature%20Database/paper6.pdf;‚úîÔ∏è;‚ùå;‚ùå;;;;TRUE;;‚ùå;Equity index;;;;;Index
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11096317;Beyond Single-Text Analysis: A Holistic Approach to Chinese Financial Sentiment;\textcite{zhang_du_2025};Sondre;Yes;Literature%20Database/Beyond_Single-Text_Analysis__A_Holistic_Approach_to_Chinese_Financial_Sentiment.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;TRUE;;;;‚ùå;?;10.1109/icaci65340.2025.11096317;https://doi.org/10.1109/icaci65340.2025.11096317;Zhang & Du (2025) develops Con-LLAMA, a context-aware sentiment analysis model that integrates titles, article content, and user comments from Chinese financial texts. The model, based on LLAMA, generates sentiment predictions that are then correlated with actual stock price movements to evaluate market relevance. Results show that Con-LLAMA achieves 81.5% accuracy and exhibits a significantly stronger correlation with stock price changes than GPT-3.5, Qwen-Turbo, or DeepSeek-v3.;Con-LLAMA, DeepSeek-V3, GPT-3.5-Turbo, Qwen;Stock
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10982029;CryptoPulse: Short-Term Cryptocurrency Forecasting with Dual-Prediction and Cross-Correlated Market Indicators;\textcite{kumar_ji_2024};Sander;Yes;Literature%20Database/CryptoPulse_Short-Term_Cryptocurrency_Forecasting_with_Dual-Prediction_and_Cross-Correlated_Market_Indicators.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Cryptocurrency;10.1109/bigdata62323.2024.10982029;https://doi.org/10.1109/bigdata62323.2024.10982029;;GPT 3.5 Turbo;Cryptocurrency
10.3390/jrfm17120537;Fin-ALICE: Artificial Linguistic Intelligence Causal Econometrics;\textcite{mccarthy_alaghband_2024};Sondre;Yes;Literature%20Database/jrfm-17-00537.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input, Financial Text Input, Multimodal Input;‚ùå;Stocks;10.3390/jrfm17120537;https://doi.org/10.3390/jrfm17120537;McCarthy & Alaghband (2024) introduces a hybrid forecasting framework that combines sentiment, supply chain, and market data for financial time-series prediction. Several LLMs (FinGPT, Time-LLM, and Lag-Llama) are used to extract linguistic and emotional features‚Äîsuch as emotion magnitude and interaction‚Äîfrom financial news, which are then fed into a Temporal Convolutional Network (TCN) for prediction. Results show that Fin-ALICE achieves the lowest MAE (0.0103) and outperforms standalone LLM forecasters, demonstrating the value of sentiment- and behavior-aware inputs for market trend prediction.;FinGPT, LLaMA 7B, Lag-LLaMA, Time-LLM;ETF, Index
10.1016/j.dss.2024.114362;Revisiting time-varying dynamics in stock market forecasting: A multi-source sentiment analysis approach with large language model;;Sander;Tja;Literature%20Database/1-s2.0-S0167923624001957-main.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚ùå;Stock;10.1016/j.dss.2024.114362;https://doi.org/10.1016/j.dss.2024.114362;BERT;;
10.54364/AAIML.2025.52216;Assessing Lag-Llama in Probabilistic Time Series Forecasting for the Indonesian Stock Market;\textcite{nasution_et_al_2025};Sondre;Yes;Literature%20Database/111752216.pdf;‚ùå;‚úîÔ∏è;‚ùå;;;;;Financial Numerical Input;‚ùå;Stock;10.54364/aaiml.2025.52216;https://doi.org/10.54364/aaiml.2025.52216;Nasution et al. (2025) evaluates the LLM-based model Lag-Llama for predicting stock prices on the Indonesian Stock Exchange. Lag-Llama is used as a probabilistic forecasting engine, generating predictive distributions for future prices of major stocks (BBCA, BMRI, AMRT) in both zero-shot and fine-tuned settings. Results show that fine-tuned Lag-Llama achieves a CRPS of 0.0195, nearly matching the Temporal Fusion Transformer (0.0179) and outperforming DeepAR (0.0270).;Lag-LLaMA;Stock
10.1111/exsy.70018;Generative AI for Finance: Applications, Case Studies and Challenges;;Sander;No;;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;?;10.1111/exsy.70018;https://doi.org/10.1111/exsy.70018;Marked as survey but only small parts of the paper talks about LLMs in financial forecasting. No references used in these parts‚Ä¶;;
10.1145/3677052.3698684;Transformers and attention-based networks in quantitative trading: a comprehensive survey;;Sondre;No;Literature%20Database/Transformers_and_attention-based_networks_in_quantitative_trading__a_comprehensive_survey.pdf;‚ùå;‚ùå;‚ùå;;;;;;‚úîÔ∏è;;10.1145/3677052.3698684;https://doi.org/10.1145/3677052.3698684;Coelho e Silva et al. (2024) provides a comprehensive review of transformer and attention-based models used in quantitative trading. It analyzes how models like GPT, BERT, FinBERT, and other transformer architectures are applied across four domains: alpha generation, risk management, portfolio construction, and trade execution. The survey concludes that transformer-based models generally outperform traditional deep learning methods in financial prediction and decision-making tasks. (Does not match our research area);;
10.1080/15427560.2025.2538879;Intraday Stock Prediction Using Sentiment Analysis: Evidence from Dividend Announcements;\textcite{alvarez_diez_et_al_2025};Olav;Yes;Literature%20Database/Intraday_Stock_Prediction_Using_Sentiment_Analysis-_Evidence_from_Dividend_Announcements.pdf;‚úîÔ∏è;‚ùå;‚ùå;TRUE;;;;;‚ùå;Stock;10.1080/15427560.2025.2538879;https://doi.org/10.1080/15427560.2025.2538879;\textcite{alvarez_diez_et_al_2025} examines how sentiment extracted from financial news using ChatGPT can be employed to predict intraday stock returns following dividend announcements for S\&P~500 companies. ChatGPT is applied as an input-enhancement tool, generating continuous sentiment polarity scores ranging from --1 (negative) to +1 (positive) for each news article. The authors verified the robustness of this approach by testing multiple prompt formulations, finding that ChatGPT produced stable and consistent sentiment values, which supports the validity of the results. Machine learning models---specifically regression models for predicting the magnitude of cumulative abnormal returns (CAR) and classification models for forecasting their direction---were then trained using these sentiment scores. The findings indicate that ChatGPT-derived sentiment significantly improves the models' ability to describe and predict intraday stock movements compared to baseline specifications.;ChatGPT;Stock