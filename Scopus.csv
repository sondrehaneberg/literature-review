"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Affiliations","Authors with affiliations","Abstract","Author Keywords","Index Keywords","Molecular Sequence Numbers","Chemicals/CAS","Funding Texts","References","Editors","Publisher","Sponsors","Conference name","Conference date","Conference location","Conference code","ISSN","ISBN","CODEN","PubMed ID","Language of Original Document","Document Type","Publication Stage","Open Access","Source","EID"
"S.L., Medha, Suporna L.; M.T., Tushar, Md Tanbin; S., Rashmi, S.; A., Reddy A, Ashish; T.R., Prajwala, T. R.","Medha, Suporna L. (59157568200); Tushar, Md Tanbin (59134122500); Rashmi, S. (60096339500); Reddy A, Ashish (60096024300); Prajwala, T. R. (57781527000)","59157568200; 59134122500; 60096339500; 60096024300; 57781527000","Predicting Startup IPO: A Data-Driven Approach Using Crunchbase Insights","2026","Communications in Computer and Information Science","2540 CCIS","","","385","397","0","0","10.1007/978-3-031-99353-4_33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015803022&doi=10.1007%2F978-3-031-99353-4_33&partnerID=40&md5=6c75810a4e6d1ebc13d27cca76c89b64","PES University, Bengaluru, India","Medha, Suporna L., Department of Computer Science and Engineering, PES University, Bengaluru, India; Tushar, Md Tanbin, Department of Computer Science and Engineering, PES University, Bengaluru, India; Rashmi, S., Department of Computer Science and Engineering, PES University, Bengaluru, India; Reddy A, Ashish, Department of Computer Science and Engineering, PES University, Bengaluru, India; Prajwala, T. R., Department of Computer Science and Engineering, PES University, Bengaluru, India","The startup ecosystem is constantly evolving, posing significant challenges for investors and venture capitalists (VCs) in identifying and evaluating the most promising startups for investment. Additionally, To address these challenges, a comprehensive solution has been developed that leverages data analytics, including Crunchbase data and machine learning models, to provide tailored insights. By integrating large language model capabilities, the platform delivers customized predictions and evaluates critical factors such as industry dynamics, funding rounds, team composition, and growth metrics, empowering users to make well-informed decisions. For investors and VCs, the platform offers a data-driven approach to identifying high-growth organizations by analyzing market trends, financial data, and various other non-financial metrics. Founders and aspiring entrepreneurs can use the platform to validate their startup ideas, analyze competitors, and explore funding opportunities, with the help of industry-specific machine learning models that assess the viability of their ventures. Startup enthusiasts can stay informed about market trends and draw inspiration from success stories, gaining deeper insights into the startup ecosystem. © 2025 Elsevier B.V., All rights reserved.","Api; Cosine Similarity; Explainable Ai; Feature Engineering; Llm; Machine Learning; Pearson Correlation; Startup Ipo Prediction; Tf-idf (term Frequency-inverse Document Frequency); Commerce; Correlation Methods; Inverse Problems; Investments; Machine Learning; Reactor Startup; Api; Cosine Similarity; Explainable Ai; Feature Engineerings; Llm; Machine-learning; Pearson Correlation; Startup Ipo Prediction; Term Frequency-inverse Document Frequency; Term Frequencyinverse Document Frequency (tf-idf); Learning Systems","Commerce; Correlation methods; Inverse problems; Investments; Machine learning; Reactor startup; API; Cosine similarity; Explainable AI; Feature engineerings; LLM; Machine-learning; Pearson correlation; Startup IPO prediction; Term frequency-inverse document frequency; Term frequencyinverse document frequency (TF-IDF); Learning systems","","","","undefined; undefined; undefined; Chatterjee, Manali, Studies on Indian IPO: systematic review and future research agenda, Qualitative Research in Financial Markets, 16, 3, pp. 477-502, (2024); Pasayat, Ajit Kumar, Factors Responsible for the Success of a Start-up: A Meta-Analytic Approach, IEEE Transactions on Engineering Management, 70, 1, pp. 342-352, (2023); Indian Start Ups Success Prediction Using Machine Learning, (2023); Kim, Jongwoo, How to succeed in the market? Predicting startup success using a machine learning approach, Technological Forecasting and Social Change, 193, (2023); Allu, Ramakrishna, Predicting the success rate of a start-up using LSTM with a swish activation function, Journal of Control and Decision, 9, 3, pp. 355-363, (2022); Ross, Greg, CapitalVX: A machine learning model for startup selection and exit prediction, Journal of Finance and Data Science, 7, pp. 94-114, (2021); Żbikowski, Kamil, A machine learning, bias-free approach for predicting business success using Crunchbase data, Information Processing and Management, 58, 4, (2021)","Li, S.","Springer Science and Business Media Deutschland GmbH","","11th International Conference on Information Management, ICIM 2025","","London","337999","18650937; 18650929","9789819671748; 9789819664610; 9783032026743; 9783032008831; 9783032026712; 9789819671779; 9783031949425; 9789819666874; 9783031936968; 9783031941207","","","English","Conference paper","Final","","Scopus","2-s2.0-105015803022"
"H., Phalangpatanakij, Harith; C., Deemee, Chanatip; S.C., Chen, S. C.; T., Thaipisutikul, Tipajin","Phalangpatanakij, Harith (60019601700); Deemee, Chanatip (58903433200); Chen, S. C. (50860891500); Thaipisutikul, Tipajin (57200143248)","60019601700; 58903433200; 50860891500; 57200143248","Stock Price Prediction Using Univariate and Multivariate Historical Data with Post-Interpretation via Large Language Models","2026","Communications in Computer and Information Science","2380 CCIS","","","30","47","0","0","10.1007/978-981-96-6291-3_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011987910&doi=10.1007%2F978-981-96-6291-3_3&partnerID=40&md5=5e532096fafabc283393103dde198f2b","Mahidol University, Nakhon Pathom, Thailand; National Chengchi University, Taipei, Taiwan","Phalangpatanakij, Harith, Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand; Deemee, Chanatip, Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand; Chen, S. C., Master's Program of Digital Content and Technologies, National Chengchi University, Taipei, Taiwan; Thaipisutikul, Tipajin, Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand","In this study, we propose a hybrid approach that utilizes both univariate and multivariate historical data from key variables and related factors across four distinct groups. We developed a hybrid approach combining Volume Features, Valuation Metrics, Technical Indicators, and Market Sentiment for stock price prediction and investigate several state-of-the-art models, including Artificial Neural Networks (ANN), Gated Recurrent Units (GRU), Bidirectional GRU (BI-GRU), and Transformer-based Time Series (TST) models, while experimenting with different lags of inputs to capture intricate temporal patterns in stock price movements. Our experiments, conducted on seven stocks from various sectors, allow us to evaluate the robustness and generalizability of the models across different industries. To enhance interpretability, we employ large language models (LLMs) in the post-prediction phase, which transform the predictive outputs into human-readable narratives explaining the factors driving stock price predictions. Empirical results demonstrate that our approach, incorporating advanced deep learning models like ANN, GRU, BI-GRU, and TST with varying input lags, significantly improves prediction accuracy over traditional methods while providing actionable insights for financial decision-making. © 2025 Elsevier B.V., All rights reserved.","Large Language Models (llm); Multivariate Analysis; Stock Price Prediction; Time Series Forecasting; Univariate Data; Decision Making; Deep Learning; Electronic Trading; Financial Markets; Forecasting; Learning Systems; Neural Networks; Prediction Models; Time Series; Time Series Analysis; Historical Data; Hybrid Approach; Language Model; Large Language Model; Multi Variate Analysis; Neural-networks; Stock Price Prediction; Time Series Forecasting; Univariate; Univariate Data; Multivariant Analysis","Decision making; Deep learning; Electronic trading; Financial markets; Forecasting; Learning systems; Neural networks; Prediction models; Time series; Time series analysis; Historical data; Hybrid approach; Language model; Large language model; Multi variate analysis; Neural-networks; Stock price prediction; Time series forecasting; Univariate; Univariate data; Multivariant analysis","","","","Proceedings of the International Conference on Emerging Trends in Engineering and Technology Icetet, (2020); J Finan Markets Algo, (2022); IEEE Access, (2020); J Finan Data Sci, (2023); Int J Finan Res, (2020); Finan Technol Rev, (2020); International Journal of Computer Science Engineering and Applications, (2014); Sherstinsky, Alex S., Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network, Physica D: Nonlinear Phenomena, 404, (2020); Proceedings of the 30th International Conference on Neural Information Processing Systems Neurips 2022, (2022); Dudukcu, Hatice Vildan, Temporal Convolutional Networks with RNN approach for chaotic time series prediction, Applied Soft Computing, 133, (2023)","Hui, L.; Hsu, C.-H.; Ruengittinun, S.","Springer Science and Business Media Deutschland GmbH","","13th International Conference on Ubi-Media Computing, Ubi-Media 2025 and 17th International Symposium on Pervasive Systems, Algorithms, and Networks, I-SPAN 2025","","Bangkok","335729","18650937; 18650929","9789819671748; 9789819664610; 9783032026743; 9783032008831; 9783032026712; 9789819671779; 9783031949425; 9789819666874; 9783031936968; 9783031941207","","","English","Conference paper","Final","","Scopus","2-s2.0-105011987910"
"R., Zhang, Rongquan; S., Bu, Siqi; G., Li, Gangqiang; J., Qiu, Jing","Zhang, Rongquan (57197718391); Bu, Siqi (59434191400); Li, Gangqiang (55534065200); Qiu, Jing (55846308000)","57197718391; 59434191400; 55534065200; 55846308000","Probabilistic prediction of photovoltaic power: A multi-task learning and large language model-based approach","2026","Renewable Energy","256","","124004","","","0","1","10.1016/j.renene.2025.124004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011756211&doi=10.1016%2Fj.renene.2025.124004&partnerID=40&md5=14ef4b514cdc95c6668481c8dd761ab8","Nanchang JiaoTong Institute, Nanchang, China; The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Huanghuai University, Zhumadian, China; Faculty of Engineering, Sydney, Australia","Zhang, Rongquan, College of Transportation, Nanchang JiaoTong Institute, Nanchang, China, Department of Electrical Engineering, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Bu, Siqi, Department of Electrical Engineering, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Li, Gangqiang, Henan International Joint Laboratory of Behavior Optimization Control for Smart Robots, Huanghuai University, Zhumadian, China; Qiu, Jing, Faculty of Engineering, Sydney, Australia","Accurate weekly probabilistic forecasting of photovoltaic power holds immense value for optimizing power generation schedules and market trading strategies. However, current research for photovoltaic power forecasting focuses on short-term prediction, and there is insufficient research on weekly probabilistic prediction, especially when data availability is limited. For this purpose, this paper proposes a weekly probabilistic photovoltaic power forecasting approach based on multi-task learning and a large language model (LLM). First, the wavelet transform is employed to decompose the photovoltaic power time series into smoother sub-frequency curves, which are predicted using a new LLM meta AI (LLaMA)-based LLM. The proposed LLM harnesses the shared feature correlations derived from multi-task learning, coupled with the robust generalization capabilities of the pre-trained LLaMA, to effectively capture intricate nonlinear characteristics of photovoltaic power under zero-shot and few-shot data. Then, to adapt to the photovoltaic power prediction task and improve the prediction accuracy, a dilated convolutional bidirectional long short-term memory-based adapter is introduced for fine-tuning the LLM. Finally, a new probabilistic forecasting approach that integrates the proposed LLM with direct probability forecasting methods is introduced to characterize uncertainties across different quantiles, and deterministic forecasting is achieved by setting the quantile to 0.5. The proposed deterministic and probabilistic forecasting performance has been validated using weekly data from two photovoltaic power stations in northwestern China, and experimental results have indicated that the proposed approach achieves an average improvement of 112.16% in the average interval sharpness metric compared with state-of-the-art benchmarks under zero-shot and few-shot data predictions. © 2025 Elsevier B.V., All rights reserved.","Deepseekr1; Fine-tuning Adapter; Large Language Model; Multi-task Learning; Photovoltaic Power; Weekly Probabilistic Forecasting; Forecasting; Learning Systems; Photovoltaics; Power Markets; Tuning; Deepseekr1; Fine Tuning; Fine-tuning Adapter; Language Model; Large Language Model; Multitask Learning; Photovoltaic Power; Probabilistic Forecasting; Probabilistic Prediction; Weekly Probabilistic Forecasting; Wavelet Transforms; Detection Method; Integrated Approach; Photovoltaic System; Power Generation; Probability; Time Series Analysis; China","Forecasting; Learning systems; Photovoltaics; Power markets; Tuning; Deepseekr1; Fine tuning; Fine-tuning adapter; Language model; Large language model; Multitask learning; Photovoltaic power; Probabilistic forecasting; Probabilistic prediction; Weekly probabilistic forecasting; Wavelet transforms; detection method; integrated approach; photovoltaic system; power generation; probability; time series analysis; China","","","This work was jointly supported by the Science and Technology Research Project of the Jiangxi Provincial Department of Education under Grant GJJ2403005 and GJJ2403008 , and in part by the Zhumadian Science and Technology Youth Innovation Special Fund under Grant Nos. QNZX202407 , and in part by the Key Science and Technology Research of Henan Province under Grant Nos. 252102210239 , and in part by the National Natural Science Foundation of China under Grant Nos. 62265007 and 32260622","Feng, Zhengkun, Hierarchical gated pooling and progressive feature fusion for short-term PV power forecasting, Renewable Energy, 247, (2025); undefined, (2025); Li, Peidu, Advancing photovoltaic panel temperature forecasting: A comparative study of numerical simulation and machine learning in two types of PV power plant, Renewable Energy, 237, (2024); Zhang, Rongquan, Multi-market P2P trading of cooling–heating-power-hydrogen integrated energy systems: An equilibrium-heuristic online prediction optimization approach, Applied Energy, 367, (2024); Zhang, Rongquan, Deep reinforcement learning based interpretable photovoltaic power prediction framework, Sustainable Energy Technologies and Assessments, 67, (2024); Thaker, Jayesh, Hybrid model for intra-day probabilistic PV power forecast, Renewable Energy, 232, (2024); Wang, Hu, Multi-prediction of electric load and photovoltaic solar power in grid-connected photovoltaic system using state transition method, Applied Energy, 353, (2024); Sabadus, Andreea, A cross-sectional survey of deterministic PV power forecasting: Progress and limitations in current approaches, Renewable Energy, 226, (2024); Pawar, Punam, Solar PV Power Forecasting Using Modified SVR with Gauss-Newton Method, pp. 226-231, (2020); Zhu, Jiebei, Short-term PV power forecast methodology based on multi-scale fluctuation characteristics extraction, Renewable Energy, 208, pp. 141-151, (2023)","","Elsevier Ltd","","","","","","18790682; 09601481","9780123750259","","","English","Article","Final","","Scopus","2-s2.0-105011756211"
"D.T., Pele, Daniel Traian; V., Bolovăneanu, Vlad; M., Lin, Minbin; R., Ren, Rui; A.T., Ginavar, Andrei Theodor; B., Spilak, Bruno; A.V., Andrei, Alexandru Victor; F.M., Toma, Filip Mihai; S., Lessmann, Stefan; W.K., Härdle, Wolfgang Karl","Pele, Daniel Traian (25960307700); Bolovăneanu, Vlad (59533677400); Lin, Minbin (57211181900); Ren, Rui (57208071255); Ginavar, Andrei Theodor (59533880300); Spilak, Bruno (57221324739); Andrei, Alexandru Victor (59451896500); Toma, Filip Mihai (59663057200); Lessmann, Stefan (6506377858); Härdle, Wolfgang Karl (6701684466)","25960307700; 59533677400; 57211181900; 57208071255; 59533880300; 57221324739; 59451896500; 59663057200; 6506377858; 6701684466","In the beginning was the Word: LLM-VaR and LLM-ES","2026","Expert Systems with Applications","295","","128676","","","0","1","10.1016/j.eswa.2025.128676","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009903193&doi=10.1016%2Fj.eswa.2025.128676&partnerID=40&md5=15fc2364ba9d22162752c15267ffdad4","Bucharest University of Economic Studies, Bucharest, Romania; Academia Româna, Bucharest, Romania; Universität Augsburg, Augsburg, Germany; California Institute of Technology, Pasadena, United States; Humboldt-Universität zu Berlin, Berlin, Germany; The University of Edinburgh, Edinburgh, United Kingdom; National Yang Ming Chiao Tung University, Hsinchu, Taiwan","Pele, Daniel Traian, Bucharest University of Economic Studies, Bucharest, Romania, Institute for Economic Forecasting, Academia Româna, Bucharest, Romania; Bolovăneanu, Vlad, Bucharest University of Economic Studies, Bucharest, Romania; Lin, Minbin, Bucharest University of Economic Studies, Bucharest, Romania; Ren, Rui, Bucharest University of Economic Studies, Bucharest, Romania, Universität Augsburg, Augsburg, Germany; Ginavar, Andrei Theodor, Bucharest University of Economic Studies, Bucharest, Romania; Spilak, Bruno, Bucharest University of Economic Studies, Bucharest, Romania; Andrei, Alexandru Victor, Bucharest University of Economic Studies, Bucharest, Romania; Toma, Filip Mihai, Bucharest University of Economic Studies, Bucharest, Romania, California Institute of Technology, Pasadena, United States; Lessmann, Stefan, Bucharest University of Economic Studies, Bucharest, Romania, School of Business and Economics, Humboldt-Universität zu Berlin, Berlin, Germany; Härdle, Wolfgang Karl, Bucharest University of Economic Studies, Bucharest, Romania, School of Business and Economics, Humboldt-Universität zu Berlin, Berlin, Germany, The University of Edinburgh, Edinburgh, United Kingdom, Department of Information Management and Finance, National Yang Ming Chiao Tung University, Hsinchu, Taiwan","This study introduces LLM-VaR and LLM-ES, novel risk estimation metrics that utilize general-purpose large language models (LLMs) for the forecasting tasks of Value at Risk (VaR) and Expected Shortfall (ES) in a zero-shot setting. Building on the input encoding mechanism of the LLMTime framework, we extend its application by defining new financial risk measures and performing an empirical evaluation of three generations of GPT models, GPT-3.5, GPT-4 and GPT-4o, versus advanced benchmark models such as GARCH with Student innovations and EWMA with Dynamic Conditional Score (DCS). Financial time series are encoded as numerical strings, allowing for model-free inference without requiring retraining. Results show that LLMs perform well when short rolling windows are used, particularly in volatile markets like cryptocurrencies. GPT-3.5 frequently outperforms or matches the performance of newer models, raising questions about model complexity, alignment, and biases. In contrast, performance deteriorates with longer windows, where the econometric models prove more reliable. Our findings demonstrate the potential of general-purpose LLMs as adaptive tools for short-horizon financial risk assessment and contribute a first-of-its-kind benchmark for LLM-based VaR/ES estimation. © 2025 Elsevier B.V., All rights reserved.","Expected Shortfall; Gpt; Large Language Models; Llm-es; Llm-var; Value At Risk; Benchmarking; Computational Linguistics; Finance; Financial Data Processing; Risk Perception; Statistical Methods; Value Engineering; Expected Shortfall; Gpt; Language Model; Large Language Model; Large Language Model-expected Shortfall; Large Language Model-value At Risk; Value At Risk; Risk Assessment","Benchmarking; Computational linguistics; Finance; Financial data processing; Risk perception; Statistical methods; Value engineering; Expected shortfall; GPT; Language model; Large language model; Large language model-expected shortfall; Large language model-value at risk; Value at Risk; Risk assessment","","","Funding text 1: This paper is supported through the European Cooperation in Science & Technology COST Action under Grant No. CA19130 - Fintech and Artificial Intelligence in Finance - Towards a transparent financial industry; the project \u201CIDA Institute of Digital Assets\u201D, CF166/15.11.2022, CN760046/23.05.2023; the project \u201CAI for Energy Finance (AI4EFin)\u201D, CF162/15.11.2022, CN760048/23.05.2023, financed under the Romania's National Recovery and Resilience Plan, Apel nr. PNRR-III-C9-2022-I8; and the Marie Sk\u0142odowska-Curie Actions under the European Union's Horizon Europe research and innovation program for the Industrial Doctoral Network on Digital Finance, acronym DIGITAL, Project No. 101119635.; Funding text 2: This paper is supported through the European Cooperation in Science & Technology COST Action under Grant No. CA19130 - Fintech and Artificial Intelligence in Finance - Towards a transparent financial industry; the project \u201CIDA Institute of Digital Assets\u201D, CF166/15.11.2022, CN760046/23.05.2023; the project \u201CAI for Energy Finance (AI4EFin)\u201D, CF162/15.11.2022, CN760048/23.05.2023, financed under the Romania\u2019s National Recovery and Resilience Plan, Apel nr. PNRR-III-C9-2022-I8; and the Marie Sk\u0142odowska-Curie Actions under the European Union\u2019s Horizon Europe research and innovation program for the Industrial Doctoral Network on Digital Finance, acronym DIGITAL, Project No. 101119635.","Risk, (2014); Ahmed, Sabeen, Transformers in Time-Series Analysis: A Tutorial, Circuits, Systems, and Signal Processing, 42, 12, pp. 7433-7466, (2023); Alexander, Carol O., Assessing the accuracy of exponentially weighted moving average models for Value-at-Risk and Expected Shortfall of crypto portfolios, Quantitative Finance, 23, 3, pp. 393-427, (2023); undefined, (2024); undefined, (2024); undefined, (1996); Bento, João, TimeSHAP: Explaining Recurrent Models through Sequence Perturbations, pp. 2565-2573, (2021); Bhatia, Gagan, FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models, Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 13064-13087, (2024); undefined, (2025); Bollerslev, Tim, Generalized autoregressive conditional heteroskedasticity, Journal of Econometrics, 31, 3, pp. 307-327, (1986)","","Elsevier Ltd","","","","","","09574174","","ESAPE","","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-105009903193"
"H., Liu, Haoquan; Y., Jian, Yiren; C., Zeng, Chen; Y., Zhao, Yunjie","Liu, Haoquan (57212038074); Jian, Yiren (57194507754); Zeng, Chen (7103181392); Zhao, Yunjie (37000276500)","57212038074; 57194507754; 7103181392; 37000276500","RNA-protein interaction prediction using network-guided deep learning","2025","Communications Biology","8","1","247","","","0","6","10.1038/s42003-025-07694-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218918853&doi=10.1038%2Fs42003-025-07694-9&partnerID=40&md5=ff4df08ef19517ddac7661f61514b8b6","Central China Normal University, Wuhan, China; Department of Computer Science, Hanover, United States; The George Washington University, Washington, D.C., United States","Liu, Haoquan, Institute of Biophysics and Department of Physics, Central China Normal University, Wuhan, China; Jian, Yiren, Department of Computer Science, Hanover, United States; Zeng, Chen, Department of Physics, The George Washington University, Washington, D.C., United States; Zhao, Yunjie, Institute of Biophysics and Department of Physics, Central China Normal University, Wuhan, China","Accurate computational determination of RNA-protein interactions remains challenging, particularly when encountering unknown RNAs and proteins. The limited number of RNAs and their flexibility constrained the effectiveness of the deep-learning models for RNA-protein interaction prediction. Here, we introduce ZHMolGraph, which integrates graph neural network and unsupervised large language models to predict RNA-protein interaction. We validate ZHMolGraph predictions on two benchmark datasets and outperform the current best methods. For the dataset of entirely unknown RNAs and proteins, ZHMolGraph shows an improvement in achieving high AUROC of 79.8% and AUPRC of 82.0%. This represents a substantial improvement of 7.1%–28.7% in AUROC and 4.6%–30.0% in AUPRC over other methods. We utilize ZHMolGraph to enhance the challenging SARS-CoV-2 RPI and unbound RNA-protein complex predictions. Such enhancements make ZHMolGraph a reliable option for genome-wide RNA-protein prediction. ZHMolGraph holds broad potential for modeling and designing RNA-protein complexes. © 2025 Elsevier B.V., All rights reserved.","Rna; Rna; Rna, Viral; Rna-binding Proteins; Protein Binding; Rna; Rna Binding Protein; Virus Rna; Artificial Neural Network; Bioinformatics; Chemistry; Coronavirus Disease 2019; Deep Learning; Genetics; Human; Metabolism; Procedures; Severe Acute Respiratory Syndrome Coronavirus 2; Virology; Computational Biology; Covid-19; Deep Learning; Humans; Neural Networks, Computer; Protein Binding; Rna, Viral; Rna-binding Proteins; Sars-cov-2","protein binding; RNA; RNA binding protein; virus RNA; artificial neural network; bioinformatics; chemistry; coronavirus disease 2019; deep learning; genetics; human; metabolism; procedures; Severe acute respiratory syndrome coronavirus 2; virology; Computational Biology; COVID-19; Deep Learning; Humans; Neural Networks, Computer; Protein Binding; RNA, Viral; RNA-Binding Proteins; SARS-CoV-2","","RNA, 63231-63-0; RNA; RNA, Viral; RNA-Binding Proteins","This work was supported by the National Natural Science Foundation of China (grant no. 12175081); Hubei Science Fund for Distinguished Young Scholars (grant no. 2024AFA077); Fundamental Research Funds for the Central Universities (grant no. CCNU22QN004 and CCNU24JCPT011). The Central China Normal University\u2019s excellent postgraduate education innovation funding project (grant no. 2024CXZZ146).","Cramer, Patrick, Organization and regulation of gene transcription, Nature, 573, 7772, pp. 45-54, (2019); Simen Zhao, Boxuan Simen, Post-transcriptional gene regulation by mRNA modifications, Nature Reviews Molecular Cell Biology, 18, 1, pp. 31-42, (2016); Statello, Luisa, Gene regulation by long non-coding RNAs and its biological functions, Nature Reviews Molecular Cell Biology, 22, 2, pp. 96-118, (2021); Gebauer, Fátima, RNA-binding proteins in human genetic disease, Nature Reviews Genetics, 22, 3, pp. 185-198, (2021); McCune, Joseph M., The dynamics of CD4+ T-cell depletion in HIV disease, Nature, 410, 6831, pp. 974-979, (2001); Wang, Huiwen, A computational study of Tat-CDK9-Cyclin binding dynamics and its implication in transcription-dependent HIV latency, Physical Chemistry Chemical Physics, 22, 44, pp. 25474-25482, (2020); Szpotkowski, Kamil, Structural studies of protein–nucleic acid complexes: A brief overview of the selected techniques, Computational and Structural Biotechnology Journal, 21, pp. 2858-2872, (2023); Guo, Li, Biochemical and structural insights into RNA binding by Ssh10b, a member of the highly conserved Sac10b protein family in archaea, Journal of Biological Chemistry, 289, 3, pp. 1478-1490, (2014); Ahmed, Mumdooh A.M., Structure of a Protein–RNA Complex by Solid-State NMR Spectroscopy, Angewandte Chemie - International Edition, 59, 17, pp. 6866-6873, (2020); Nakagawa, Ryoya, Structure and engineering of the minimal type VI CRISPR-Cas13bt3, Molecular Cell, 82, 17, pp. 3178-3192.e5, (2022)","","Nature Research","","","","","","23993642","","","39956833","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-85218918853"
"Y., Lu, Yi; J., Hao, Jinxing; X., Tang, Xuesong","Lu, Yi (60110995400); Hao, Jinxing (59664897600); Tang, Xuesong (55643138900)","60110995400; 59664897600; 55643138900","Dual-model synergy for audit opinion prediction: A collaborative LLM agent framework approach","2025","International Review of Economics and Finance","104","","104642","","","0","0","10.1016/j.iref.2025.104642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016821250&doi=10.1016%2Fj.iref.2025.104642&partnerID=40&md5=9b5542d29f08419ef4163b6e1a336cc3","Southwestern University of Finance and Economics, Chengdu, China","Lu, Yi, Southwestern University of Finance and Economics, Chengdu, China; Hao, Jinxing, Southwestern University of Finance and Economics, Chengdu, China; Tang, Xuesong, Southwestern University of Finance and Economics, Chengdu, China","By combining the capabilities of Moonshot and DeepSeek-R1, which respectively evaluate risk scores based on MD&A text information and financial data, we exploit the complementary strengths of long-context and reasoning large language models (LLMs) to help evaluate material misstatement risks in audit opinions. Our results suggest that both MD&A-based and financial-based risk evaluations effectively distinguish qualified and unqualified audit opinions, but combining them yields the best performance. In addition to the interpretative analysis text output, the combined LLM evaluation consistently outperforms logistic regression prediction that incorporates all indicators, and it achieves comparable performance compared to the sophisticated machine learning methods like gradient boosting regression and random forests. Further analysis reveals that LLMs excel in high-risk scenarios: in firms with 1) high financial constraints, 2) low internal controls, 3) low audit quality, 4) low readability, or 5) negative tone of MD&A texts. A topic model analysis has shown clear difference in the MD&A emphasis for firms the qualified and unqualified opinions given by our framework. These findings shed light on the potential role of the collaborative LLM agent framework as a tool to help auditors and investors detect financial fraud. © 2025 Elsevier B.V., All rights reserved.","Audit Opinion Prediction; Financial Fraud; Generative Ai; Large Language Model; Long-context Model; Material Misstatement Risk Assessment; Reasoning Model","","","","This work was supported by the National Natural Science Foundation of China : \u201CResearch on the Operation Effect and Mechanism of China Investor Protection Public Welfare Organizations -- Based on the Perspective of the exercise of Rights of China Investment Service Center in Merger and Reorganization\u201D [72272123]; \u201CIndependent Directors, Executive Corruption and External Environment\u201D [71672152].","Baker, Andrew C., Diversity Washing, Journal of Accounting Research, 62, 5, pp. 1661-1709, (2024); Bao, Yang, Detecting Accounting Fraud in Publicly Traded U.S. Firms Using a Machine Learning Approach, Journal of Accounting Research, 58, 1, pp. 199-235, (2020); Journal of Accounting Research, (1966); Beneish, Messod Daniel, The Detection of Earnings Manipulation, Financial Analysts Journal, 55, 5, pp. 24-36, (1999); Blei, David M., Latent Dirichlet allocation, Journal of Machine Learning Research, 3, 4-5, pp. 993-1022, (2003); Bochkay, Khrystyna, Hyperbole or reality? Investor response to extreme language in earnings conference calls, Accounting Review, 95, 2, pp. 31-60, (2020); Bozanic, Zahn, Management earnings forecasts and other forward-looking statements, Journal of Accounting and Economics, 65, 1, pp. 1-20, (2018); Breiman, Leo, Bagging predictors, Machine Learning, 24, 2, pp. 123-140, (1996); Breiman, Leo, Random forests, Machine Learning, 45, 1, pp. 5-32, (2001); Breitung, Christian, Global Business Networks, Journal of Financial Economics, 166, (2025)","","Elsevier Inc.","","","","","","10590560","","","","English","Article","Final","","Scopus","2-s2.0-105016821250"
"F., Xiao, Feng; X.T., Wang, X. T.","Xiao, Feng (58107127700); Wang, X. T. (57835044400)","58107127700; 57835044400","Evaluating the ability of large Language models to predict human social decisions","2025","Scientific Reports","15","1","32290","","","0","0","10.1038/s41598-025-17188-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014917321&doi=10.1038%2Fs41598-025-17188-7&partnerID=40&md5=cf50ceeb303fc46b7d9af807a4ec42ae","The Chinese University of Hong Kong, Shenzhen, Shenzhen, China","Xiao, Feng, Department of Psychology, The Chinese University of Hong Kong, Shenzhen, Shenzhen, China; Wang, X. T., Department of Psychology, The Chinese University of Hong Kong, Shenzhen, Shenzhen, China","Recent advances in large language models (LLMs) have highlighted their potential to predict human decisions. In two studies, we compared predictions by GPT-3.5 and GPT-4 across 51 scenarios (9,600 responses) against published data from 2,104 human participants within an evolutionary-psychology framework. We further examined our findings with GPT-4o across eight social-group and kinship conditions (1,600 responses). Our results revealed behavioral differences between humans and LLMs’ predictions: Humans showed a greater sensitivity to kinship and group size than the LLMs when making life-death decisions. LLMs align closer with humans with a higher risk-seeking preference in financial domains. While human choices followed Prospect theory’s value function (risk-averse in gains, risk-seeking in losses), LLMs often predicted reversed patterns. GPT-3.5 matched the average level of human risk preference but showed reversed framing effects; GPT-4 was indiscriminately risk-averse across social contexts. While humans were more risk-seeking in small or kin groups than in large groups, GPT-4o made the opposite predictions. Our results suggest a set of criteria for a psychological version of the Turing Test reflected in framing effects and social context-dependent risk preference involving kinship, group size, social relations, sense of fairness, self-age awareness, public vs. personal properties, and social group-dependent aspiration levels. © 2025 Elsevier B.V., All rights reserved.","Framing Effects; Generative Ai; Group Size; Group-dependent Aspiration Levels; Kinship; Social Decision-making; Adult; Decision Making; Female; High Risk Behavior; Human; Language; Large Language Model; Male; Social Behavior; Young Adult; Adult; Decision Making; Female; Humans; Language; Large Language Models; Male; Risk-taking; Social Behavior; Young Adult","adult; decision making; female; high risk behavior; human; language; large language model; male; social behavior; young adult; Adult; Decision Making; Female; Humans; Language; Large Language Models; Male; Risk-Taking; Social Behavior; Young Adult","","","","Buss, David Michael, Evolutionary psychology: The new science of the mind, pp. 1-518, (2019); Wisdom of Evolution and Rationalities of Decision Making Final Ed, (2016); Capraro, Valerio, A publicly available benchmark for assessing large language models’ ability to predict how humans balance self-interest and the interest of others, Scientific Reports, 15, 1, (2025); Administrative Behavior, (1976); Hamilton, William D., The genetical evolution of social behaviour. II, Journal of Theoretical Biology, 7, 1, pp. 17-52, (1964); Capraro, Valerio, Language-based game theory in the age of artificial intelligence, Journal of the Royal Society Interface, 21, 212, (2024); Wang, Xiaotian, Risk communication and risky choice in context: Ambiguity and ambivalence hypothesis, Annals of the New York Academy of Sciences, 1128, pp. 78-89, (2008); Hagendorff, Thilo, Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT, Nature Computational Science, 3, 10, pp. 833-838, (2023); Suri, Gaurav R., Do Large Language Models Show Decision Heuristics Similar to Humans? A Case Study Using GPT-3.5, Journal of Experimental Psychology: General, 153, 4, pp. 1066-1075, (2024); Zhao, Yukun, Risk and prosocial behavioural cues elicit human-like response patterns from AI chatbots, Scientific Reports, 14, 1, (2024)","","Nature Research","","","","","","20452322","","","40897780","English","Article","Final","","Scopus","2-s2.0-105014917321"
"Z., Piao, Zhefan; S., Zou, Shengyang; H., You, Huihui; Y., Zhao, Yingxue","Piao, Zhefan (36987203400); Zou, Shengyang (58962658100); You, Huihui (58962710600); Zhao, Yingxue (57191204322)","36987203400; 58962658100; 58962710600; 57191204322","The impact of financial technology on corporate total factor productivity: from the perspectives of competitive strategy and corporate innovation capability","2025","Technology in Society","83","","103035","","","0","0","10.1016/j.techsoc.2025.103035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012851400&doi=10.1016%2Fj.techsoc.2025.103035&partnerID=40&md5=18e746458f7e8a438ab3fa03565c7fd1","Zhejiang University of Finance and Economics, Hangzhou, China","Piao, Zhefan, School of Finance, Zhejiang University of Finance and Economics, Hangzhou, China; Zou, Shengyang, School of Finance, Zhejiang University of Finance and Economics, Hangzhou, China; You, Huihui, School of Finance, Zhejiang University of Finance and Economics, Hangzhou, China; Zhao, Yingxue, School of Finance, Zhejiang University of Finance and Economics, Hangzhou, China","This study examines the impact of FinTech development on Chinese corporate total factor productivity (TFP) using a logical framework of "" FinTech development-competitive strategy and corporate innovation-corporate TFP"". Analyzing data from Chinese A-share listed companies in Shanghai and Shenzhen (2011–2021) through web crawler text analysis and employing fixed effect and mediating effect models, we find that FinTech effectively enhances TFP by promoting differentiation strategy. Despite inhibiting cost leadership due to an adaptation dilemma, FinTech still contributes positively to overall TFP. FinTech development also correlates with increased innovation, further elevating corporate TFP. Extending the analysis to consider corporate nature, geographical location, and policy implementation reveals nuanced impacts, with non-state-owned corporations and central region corporate experiencing more significant TFP benefits from FinTech. Robustness checks using GMM, instrumental variable, LLM and Hausman-Taylor estimation validate these findings. © 2025 Elsevier B.V., All rights reserved.","Competitive Strategy; Corporate Innovation; Corporate Tfp; Financial Technology; Competition; Competitive Strategy; Corporate Innovation; Corporate Total Factor Productivity; Corporates; Financial Technology; Fixed Effects; Innovation Capability; Logical Frameworks; Text Analysis; Total Factor Productivity; Fintech; Competition (economics); Competitiveness; Corporate Strategy; Financial System; Industrial Investment; Innovation; Strategic Approach; Total Factor Productivity; China; Guangdong; Shanghai; Shenzhen","Competition; Competitive strategy; Corporate innovation; Corporate total factor productivity; Corporates; Financial technology; Fixed effects; Innovation capability; Logical frameworks; Text analysis; Total factor productivity; Fintech; competition (economics); competitiveness; corporate strategy; financial system; industrial investment; innovation; strategic approach; total factor productivity; China; Guangdong; Shanghai; Shenzhen","","","This work is partially supported by grants from the Major Humanities and Social Sciences Research Projects in Zhejiang higher education institutions (No. 2023GH031 ), Zhejiang University of Finance and Economics postgraduate research training program ( 23TYDC022 ), the China Scholarship Council (CSC, under the support of the National Scholarship Fund for Studying Abroad), and the Research Project of Zhejiang Provincial Department of Education ( Y201737633 ).","How do the Effects of Local Growth on Employment Rates Vary with Initial Labor Market Conditions, (2009); Bhutto, Sana Arz, FinTech adoption, HR competency potential, service innovation and firm growth in banking sector, Heliyon, 9, 3, (2023); Management World, (2020); Chatgpt Informed Graph Neural Network for Stock Movement Prediction, (2023); Das, Sidhartha R., Linking manufacturing and competitive strategies for successful firm performance: a review and reconceptualization, Journal of Strategy and Management, 16, 1, pp. 148-172, (2023); J Hunan Univ, (2022); Ding, Na, Fintech, financial constraints and innovation: Evidence from China, Journal of Corporate Finance, 73, (2022); Dong, Mengming Michael, A scoping review of ChatGPT research in accounting and finance, International Journal of Accounting Information Systems, 55, (2024); Fuster, Andreas, The Role of Technology in Mortgage Lending, Review of Financial Studies, 32, 5, pp. 1854-1899, (2019); China Economic Quarterly, (2020)","","Elsevier Ltd","","","","","","0160791X","","","","English","Article","Final","","Scopus","2-s2.0-105012851400"
"Y., Huang, Yiping; S., Huang, Shixin; X., Chen, Xiangjian","Huang, Yiping (59972402100); Huang, Shixin (58075198500); Chen, Xiangjian (36163082200)","59972402100; 58075198500; 36163082200","Predictive model on employee stock ownership impacting corporate performance","2025","Scientific Reports","15","1","22133","","","0","0","10.1038/s41598-025-06280-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009615560&doi=10.1038%2Fs41598-025-06280-7&partnerID=40&md5=8d7299441bd2f4b45615839e3706df65","Jiangsu University of Science and Technology, Zhenjiang, China; Yangzhou University, Yangzhou, China","Huang, Yiping, Jiangsu University of Science and Technology, Zhenjiang, China; Huang, Shixin, Jiangsu University of Science and Technology, Zhenjiang, China; Chen, Xiangjian, College of Information Engineering, Yangzhou University, Yangzhou, China","Enterprises in the context of smart manufacturing face great challenges in terms of human capital strategies as well as incentive mechanisms. Employee Stock Ownership Plans (ESOPs) is one of the key incentive mechanisms with long-term oriented function, but due to the lack of relevant explanations in the context of smart manufacturing, the mechanism of the dynamic impact of ESOPs on corporate performance has not yet been elucidated. In this study, with the idea of combining AI and accounting, we constructed a prediction model of the impact of ESOPs on enterprise performance that integrates language modeling and social sentiment mass data analysis, and introduced the prediction model to analyze the long-term, dynamic and nonlinear impact of ESOPs on enterprises; finally, we constructed an explainable AI (XAI) based on the LSTM model, and used the SHAP value method to explain the impact of ESOPs on enterprise performance. Finally, the Explainable AI (XAI) is built based on the LSTM model, and the SHAP value method is used to downsize the performance of the complex black box model LSTM, present the model “black box”, and analyze the common roles played by the elements of ESOPs, the maturity level of smart manufacturing, and the social sentiment on ESOPs in the long term and nonlinear process. Aiming at the above research problems and shortcomings, the main contributions of this paper include: analyzing the dynamic evolution path of ESOP effectiveness from the perspective of intelligent transformation of manufacturing enterprises; predicting the ESOP effectiveness of enterprises through multi-source heterogeneous data (financial data, social sentiment data, operation data) and advanced AI models (LSTM, LLM), and proposing new prediction tools and prediction theories; using XAI technology to realize ESOP effectiveness; and using XAI technology to realize ESOP effectiveness in the long term and non-linear process. Theory; the use of XAI technology to achieve ESOP incentive effect attribution analysis, for management accounting decision support to provide a new dimension of interpretation, which can be used as a research on ESOP dynamic incentive evaluation, integration of non-financial information, predictive analysis of new perspectives for the field of accounting to develop a new research direction, and for the transformation of intelligent manufacturing design and optimization of ESOP to provide empirical data basis and decision support. The study also provides empirical data basis and decision support for the design and optimization of ESOPs during the transformation of smart manufacturing. © 2025 Elsevier B.V., All rights reserved.","Artificial Intelligence And Big Data; Corporate Performance; Employee Stock Ownership Plan (esop); Incentive Mechanism; Lstm Prediction Model; Smart Manufacturing; Animal Experiment; Article; Artificial Intelligence; Big Data; Data Analysis; Decision Support System; Employee; Explainable Artificial Intelligence; Human; Incentive; Long Short Term Memory Network; Male; Organization And Management; Prediction; Predictive Model","animal experiment; article; artificial intelligence; big data; data analysis; decision support system; employee; explainable artificial intelligence; human; incentive; long short term memory network; male; organization and management; prediction; predictive model","","","","Dasilas, Apostolos, The nonlinear relationship between employee stock ownership plans and firm performance: Evidence from China, Journal of Business Research, 173, (2024); Song, Meiyi, Ownership property, it investment and firm performance, Journal of High Technology Management Research, 34, 2, (2023); Liu, Xiaoqian, The impact of government environmental attention on firms’ ESG performance: Evidence from China, Research in International Business and Finance, 67, (2024); Liu, Yijun, The implications of smart logistics policy on corporate performance: Evidence from listed companies in China, Heliyon, 10, 17, (2024); Lyu, Wenjing, Going green and profitable: The impact of smart manufacturing on Chinese enterprises, Computers and Industrial Engineering, 181, (2023); Ju, Wenxin, The impact of green innovation on the carbon performance of Chinese manufacturing enterprises: Moderating role of internal governance, Heliyon, 10, 10, (2024); Wang, Di, Differentiated digital transformation strategies in manufacturing: The impact of firm ownership on productivity, International Review of Economics and Finance, 99, (2025); Cao, Zhong, A decentralized authentication scheme for smart factory based on blockchain, Scientific Reports, 14, 1, (2024); Xu, Zhaocheng, Effects of intelligent manufacturing on the high-quality development of manufacturing industry: The mediating role of green technology innovation, Scientific Reports, 14, 1, (2024); Wang, Jinzhan, Enhancing employee performance appraisal through optimized association rule algorithms: a data mining approach, Scientific Reports, 14, 1, (2024)","","Nature Research","","","","","","20452322","","","40593046","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-105009615560"
"V., Moravec, Vaclav; B., Gavurová, Beata; N., Hynek, Nik; M., Rigelsky, Martin","Moravec, Vaclav (57217421484); Gavurová, Beata (37118698100); Hynek, Nik (35078509000); Rigelsky, Martin (57218765827)","57217421484; 37118698100; 35078509000; 57218765827","Human-machine in the vortex of digital synergy","2025","Humanities and Social Sciences Communications","12","1","691","","","0","1","10.1057/s41599-025-05014-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005455531&doi=10.1057%2Fs41599-025-05014-4&partnerID=40&md5=21bcbc24d308b7deca398e74b68854a3","Charles University, Prague, Czech Republic; Technická Univerzita v Košiciach, Kosice, Slovakia; Charles University, Prague, Czech Republic; University of Presov in Presov, Presov-Lubotice, Slovakia","Moravec, Vaclav, Institute of Formal and Applied Linguistics, Charles University, Prague, Czech Republic; Gavurová, Beata, Process Control and Geotechnologies, Technická Univerzita v Košiciach, Kosice, Slovakia; Hynek, Nik, Department of Security Studies, Charles University, Prague, Czech Republic; Rigelsky, Martin, Faculty of Management, University of Presov in Presov, Presov-Lubotice, Slovakia","This study explores whether experience with AI tools and the intensity of their use influence individuals’ adoption of ChatGPT in the Czech Republic. Using data from 1232 respondents (aged 15+), collected via a quota-based online survey from April 8 to April 26, 2024, logistic regression analyses investigated two key questions: (1) Does increased use of virtual assistants correlate with a higher likelihood of ChatGPT adoption? and (2) Does frequent ChatGPT usage predict more intensive engagement with other AI tools? Findings confirm that people who use voice/chatbots more often are significantly more likely to try ChatGPT, and vice versa. Preference for text-based assistants also correlates positively with ChatGPT adoption. Unexpectedly, a generally positive outlook on AI across sectors (banking, healthcare, customer service) does not always translate into ChatGPT usage, implying that trust or scepticism can be context-specific. Another notable insight is that ethical concerns and a strong preference for human contact consistently dampen ChatGPT uptake, suggesting that perceived privacy risks remain a critical barrier. These results highlight the importance of digital synergy in AI adoption. Policymakers and industry stakeholders can use these insights to develop targeted strategies for fostering inclusive, ethical, and sustainable digital transformation. © 2025 Elsevier B.V., All rights reserved.","","","","","This article was produced with the support of the Technology Agency of the Czech Republic under the SIGMA Programme, project TQ01000100 Newsroom AI: public service in the era of automated journalism. This paper was supported by the Scientific Grant Agency of the Ministry of Education, Research, Development and Youth of the Slovak Republic and the Slovak Academy Sciences as part of the research project VEGA No. 1/0700/25.","Adam, Martin, AI-based chatbots in customer service and their effects on user compliance, Electronic Markets, 31, 2, pp. 427-445, (2021); Ahn, Michael J., Digital transformation toward AI-augmented public administration: The perception of government employees and the willingness to use AI in government, Government Information Quarterly, 39, 2, (2022); Finance Accounting Research Journal, (2024); Anantrasirichai, Nantheera, Artificial intelligence in the creative industries: a review, Artificial Intelligence Review, 55, 1, pp. 589-656, (2022); Arifin, Anisa Aini, Ethical aspects of voice assistants: a critical discourse analysis of Indonesian media texts, Journal of Information, Communication and Ethics in Society, 20, 1, pp. 18-36, (2022); AI and Ethics, (2022); Bedué, Patrick, Can we trust AI? An empirical investigation of trust requirements and guide to successful AI adoption, Journal of Enterprise Information Management, 35, 2, pp. 530-549, (2022); Berriche, Amira, Who are voice users? The contributions of decision-making conflict theory, Journal of Consumer Marketing, 39, 7, pp. 800-813, (2022); Bernotat, Jasmin, The (Fe)male Robot: How Robot Body Shape Impacts First Impressions and Trust Towards Robots, International Journal of Social Robotics, 13, 3, pp. 477-489, (2021); Language Education and Technology, (2023)","","Springer Nature","","","","","","26629992","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105005455531"
"W., Chen, Weisi; W., Liu, Wulong; J., Zheng, Jiaxin; X., Zhang, Xu","Chen, Weisi (56093037400); Liu, Wulong (59161210100); Zheng, Jiaxin (59647406600); Zhang, Xu (57072208100)","56093037400; 59161210100; 59647406600; 57072208100","Leveraging large language model as news sentiment predictor in stock markets: a knowledge-enhanced strategy","2025","Discover Computing","28","1","74","","","0","0","10.1007/s10791-025-09573-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005003252&doi=10.1007%2Fs10791-025-09573-7&partnerID=40&md5=ca31a11d1c3e912831be23f6aff7087e","Xiamen University of Technology, Xiamen, China; Xiamen University of Technology, Xiamen, China","Chen, Weisi, School of Software Engineering, Xiamen University of Technology, Xiamen, China; Liu, Wulong, School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China; Zheng, Jiaxin, School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China; Zhang, Xu, School of Software Engineering, Xiamen University of Technology, Xiamen, China","In the fast-evolving artificial intelligence era, the intersection of natural language processing and financial analysis has attracted significant attention, primarily due to its potential to provide valuable insights into financial market behavior. Sentiment analysis of financial news articles is a crucial aspect of this intersection, providing cues about market sentiment that may affect stock price dynamics. Traditional sentiment analysis methods often rely on rules or machine learning algorithms trained on labeled datasets, but these methods face challenges in capturing the context within the text. This paper proposes a framework that incorporates prompt engineering strategies, including a novel Domain Knowledge Chain-of-Thought (DK-CoT) strategy, integrating domain-specific financial knowledge with chain-of-thought reasoning, designed to leverage and enhance the performance of large language models (LLMs) in financial news sentiment analysis. DK-CoT has been compared with various prompt engineering techniques, including zero-shot, few-shot, and chain-of-thought, as well as other benchmark models like BERT and RoBERTa. Through comprehensive experiments and evaluations, we introduce the weighted F1 score as a more practical metric, emphasizing the disproportionate impact of negative news on financial markets, which better reflects real-world financial dynamics, as negative sentiments often lead to more significant market reactions than positive or neutral sentiments. Experimental results have shown that DK-CoT adopted in an LLM called GLM is effective in improving the performance and reliability of financial news sentiment analysis. Our findings provide insights into optimal prompt designs and highlight the importance of incorporating financial knowledge to uplift LLM performance while reducing the need for extensive computational resources and fine-tuning. © 2025 Elsevier B.V., All rights reserved.","Accessible Machine Learning; Financial News; Large Language Model; Natural Language Processing; Prompt Engineering; Sentiment Analysis","","","","This research was supported by the Fujian Provincial Natural Science Foundation of China (Grant No. 2022J05291).","Cui, Jingfeng, Survey on sentiment analysis: evolution of research methods and topics, Artificial Intelligence Review, 56, 8, pp. 8469-8510, (2023); Chen, Weisi, Deep Learning for Financial Time Series Prediction: A State-of-the-Art Review of Standalone and Hybrid Models, CMES - Computer Modeling in Engineering and Sciences, 139, 1, pp. 187-224, (2023); Chatglm A Family of Large Language Models from Glm 130b to Glm 4 all Tools, (2024); Chen, Weisi, A Framework for Facilitating Reproducible News Sentiment Impact Analysis, ACM International Conference Proceeding Series, pp. 125-131, (2022); Yazdani, Sepideh Foroozan, Sentiment classification of financial news using statistical features, International Journal of Pattern Recognition and Artificial Intelligence, 31, 3, (2017); Ahmad, Hero O., Sentiment Analysis of Financial Textual data Using Machine Learning and Deep Learning Models, Informatica (Slovenia), 47, 5, pp. 153-158, (2023); Das, Nabanita, Integrating EEMD and ensemble CNN with X (Twitter) sentiment for enhanced stock price predictions, Social Network Analysis and Mining, 14, 1, (2024); Li, Wei, User reviews: Sentiment analysis using lexicon integrated two-channel CNN–LSTM​ family models, Applied Soft Computing, 94, (2020); Sharaff, Aakanksha, LSTM based Sentiment Analysis of Financial News, SN Computer Science, 4, 5, (2023); Lengkeek, Matteo, Leveraging hierarchical language models for aspect-based sentiment analysis on financial data, Information Processing and Management, 60, 5, (2023)","","Springer Science and Business Media B.V.","","","","","","29482992","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105005003252"
"M., Raza, Mubashar; Z., Jahangir, Zarmina; M.B., Riaz, Muhammad Bilal; M.J., Saeed, Muhammad Jasim; M.A., Sattar, Muhammad Awais","Raza, Mubashar (59035552400); Jahangir, Zarmina (57203283592); Riaz, Muhammad Bilal (57213314244); Saeed, Muhammad Jasim (59492252700); Sattar, Muhammad Awais (59750371300)","59035552400; 57203283592; 57213314244; 59492252700; 59750371300","Industrial applications of large language models","2025","Scientific Reports","15","1","13755","","","0","7","10.1038/s41598-025-98483-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003251970&doi=10.1038%2Fs41598-025-98483-1&partnerID=40&md5=9684c6e997680aeb21d0a4b6dfa540e6","COMSATS University Islamabad, Islamabad, Pakistan; Riphah International University, Islamabad, Pakistan; Luleå University of Technology, Lulea, Sweden; VSB – Technical University of Ostrava, Ostrava, Czech Republic; Applied Science Private University, Amman, Jordan","Raza, Mubashar, COMSATS University Islamabad, Islamabad, Pakistan; Jahangir, Zarmina, Department of Computer Science, Riphah International University, Islamabad, Pakistan; Riaz, Muhammad Bilal, IT4Innovations, VSB – Technical University of Ostrava, Ostrava, Czech Republic, Applied Science Research Center, Applied Science Private University, Amman, Jordan; Saeed, Muhammad Jasim, Department of Computer Science, Riphah International University, Islamabad, Pakistan; Sattar, Muhammad Awais, Department of Computer Science, Luleå University of Technology, Lulea, Sweden","Large language models (LLMs) are artificial intelligence (AI) based computational models designed to understand and generate human like text. With billions of training parameters, LLMs excel in identifying intricate language patterns, enabling remarkable performance across a variety of natural language processing (NLP) tasks. After the introduction of transformer architectures, they are impacting the industry with their text generation capabilities. LLMs play an innovative role across various industries by automating NLP tasks. In healthcare, they assist in diagnosing diseases, personalizing treatment plans, and managing patient data. LLMs provide predictive maintenance in automotive industry. LLMs provide recommendation systems, and consumer behavior analyzers. LLMs facilitates researchers and offer personalized learning experiences in education. In finance and banking, LLMs are used for fraud detection, customer service automation, and risk management. LLMs are driving significant advancements across the industries by automating tasks, improving accuracy, and providing deeper insights. Despite these advancements, LLMs face challenges such as ethical concerns, biases in training data, and significant computational resource requirements, which must be addressed to ensure impartial and sustainable deployment. This study provides a comprehensive analysis of LLMs, their evolution, and their diverse applications across industries, offering researchers valuable insights into their transformative potential and the accompanying limitations. © 2025 Elsevier B.V., All rights reserved.","Large Language Models; Llms; Nlp; Transformers; Artificial Intelligence; Human; Industry; Large Language Model; Natural Language Processing; Artificial Intelligence; Humans; Industry; Large Language Models; Natural Language Processing","artificial intelligence; human; industry; large language model; natural language processing; Artificial Intelligence; Humans; Industry; Large Language Models; Natural Language Processing","","","","Khurana, Diksha, Natural language processing: state of the art, current trends and challenges, Multimedia Tools and Applications, 82, 3, pp. 3713-3744, (2023); Kosch, Thomas, A Survey on Measuring Cognitive Workload in Human-Computer Interaction, ACM Computing Surveys, 55, 13s, (2023); Fundamentals of Artificial Intelligence, (2020); Introduction to Artificial Intelligence, (2023); Introduction to Natural Language Processing, (2019); Bayer, Markus, Data augmentation in natural language processing: a novel text generation approach for long and short text classifiers, International Journal of Machine Learning and Cybernetics, 14, 1, pp. 135-150, (2023); Li, Junyi, Pre-Trained Language Models for Text Generation: A Survey, ACM Computing Surveys, 56, 9, (2024); A Survey of Large Language Models, (2023); Riedl, Mark Owen, Human-centered artificial intelligence and machine learning, Human Behavior and Emerging Technologies, 1, 1, pp. 33-36, (2019); Jiang, Zhengbao, How can we know what language models know?, Transactions of the Association for Computational Linguistics, 8, pp. 423-438, (2020)","","Nature Research","","","","","","20452322","","","40258923","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-105003251970"
"O., Chaffard, O.; P., Mollá, Pablo; M., Cavazza, Marc; H., Prendinger, Helmut","Chaffard, O. (59367694000); Mollá, Pablo (60105522600); Cavazza, Marc (7007101480); Prendinger, Helmut (6701628836)","59367694000; 60105522600; 7007101480; 6701628836","Enhancing large language models for bitcoin time series forecasting","2025","Knowledge-Based Systems","330","","114449","","","0","0","10.1016/j.knosys.2025.114449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016463617&doi=10.1016%2Fj.knosys.2025.114449&partnerID=40&md5=238812e0617e1a763a643a97ec91a0a0","CARDO S.R.L., Milan, Italy; Rheinland-Pfälzische Technische Universität Kaiserslautern-Landau, Kaiserslautern, Germany; Université Paris-Saclay, Gif-sur-Yvette, France; University of Stirling, Stirling, United Kingdom; Research Organization of Information and Systems National Institute of Informatics, Tokyo, Japan","Chaffard, O., CARDO S.R.L., Milan, Italy, Rheinland-Pfälzische Technische Universität Kaiserslautern-Landau, Kaiserslautern, Germany; Mollá, Pablo, Université Paris-Saclay, Gif-sur-Yvette, France; Cavazza, Marc, University of Stirling, Stirling, United Kingdom; Prendinger, Helmut, Research Organization of Information and Systems National Institute of Informatics, Tokyo, Japan","In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection. © 2025 Elsevier B.V., All rights reserved.","Financial Time Series; Language Models; Time Series Forecasting; Data Accuracy; Data Handling; Decision Making; Deep Learning; Finance; Forecasting; Learning Systems; Prediction Models; Time Series; Benchmark Datasets; Complex Datasets; End To End; Financial Time Series; Language Model; Performance; Predictive Capabilities; Seasonality; Time Series Forecasting; Time-series Data; Financial Data Processing","Data accuracy; Data handling; Decision making; Deep learning; Finance; Forecasting; Learning systems; Prediction models; Time series; Benchmark datasets; Complex datasets; End to end; Financial time series; Language model; Performance; Predictive capabilities; Seasonality; Time series forecasting; Time-series data; Financial data processing","","","Funding text 1: This work was in part supported by the National Institute of Informatics, Tokyo. The first 2 co-authors conducted this work while enrolled in the NII International Internship program. This project was supported by funding from the Horizon Europe research and innovation programme under the Marie Sklodowska-Curie Grant Agreement, acronym: DIGITAL, No. 101119635. The authors would also like to acknowledge the support of the project \u201CIDA Institute of Digital Assets\u201D, CF166/15.11.2022, contract number CN760046/23.05.2023; of which the first co-author is a team member. [Figure presented]; Funding text 2: This work was in part supported by the National Institute of Informatics, Tokyo. The first 2 co-authors conducted this work while enrolled in the NII International Internship program. This project was supported by funding from the Horizon Europe research and innovation programme under the Marie Sklodowska-Curie Grant Agreement, acronym: DIGITAL, No. 101119635. The authors would also like to acknowledge the support of the project \u201CIDA Institute of Digital Assets\u201D, CF166/15.11.2022, contract number CN760046/23.05.2023; of which the first co-author is a team member.","undefined, (2023); undefined, (2018); Cao, Jian, Financial time series forecasting model based on CEEMDAN and LSTM, Physica A: Statistical Mechanics and its Applications, 519, pp. 127-139, (2019); Cao, Defu, Spectral temporal graph neural network for multivariate time-series forecasting, Advances in Neural Information Processing Systems, 2020-December, (2020); Vaswani, Ashish, Attention is all you need, Advances in Neural Information Processing Systems, 2017-December, pp. 5999-6009, (2017); Zeng, Ailing, Are Transformers Effective for Time Series Forecasting?, 37, pp. 11121-11128, (2023); undefined, (2023); undefined, (2023); Zhou, Tian, One Fits All: Power General Time Series Analysis by Pretrained LM, Advances in Neural Information Processing Systems, 36, (2023); Cao, Defu, TEMPO: PROMPT-BASED GENERATIVE PRE-TRAINED TRANSFORMER FOR TIME SERIES FORECASTING, (2024)","","Elsevier B.V.","","","","","","09507051","","KNSYE","","English","Article","Final","","Scopus","2-s2.0-105016463617"
"M., Zhou, Mingyu; P., Du, Pei","Zhou, Mingyu (60093050100); Du, Pei (59871533400)","60093050100; 59871533400","Multivariate events enhanced pre-trained large language model for carbon price forecasting","2025","Energy","336","","138377","","","0","0","10.1016/j.energy.2025.138377","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015423860&doi=10.1016%2Fj.energy.2025.138377&partnerID=40&md5=db6587810ebf29d8ece0cb17b28d0052","Jiangnan University, Wuxi, China","Zhou, Mingyu, School of Business, Jiangnan University, Wuxi, China; Du, Pei, School of Business, Jiangnan University, Wuxi, China","Carbon prices are affected by multiple factors, exhibiting high volatility and nonlinear complexity, making their accurate prediction still a challenging task. However, existing models are limited in scale and struggle to effectively extract complex features from high-dimensional data. Recently, pre-trained large language models have demonstrated significant performance advantages in a variety of tasks, but their application in the field of carbon price prediction remains limited. Therefore, this study proposes a multivariate event-enhanced pre-trained large language model, which is constructed based on pre-trained large language models and thus does not require large data for fine-tuning. Specifically, this study first adopts the least absolute shrinkage and selection operator method to identify the key variables that have the most significant impact on carbon price. Meanwhile, unstructured events information is quantified through text sentiment analysis techniques, thus forming a complete model input dataset. Subsequently, these datasets are sequentially processed through the input module, the frozen large language model and the output module to finally generate the prediction results. Carbon price datasets from Hubei and Shanghai carbon markets are used as study cases. The experimental results show that the proposed multivariate events enhanced pre-trained large language model exhibits significant advantages in both prediction accuracy and robustness compared with other existing artificial models. © 2025 Elsevier B.V., All rights reserved.","Carbon Price Forecasting; Large Language Model; Multivariate Prediction; Policies And News Information; Carbon; Carbon Economy; Costs; Data Mining; Large Datasets; Prediction Models; Carbon Price; Carbon Price Forecasting; High Volatility; Language Model; Large Language Model; Multiple Factors; Multivariate Prediction; News Information; Policy And News Information; Price Forecasting; Forecasting; Carbon Emission; Emissions Trading; Language; Model Test; Multivariate Analysis; Price Determination; China; Hubei; Shanghai","Carbon; Carbon Economy; Costs; Data mining; Large datasets; Prediction models; Carbon price; Carbon price forecasting; High volatility; Language model; Large language model; Multiple factors; Multivariate prediction; News information; Policy and news information; Price forecasting; Forecasting; carbon emission; emissions trading; language; model test; multivariate analysis; price determination; China; Hubei; Shanghai","","","This study was supported by the Humanities and Social Science Fund of the Ministry of Education of China (22YJCZH028) and the Fundamental Research Funds for the Central Universities (No. JUSRP124043).","Shi, Beibei, Market incentives, carbon quota allocation and carbon emission reduction: Evidence from China's carbon trading pilot policy, Journal of Environmental Management, 319, (2022); Liu, Zhu, Challenges and opportunities for carbon neutrality in China, Nature Reviews Earth and Environment, 3, 2, pp. 141-155, (2022); Sun, Lili, Will China achieve its 2060 carbon neutral commitment from the provincial perspective?, Advances in Climate Change Research, 13, 2, pp. 169-178, (2022); Lin, Boqiang, Analysis of emission reduction effects of carbon trading: Market mechanism or government intervention?, Sustainable Production and Consumption, 33, pp. 28-37, (2022); Tang, Yunen, Rethinking personal carbon trading (PCT) mechanism: A comprehensive review, Journal of Environmental Management, 344, (2023); Wang, Jujie, A novel cluster based multi-index nonlinear ensemble framework for carbon price forecasting, Environment, Development and Sustainability, 25, 7, pp. 6225-6247, (2023); Wu, Zhibin, Exploring the short-term and long-term linkages between carbon price and influence factors considering COVID-19 impact, Environmental Science and Pollution Research, 30, 22, pp. 61479-61495, (2023); Ren, Youyang, Forecasting carbon price in Hubei Province using a mixed neural model based on mutual information and Multi-head Self-Attention, Journal of Cleaner Production, 494, (2025); Jiang, Meiqin, Incorporating key features from structured and unstructured data for enhanced carbon trading price forecasting with interpretability analysis, Applied Energy, 382, (2025); Yin, Hao, Carbon emissions trading price forecasting based on temporal-spatial multidimensional collaborative attention network and segment imbalance regression, Applied Energy, 377, (2025)","","Elsevier Ltd","","","","","","03605442; 18736785","0080319424; 0080328016; 0080340016; 0080311202; 0080305326; 0080316549; 008032780X; 9780080327808","ENEYD","","English","Article","Final","","Scopus","2-s2.0-105015423860"
"Z., Wu, Zongxiao; Y., Dong, Yizhe; Y., Li, Yaoyiran; B., Shi, Baofeng","Wu, Zongxiao (58531464900); Dong, Yizhe (55898612800); Li, Yaoyiran (57219819206); Shi, Baofeng (55853837600)","58531464900; 55898612800; 57219819206; 55853837600","Unleashing the power of text for credit default prediction: Comparing human-written and generative AI-refined texts","2025","European Journal of Operational Research","326","3","","691","706","0","0","10.1016/j.ejor.2025.04.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003913138&doi=10.1016%2Fj.ejor.2025.04.032&partnerID=40&md5=8ba8866af709f36c0e151b10becef2f4","University of Edinburgh Business School, Edinburgh, United Kingdom; University of Cambridge, Cambridge, United Kingdom; Northwest A&F University, Yangling, China","Wu, Zongxiao, University of Edinburgh Business School, Edinburgh, United Kingdom; Dong, Yizhe, University of Edinburgh Business School, Edinburgh, United Kingdom; Li, Yaoyiran, Language Technology Lab, University of Cambridge, Cambridge, United Kingdom; Shi, Baofeng, College of Economics and Management, Northwest A&F University, Yangling, China","This study explores the integration of a representative large language model, ChatGPT, into lending decision-making with a focus on credit default prediction. Specifically, we use ChatGPT to analyse and interpret loan assessments written by loan officers and generate refined versions of these texts. Our comparative analysis reveals significant differences between generative artificial intelligence (AI)-refined and human-written texts in terms of text length, semantic similarity, and linguistic representations. Using deep learning techniques, we show that incorporating unstructured text data, particularly ChatGPT-refined texts, alongside conventional structured data significantly enhances credit default predictions. Furthermore, we demonstrate how the contents of both human-written and ChatGPT-refined assessments contribute to the models’ prediction and show that the effect of essential words is highly context-dependent. Moreover, we find that ChatGPT's analysis of borrower delinquency contributes the most to improving predictive accuracy. We also evaluate the business impact of the models based on human-written and ChatGPT-refined texts, and find that, in most cases, the latter yields higher profitability than the former. This study provides valuable insights into the transformative potential of generative AI in financial services. © 2025 Elsevier B.V., All rights reserved.","Credit Risk; Generative Ai; Large Language Model; Or In Banking; Text Mining; Decision Making; Comparative Analyzes; Credit Risks; Decisions Makings; Generative Artificial Intelligence; Language Model; Large Language Model; Or In Banking; Power; Text-mining; Written Texts; Deep Learning","Decision making; Comparative analyzes; Credit risks; Decisions makings; Generative artificial intelligence; Language model; Large language model; OR in banking; Power; Text-mining; Written texts; Deep learning","","","The authors would like to express their sincere gratitude to the associate editor and three anonymous reviewers for their constructive feedback, which helped to improve the quality of this paper significantly. We also thank Galina Andreeva, Anthony Bellotti, Cristi\u00E1n Bravo, Raffaella Calabrese, Jonathan Crook, Johannes Kriebel, Jianping Li, Zhiyong Li, Gbenga Ibikunle, Tong Wang, Zhao Wang, Zhipeng Zhang, Huimin Zhao and conference and seminar participants at Credit Scoring & Credit Control Conference XVIII, Chinese Economics Association 2023 Annual Conference, University of Chinese Academy of Sciences, Dalian University of Technology, Dongbei University, Nanjing Agricultural University, and Yunnan University of Finance and Economics for their helpful feedback. Dong thanks for financial support from UoE Big Ideas Accelerator Fund (2023) and Credit Research Centre Small Grant (2024), and Shi thanks for financial support from the Major Project of the National Social Science Foundation of China (No. 23&ZD175) and the National Natural Science Foundation of China (Nos. 71873103, 72173096).","View in Article, (2023); Ssrn Electronic Journal, (2023); Machine Learning with Applications, (2024); Bazley, William J., Visual finance: The pervasive effects of red on investor behavior, Management Science, 67, 9, pp. 5616-5641, (2021); Berg-Kirkpatrick, Taylor, An empirical investigation of statistical significance in NLP, pp. 995-1005, (2012); Blei, David M., Latent Dirichlet allocation, Journal of Machine Learning Research, 3, 4-5, pp. 993-1022, (2003); Transactions of the Association for Computational Linguistics, (2017); Cao, Yi, Bridging the gap–the impact of ChatGPT on financial research, Journal of Chinese Economic and Business Studies, 21, 2, pp. 177-191, (2023); Chen, Boyang, From fiction to fact: the growing role of generative AI in business and finance, Journal of Chinese Economic and Business Studies, 21, 4, pp. 471-496, (2023); Information Systems Research, (2023)","","Elsevier B.V.","","","","","","03772217","","EJORD","","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-105003913138"
"D., Guariso, Daniele; R.A., Adewoyin, Rilwan A.; G.R., Aguilar, Gisela Robles; O.A., Guerrero, Omar A.; A.R., Davies, Alisha Ruth","Guariso, Daniele (57226808282); Adewoyin, Rilwan A. (57219621345); Aguilar, Gisela Robles (57219225197); Guerrero, Omar A. (55511204700); Davies, Alisha Ruth (57190488981)","57226808282; 57219621345; 57219225197; 55511204700; 57190488981","A generalized LLMs framework to support public health financing through probabilistic predictions and uncertainty quantification","2025","Artificial Intelligence in Medicine","168","","103203","","","0","0","10.1016/j.artmed.2025.103203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011028295&doi=10.1016%2Fj.artmed.2025.103203&partnerID=40&md5=cf69f4311ca7a50b85c325a1fab29e1b","Fondazione Centro Euro-Mediterraneo sui Cambiamenti Climatici, Lecce, Italy; The Alan Turing Institute, London, United Kingdom; European Centre for Medium-Range Weather Forecasts, Reading, United Kingdom; Nuffield Department of Medicine, Oxford, United Kingdom; Fundación Espinosa Rugarcía, Mexico; Public Health Wales, Cardiff, United Kingdom","Guariso, Daniele, Fondazione Centro Euro-Mediterraneo sui Cambiamenti Climatici, Lecce, Italy, The Alan Turing Institute, London, United Kingdom; Adewoyin, Rilwan A., European Centre for Medium-Range Weather Forecasts, Reading, United Kingdom; Aguilar, Gisela Robles, Nuffield Department of Medicine, Oxford, United Kingdom; Guerrero, Omar A., The Alan Turing Institute, London, United Kingdom, Fundación Espinosa Rugarcía, Mexico; Davies, Alisha Ruth, Public Health Wales, Cardiff, United Kingdom","As a systemic problem, public health cannot be addressed without considering other policy dimensions. Hence, a holistic approach across public policy areas is necessary to incorporate Health-for-All values into decision-making. However, such multisectoral interventions require public budgets that are effectively mapped into public health outcomes and indicators of their wider determinants. This budget-tagging procedure is high-cost, given that it is often done manually by domain experts. In this paper, we propose Categorical Perplexity-based Uncertainty Quantification (CPUQ), a novel, cost-effective Large Language Models (LLMs) framework that can be leveraged by policymakers to build budget-to-indicator and indicator-to-indicator mappings. This model-agnostic method employs categorical-style prompts to generate interpretable Bernoulli and categorical distributions for edges in a Text-attributed Graph, which is associated with the descriptions of the budget items and indicators. The prompting strategy proposed provides a novel way to incorporate models’ uncertainty within the final outputs, enhancing accuracy and safety, We find that the budget-to-indicator mapping predicted by the framework aligns effectively with expert annotations, while when prompted to infer indicator-to-indicator networks, CPUQ estimates more nuanced relationships compared to alternative LLMs-based methods. Through our work, we hope to provide valuable insights into the strengths and weaknesses of leveraging LLMs to support public health budget planning, with the aim of promoting the implementation of the Health-for-All agenda across diverse governments and institutions. © 2025 Elsevier B.V., All rights reserved.","Health-for-all; Large Language Models; Prompt Engineering; Public Health Financing; Uncertainty Quantification; Wider Determinants Of Health; Budget Control; Decision Making; Public Health; Public Policy; Uncertainty Analysis; Determinants Of Healths; Health-for-all; Language Model; Large Language Model; Modelling Framework; Probabilistic Prediction; Prompt Engineering; Public Health Financing; Uncertainty Quantifications; Wide Determinant Of Health; Cost Effectiveness; Article; Artificial Intelligence; Budget; Conceptual Framework; Decision Making; Financial Management; Government; Health Outcome; Human; Large Language Model; Methodology; Policy; Prediction; Probability; Prompt Engineering; Public Health; Uncertainty; Validation Study; Cost Benefit Analysis; Economics; Budgets; Cost-benefit Analysis; Humans; Public Health; Uncertainty","Budget control; Decision making; Public health; Public policy; Uncertainty analysis; Determinants of healths; Health-for-all; Language model; Large language model; Modelling framework; Probabilistic prediction; Prompt engineering; Public health financing; Uncertainty quantifications; Wide determinant of health; Cost effectiveness; Article; artificial intelligence; budget; conceptual framework; decision making; financial management; government; health outcome; human; large language model; methodology; policy; prediction; probability; prompt engineering; public health; uncertainty; validation study; cost benefit analysis; economics; Budgets; Cost-Benefit Analysis; Humans; Public Health; Uncertainty","","","The authors acknowledge funding from the Engineering and Physical Sciences Research Council (EPSRC), United Kingdom. Grant code: EP/T001569/1. The funding source had no involvement in the development of the research.","undefined, (2023); Collins, Téa E., Converging global health agendas and universal health coverage: financing whole-of-government action through UHC+, The Lancet Global Health, 11, 12, pp. e1978-e1985, (2023); Counc Brief, (2022); undefined, (2023); Anderson, Michael, Beyond gross domestic product for New Zealand's wellbeing budget, The Lancet Public Health, 4, 7, pp. e320-e321, (2019); Health Financing and Budgeting Reforms in Gabon Progress and Challenges on the Road to Universal Health Coverage, (2020); Budgeting for Results in Health Key Features Achievements and Challenges in Peru 9240004432, (2020); Transition to Programme Budgeting in Uganda Status of the Reform and Preliminary Lessons for Health, (2021); undefined, (2020); Guariso, Daniele, Automatic SDG budget tagging: Building public financial management capacity through natural language processing, Data and Policy, 5, (2023)","","Elsevier B.V.","","","","","","18732860; 09333657","9789051991413; 905199141X","AIMEE","40690805","English","Article","Final","","Scopus","2-s2.0-105011028295"
"O., Mutian, Ouyang; J.J., Thomas, J. Joshua; Y., Tianzhou, Yu; U., Fiore, Ugo","Mutian, Ouyang (59763393900); Thomas, J. Joshua (57783326100); Tianzhou, Yu (59762769300); Fiore, Ugo (8895749600)","59763393900; 57783326100; 59762769300; 8895749600","LLM-guided semantic feature selection for interpretable financial market forecasting in low-resource financial markets","2025","Franklin Open","12","","100359","","","0","0","10.1016/j.fraope.2025.100359","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016149363&doi=10.1016%2Fj.fraope.2025.100359&partnerID=40&md5=8bc0dd9fc50a7c0741aaba8aad8f029b","UOW Malaysia KDU Penang University College, Georgetown, Malaysia; UNSW Sydney, Sydney, Australia; Università degli Studi di Salerno, Salerno, Italy","Mutian, Ouyang, Department of Computing, UOW Malaysia KDU Penang University College, Georgetown, Malaysia; Thomas, J. Joshua, Department of Computing, UOW Malaysia KDU Penang University College, Georgetown, Malaysia; Tianzhou, Yu, Faculty of Engineering, UNSW Sydney, Sydney, Australia; Fiore, Ugo, Department of Computer Science, Università degli Studi di Salerno, Salerno, Italy","Feature selection is critical for accurate and interpretable financial forecasting, particularly in data-scarce environments. This study introduces a semantic feature selection framework empowered by GPT-4, which ranks financial indicators through prompt engineering and retrieval-augmented descriptions. Using weekly macro-financial data from the Malaysian equity market, including the FTSE Bursa Malaysia KLCI index obtained via the yfinance API, the proposed method is integrated with XGBoost and evaluated against multiple baselines. Results show that the LLM-based approach achieves the best forecasting accuracy, with RMSE = 12.82, MSE = 164.38, and R2 = 0.75, consistently outperforming alternatives across different feature sizes and time windows. These findings highlight the effectiveness of semantic feature selection in improving predictive accuracy, robustness, and interpretability, offering a promising direction for financial forecasting in low-resource settings. © 2025 Elsevier B.V., All rights reserved.","Data-centric Ai; Financial Forecasting; Large Language Models; Semantic Feature Selection; Time Series; Commerce; Data Accuracy; Electronic Trading; Feature Extraction; Forecasting; Semantics; Time Series; Data Centric; Data-centric Ai; Features Selection; Financial Forecasting; Language Model; Large Language Model; Market Forecasting; Semantic Feature Selection; Semantic Features; Times Series; Financial Markets","Commerce; Data accuracy; Electronic trading; Feature extraction; Forecasting; Semantics; Time series; Data centric; Data-centric AI; Features selection; Financial forecasting; Language model; Large language model; Market forecasting; Semantic feature selection; Semantic features; Times series; Financial markets","","","","Expert Syst Appl, (2022); ACM Trans Knowl Discov Data Tkdd, (2022); IEEE Access, (2022); Appl Soft Comput, (2022); Appl Soft Comput, (2021); Fischer, Thomas Günter, Deep learning with long short-term memory networks for financial market predictions, European Journal of Operational Research, 270, 2, pp. 654-669, (2018); A Survey on Evaluation of Large Language Models, (2023); A Survey of Large Language Models, (2023); A Comprehensive Overview of Large Language Models, (2023); Chatgpt is Not Enough Enhancing Large Language Models with Knowledge Graphs for Fact Aware Language Modeling, (2023)","","Elsevier B.V.","","","","","","27731863; 27731871","","","","English","Article","Final","","Scopus","2-s2.0-105016149363"
"A., Mamun, Abdullah; A., Arefeen, Asiful; S.B., Racette, Susan B.; D.D., Sears, Dorothy D.; C.M., Whisner, Corrie M.; M.P., Buman, Matthew P.; H., Ghasemzadeh, Hassan","Mamun, Abdullah (57892297500); Arefeen, Asiful (57216612138); Racette, Susan B. (6603921261); Sears, Dorothy D. (22951904900); Whisner, Corrie M. (55905818500); Buman, Matthew P. (23388260400); Ghasemzadeh, Hassan (24470943700)","57892297500; 57216612138; 6603921261; 22951904900; 55905818500; 23388260400; 24470943700","LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral Treatment Pathways from Wearables and Diet","2025","Sensors","25","17","5372","","","0","0","10.3390/s25175372","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015895257&doi=10.3390%2Fs25175372&partnerID=40&md5=24199354c918e9b6b6cf76fa327c5618","Arizona State University Downtown Phoenix Campus, Phoenix, United States; School of Computing and Augmented Intelligence, Tempe, United States","Mamun, Abdullah, Arizona State University Downtown Phoenix Campus, Phoenix, United States, School of Computing and Augmented Intelligence, Tempe, United States; Arefeen, Asiful, Arizona State University Downtown Phoenix Campus, Phoenix, United States; Racette, Susan B., Arizona State University Downtown Phoenix Campus, Phoenix, United States; Sears, Dorothy D., Arizona State University Downtown Phoenix Campus, Phoenix, United States; Whisner, Corrie M., Arizona State University Downtown Phoenix Campus, Phoenix, United States; Buman, Matthew P., Arizona State University Downtown Phoenix Campus, Phoenix, United States; Ghasemzadeh, Hassan, Arizona State University Downtown Phoenix Campus, Phoenix, United States","Postprandial hyperglycemia, marked by the blood glucose level exceeding the normal range after consuming a meal, is a critical indicator of progression toward type 2 diabetes in people with prediabetes and in healthy individuals. A key metric for understanding blood glucose dynamics after eating is the postprandial Area Under the Curve (AUC). Predicting postprandial AUC in advance based on a person’s lifestyle factors, such as diet and physical activity level, and explaining the factors that affect postprandial blood glucose could allow an individual to adjust their behavioral choices accordingly to maintain normal glucose levels. In this work, we develop an explainable machine learning solution, GlucoLens, that takes sensor-driven inputs and utilizes advanced data processing, large language models, and trainable machine learning models to estimate postprandial AUC and predict hyperglycemia from diet, physical activity, and recent glucose patterns. We use data obtained using wearables in a five-week clinical trial of 10 adults who worked full-time to develop and evaluate the proposed computational model that integrates wearable sensing, multimodal data, and machine learning. Our machine learning model takes multimodal data from wearable activity and glucose monitoring sensors, along with food and work logs, and provides an interpretable prediction of the postprandial glucose patterns. GlucoLens achieves a normalized root mean squared error (NRMSE) of 0.123 in its best configuration. On average, the proposed technology provides a 16% better predictive performance compared to the comparison models. Additionally, our technique predicts hyperglycemia with an accuracy of 79% and an F1 score of 0.749 and recommends different treatment options to help avoid hyperglycemia through diverse counterfactual explanations. With systematic experiments and discussion supported by established prior research, we show that our method is generalizable and consistent with clinical understanding. © 2025 Elsevier B.V., All rights reserved.","Continuous Glucose Monitoring; Diabetes; Hyperglycemia; Large Language Models; Machine Learning; Metabolic Health; Blood Glucose; Behavioral Research; Blood; Data Handling; Forecasting; Glucose; Glucose Sensors; Learning Algorithms; Learning Systems; Machine Learning; Nutrition; Wearable Sensors; Areas Under The Curves; Blood Glucose; Continuous Glucose Monitoring; Hyperglycaemia; Language Model; Large Language Model; Machine Learning Models; Machine-learning; Metabolic Health; Multi-modal; Medical Problems; Adult; Blood; Diagnosis; Diet; Exercise; Female; Glucose Blood Level; Human; Hyperglycemia; Machine Learning; Male; Middle Aged; Non Insulin Dependent Diabetes Mellitus; Physiology; Postprandial State; Self-monitoring Blood Glucose; Wearable Electronic Device; Adult; Blood Glucose; Blood Glucose Self-monitoring; Diabetes Mellitus, Type 2; Diet; Exercise; Female; Humans; Hyperglycemia; Machine Learning; Male; Middle Aged; Postprandial Period; Wearable Electronic Devices","Behavioral research; Blood; Data handling; Forecasting; Glucose; Glucose sensors; Learning algorithms; Learning systems; Machine learning; Nutrition; Wearable sensors; Areas under the curves; Blood glucose; Continuous glucose monitoring; Hyperglycaemia; Language model; Large language model; Machine learning models; Machine-learning; Metabolic health; Multi-modal; Medical problems; adult; blood; diagnosis; diet; exercise; female; glucose blood level; human; hyperglycemia; machine learning; male; middle aged; non insulin dependent diabetes mellitus; physiology; postprandial state; self-monitoring blood glucose; wearable electronic device; Adult; Blood Glucose; Blood Glucose Self-Monitoring; Diabetes Mellitus, Type 2; Diet; Exercise; Female; Humans; Hyperglycemia; Machine Learning; Male; Middle Aged; Postprandial Period; Wearable Electronic Devices","","Blood Glucose","A. Mamun was supported in part by the National Science Foundation under grant 2227002. A. Arefeen was supported in part by the National Institute of Diabetes and Digestive and Kidney Diseases of the National Institutes of Health under award number T32DK137525. Funding for the WorkWell study was provided by Arizona State University College of Health Solutions Translational Science Award to the Metabolic Health Translational Team. The project was also supported by the College of Health Solutions\u2019 Clinical and Community Translational Science Initiative. The College of Health Solutions did not contribute to the study design and was not involved in the implementation, analysis, or interpretation of study results. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding organizations.","Vaghasiya, Jayraj Vinubhai, Wearable sensors for telehealth based on emerging materials and nanoarchitectonics, npj Flexible Electronics, 7, 1, (2023); Clubbs Coldron, Benjamin M., Use of Continuous Glucose Monitoring in Non-ICU Hospital Settings for People With Diabetes: A Scoping Review of Emerging Benefits and Issues, Journal of Diabetes Science and Technology, 17, 2, pp. 467-473, (2023); Uddin, Md Zia, Human activity recognition using wearable sensors, discriminant analysis, and long short-term memory-based neural structured learning, Scientific Reports, 11, 1, (2021); Mamun, Abdullah, Multimodal Time-Series Activity Forecasting for Adaptive Lifestyle Intervention Design, (2022); Shields, Stephen, Continuous glucose monitoring among adults with type 2 diabetes receiving noninsulin or basal insulin therapy in primary care, Scientific Reports, 14, 1, (2024); Steck, Andrea K., Continuous Glucose Monitoring Predicts Progression to Diabetes in Autoantibody Positive Children, Journal of Clinical Endocrinology and Metabolism, 104, 8, pp. 3337-3344, (2019); Mamun, Abdullah, Designing Deep Neural Networks Robust to Sensor Failure in Mobile Health Environments, Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings, 2022-July, pp. 2442-2446, (2022); Maray, Nader, Transfer Learning on Small Datasets for Improved Fall Detection, Sensors, 23, 3, (2023); Soumma, Shovito Barua, Domain-Informed Label Fusion Surpasses LLMs in Free-Living Activity Classification, Proceedings of the AAAI Conference on Artificial Intelligence, 39, 28, pp. 29495-29497, (2025); Pickup, John C., Real-time continuous glucose monitoring in type 1 diabetes: A qualitative framework analysis of patient narratives, Diabetes Care, 38, 4, pp. 544-550, (2015)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","14248220","","","40942802","English","Article","Final","","Scopus","2-s2.0-105015895257"
"M., Metzger, Michael; S., O'Reilly, Sean; C., Mac an Bhaird, Ciarán","Metzger, Michael (59998098400); O'Reilly, Sean (57226653991); Mac an Bhaird, Ciarán (25931050800)","59998098400; 57226653991; 25931050800","Generative artificial intelligence augmenting SME financial management","2025","Technovation","147","","103313","","","0","0","10.1016/j.technovation.2025.103313","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010689210&doi=10.1016%2Fj.technovation.2025.103313&partnerID=40&md5=ac66d3a55ed9c3f042f0f2b74626914a","University College Dublin, Dublin, Ireland; Dublin City University, Dublin, Ireland","Metzger, Michael, University College Dublin, Dublin, Ireland, Dublin City University, Dublin, Ireland; O'Reilly, Sean, University College Dublin, Dublin, Ireland; Mac an Bhaird, Ciarán, Dublin City University, Dublin, Ireland","This study investigates the potential for entrepreneurs to leverage advances in technological innovation, specifically generative Artificial Intelligence (AI), to build management capability to mitigate business and financial risks. Drawing on theories of Technology Affordances and Constraints and the Resource-Based View (RBV) of the firm, recognising that small and medium-sized enterprises (SMEs) are inherently resource-constrained. We examine how AI-generated financial diagnostics can empower SMEs by generating accessible, real-time analysis and insights, thus bolstering the management function and increasing chances of survival and growth. Using a dataset of 1,150 UK SMEs spanning eight years of financial statements, we test a large language model (LLM) prediction assessment and analyse the potential for SMEs to utilise the technology, notwithstanding enterprise-specific constraints. We conclude that AI may be a very effective tool for smaller enterprises to augment the financial management function, although its efficacy hinges on organisational readiness, competence in interpreting data, and the will to act on automated red-flag alerts. These findings offer practical guidance for SMEs seeking to enhance their financial management processes in today's digital era. © 2025 Elsevier B.V., All rights reserved.","Artificial Intelligence; Digital Technologies; Financial Management; Going Concern; Predictive Modelling; Smes; Finance; Information Management; Business Risks; Digital Technologies; Enterprise's Financial Managements; Financial Managements; Going Concern; Management Capabilities; Management Functions; Predictive Models; Small And Medium-sized Enterprise; Technological Innovation; Artificial Intelligence","Finance; Information management; Business risks; Digital technologies; Enterprise's financial managements; Financial managements; Going concern; Management capabilities; Management functions; Predictive models; Small and medium-sized enterprise; Technological innovation; Artificial intelligence","","","","Alaka, Hafiz A., Systematic review of bankruptcy prediction models: Towards a framework for tool selection, Expert Systems with Applications, 94, pp. 164-184, (2018); Albadarin, Yazid, A systematic literature review of empirical research on ChatGPT in education, Discover Education, 3, 1, (2024); An, Jiafu, Finance, technology and disruption, European Journal of Finance, 27, 4-5, pp. 334-345, (2021); Autio, Erkko, Digital affordances, spatial affordances, and the genesis of entrepreneurial ecosystems, Strategic Entrepreneurship Journal, 12, 1, pp. 72-95, (2018); Baden-Fuller, Charles W.F., Business Models and Technological Innovation, Long Range Planning, 46, 6, pp. 419-426, (2013); Barney, Jay Bryan, Firm Resources and Sustained Competitive Advantage, Journal of Management, 17, 1, pp. 99-120, (1991); Beck, Thorsten, Financing patterns around the world: Are small firms different?, Journal of Financial Economics, 89, 3, pp. 467-487, (2008); Beliaeva, Tatiana, Dynamics of digital entrepreneurship and the innovation ecosystem: A multilevel perspective, International Journal of Entrepreneurial Behaviour and Research, 26, 2, pp. 266-284, (2020); MIS Quarterly, (2021); Berthelot, Sylvie, Management control systems and the presence of a full-time accountant: An empirical study of small - And medium-sized enterprises (SMEs), Advances in Management Accounting, 27, pp. 207-242, (2016)","","Elsevier Ltd","","","","","","01664972","","TNVTD","","English","Article","Final","","Scopus","2-s2.0-105010689210"
"X., Wang, Xiang; H., Ren, Hao; G., Tan, Guozhen; J., Li, Jianping; J., Wang, Jue; Y., Wang, Yanli","Wang, Xiang (57869895000); Ren, Hao (60086459300); Tan, Guozhen (55647325700); Li, Jianping (57571877000); Wang, Jue (60086858300); Wang, Yanli (55733974900)","57869895000; 60086459300; 55647325700; 57571877000; 60086858300; 55733974900","Autonomous Driving Decision-making Method Based on Cooperative Reinforcement Learning of Large Language Model; 大语言模型协同强化学习的自动驾驶决策方法","2025","Jiaotong Yunshu Xitong Gongcheng Yu Xinxi/ Journal of Transportation Systems Engineering and Information Technology","25","4","","137","161","0","0","10.16097/j.cnki.1009-6744.2025.04.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015142872&doi=10.16097%2Fj.cnki.1009-6744.2025.04.014&partnerID=40&md5=bd65488ae73eb7be1099e746e3a017e1","Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Tsinghua University, Beijing, China","Wang, Xiang, School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Ren, Hao, Department of Precision Instrument, Tsinghua University, Beijing, China; Tan, Guozhen, School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Li, Jianping, School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Wang, Jue, School of Control Science and Engineering, Dalian University of Technology, Dalian, China; Wang, Yanli, School of Computer Science and Technology, Dalian University of Technology, Dalian, China","Aiming at the problems that the high- level decision- making of the current autonomous driving system lacks specific execution details and continuous learning ability, this paper focuses on applying the Large Language Model (LLM) in refining the decision-making process of autonomous driving. Based on the powerful reasoning ability of the LLM and the exploration ability of Reinforcement Learning (RL), this paper proposes a method of combining the LLM and RL to refine the vehicle decision-making process. First, based on the high-level actions output of the RL, the reasoning ability of the LLM is used to predict the future trajectory points of the host vehicle. Then, the output of the RL model is combined with the current state information to make a safe, collision-free and interpretable prediction of the next state. At last, the above driving decision-making process is vectorized and stored in the memory module as driving experience, and the driving experience is updated regularly to achieve sustainable learning. The trajectory points predicted by the LLM provide a detailed motion path for the Proportional-Integral-Derivative (PID) controller, providing a basis for adjusting the vehicle's acceleration and speed to ensure that the vehicle travels along the predetermined path. In addition, the trajectory prediction can also evaluate and avoid potential collision risks, and create a safe path by analyzing the traffic state and historical data. The results of the closed-loop experiment show that the proposed decision-making method outperforms other models in all evaluation indicators. Compared to the RL, the decision-making method based solely on the LLM, and the LLM-based car-following model, the driving scores are increased by 35.12, 14.33 and 12.28 respectively. The method with the memory module increases the driving score by 25.59 compared to the method without the memory module. © 2025 Elsevier B.V., All rights reserved.","Autonomous Driving; Continual Learning; Intelligent Traffic; Large Language Model; Reinforcement Learning; Trajectory Prediction; Autonomous Vehicles; Computational Linguistics; Decision Making; Forecasting; High Level Languages; Trajectories; Two Term Control Systems; Autonomous Driving; Continual Learning; Decision-making Method; Decision-making Process; Intelligent Traffics; Language Model; Large Language Model; Memory Modules; Reinforcement Learnings; Trajectory Prediction; Reinforcement Learning","Autonomous vehicles; Computational linguistics; Decision making; Forecasting; High level languages; Trajectories; Two term control systems; Autonomous driving; Continual learning; Decision-making method; Decision-making process; Intelligent traffics; Language model; Large language model; Memory modules; Reinforcement learnings; Trajectory prediction; Reinforcement learning","","","Key Program of the National Natural Science Foundation of China (Ul 808206)","Huang, Zhiqing, End-to-End Autonomous Driving Decision Based on Deep Reinforcement Learning, Tien Tzu Hsueh Pao/Acta Electronica Sinica, 48, 9, pp. 1711-1719, (2020); Deng, Yao, Scenario-based test reduction and prioritization for multi-module autonomous driving systems, pp. 82-93, (2022); Song, Xiaolin, Lane-change Behavior Decision-making of Intelligent Vehicle Based on Imitation Learning and Reinforcement Learning, Qiche Gongcheng/Automotive Engineering, 43, 1, pp. 59-67, (2021); Peng, Yanfei, RTA-IR: A runtime assurance framework for behavior planning based on imitation learning and responsibility-sensitive safety model, Expert Systems with Applications, 232, (2023); Zhou, Weilin, Decision Algorithm for Autonomous Driving Behavior Based on Piecewise Learning Model, Zhongguo Gonglu Xuebao/China Journal of Highway and Transport, 35, 6, pp. 324-338, (2022); Li, Weidong, An automatic driving decision control algorithm based on hierarchical reinforcement learning, Jilin Daxue Xuebao (Gongxueban)/Journal of Jilin University (Engineering and Technology Edition), 55, 5, pp. 1798-1805, (2025); Li, Chuanyao, Signalized Intersection Eco-driving Strategy Based on Deep Reinforcement Learning, Jiaotong Yunshu Xitong Gongcheng Yu Xinxi/ Journal of Transportation Systems Engineering and Information Technology, 24, 1, pp. 81-92, (2024); Tang, Bin, Collaborative Study of Decision-making and Trajectory Planning for Autonomous Driving Based on Soft Acto-Critic Algorithm, Jiaotong Yunshu Xitong Gongcheng Yu Xinxi/ Journal of Transportation Systems Engineering and Information Technology, 24, 2, pp. 105-113, (2024); Journal of Transportation Engineering and Information, (2025); Journal of Jilin University Engineering and Technology Edition","","Science Press","","","","","","10096744","","","","Chinese","Article","Final","","Scopus","2-s2.0-105015142872"
"","","","14th Symposium on Languages, Applications and Technologies, SLATE 2025","2025","OpenAccess Series in Informatics","135","","","","","218","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013137151&partnerID=40&md5=6119d4963cf267c2440b0e88d197f2ab","","","The proceedings contain 13 papers. The topics discussed include: from prediction to precision: leveraging LLMs for equitable and data-driven writing placement in developmental education; a DSL for swarm intelligence algorithms; elements for weighted answer-set programming; beyond the score: exploring the intersection between sociodemographics and linguistic features in English (L1) writing placement; a chatbot to help promoting financial literacy; an architecture for composite combinatorial optimization solvers; semantic representation of adverbs in the lexicalized meaning representation (LMR) framework; stepwise source, a supporting tool for source code demonstration; bridging language barriers: a comparative review and empirical evaluation of source-to-source transpilers; and mining GitHub software repositories to look for programming language cocktails. © 2025 Elsevier B.V., All rights reserved.","","","","","","","Baptista, J.; Baptista, J.; Barateiro, J.","Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing","","14th Symposium on Languages, Applications and Technologies, SLATE 2025","","Faro; University of Algarve","210905","21906807","9783939897125; 9783959770729; 9783939897637; 9783959773669; 9783959772686; 9783959773065; 9783939897828; 9783959771184; 9783959771948; 9783939897040","","","English","Conference review","Final","","Scopus","2-s2.0-105013137151"
"H., Koubeissy, Hadi; A., Amine, Amir; M., Kamradt, Marc; A., Makhoul, Abdallah","Koubeissy, Hadi (60078022900); Amine, Amir (60079019600); Kamradt, Marc (57204076427); Makhoul, Abdallah (18434649900)","60078022900; 60079019600; 57204076427; 18434649900","Survey on Tabular Data Privacy and Synthetic Data Generation in Industry 4.0","2025","Applied Intelligence","55","13","935","","","0","0","10.1007/s10489-025-06823-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014607047&doi=10.1007%2Fs10489-025-06823-5&partnerID=40&md5=aa791ad5c43a8c9b2b2993a40b7aed00","Bavarian Motor Works Group, Munich, Germany; CNRS Centre National de la Recherche Scientifique, Paris, France","Koubeissy, Hadi, Bavarian Motor Works Group, Munich, Germany, CNRS Centre National de la Recherche Scientifique, Paris, France; Amine, Amir, Bavarian Motor Works Group, Munich, Germany; Kamradt, Marc, Bavarian Motor Works Group, Munich, Germany; Makhoul, Abdallah, CNRS Centre National de la Recherche Scientifique, Paris, France","Synthetic data is an emerging field that solves the raised need for privacy-preserving data sharing and the lack of real data. One of the most common data types used is tabular data, which is widely used to train machine learning models, especially in the industrial domain for better decision-making and edge case handling, two key points in Industry 4.0. In this paper, we present and evaluate state-of-the-art models for tabular data generation under a proposed taxonomy consisting of statistical models, generative adversarial networks (GANs)-based models, denoising diffusion probabilistic models (DDPMs), and large language models (LLMs). Additionally, we propose a revised evaluation taxonomy consisting of three dimensions, including realism, representativeness, and privacy. The results proved that analyzing models based on multiple metrics from each category could ensure a better understanding of the dataset when used for downstream tasks. Finally, we found that models based on GANs are still a solid option in multiple cases, such as a constrained computational environment. In contrast, models based on LLMs and DDPMs are more promising in terms of realism and representativeness. More research should be invested in overcoming limitations such as numerical data representation and long training times for LLMs. Our survey serves as a study for existing models and newer directions in the field, with guidelines for evaluation that can be applied to industrial and other domains. © 2025 Elsevier B.V., All rights reserved.","Data Privacy; Evaluation Of Synthetic Tabular Data; Industry 4.0; Synthetic Data; Tabular Data Generation; Data Sharing; Decision Making; Learning Systems; Machine Learning; Privacy-preserving Techniques; Adversarial Networks; Data Generation; De-noising; Evaluation Of Synthetic Tabular Data; Language Model; Model-based Opc; Synthetic Data; Tabular Data; Tabular Data Generation; Industry 4.0","Data Sharing; Decision making; Learning systems; Machine learning; Privacy-preserving techniques; Adversarial networks; Data generation; De-noising; Evaluation of synthetic tabular data; Language model; Model-based OPC; Synthetic data; Tabular data; Tabular data generation; Industry 4.0","","","This research is supported by the EIPHI Graduate School (contract \u201CANR-17-EURE-0002\u201D) and the BMW TechOffice Munich.","Industrie 4 0 Maturity Index, (2017); Zuehlke, Detlef, SmartFactory-Towards a factory-of-things, Annual Reviews in Control, 34, 1, pp. 129-138, (2010); Industry 5 0 Towards A Sustainable Human Centric and Resilient European Industry, (2021); Xu, Xun William, Industry 4.0 and Industry 5.0—Inception, conception and perception, Journal of Manufacturing Systems, 61, pp. 530-535, (2021); Sajid, Sufiyan, Data science applications for predictive maintenance and materials science in context to Industry 4.0, Materials Today: Proceedings, 45, pp. 4898-4905, (2021); International Conference on Intelligent Computing and Communication Technologies, (2019); Shwartz-Ziv, Ravid, Tabular data: Deep learning is not all you need, Information Fusion, 81, pp. 84-90, (2022); Personal Data Privacy Challenges of the Fourth Industrial Revolution, (2019); Alazab, Mamoun, Guest Editorial: Security and Privacy Issues in Industry 4.0 Applications, IEEE Transactions on Industrial Informatics, 18, 9, pp. 6326-6329, (2022); Tabular Data Anomaly Patterns, (2017)","","Springer","","","","","","15737497; 0924669X","9780511611445; 9780521884280","APITE","","English","Article","Final","","Scopus","2-s2.0-105014607047"
"A., Ramamurthi, Adhitya; B., Neupane, Bhabishya; P., Deshpande, Priya; R., Hanson, Ryan; S., Vegesna, Srujan; D., Cray, Deborah; B.H., Crotty, Bradley H.; M., Somai, Melek; K.R., Brown, Kellie R.; S.S., Pawar, Sachin S.","Ramamurthi, Adhitya (57221422478); Neupane, Bhabishya (59446805600); Deshpande, Priya (57205491751); Hanson, Ryan (59446902600); Vegesna, Srujan (59894101400); Cray, Deborah (60051495100); Crotty, Bradley H. (6701854527); Somai, Melek (57208811899); Brown, Kellie R. (7404382551); Pawar, Sachin S. (23036142000)","57221422478; 59446805600; 57205491751; 59446902600; 59894101400; 60051495100; 6701854527; 57208811899; 7404382551; 23036142000","Applying Large Language Models for Surgical Case Length Prediction","2025","JAMA Surgery","160","8","","894","902","0","0","10.1001/jamasurg.2025.2154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013527436&doi=10.1001%2Fjamasurg.2025.2154&partnerID=40&md5=c1eba795c37ae4d866844bdcfd59d46f","Medical College of Wisconsin, Milwaukee, United States; Medical College of Wisconsin, Milwaukee, United States; Medical College of Wisconsin, Milwaukee, United States; Opus College of Engineering, Milwaukee, United States; Froedert & Medical College of Wisconsin, Milwaukee, United States; Medical College of Wisconsin, Milwaukee, United States; Medical College of Wisconsin, Milwaukee, United States","Ramamurthi, Adhitya, Medical College of Wisconsin, Milwaukee, United States, Department of Surgery, Medical College of Wisconsin, Milwaukee, United States; Neupane, Bhabishya, Clinical and Translational Science Institute, Medical College of Wisconsin, Milwaukee, United States; Deshpande, Priya, Opus College of Engineering, Milwaukee, United States; Hanson, Ryan, Froedert & Medical College of Wisconsin, Milwaukee, United States; Vegesna, Srujan, Froedert & Medical College of Wisconsin, Milwaukee, United States; Cray, Deborah, Froedert & Medical College of Wisconsin, Milwaukee, United States; Crotty, Bradley H., Inception Labs, Medical College of Wisconsin, Milwaukee, United States; Somai, Melek, Inception Labs, Medical College of Wisconsin, Milwaukee, United States; Brown, Kellie R., Department of Surgery, Medical College of Wisconsin, Milwaukee, United States; Pawar, Sachin S., Department of Otorhinolaryngology, Medical College of Wisconsin, Milwaukee, United States","Importance: Accurate prediction of surgical case duration is critical for operating room (OR) management, as inefficient scheduling can lead to reduced patient and surgeon satisfaction while incurring considerable financial costs. Objective: To evaluate the feasibility and accuracy of large language models (LLMs) in predicting surgical case length using unstructured clinical data compared to existing estimation methods. Design, Setting, and Participants: This was a retrospective study analyzing elective surgical cases performed between January 2017 and December 2023 at a single academic medical center and affiliated community hospital ORs. Analysis included 125 493 eligible surgical cases, with 1950 used for LLM fine-tuning and 2500 for evaluation. An additional 500 cases from a community site were used for external validation. Cases were randomly sampled using strata to ensure representation across surgical specialties. Exposures: Eleven LLMs, including base models (GPT-4, GPT-3.5, Mistral, Llama-3, Phi-3) and 2 fine-tuned variants (GPT-4 fine-tuned, GPT-3.5 fine-tuned), were used to predict surgical case length based on clinical notes. Main Outcomes and Measures: The primary outcome was average error between predicted and actual surgical case length (wheels-in to wheels-out time). The secondary outcome was prediction accuracy, defined as predicted length within 20% of actual duration. Results: Fine-tuned GPT-4 achieved the best performance with a mean absolute error (MAE) of 47.64 minutes (95% CI, 45.71-49.56) and R2 of 0.61, matching the performance of current OR scheduling (MAE, 49.34 minutes; 95% CI, 47.60-51.09; R2, 0.63; P = .10). Both GPT-4 fine-tuned and GPT-3.5 fine-tuned significantly outperformed current scheduling methods in accuracy (46.12% and 46.08% vs 40.92%, respectively; P < .001). GPT-4 fine-tuned outperformed all other models during external validation with similar performance metrics (MAE, 48.66 minutes; 95% CI, 45.31-52.00; accuracy, 46.0%). Base models demonstrated variable performance, with GPT-4 showing the highest performance among non-fine-tuned models (MAE, 59.20 minutes; 95% CI, 56.88 - 61.52). Conclusion and Relevance: The findings in this study suggest that fine-tuned LLMs can predict surgical case length with accuracy comparable to or exceeding current institutional scheduling methods. This indicates potential for LLMs to enhance operating room efficiency through improved case length prediction using existing clinical documentation. This record is sourced from MEDLINE/PubMed, a database of the U.S. National Library of Medicine","Elective Surgery; Feasibility Study; Female; Human; Large Language Model; Male; Middle Aged; Operating Room; Operation Duration; Organization And Management; Retrospective Study; Elective Surgical Procedures; Feasibility Studies; Female; Humans; Large Language Models; Male; Middle Aged; Operating Rooms; Operative Time; Retrospective Studies","elective surgery; feasibility study; female; human; large language model; male; middle aged; operating room; operation duration; organization and management; retrospective study; Elective Surgical Procedures; Feasibility Studies; Female; Humans; Large Language Models; Male; Middle Aged; Operating Rooms; Operative Time; Retrospective Studies","","","","","","","","","","","","21686262; 21686254","","","40632526","English","Note","Final","","Scopus","2-s2.0-105013527436"
"J., Kim, Jong-min","Kim, Jong-min (55720212100)","55720212100","LLM-Guided Ensemble Learning for Contextual Bandits with Copula and Gaussian Process Models","2025","Mathematics","13","15","2523","","","0","0","10.3390/math13152523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013213288&doi=10.3390%2Fmath13152523&partnerID=40&md5=beaf075c64a02524338113563d58269d","University of Minnesota Morris, Morris, United States; EGADE Business School, San Pedro Garza Garcia, Mexico","Kim, Jong-min, Statistics Discipline, University of Minnesota Morris, Morris, United States, EGADE Business School, San Pedro Garza Garcia, Mexico","Contextual multi-armed bandits (CMABs) are vital for sequential decision-making in areas such as recommendation systems, clinical trials, and finance. We propose a simulation framework integrating Gaussian Process (GP)-based CMABs with vine copulas to model dependent contexts and GARCH processes to capture reward volatility. Rewards are generated via copula-transformed Beta distributions to reflect complex joint dependencies and skewness. We evaluate four policies—ensemble, Epsilon-greedy, Thompson, and Upper Confidence Bound (UCB)—over 10,000 replications, assessing cumulative regret, observed reward, and cumulative reward. While Thompson sampling and LLM-guided policies consistently minimize regret and maximize rewards under varied reward distributions, Epsilon-greedy shows instability, and UCB exhibits moderate performance. Enhancing the ensemble with copula features, GP models, and dynamic policy selection driven by a large language model (LLM) yields superior adaptability and performance. Our results highlight the effectiveness of combining structured probabilistic models with LLM-based guidance for robust, adaptive decision-making in skewed, high-variance environments. © 2025 Elsevier B.V., All rights reserved.","Adaptive Policy; Contextual Bandits; Functional Garch; Gaussian Processes; Large Language Models; Sequential Decision-making; Vine Copulas","","","","","Auer, Péter, Finite-time analysis of the multiarmed bandit problem, Machine Learning, 47, 2-3, pp. 235-256, (2002); Advances in Neural Information Processing Systems, (2007); Li, Lihong, A contextual-bandit approach to personalized news article recommendation, pp. 661-670, (2010); Lai, Tze Leung, Asymptotically efficient adaptive allocation rules, Advances in Applied Mathematics, 6, 1, pp. 4-22, (1985); Reinforcement Learning an Introduction, (2018); Srinivas, Niranjan, Gaussian process optimization in the bandit setting: No regret and experimental design, pp. 1015-1022, (2010); Agrawal, Shipra, Thompson sampling for contextual bandits with linear payoffs, PART 2, pp. 1164-1172, (2013); Gaussian Processes for Machine Learning, (2006); Econometrica, (1982); Zakoïan, Jean Michel, Threshold heteroskedastic models, Journal of Economic Dynamics and Control, 18, 5, pp. 931-955, (1994)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","22277390","","","","English","Article","Final","","Scopus","2-s2.0-105013213288"
"R., Nagpal, Rashmi; U., Usua, Unyimeabasi; R., Palacios, Rafael; A., Gupta, Amar","Nagpal, Rashmi (59347103300); Usua, Unyimeabasi (60040757300); Palacios, Rafael (55675224166); Gupta, Amar (8451638300)","59347103300; 60040757300; 55675224166; 8451638300","FairRAG: A Privacy-Preserving Framework for Fair Financial Decision-Making","2025","Applied Sciences (Switzerland)","15","15","8282","","","0","0","10.3390/app15158282","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013090397&doi=10.3390%2Fapp15158282&partnerID=40&md5=9b4304f000f51cc5aaa04db0a1e10e29","MIT Computer Science & Artificial Intelligence Laboratory, Cambridge, United States; MIT Sloan School of Management, Cambridge, United States; Universidad Pontificia Comillas, Escuela Técnica Superior de Ingeniería, Instituto de Investigación Tecnológica, Madrid, Spain; The University of Texas at El Paso, El Paso, United States","Nagpal, Rashmi, MIT Computer Science & Artificial Intelligence Laboratory, Cambridge, United States; Usua, Unyimeabasi, MIT Computer Science & Artificial Intelligence Laboratory, Cambridge, United States; Palacios, Rafael, MIT Sloan School of Management, Cambridge, United States, Universidad Pontificia Comillas, Escuela Técnica Superior de Ingeniería, Instituto de Investigación Tecnológica, Madrid, Spain; Gupta, Amar, MIT Computer Science & Artificial Intelligence Laboratory, Cambridge, United States, The University of Texas at El Paso, El Paso, United States","Customer churn prediction has become crucial for businesses, yet it poses significant challenges regarding privacy preservation and prediction accuracy. In this paper, we address two fundamental questions: (1) How can customer churn be effectively predicted while ensuring robust privacy protection of sensitive data? (2) How can large language models enhance churn prediction accuracy while maintaining data privacy? To address these questions, we propose FairRAG, a robust architecture that combines differential privacy, retrieval-augmented generation, and LLMs. Our approach leverages OPT-125M as the core language model along with a sentence transformer for semantic similarity matching while incorporating differential privacy mechanisms to generate synthetic training data. We evaluate FairRAG on two diverse datasets: Bank Churn and Telco Churn. The results demonstrate significant improvements over both traditional machine learning approaches and standalone LLMs, achieving accuracy improvements of up to 11% on the Bank Churn dataset and 12% on the Telco Churn dataset. These improvements were maintained when using differentially private synthetic data, thus indicating robust privacy and accuracy trade-offs. © 2025 Elsevier B.V., All rights reserved.","Algorithmic Fairness; Differential Privacy; Privacy-preserving Machine Learning; Retrieval-augmented Generation; Computational Linguistics; Decision Making; Differential Privacy; Forecasting; Learning Systems; Machine Learning; Privacy-preserving Techniques; Semantics; Algorithmic Fairness; Algorithmics; Differential Privacies; Financial Decisions; Language Model; Machine-learning; Prediction Accuracy; Privacy Preserving; Privacy-preserving Machine Learning; Retrieval-augmented Generation; Economic And Social Effects","Computational linguistics; Decision making; Differential privacy; Forecasting; Learning systems; Machine learning; Privacy-preserving techniques; Semantics; Algorithmic fairness; Algorithmics; Differential privacies; Financial decisions; Language model; Machine-learning; Prediction accuracy; Privacy preserving; Privacy-preserving machine learning; Retrieval-augmented generation; Economic and social effects","","","This work is a part of MIT internal funding, which is partially funded by two industry alliances at MIT Computer Science and Artificial Intelligence Lab (CSAIL): Future of Data consortium and FinTechAI consortium.","Dwork, Cynthia, The algorithmic foundations of differential privacy, Foundations and Trends in Theoretical Computer Science, 9, 3-4, pp. 211-487, (2013); Mehrabi, Ninareh, A Survey on Bias and Fairness in Machine Learning, ACM Computing Surveys, 54, 6, (2022); Cummings, Rachel, On the compatibility of privacy and fairness, pp. 309-315, (2019); Ethical Algorithm Design Guiding Principles for Technology Regulation, (2020); Algorithmic Fairness in Chest X Ray Diagnosis A Case Study MIT Case Studies in Social and Ethical Responsibilities of Computing, (2023); Hoofnagle, Chris Jay, The European Union general data protection regulation: What it is and what it means, Information and Communications Technology Law, 28, 1, pp. 65-98, (2019); Harding, Elizabeth, Understanding the scope and impact of the California Consumer Privacy Act of 2018, Journal of Data Protection and Privacy, 2, 3, pp. 234-253, (2019); Fairness and Machine Learning Limitations and Opportunities, (2023); Bhutta, Neil, How Much Does Racial Bias Affect Mortgage Lending? Evidence from Human and Algorithmic Credit Decisions, Journal of Finance, 80, 3, pp. 1463-1496, (2025); Haw, Su Cheng, Utilizing data sampling techniques on algorithmic fairness for customer churn prediction with data imbalance problems, F1000Research, 10, (2022)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","20763417","","","","English","Article","Final","","Scopus","2-s2.0-105013090397"
"S., Zhang, Shengli; K., Liu, Kai; Y., Xu, Yujie","Zhang, Shengli (35757189000); Liu, Kai (59761605700); Xu, Yujie (58746810900)","35757189000; 59761605700; 58746810900","TransCNN: A novel architecture combining transformer and TextCNN for detecting N4-acetylcytidine sites in human mRNA","2025","Analytical Biochemistry","703","","115882","","","0","0","10.1016/j.ab.2025.115882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003940234&doi=10.1016%2Fj.ab.2025.115882&partnerID=40&md5=68b377aa2b8ba5233f6d5083e3fb6867","Xidian University, Xi'an, China","Zhang, Shengli, School of Mathematics and Statistics, Xidian University, Xi'an, China; Liu, Kai, School of Mathematics and Statistics, Xidian University, Xi'an, China; Xu, Yujie, School of Mathematics and Statistics, Xidian University, Xi'an, China","N4-acetylcytidine (ac4C), a pivotal post-transcriptional RNA modification, is central to understanding transcriptional regulation and diverse biological processes. As a key determinant of RNA structural stability and functional regulation, ac4C has been strongly associated with multiple human diseases. We can obtain a better understanding of regulation mechanism of gene expression by identifying ac4C sites rapidly and precisely. However, existing predictive approaches are constrained by limitations in feature representation and sequence context modeling, necessitating the development of advanced methodologies. In this study, we introduce a novel architecture named TransCNN that integrates transformer and Text convolutional neural network (TextCNN) to predict ac4C sites. TransCNN demonstrates superior performance compared to existing models on both 10-fold cross-validation and independent dataset with the accuracy of 83.27 % and 82.89 %, respectively. The enhanced performance of TransCNN is attributed to the transformer's ability to extract adaptive features and TextCNN's capability to form both narrow and broad connections within the sequence. This study aims to contribute significantly to the field by advancing the understanding and prediction of RNA modifications. The datasets and code used in this study are available at https://github.com/liukai23157/TransCNN. © 2025 Elsevier B.V., All rights reserved.","N4-acetylcytidine; Natural Language Processing; Text Convolutional Neural Network; Transformer; Cytidine; Cytidine; N-acetylcytidine; Rna, Messenger; Convolutional Neural Networks; Convolutional Neural Network; Language Processing; N4-acetylcytidine; Natural Language Processing; Natural Languages; Novel Architecture; Performance; Post-transcriptional; Text Convolutional Neural Network; Transformer; Transcription; Cytidine Derivative; Messenger Rna; N4 Acetylcytidine; Nucleotide; Unclassified Drug; Cytidine; N-acetylcytidine; 10 Fold Cross Validation; Article; Binary Classification; Comparative Study; Computer Model; Controlled Study; Convolutional Neural Network; Cross Validation; Data Accuracy; Deep Learning; Dimensionality Reduction; Embedding; Entropy; False Negative Result; False Positive Result; Feature Extraction; Gene Expression Regulation; Human; Rna Sequence; Sensitivity And Specificity; Text Convolutional Neural Network; Transformer Convolutional Neural Network; Artificial Neural Network; Chemistry; Genetics; Metabolism; Rna Processing; Cytidine; Humans; Neural Networks, Computer; Rna Processing, Post-transcriptional; Rna, Messenger","Convolutional neural networks; Convolutional neural network; Language processing; N4-acetylcytidine; Natural language processing; Natural languages; Novel architecture; Performance; Post-transcriptional; Text convolutional neural network; Transformer; Transcription; cytidine derivative; messenger RNA; n4 acetylcytidine; nucleotide; unclassified drug; cytidine; N-acetylcytidine; 10 fold cross validation; Article; binary classification; comparative study; computer model; controlled study; convolutional neural network; cross validation; data accuracy; deep learning; dimensionality reduction; embedding; entropy; false negative result; false positive result; feature extraction; gene expression regulation; human; RNA sequence; sensitivity and specificity; text convolutional neural network; transformer convolutional neural network; artificial neural network; chemistry; genetics; metabolism; RNA processing; Cytidine; Humans; Neural Networks, Computer; RNA Processing, Post-Transcriptional; RNA, Messenger","","cytidine, 65-46-3; Cytidine; N-acetylcytidine; RNA, Messenger","This work was supported by the Natural Science Basic Research Program of Shaanxi (No.2024JC-YBMS-004) and Xidian University Specially Funded Project for Interdisciplinary Exploration (No.TZJH2024028).","Boccaletto, Pietro, MODOMICS: A database of RNA modification pathways. 2017 update, Nucleic Acids Research, 46, D1, pp. D303-D307, (2018); Zhang, Guiyang, CNNLSTMac4CPred: A Hybrid Model for N4-Acetylcytidine Prediction, Interdisciplinary Sciences - Computational Life Sciences, 14, 2, pp. 439-451, (2022); Wei, Wei, NAT10-mediated ac4C tRNA modification promotes EGFR mRNA translation and gefitinib resistance in cancer, Cell Reports, 42, 7, (2023); Yu, Xiaomei, N4-acetylcytidine modification of lncRNA CTC-490G23.2 promotes cancer metastasis through interacting with PTBP1 to increase CD44 alternative splicing, Oncogene, 42, 14, pp. 1101-1116, (2023); Thalalla-Gamage, Supuni, Quantitative nucleotide resolution profiling of RNA cytidine acetylation by ac4C-seq, Nature Protocols, 16, 4, pp. 2286-2307, (2021); Taoka, Masato, RNA cytidine acetyltransferase of small-subunit ribosomal RNA: Identification of acetylation sites and the responsible acetyltransferase in Fission Yeast, Schizosaccharomyces pombe, PLOS ONE, 9, 11, (2014); Arango, Daniel, Direct epitranscriptomic regulation of mammalian translation initiation through N4-acetylcytidine, Molecular Cell, 82, 15, pp. 2797-2814.e11, (2022); Ito, Satoshi, A single acetylation of 18 S rRNA is essential for biogenesis of the small ribosomal subunit in saccharomyces cerevisiae, Journal of Biological Chemistry, 289, 38, pp. 26201-26212, (2014); Thomas, Justin M., A Chemical Signature for Cytidine Acetylation in RNA, Journal of the American Chemical Society, 140, 40, pp. 12667-12670, (2018); Jin, Gehui, The Processing, Gene Regulation, Biological Functions, and Clinical Relevance of N4-Acetylcytidine on RNA: A Systematic Review, Molecular Therapy Nucleic Acids, 20, pp. 13-24, (2020)","","Academic Press Inc.","","","","","","00032697; 10960309","","ANBCA","40311775","English","Article","Final","","Scopus","2-s2.0-105003940234"
"S., Golchin, Shahriar; M., Surdeanu, Mihai","Golchin, Shahriar (57873692300); Surdeanu, Mihai (23398535300)","57873692300; 23398535300","Data Contamination Quiz: A Tool to Detect and Estimate Contamination in Large Language Models","2025","Transactions of the Association for Computational Linguistics","13","","","809","830","0","0","10.1162/TACL.a.20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012897987&doi=10.1162%2FTACL.a.20&partnerID=40&md5=a60367dd297c51f643ca573119338557","Department of Computer Science, Tucson, United States","Golchin, Shahriar, Department of Computer Science, Tucson, United States; Surdeanu, Mihai, Department of Computer Science, Tucson, United States","We propose the Data Contamination Quiz (DCQ), a simple and effective approach to detect data contamination in large language models (LLMs) and estimate the amount of it. Specifically, we frame data contamination detection as a series of multiple-choice questions, devising a quiz format wherein three perturbed versions of each instance, subsampled from a specific dataset partition, are created. These changes only include word-level perturbations. The generated perturbations, along with the original dataset instance, form the options in the DCQ, with an extra option accommodating the selection of none of the provided options. Given that the only distinguishing signal among the options is the exact wording with respect to the original dataset instance, an LLM, when tasked with identifying the original dataset instance, gravitates towards selecting the original one if it has been exposed to it. While accounting for positional biases in LLMs, the quiz performance reveals the contamination level for the tested model with the dataset partition to which the quiz pertains. Applied to various datasets and LLMs, under controlled and uncontrolled contamination, our findings—while fully lacking access to training data and model parameters—suggest that DCQ achieves state-of-the-art results and uncovers greater contamination levels through memorization compared to existing methods. Also, it proficiently bypasses more safety filters, especially those set to avoid generating copyrighted content.1 © 2025 Elsevier B.V., All rights reserved.","Computational Linguistics; Contamination; Natural Language Processing Systems; Contamination Detection; Contamination Levels; Dataset Partitions; Effective Approaches; Exposed To; Frame Data; Language Model; Multiple-choice Questions; Simple Approach; Word Level; Pollution Detection","Computational linguistics; Contamination; Natural language processing systems; Contamination detection; Contamination levels; Dataset partitions; Effective approaches; Exposed to; Frame data; Language model; Multiple-choice questions; Simple approach; Word level; Pollution detection","","","","Arxiv, (2023); Palm 2 Technical Report, (2023); Announcing Arc Agi 2 and the Arc Prize 2025, (2024); Leak Cheat Repeat Data Contamination and Evaluation Malpractices in Closed Source Llms, (2024); A Multitask Multilingual Multimodal Evaluation of Chatgpt on Reasoning Hallucination and Interactivity, (2023); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Sparks of Artificial General Intelligence Early Experiments with Gpt 4, (2023); Carlini, Nicholas, QUANTIFYING MEMORIZATION ACROSS NEURAL LANGUAGE MODELS, (2023); Evaluating Large Language Models Trained on Code, (2021); On the Measure of Intelligence, (2019)","","Massachusetts Institute of Technology","","","","","","2307387X","","","","English","Article","Final","","Scopus","2-s2.0-105012897987"
"R., Wu, Ruonan; H., Liu, Hong","Wu, Ruonan (59964303500); Liu, Hong (59964081000)","59964303500; 59964081000","A survey on the application and research progress of large language models in financial forecasting","2025","AIP Advances","15","6","060704","","","0","0","10.1063/5.0274031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009123895&doi=10.1063%2F5.0274031&partnerID=40&md5=fad3df44867af5b722b6eb8d334880b3","Capital University of EcoNomics and Business, Beijing, China","Wu, Ruonan, School of Economics, Capital University of EcoNomics and Business, Beijing, China; Liu, Hong, School of Economics, Capital University of EcoNomics and Business, Beijing, China","Large language models (LLMs) are reshaping the technical paradigms of financial forecasting through their robust representation learning and reasoning capabilities. This paper systematically reviews the application pathways of architectures such as transformers and graph neural networks in scenarios like stock prediction and risk management, highlighting key technologies for enhancing prediction accuracy through knowledge injection and temporal modeling improvements. The study reveals that LLMs demonstrate significant advantages in unstructured data processing and cross-market correlation analysis but face challenges related to economic logic interpretability and data non-stationarity. Future research should focus on advancing causal reasoning augmentation and federated learning collaboration to achieve secure and trustworthy evolution of financial forecasting systems. © 2025 Elsevier B.V., All rights reserved.","Data Accuracy; Data Handling; Finance; Forecasting; Prediction Models; Risk Perception; Financial Forecasting; Graph Neural Networks; Injection Modeling; Key Technologies; Language Model; Learning Capabilities; Prediction Accuracy; Reasoning Capabilities; Risks Management; Stock Predictions; Risk Management","Data accuracy; Data handling; Finance; Forecasting; Prediction models; Risk perception; Financial forecasting; Graph neural networks; Injection modeling; Key technologies; Language model; Learning capabilities; Prediction accuracy; Reasoning capabilities; Risks management; Stock predictions; Risk management","","","This research was funded by the National Social Science Fund of China, Grant No. 21BJY241.","Artificial Intelligence, (2014); International Journal of Science and Research Ijsr, (2020); Revolutionizing Finance with Llms an Overview of Applications and Insights, (2024); undefined, (2024); International Journal of Scientific Research in Computer Science Engineering and Information Technology, (2025); de Zarzà, I., Optimized Financial Planning: Integrating Individual and Cooperative Budgeting Models with LLM Recommendations, AI (Switzerland), 5, 1, pp. 91-114, (2024); Lee, Jean, Large Language Models in Finance (FinLLMs), Neural Computing and Applications, (2025); Arxiv, (2025); Responsible Innovation A Strategic Framework for Financial Llm Integration, (2025); Tenney, Ian F., BERT rediscovers the classical NLP pipeline, pp. 4593-4601, (2020)","","American Institute of Physics","","","","","","21583226","","","","English","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105009123895"
"G., Cohen, Gil; A., Aiche, Avishay; R., Eichel, Ron","Cohen, Gil (57206355677); Aiche, Avishay (56183436300); Eichel, Ron (57209657920)","57206355677; 56183436300; 57209657920","Artificial Intelligence Models for Predicting Stock Returns Using Fundamental, Technical, and Entropy-Based Strategies: A Semantic-Augmented Hybrid Approach","2025","Entropy","27","6","550","","","0","0","10.3390/e27060550","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009099552&doi=10.3390%2Fe27060550&partnerID=40&md5=7bc1923bcb399b30db2429906025fd54","Western Galilee College, Acre, Israel","Cohen, Gil, School of Management, Western Galilee College, Acre, Israel; Aiche, Avishay, School of Management, Western Galilee College, Acre, Israel; Eichel, Ron, School of Management, Western Galilee College, Acre, Israel","This study examines the effectiveness of combining semantic intelligence drawn from large language models (LLMs) such as ChatGPT-4o with traditional machine-learning (ML) algorithms to develop predictive portfolio strategies for NASDAQ-100 stocks over the 2020–2025 period. Three different predictive frameworks––fundamental, technical, and entropy-based––are tested through examination of novel combinations of ML- and LLM-derived semantic metrics. The empirical results reveal a considerable divergence in optimal blending methods across the methodologies; namely, the technical methodology exhibits the best performance when using only ML predictions, with around 1978% cumulative returns with monthly rebalancing. In contrast, the fundamental methodology achieves its full potential when it is based primarily on LLM-derived semantic insights. The Entropy methodology is improved by a balanced combination of both semantic and ML signals, thus highlighting the potential of LLMs to improve predictive power by offering interpretative context for complex market interactions. These findings highlight the strategic importance of tailoring the semantic–algorithmic fusion to suit the nature of the predictive data and the investment horizon, with significant implications for portfolio management and future research in financial modeling. © 2025 Elsevier B.V., All rights reserved.","Artificial Intelligence; Fundamental; Fuzzy Logic; Technical; Trading","","","","This research was funded by Western Galilee Academic College.","Information Systems Journal, (2022); Krämer, Bastian, Automated valuation models: improving model performance by choosing the optimal spatial training level, Journal of Property Research, 40, 4, pp. 365-390, (2023); Shi, Mingze, Stock market trend prediction and investment strategy by deep neural networks, (2020); Effectiveness of Artificial Intelligence in Stock Market Prediction Based on Machine Learning, (2021); Agusta, Stiven, Enhancing the accuracy of stock return movement prediction in Indonesia through recent fundamental value incorporation in multilayer perceptron, Asian Journal of Accounting Research, 9, 4, pp. 358-377, (2024); Zhou, Qing, The complementary role of cross-sectional and time-series information in forecasting stock returns, Australian Journal of Management, 42, 1, pp. 113-139, (2017); Dawson, Edward R., On the existence of visual technical patterns in the UK stock market, Journal of Business Finance and Accounting, 30, 1-2, pp. 263-293, (2003); Hurriyati, Ratih, Stock Market Trend Analysis and Machine Learning-based Predictive Evaluation, Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications, 14, 3, pp. 267-281, (2023); Alizadeh, Meysam, An adaptive neuro-fuzzy system for stock portfolio analysis, International Journal of Intelligent Systems, 26, 2, pp. 99-114, (2011); Ayyildiz, Nazif, How effective is machine learning in stock market predictions?, Heliyon, 10, 2, (2024)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","10994300","","","","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-105009099552"
"M., Chen, Mingming; Y., Tang, Yifan; Q., Qi, Qi; H., Dai, Hongyi; Y., Lin, Yi; C., Ling, Chengxiu; T., Li, Tenglong","Chen, Mingming (58872233100); Tang, Yifan (59947739300); Qi, Qi (59952537000); Dai, Hongyi (59952434900); Lin, Yi (59952435000); Ling, Chengxiu (55208612600); Li, Tenglong (57191738382)","58872233100; 59947739300; 59952537000; 59952434900; 59952435000; 55208612600; 57191738382","Enhancing stock timing predictions based on multimodal architecture: Leveraging large language models (LLMs) for text quality improvement","2025","PLOS ONE","20","6 June","e0326034","","","0","0","10.1371/journal.pone.0326034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008471640&doi=10.1371%2Fjournal.pone.0326034&partnerID=40&md5=98a5d95e4c7ae2a55e9367ab9130232b","Xi'an Jiaotong-Liverpool University, Suzhou, China; University of Liverpool, Liverpool, United Kingdom; Boston University, Boston, United States","Chen, Mingming, Academy of Pharmacy, Xi'an Jiaotong-Liverpool University, Suzhou, China, Waterhouse Building, University of Liverpool, Liverpool, United Kingdom; Tang, Yifan, Academy of Pharmacy, Xi'an Jiaotong-Liverpool University, Suzhou, China; Qi, Qi, Academy of Pharmacy, Xi'an Jiaotong-Liverpool University, Suzhou, China; Dai, Hongyi, Faculty of Computing and Data Sciences, Boston University, Boston, United States; Lin, Yi, Academy of Pharmacy, Xi'an Jiaotong-Liverpool University, Suzhou, China; Ling, Chengxiu, Academy of Pharmacy, Xi'an Jiaotong-Liverpool University, Suzhou, China; Li, Tenglong, Academy of Pharmacy, Xi'an Jiaotong-Liverpool University, Suzhou, China, Waterhouse Building, University of Liverpool, Liverpool, United Kingdom","This study aims to enhance stock timing predictions by leveraging large language models (LLMs), specifically GPT-4, to filter and analyze online investor comment data. Recognizing challenges such as variable comment quality, redundancy, and authenticity issues, we propose a multimodal architecture that integrates filtered comment data with stock price dynamics and technical indicators. Using data from nine Chinese banks, we compare four filtering models and demonstrate that employing GPT-4 significantly improves financial metrics like profit-loss ratio, win rate, and excess return rate. The multimodal architecture outperforms baseline models by effectively preprocessing comment data and combining it with quantitative financial data. While focused on Chinese banks, the approach can be adapted to broader markets by modifying the prompts of large language models. Our findings highlight the potential of LLMs in financial forecasting and provide more reliable decision support for investors. © 2025 Elsevier B.V., All rights reserved.","Methadone; Methadone; Article; Artificial Intelligence; Artificial Neural Network; Decision Making; Decision Support System; Human; Language; Learning Algorithm; Machine Learning; Mathematical Analysis; Mathematical Model; Multimodal Architecture; Multimodal Imaging; Natural Language Processing; Total Quality Management; China; Economic Model; Economics; Investment; Large Language Model; Humans; Investments; Language; Large Language Models; Models, Economic; Quality Improvement","methadone; Article; artificial intelligence; artificial neural network; decision making; decision support system; human; language; learning algorithm; machine learning; mathematical analysis; mathematical model; multimodal architecture; multimodal imaging; natural language processing; total quality management; China; economic model; economics; investment; large language model; Humans; Investments; Language; Large Language Models; Models, Economic; Quality Improvement","","methadone, 1095-90-5, 125-56-4, 23142-53-2, 297-88-1, 76-99-3","","Chikwira, Collin, The Impact of the Stock Market on Liquidity and Economic Growth: Evidence of Volatile Market, Economies, 11, 6, (2023); Int J Finance Banking Studies, (2025); Cole, Rebel A., Bank stock returns and economic growth, Journal of Banking and Finance, 32, 6, pp. 995-1007, (2008); Economics of Agriculture, (2017); Khan, Muhammad Nauman, Impact of macroeconomic variables on stock prices: Empirical evidence from Karachi stock exchange, Pakistan, Advances in Intelligent and Soft Computing, 143 AISC, pp. 227-233, (2012); Shieh, Shwu Jane, Large changes in stock prices: Market, liquidity, and momentum effect, Quarterly Review of Economics and Finance, 52, 2, pp. 183-197, (2012); Demiralay, Sercan, Geopolitical risks and climate change stocks, Journal of Environmental Management, 352, (2024); Abudy, Menachem Meni, Retail investors’ trading and stock market liquidity, North American Journal of Economics and Finance, 54, (2020); Bis Quarterly Review, (2021); Impact of Retail Investors on Stock Liquidity and Crash Risk, (2022)","","Public Library of Science","","","","","","19326203","","POLNC","40531828","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-105008471640"
"C., Zheng, Chunrao; Q., Li, Qunfang; G., Lu, Geling; Y., Mai, Yuchang; Y., Hu, Yuan","Zheng, Chunrao (59627662100); Li, Qunfang (59753775800); Lu, Geling (58139115900); Mai, Yuchang (57205625216); Hu, Yuan (59754495000)","59627662100; 59753775800; 58139115900; 57205625216; 59754495000","Large language models in breast cancer reconstruction: A framework for patient-specific recovery and predictive insights","2025","SLAS Technology","32","","100285","","","0","1","10.1016/j.slast.2025.100285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003596480&doi=10.1016%2Fj.slast.2025.100285&partnerID=40&md5=a330fc597bc0f37b4cb8121a7a31f3f8","University of Jinan, Jinan, China","Zheng, Chunrao, Department of General Surgery, University of Jinan, Jinan, China; Li, Qunfang, Department of General Surgery, University of Jinan, Jinan, China; Lu, Geling, Department of General Surgery, University of Jinan, Jinan, China; Mai, Yuchang, Department of General Surgery, University of Jinan, Jinan, China; Hu, Yuan, Department of General Surgery, University of Jinan, Jinan, China","Breast cancer reconstruction, a vital part of comprehensive cancer therapy, can be performed concurrently with cancer resection, improving both physical and psychological recovery for patients. However, the intricacy and variety of recovery demand a specialized strategy. Thus, a unique framework that uses Natural Language Processing (NLP) and Large Language Models (LLMs) is developed to improve patient-specific recovery and predictive insights during breast cancer reconstruction. Lemmatization/Stemming is used for pre-processing large volumes of data from medical records, clinical notes, and treatment histories and BioBERT, a model pretrained on biomedical texts to capture complex medical terminology used for feature extraction and aids in the transformation of text data into numerical vectors. The approach employs forecasting models like ChatGPT-4 and Gemini to offer insights into the likelihood of successful reconstruction and associated problems based on specific patient characteristics, treatment options, and recovery timelines. Using sophisticated LLMs, this framework provides clinicians with a powerful tool for personalizing care by anticipating postoperative complications, recovery durations, and psychosocial consequences. Furthermore, it allows for the development of targeted rehabilitation programs that are adapted to unique patient needs, enabling greater recovery and overall quality of life. This approach not only improves clinical decision-making but also empowers patients by offering personalized recovery strategies. As a result, the accuracy of ChatGPT-4 is 98.4 % and Gemini is 98.7 %; the score per response is 2.52 for ChatGPT-4 and 2.89 for Gemini. Readability of ChatGPT-4 is 93.0 % and Gemini is 94.5 %; a relevance score is 95.5 % and 94.0 % for ChatGPT-4 and Gemini, and time response is 2.5 s for ChatGPT-4 and 2.5 s for Gemini. Finally, this research indicates how NLP and LLMs can transform breast cancer reconstruction by offering predictive insights and promoting tailored, patient-centered therapy, bridging the gap between powerful computational technologies and life science research to better patient care. © 2025 Elsevier B.V., All rights reserved.","Breast Cancer Reconstruction; Large Language Models (llms); Natural Language Processing (nlp); Patient Recovery; Personalizing Care; Clinical Research; Hospital Data Processing; Medical Computing; Natural Language Processing Systems; Patient Rehabilitation; Patient Treatment; Personalized Medicine; Breast Cancer; Breast Cancer Reconstruction; Language Model; Language Processing; Large Language Model; Natural Language Processing; Natural Languages; Patient Recovery; Patient Specific; Personalizing Care; Diseases; Adult; Aged; Article; Breast Cancer; Breast Cancer Reconstruction; Cancer Surgery; Cancer Therapy; Chatgpt; Clinical Decision Making; Cohort Analysis; Comorbidity; Demographics; Duration; Feature Extraction; Female; Health Care; Human; Large Language Model; Logistic Regression Analysis; Machine Learning; Medical Record; Medical Terminology; Natural Language Processing; Observational Study; Patient Care; Patient-specific Recovery; Predictive Model; Quality Of Life; Retrospective Study; Socioeconomic Background; Breast Reconstruction; Breast Tumor; Procedures; Rehabilitation; Surgery; Breast Neoplasms; Female; Humans; Large Language Models; Mammaplasty; Natural Language Processing","Clinical research; Hospital data processing; Medical computing; Natural language processing systems; Patient rehabilitation; Patient treatment; Personalized medicine; Breast Cancer; Breast cancer reconstruction; Language model; Language processing; Large language model; Natural language processing; Natural languages; Patient recovery; Patient specific; Personalizing care; Diseases; adult; aged; Article; breast cancer; breast cancer reconstruction; cancer surgery; cancer therapy; ChatGPT; clinical decision making; cohort analysis; comorbidity; demographics; duration; feature extraction; female; health care; human; large language model; logistic regression analysis; machine learning; medical record; medical terminology; natural language processing; observational study; patient care; patient-specific recovery; predictive model; quality of life; retrospective study; socioeconomic background; breast reconstruction; breast tumor; procedures; rehabilitation; surgery; Breast Neoplasms; Female; Humans; Large Language Models; Mammaplasty; Natural Language Processing","","","Funding : This research was supported by the Shenzhen Key Medical Discipline Construction Fund (No. SZXK015 ), the Guangdong Provincial and National Key Clinical Specialty Construction Project , the National Key Clinical Specialty Construction Project, and the Sanming Project of Medicine in Shenzhen .","Zhang, Hao, Big data in breast cancer: Towards precision treatment, Digital Health, 10, (2024); Shi, Honyi, Quality of life and cost-effectiveness of different breast cancer surgery procedures: a Markov decision tree-based approach in the framework of Predictive, Preventive, and Personalized Medicine, EPMA Journal, 14, 3, pp. 457-475, (2023); Aquino, Nelson J., Implementation of an Enhanced Recovery after Surgery Pathway for Transgender and Gender-Diverse Individuals Undergoing Chest Reconstruction Surgery: An Observational Cohort Study, Journal of Clinical Medicine, 12, 22, (2023); Atkinson, Connor John, Artificial Intelligence Language Model Performance for Rapid Intraoperative Queries in Plastic Surgery: ChatGPT and the Deep Inferior Epigastric Perforator Flap, Journal of Clinical Medicine, 13, 3, (2024); Deshmukh, Pratiksha Vilas, Information extraction for prognostic stage prediction from breast cancer medical records using NLP and ML, Medical and Biological Engineering and Computing, 59, 9, pp. 1751-1772, (2021); Gorgy, Andrew, Integrating AI into Breast Reconstruction Surgery: Exploring Opportunities, Applications, and Challenges, Plastic Surgery, (2024); undefined, (2023); Nassiri, Khalid, Recent Advances in Large Language Models for Healthcare, BioMedInformatics, 4, 2, pp. 1097-1143, (2024); Rautalin, Mervi, Breast Reconstruction–Prospective Follow up on Breast Cancer Patients’ Health-Related Quality of Life, World Journal of Surgery, 46, 4, pp. 836-844, (2022); Coriddi, Michelle R., Efficacy of Immediate Lymphatic Reconstruction to Decrease Incidence of Breast Cancer-related Lymphedema: Preliminary Results of Randomized Controlled Trial, Annals of Surgery, 278, 4, pp. 630-637, (2023)","","Elsevier B.V.","","","","","","24726303; 24726311","","","40216254","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105003596480"
"H., Tong, Hanshuang; J., Li, Jun; N., Wu, Ning; M., Gong, Ming; D., Zhang, Dongmei; Q., Zhang, Qi","Tong, Hanshuang (57209661135); Li, Jun (58959367000); Wu, Ning (57219648278); Gong, Ming (57214933038); Zhang, Dongmei (55717568500); Zhang, Qi (54931372200)","57209661135; 58959367000; 57219648278; 57214933038; 55717568500; 54931372200","Ploutos: Towards Explainable Stock Movement Prediction with Financial Large Language Model","2025","","","","","490","499","0","0","10.1145/3701716.3715254","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009207733&doi=10.1145%2F3701716.3715254&partnerID=40&md5=bbdc239b1a7a5588b836c71d601b5bc5","Microsoft Corporation, Redmond, United States","Tong, Hanshuang, Microsoft Corporation, Redmond, United States; Li, Jun, Microsoft Corporation, Redmond, United States; Wu, Ning, Microsoft Corporation, Redmond, United States; Gong, Ming, Microsoft Corporation, Redmond, United States; Zhang, Dongmei, Microsoft Corporation, Redmond, United States; Zhang, Qi, Microsoft Corporation, Redmond, United States","Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical deep learning-based methods for quantitative finance. First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and explainability, which impedes their application in scenarios where the justification for predictions is essential. To solve the above challenges, we propose Ploutos, a novel financial LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen contains multiple primary experts that can analyze different modal data, such as text and numbers, and provide quantitative strategies from different perspectives. Then PloutosGPT combines their insights and predictions and generates explainable rationales. To generate accurate and faithful rationales, the training strategy of PloutosGPT leverages a rearview-mirror prompting mechanism to guide GPT-4 to generate rationales and a dynamic token weighting mechanism to finetune LLM by detecting and emphasizing key tokens in rationales. Extensive experiments show our framework outperforms the state-of-the-art methods on both prediction accuracy and explainability. © 2025 Elsevier B.V., All rights reserved.","Computational Finance; Large Language Model; Quantitative Investment; Stock Prediction; Deep Learning; Economics; Investments; Learning Systems; Modal Analysis; Computational Finance; Financial Investments; Language Model; Large Language Model; Learning-based Methods; Movement Prediction; Quantitative Investment; Stock Movement; Stock Predictions; Textual Information; Forecasting","Deep learning; Economics; Investments; Learning systems; Modal analysis; Computational finance; Financial investments; Language model; Large language model; Learning-based methods; Movement prediction; Quantitative investment; Stock movement; Stock predictions; Textual information; Forecasting","","","","Gpt 4 Technical Report, (2023); Adam, Klaus, Stock Market Volatility and Learning, Journal of Finance, 71, 1, pp. 33-82, (2016); Smoothing Forecasting and Prediction of Discrete Time Series, (1963); Letter to Shareholders, (1991); Chatgpt Informed Graph Neural Network for Stock Movement Prediction, (2023); Data Centric Financial Large Language Models, (2023); Duan, Yitong, FactorVAE: A Probabilistic Dynamic Factor Model Based on Variational Autoencoder for Predicting Cross-Sectional Stock Returns, 36, pp. 4468-4476, (2022); Gao, Siyu, StockFormer: Learning Hybrid Trading Machines with Predictive Coding, IJCAI International Joint Conference on Artificial Intelligence, 2023-August, pp. 4766-4774, (2023); Large Language Models are Zero Shot Time Series Forecasters, (2023); Bitcoin Tweets Sentiment Analysis, (2023)","","Association for Computing Machinery, Inc","ACM SIGWEB; Baidu; et al.; Google; Huawei; Meta","34th ACM Web Conference, WWW Companion 2025","","Sydney; NSW; Sydney Convention and Exhibition Centre","209280","","9798400713316","","","English","Conference paper","Final","All Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-105009207733"
"J., Rao, Jiarui; X., Shang, Xuerong; Z., Wang, Zeyu; Y., Mo, Yuhong","Rao, Jiarui (59230405900); Shang, Xuerong (59934397900); Wang, Zeyu (59105941900); Mo, Yuhong (59933665900)","59230405900; 59934397900; 59105941900; 59933665900","Optimizing Stock Market Return Forecasts with Uncertainty Sentiment: Leveraging LLM-based Insights","2025","","","","","523","527","0","0","10.1145/3724154.3724240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007549549&doi=10.1145%2F3724154.3724240&partnerID=40&md5=f5cc662d9088d97a28fc87e42c1d9570","Uber Technologies Inc, San Francisco, United States; The University of Chicago, Chicago, United States; University of California, Los Angeles, Los Angeles, United States; Tencent, Shenzhen, China","Rao, Jiarui, Uber Technologies Inc, San Francisco, United States; Shang, Xuerong, The University of Chicago, Chicago, United States; Wang, Zeyu, University of California, Los Angeles, Los Angeles, United States; Mo, Yuhong, Tencent, Shenzhen, China","Accurately predicting stock market returns is crucial for both investors and policy makers. This study proposes an innovative hybrid Particle Swarm Optimization Support Vector Regression (PSO-SVR) machine learning framework that integrates uncertainty sentiment to improve the accuracy of stock market return prediction. Uncertainty sentiment and historical stock market returns are identified as the main input factors, and the PSO algorithm is used to fine-tune the parameters of SVR to obtain the integrated PSO-SVR model. Empirical results show that the PSO-SVR model significantly reduces the root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) when uncertainty sentiment is added. This provides a novel and effective method for predicting stock market returns. © 2025 Elsevier B.V., All rights reserved.","Empirical Asset Pricing; Machine Learning; Pso-svr Hybrid Model; Uncertainty Sentiment; Asset Pricing; Empirical Asset Pricing; Hybrid Model; Machine-learning; Particle Swarm; Particle Swarm Optimization Support Vector Regression Hybrid Model; Support Vector Regressions; Swarm Optimization; Uncertainty; Uncertainty Sentiment; Mean Square Error","Asset pricing; Empirical asset pricing; Hybrid model; Machine-learning; Particle swarm; Particle swarm optimization support vector regression hybrid model; Support vector regressions; Swarm optimization; Uncertainty; Uncertainty sentiment; Mean square error","","","","Fama, Eugene F., Common risk factors in the returns on stocks and bonds, Journal of Financial Economics, 33, 1, pp. 3-56, (1993); Mediterranean Journal of Basic and Applied Sciences Mjbas, (2024); Global Academic Frontiers, (2024); Medrxiv, (2024); Exploiting Diffusion Prior for Out of Distribution Detection, (2024); Exploring the Impact of Quantum Computing on Machine Learning Performance, (2024); Predicting Stock Prices with Finbert Lstm Integrating News Sentiment Analysis, (2024); Research on Autonomous Robots Navigation Based on Reinforcement Learning, (2024); Attention Mechanism and Context Modeling System for Text Mining Machine Translation, (2024); Qian, Yang, Heterogeneous optoelectronic characteristics of Si micropillar arrays fabricated by metal-assisted chemical etching, Scientific Reports, 10, 1, (2020)","","Association for Computing Machinery, Inc","","2024 5th International Conference on Big Data Economy and Information Management, BDEIM 2024","","Zhengzhou","209097","","9798400711862","","","English","Conference paper","Final","","Scopus","2-s2.0-105007549549"
"Y., Liu, Yingnan; N., Bu, Ningbo; Z., Li, Zhiqiang; Y., Zhang, Yongmin; Z., Zhao, Zhenyu","Liu, Yingnan (57279737400); Bu, Ningbo (57271374600); Li, Zhiqiang (59664876800); Zhang, Yongmin (57200879893); Zhao, Zhenyu (55726190800)","57279737400; 57271374600; 59664876800; 57200879893; 55726190800","AT-FinGPT: Financial risk prediction via an audio-text large language model","2025","Finance Research Letters","77","","106967","","","0","8","10.1016/j.frl.2025.106967","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219533336&doi=10.1016%2Fj.frl.2025.106967&partnerID=40&md5=c7db138fff9b103d341c91086fed4295","Ningbo University, Ningbo, China; Ningbo Institute of Industrial Technology, Chinese Academy of Sciences, Ningbo, China; Donghai Laboratory, Zhoushan, China; Ningbo University, Ningbo, China","Liu, Yingnan, School of Business, Ningbo University, Ningbo, China; Bu, Ningbo, Zhejiang Key Laboratory of Robotics and Intelligent Manufacturing Equipment Technology, Ningbo Institute of Industrial Technology, Chinese Academy of Sciences, Ningbo, China; Li, Zhiqiang, Zhejiang Key Laboratory of Robotics and Intelligent Manufacturing Equipment Technology, Ningbo Institute of Industrial Technology, Chinese Academy of Sciences, Ningbo, China, Donghai Laboratory, Zhoushan, China; Zhang, Yongmin, School of Business, Ningbo University, Ningbo, China; Zhao, Zhenyu, School of Law, Ningbo University, Ningbo, China","Financial risk prediction is crucial for investment decision-making. Traditional machine learning methods are limited by their structures and parameter size, which hinders their generalizability and effectiveness. Large language models (LLMs), which are pretrained with very large dataset and many GPUs have recently shown promising improvements in financial risk prediction. Despite this progress, most existing financial LLMs mainly rely on textual data for training and prediction, overlooking audio data and limiting analysis to text summarization. However, natural language processing studies have shown that audio from CEOs’ quarterly earnings calls is crucial for financial risk prediction. In this work, we introduce an audio–text LLM named AT-FinGPT, which fuses financial audio data and summarization texts for financial risk prediction. The empirical experimental results show that AT-FinGPT is superior to most advanced methods. Through an ablation study, we demonstrate that different data sources can facilitate financial risk assessment and discuss the effectiveness of each part in the AT-FinGPT model. © 2025 Elsevier B.V., All rights reserved.","Fingpt; Large Language Model; Multi-sources Data Fusion; Quantitative Finance","","","","Funding text 1: This research is partly supported by the Academy of Longyuan Construction Finance Research of Ningbo University grant ( LYZDA2301 ), Major Humanities and Social Sciences Research Project in Zhejiang higher education institutions ( 2024GH026 ).; Funding text 2: This research is partly supported by Major Humanities and Social Sciences Research Project in Zhejiang higher education institutions (2024GH026), the National Social Science Fund Key Project (Grant No 24ASH009), the Academy of Longyuan Construction Finance Research of Ningbo University grant (LYZDA2301), and National Natural Science Foundation grant (71704088).","Aniunas, Povilas, Variance - Covariance risk value model for currency market, Engineering Economics, 1, 61, pp. 18-27, (2009); Baevski, Alexei, wav2vec 2.0: A framework for self-supervised learning of speech representations, Advances in Neural Information Processing Systems, 2020-December, (2020); Cui, Tianxiang, Portfolio constructions in cryptocurrency market: A CVaR-based deep reinforcement learning approach, Economic Modelling, 119, (2023); Ding, Shusheng, Futures volatility forecasting based on big data analytics with incorporating an order imbalance effect, International Review of Financial Analysis, 83, (2022); Ding, Shusheng, Liquidity effects on oil volatility forecasting: From fintech perspective, PLOS ONE, 16, 11 November, (2021); Ding, Shusheng, Modeling Price Volatility Based on a Genetic Programming Approach, British Journal of Management, 30, 2, pp. 328-340, (2019); Easton, Peter D., Forecasting Earnings Using k-Nearest Neighbors, Accounting Review, 99, 3, pp. 115-140, (2024); Mean Squared Error, (2010); Greff, Klaus, LSTM: A Search Space Odyssey, IEEE Transactions on Neural Networks and Learning Systems, 28, 10, pp. 2222-2232, (2017); Journal of Risk, (1998)","","Elsevier Ltd","","","","","","15446123","","","","English","Article","Final","","Scopus","2-s2.0-85219533336"
"K.N., Kunze, Kyle N.; N.H., Varady, Nathan H.; M.R., Mazzucco, Michael R.; A.Z., Lu, Amy Z.; J.A., Chahla, J. A.; R.K., Kyle Martin, R. Kyle; A.S., Ranawat, Anil S.; A.D., Pearle, Andrew D.; R.J., Williams, Riley Joseph","Kunze, Kyle N. (57202689199); Varady, Nathan H. (57021972500); Mazzucco, Michael R. (59286812600); Lu, Amy Z. (57203454901); Chahla, J. A. (56653427200); Kyle Martin, R. Kyle (57204968407); Ranawat, Anil S. (55315485900); Pearle, Andrew D. (6505921931); Williams, Riley Joseph (24571844600)","57202689199; 57021972500; 59286812600; 57203454901; 56653427200; 57204968407; 55315485900; 6505921931; 24571844600","The Large Language Model ChatGPT-4 Exhibits Excellent Triage Capabilities and Diagnostic Performance for Patients Presenting With Various Causes of Knee Pain","2025","Arthroscopy - Journal of Arthroscopic and Related Surgery","41","5","","1438","1447.e14","0","17","10.1016/j.arthro.2024.06.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200318191&doi=10.1016%2Fj.arthro.2024.06.021&partnerID=40&md5=364a2afd5c244051dfe6352a7bf3ba1f","Hospital for Special Surgery - New York, New York, United States; Hospital for Special Surgery - New York, New York, United States; Weill Cornell Medicine, New York, United States; Rush University Medical Center, Chicago, United States; University of Minnesota Twin Cities, Minneapolis, United States","Kunze, Kyle N., Department of Orthopaedic Surgery, Hospital for Special Surgery - New York, New York, United States, Sports Medicine and Shoulder Service, Hospital for Special Surgery - New York, New York, United States; Varady, Nathan H., Department of Orthopaedic Surgery, Hospital for Special Surgery - New York, New York, United States, Sports Medicine and Shoulder Service, Hospital for Special Surgery - New York, New York, United States; Mazzucco, Michael R., Weill Cornell Medicine, New York, United States; Lu, Amy Z., Weill Cornell Medicine, New York, United States; Chahla, J. A., Department of Orthopaedic Surgery, Rush University Medical Center, Chicago, United States; Kyle Martin, R. Kyle, Department of Orthopaedic Surgery, University of Minnesota Twin Cities, Minneapolis, United States; Ranawat, Anil S., Department of Orthopaedic Surgery, Hospital for Special Surgery - New York, New York, United States, Sports Medicine and Shoulder Service, Hospital for Special Surgery - New York, New York, United States; Pearle, Andrew D., Department of Orthopaedic Surgery, Hospital for Special Surgery - New York, New York, United States, Sports Medicine and Shoulder Service, Hospital for Special Surgery - New York, New York, United States; Williams, Riley Joseph, Department of Orthopaedic Surgery, Hospital for Special Surgery - New York, New York, United States, Sports Medicine and Shoulder Service, Hospital for Special Surgery - New York, New York, United States","Purpose: To provide a proof-of-concept analysis of the appropriateness and performance of ChatGPT-4 to triage, synthesize differential diagnoses, and generate treatment plans concerning common presentations of knee pain. Methods: Twenty knee complaints warranting triage and expanded scenarios were input into ChatGPT-4, with memory cleared prior to each new input to mitigate bias. For the 10 triage complaints, ChatGPT-4 was asked to generate a differential diagnosis that was graded for accuracy and suitability in comparison to a differential created by 2 orthopaedic sports medicine physicians. For the 10 clinical scenarios, ChatGPT-4 was prompted to provide treatment guidance for the patient, which was again graded. To test the higher-order capabilities of ChatGPT-4, further inquiry into these specific management recommendations was performed and graded. Results: All ChatGPT-4 diagnoses were deemed appropriate within the spectrum of potential pathologies on a differential. The top diagnosis on the differential was identical between surgeons and ChatGPT-4 for 70% of scenarios, and the top diagnosis provided by the surgeon appeared as either the first or second diagnosis in 90% of scenarios. Overall, 16 of 30 diagnoses (53.3%) in the differential were identical. When provided with 10 expanded vignettes with a single diagnosis, the accuracy of ChatGPT-4 increased to 100%, with the suitability of management graded as appropriate in 90% of cases. Specific information pertaining to conservative management, surgical approaches, and related treatments was appropriate and accurate in 100% of cases. Conclusions: ChatGPT-4 provided clinically reasonable diagnoses to triage patient complaints of knee pain due to various underlying conditions that were generally consistent with differentials provided by sports medicine physicians. Diagnostic performance was enhanced when providing additional information, allowing ChatGPT-4 to reach high predictive accuracy for recommendations concerning management and treatment options. However, ChatGPT-4 may show clinically important error rates for diagnosis depending on prompting strategy and information provided; therefore, further refinements are necessary prior to implementation into clinical workflows. Clinical Relevance: Although ChatGPT-4 is increasingly being used by patients for health information, the potential for ChatGPT-4 to serve as a clinical support tool is unclear. In this study, we found that ChatGPT-4 was frequently able to diagnose and triage knee complaints appropriately as rated by sports medicine surgeons, suggesting that it may eventually be a useful clinical support tool. © 2025 Elsevier B.V., All rights reserved.","Article; Chatgpt; Clinical Significance; Concept Analysis; Conservative Treatment; Differential Diagnosis; Human; Knee Pain; Large Language Model; Patient Triage; Proof Of Concept; Surgeon; Vignette; Workflow; Arthralgia; Diagnosis; Etiology; Female; Generative Artificial Intelligence; Knee Joint; Male; Procedures; Arthralgia; Diagnosis, Differential; Female; Generative Artificial Intelligence; Humans; Knee Joint; Large Language Models; Male; Proof Of Concept Study; Triage","Article; ChatGPT; clinical significance; concept analysis; conservative treatment; differential diagnosis; human; knee pain; large language model; patient triage; proof of concept; surgeon; vignette; workflow; arthralgia; diagnosis; etiology; female; generative artificial intelligence; knee joint; male; procedures; Arthralgia; Diagnosis, Differential; Female; Generative Artificial Intelligence; Humans; Knee Joint; Large Language Models; Male; Proof of Concept Study; Triage","","","","Cascella, Marco M.C., Evaluating the Feasibility of ChatGPT in Healthcare: An Analysis of Multiple Clinical and Research Scenarios, Journal of Medical Systems, 47, 1, (2023); Xiao, David, Revolutionizing Healthcare with ChatGPT: An Early Exploration of an AI Language Model's Impact on Medicine at Large and its Role in Pediatric Surgery, Journal of Pediatric Surgery, 58, 12, pp. 2410-2415, (2023); Shen, Oscar Y., How Does ChatGPT Use Source Information Compared With Google? A Text Network Analysis of Online Health Information, Clinical Orthopaedics and Related Research, 482, 4, pp. 578-588, (2024); Magruder, Matthew L., Assessing Ability for ChatGPT to Answer Total Knee Arthroplasty-Related Questions, Journal of Arthroplasty, 39, 8, pp. 2022-2027, (2024); Sosa, Branden R., Capacity for large language model chatbots to aid in orthopedic management, research, and patient queries, Journal of Orthopaedic Research, 42, 6, pp. 1276-1282, (2024); Baker, Hayden P., ChatGPT's Ability to Assist with Clinical Documentation: A Randomized Controlled Trial, Journal of the American Academy of Orthopaedic Surgeons, 32, 3, pp. 123-129, (2024); Hurley, Eoghan T., Evaluation High-Quality of Information from ChatGPT (Artificial Intelligence—Large Language Model) Artificial Intelligence on Shoulder Stabilization Surgery, Arthroscopy - Journal of Arthroscopic and Related Surgery, 40, 3, pp. 726-731.e6, (2024); Raza, Marium M., Generative AI and large language models in health care: pathways to implementation, npj Digital Medicine, 7, 1, (2024); Dave, Tirth, ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations, Frontiers in Artificial Intelligence, 6, (2023); Zheng, Yue, Innovating Healthcare: The Role of ChatGPT in Streamlining Hospital Workflow in the Future, Annals of Biomedical Engineering, 52, 4, pp. 750-753, (2024)","","W.B. Saunders","","","","","","07498063; 15263231","","ARTHE","38925234","English","Article","Final","","Scopus","2-s2.0-85200318191"
"G., Palma, Giulia; G., Cecchi, Gaia; A., Rizzo, Antonio","Palma, Giulia (57218191814); Cecchi, Gaia (59917670300); Rizzo, Antonio (35960462100)","57218191814; 59917670300; 35960462100","Large Language Models for Predictive Maintenance in the Leather Tanning Industry: Multimodal Anomaly Detection in Compressors","2025","Electronics (Switzerland)","14","10","2061","","","0","1","10.3390/electronics14102061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006684995&doi=10.3390%2Felectronics14102061&partnerID=40&md5=8dc285e07bb76ac32066ccf0505816f8","Università degli Studi di Siena, Siena, Italy","Palma, Giulia, Dipartimento di Scienze Sociali Politiche e Cognitive, Università degli Studi di Siena, Siena, Italy; Cecchi, Gaia, Dipartimento di Scienze Sociali Politiche e Cognitive, Università degli Studi di Siena, Siena, Italy; Rizzo, Antonio, Dipartimento di Scienze Sociali Politiche e Cognitive, Università degli Studi di Siena, Siena, Italy","Predictive maintenance in industrial settings increasingly demands systems capable of integrating heterogeneous data streams while balancing computational efficiency and contextual reasoning. This paper introduces a novel framework leveraging Large Language Models (LLMs) to address these challenges in compressor monitoring, demonstrating their potential to enhance anomaly detection accuracy and operational cost-effectiveness. We evaluate Qwen 2.5-32B against traditional machine learning models (ANN, CNN, LSTM), achieving superior recall (92.3%) and AUC-ROC (0.991) through transformer-based architectures optimized for multimodal data fusion. A financial case study reveals operational cost reductions of 18% via reduced downtime and optimized maintenance schedules, while a real-time monitoring dashboard validates scalability for industrial deployment. Our findings highlight the transformative role of LLMs in bridging technical innovation with domain-specific operational constraints, offering a blueprint for predictive maintenance in niche industries. © 2025 Elsevier B.V., All rights reserved.","Anomaly Detection; Industrial Compressors; Large Language Models; Machine Learning; Multimodal Data Fusion; Predictive Maintenance; Real-time Monitoring; Costs; Sensor Data Fusion; Tanning; Anomaly Detection; Industrial Compressors; Language Model; Large Language Model; Leather Tanning Industry; Machine-learning; Multi-modal; Multimodal Data Fusion; Predictive Maintenance; Real Time Monitoring","Costs; Sensor data fusion; Tanning; Anomaly detection; Industrial compressors; Language model; Large language model; Leather tanning industry; Machine-learning; Multi-modal; Multimodal data fusion; Predictive maintenance; Real time monitoring","","","","Abdelillah, Fidma Mohamed, Hybrid Data-Driven and Knowledge-Based Predictive Maintenance Framework in the Context of Industry 4.0, Lecture Notes in Computer Science, 14396 LNCS, pp. 319-337, (2024); Ak, Kenan Emir, Leveraging Efficient Training and Feature Fusion in Transformers for Multimodal Classification, Proceedings - International Conference on Image Processing, ICIP, pp. 1420-1424, (2023); Proceedings of the Cvpr 2022; Alhuqay, Saleh Othman, Improving Predictive Maintenance in Industrial Environments via IIoT and Machine Learning, International Journal of Advanced Computer Science and Applications, 15, 4, pp. 627-636, (2024); Sang, Go Muan, A Predictive Maintenance Model for Flexible Manufacturing in the Context of Industry 4.0, Frontiers in Big Data, 4, (2021); Vithi, Nontuthuzelo Lindokuhle, Advancements in Predictive Maintenance: A Bibliometric Review of Diagnostic Models Using Machine Learning Techniques, Analytics, 3, 4, pp. 493-507, (2024); Kim, Do-gyun, Optimization of design parameters in lstm model for predictive maintenance, Applied Sciences (Switzerland), 11, 14, (2021); Çınar, Zeki Murat, Machine learning in predictive maintenance towards sustainable smart manufacturing in industry 4.0, Sustainability (Switzerland), 12, 19, (2020); Aminzadeh, Ahmad, A Machine Learning Implementation to Predictive Maintenance and Monitoring of Industrial Compressors, Sensors, 25, 4, (2025); Qu, Xinji, MFGAN: Multimodal Fusion for Industrial Anomaly Detection Using Attention-Based Autoencoder and Generative Adversarial Network, Sensors, 24, 2, (2024)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","20799292","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105006684995"
"J., Hu, Jiayin; L.X., Liu, Laura Xiaolei; C.Y., Liu, Chloe Yue; H., Qu, Hao; Y., Zhang, Yingguang","Hu, Jiayin (58147411000); Liu, Laura Xiaolei (27067768300); Liu, Chloe Yue (59903975600); Qu, Hao (59904246500); Zhang, Yingguang (58669528600)","58147411000; 27067768300; 59903975600; 59904246500; 58669528600","CEO turnover, sequential disclosure, and stock returns","2025","Review of Finance","29","3","","887","921","0","0","10.1093/rof/rfaf015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005527763&doi=10.1093%2Frof%2Frfaf015&partnerID=40&md5=9ad1770a5cc2daff6f99a38208d0f1ae","Peking University, Beijing, China; Peking University, Beijing, China; Guanghua School of Management Peking University, Beijing, China; Rutgers School of Business-Camden, Camden, United States","Hu, Jiayin, Peking University, Beijing, China, Institute of Digital Finance, Peking University, Beijing, China; Liu, Laura Xiaolei, Guanghua School of Management Peking University, Beijing, China; Liu, Chloe Yue, Guanghua School of Management Peking University, Beijing, China; Qu, Hao, Rutgers School of Business-Camden, Camden, United States; Zhang, Yingguang, Guanghua School of Management Peking University, Beijing, China","We document that firms experience large negative stock returns during, and positive returns following, the first informational events after forced CEO turnovers. This V-shaped return pattern is driven by the strategic sequential disclosure of bad news and good news, aligned with incoming CEOs’ incentives to manage expectations. The pattern is more pronounced when these incentives are stronger, such as when firms earn higher stock returns and have higher valuation uncertainty leading up to the informational events. Evidence from firms’ earnings surprises, analysts’ forecast revisions, and large language model-based measures of disclosure behavior indicates that incoming CEOs often initially release bad news about realized and short-term earnings, projecting a broadly pessimistic outlook for the firm’s future performance, and subsequently disclose favorable news about longer-term earnings prospects. Our findings suggest that investors make the costly mistake of failing to discern the incentives behind managers’ disclosure. © 2025 Elsevier B.V., All rights reserved.","Ceo Turnover; Expectation Management; Stock Returns","","","","Funding text 1: We thank David Solomon (the editor), an anonymous associate editor, and an anonymous referee for their helpful feedback. We are grateful to Robert Novy-Marx, Jerold Warner, Ulrike Malmendier, Kevin Murphy, Kenneth Ahern, John Matsusaka, Oguzhan Ozbas, Wayne Ferson, Juhani Linnainmaa, Gerard Hoberg, Fernando Zapatero, and Selale Tuzel for their helpful advice and valuable comments. We also thank the participants of the University of Rochester Applied Economics Seminar, the 2024 CIRF & CFRI Joint Conference, the 2024 AsianFA annual conference, the 2023 CAAA annual conference, and the 2017 Trans-Atlantic Doctoral Conference. Laura Xiaolei Liu acknowledges financial support from the National Natural Science Foundation of China (NSFC Grant No. 72273006) and the National Social Science Fund of China (NSSFC Grant No. 23AZD082).; Funding text 2: Laura Xiaolei Liu acknowledges financial support from the National Natural Science Foundation of China (NSFC Grant No. 72273006) and the National Social Science Fund of China (NSSFC Grant No. 23AZD082).","Ajinkya, Bipin B., Dispersion of Financial Analysts' Earnings Forecasts and the (Option Model) Implied Standard Deviations of Stock Returns, Journal of Finance, 40, 5, pp. 1353-1365, (1985); Amihud, Yakov, Illiquidity and stock returns: Cross-section and time-series effects, Journal of Financial Markets, 5, 1, pp. 31-56, (2002); Anderson, Evan W., Do heterogeneous beliefs matter for asset pricing?, Review of Financial Studies, 18, 3, pp. 875-924, (2005); Asquith, Paul, Short interest, institutional ownership, and stock returns, Journal of Financial Economics, 78, 2, pp. 243-276, (2005); Atmaz, Adem, Belief Dispersion in the Stock Market, Journal of Finance, 73, 3, pp. 1225-1279, (2018); Balsam, Steven, Accruals management, investor sophistication, and equity valuation: Evidence from 10-Q filings, Journal of Accounting Research, 40, 4, pp. 987-1012, (2002); Barth, Mary E., Market rewards associated with patterns of increasing earnings, Journal of Accounting Research, 37, 2, pp. 387-413, (1999); Bartov, Eli, The rewards to meeting or beating earnings expectations, Journal of Accounting and Economics, 33, 2, pp. 173-204, (2002); Basu, Sudipta, The conservatism principle and the asymmetric timeliness of earnings, Journal of Accounting and Economics, 24, 1, pp. 3-37, (1997); Ben-Rephael, Azi, It depends on where you search: Institutional investor attention and underreaction to news, Review of Financial Studies, 30, 9, pp. 3009-3047, (2017)","","Oxford University Press","","","","","","15723097; 1573692X","","","","English","Article","Final","","Scopus","2-s2.0-105005527763"
"Y., Ke, Yusong; H., Lin, Hongru; Y., Ruan, Yuting; J., Tang, Junya; L., Li, Li","Ke, Yusong (59414498900); Lin, Hongru (59896135800); Ruan, Yuting (59896597800); Tang, Junya (57210192448); Li, Li (56261236100)","59414498900; 59896135800; 59896597800; 57210192448; 56261236100","Correctness Coverage Evaluation for Medical Multiple-Choice Question Answering Based on the Enhanced Conformal Prediction Framework","2025","Mathematics","13","9","1538","","","0","0","10.3390/math13091538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005095888&doi=10.3390%2Fmath13091538&partnerID=40&md5=89b8dfa6d591cc5b71ee29e64e87340e","Tongji University, Shanghai, China; Hunan University, Changsha, China; Fuzhou University, Fuzhou, China; Tongji University, Shanghai, China","Ke, Yusong, School of Electronic and Information Engineering, Tongji University, Shanghai, China; Lin, Hongru, School of Electrical and Information Engineering, Hunan University, Changsha, China; Ruan, Yuting, School of Economics and Management, Fuzhou University, Fuzhou, China; Tang, Junya, School of Computer Science and Technology, Tongji University, Shanghai, China; Li, Li, School of Electronic and Information Engineering, Tongji University, Shanghai, China","Large language models (LLMs) are increasingly adopted in medical question answering (QA) scenarios. However, LLMs have been proven to generate hallucinations and nonfactual information, undermining their trustworthiness in high-stakes medical tasks. Conformal Prediction (CP) is now recognized as a robust framework within the broader domain of machine learning, offering statistically rigorous guarantees of marginal (average) coverage for prediction sets. However, the applicability of CP in medical QA remains to be explored. To address this limitation, this study proposes an enhanced CP framework for medical multiple-choice question answering (MCQA) tasks. The enhanced CP framework associates the non-conformance score with the frequency score of the correct option. The framework generates multiple outputs for the same medical query by leveraging self-consistency theory. The proposed framework calculates the frequency score of each option to address the issue of limited access to the model’s internal information. Furthermore, a risk control framework is incorporated into the enhanced CP framework to manage task-specific metrics through a monotonically decreasing loss function. The enhanced CP framework is evaluated on three popular MCQA datasets using off-the-shelf LLMs. Empirical results demonstrate that the enhanced CP framework achieves user-specified average (or marginal) error rates on the test set. Moreover, the results show that the test set’s average prediction set size (APSS) decreases as the risk level increases. It is concluded that it is a promising evaluation metric for the uncertainty of LLMs. © 2025 Elsevier B.V., All rights reserved.","Average Prediction Set Size; Conformal Prediction; Large Language Models; Medical Multiple-choice Question Answering","","","","This work was supported in part by the National Natural Science Foundation of China under Grant 72171172 and 92367101; the Aeronautical Science Foundation of China under Grant 2023Z066038001; the National Natural Science Foundation of China Basic Science Research Center Program under Grant 62088101; Shanghai Municipal Science and Technology Major Project under Grant 2021SHZDZX0100.","Faria, Fatema Tuj Johora, Investigating the Predominance of Large Language Models in Low-Resource Bangla Language over Transformer Models for Hate Speech Detection: A Comparative Analysis, Mathematics, 12, 23, (2024); Singhal, Karan, Toward expert-level medical question answering with large language models, Nature Medicine, 31, 3, pp. 943-950, (2025); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Hager, Paul, Evaluation and mitigation of the limitations of large language models in clinical decision-making, Nature Medicine, 30, 9, pp. 2613-2622, (2024); Thirunavukarasu, Arun James, Large language models in medicine, Nature Medicine, 29, 8, pp. 1930-1940, (2023); He, Kai, A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics, Information Fusion, 118, (2025); Das, Badhan Chandra, Security and Privacy Challenges of Large Language Models: A Survey, ACM Computing Surveys, 57, 6, (2025); Huang, Lei, A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions, ACM Transactions on Information Systems, 43, 2, (2025); Ouyang, Long, Training language models to follow instructions with human feedback, Advances in Neural Information Processing Systems, 35, (2022); Kendall, Alex, What uncertainties do we need in Bayesian deep learning for computer vision?, Advances in Neural Information Processing Systems, 2017-December, pp. 5575-5585, (2017)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","22277390","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105005095888"
"R., Chen, Rui; H., Jiang, Haiqi; T., Guo, Tingyu; C., Fan, Chenyou","Chen, Rui (59348976100); Jiang, Haiqi (58546641500); Guo, Tingyu (59370844400); Fan, Chenyou (57191411277)","59348976100; 58546641500; 59370844400; 57191411277","Can Large Language Models forecast carbon price movements? Evidence from Chinese carbon markets","2025","Research in International Business and Finance","77","","102951","","","0","0","10.1016/j.ribaf.2025.102951","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004759515&doi=10.1016%2Fj.ribaf.2025.102951&partnerID=40&md5=d6d104805b595be55a5545462a37e798","South China Normal University, Guangzhou, China; South China Normal University, Guangzhou, China","Chen, Rui, International Business College, South China Normal University, Guangzhou, China; Jiang, Haiqi, School of Artificial Intelligence, South China Normal University, Guangzhou, China; Guo, Tingyu, International Business College, South China Normal University, Guangzhou, China; Fan, Chenyou, School of Artificial Intelligence, South China Normal University, Guangzhou, China","This paper investigates the impact of Large Language Models (LLMs) on forecasting Chinese carbon prices. We introduce a novel two-stage forecasting framework integrating a Time-Series Model (TSM) and Large Language Models. Initially, we use historical data on Chinese Emission Allowance prices to train the TSM for preliminary predictions. LLMs then refine these predictions, which process a sequence of past and corresponding future prices as a chain of thought. Additionally, we utilize the LLM to analyze and categorize the sentiment of news headlines, generating market sentiment labels that enhance the LLM's predictive accuracy. Our findings indicate that LLMs can improve TSM forecasts by 28–38 % across different regional markets. Furthermore, incorporating news sentiment labels into the LLM contributes an additional reduction in forecasting deviations, ranging from 3–4 %. © 2025 Elsevier B.V., All rights reserved.","Carbon Price Forecasting; Financial Sentiment Analysis; Large Language Models; Machine Learning","","","","The authors gratefully acknowledge the comments by the editors and reviewers that helped in improving the manuscript. Rui Chen gratefully acknowledges the support from the Research Cultivation Fund Project for Young Teachers at South China Normal University (No. 24SK30), the Social Science Planning Project of Foshan (No. 2024-QN06) and the Guangdong Planning Office of Philosophy and Social Science (No. GD24XGL054). Chenyou Fan gratefully thanks for the support from the Guangdong Basic and Applied Basic Research Foundation (No. 2024A1515011650).","undefined, (2019); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Cao, Sean Shun, How to Talk When a Machine Is Listening: Corporate Disclosure in the Age of AI, Review of Financial Studies, 36, 9, pp. 3603-3642, (2023); Chai, Shanglei, Forecasting electricity prices from the state-of-the-art modeling technology and the price determinant perspectives, Research in International Business and Finance, 67, (2024); undefined, (2023); Duan, Kun, Exploring the predictability of attention mechanism with LSTM: Evidence from EU carbon futures prices, Research in International Business and Finance, 66, (2023); undefined, (2023); Gofman, Michael, Artificial Intelligence, Education, and Entrepreneurship, Journal of Finance, 79, 1, pp. 631-667, (2024); Gu, Shihao, Empirical Asset Pricing via Machine Learning, Review of Financial Studies, 33, 5, pp. 2223-2273, (2020); Hoberg, Gerard, Text-based network industries and endogenous product differentiation, Journal of Political Economy, 124, 5, pp. 1423-1465, (2016)","","Elsevier Ltd","","","","","","02755319","","","","English","Article","Final","","Scopus","2-s2.0-105004759515"
"G., Lee, Geon; W., Yu, Wenchao; K., Shin, Kijung; W., Cheng, Wei; H., Chen, Haifeng","Lee, Geon (57219028438); Yu, Wenchao (57188803893); Shin, Kijung (56719008000); Cheng, Wei (57218967449); Chen, Haifeng (35241923100)","57219028438; 57188803893; 56719008000; 57218967449; 35241923100","TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents","2025","Proceedings of the AAAI Conference on Artificial Intelligence","39","17","","18082","18090","0","1","10.1609/aaai.v39i17.33989","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004169893&doi=10.1609%2Faaai.v39i17.33989&partnerID=40&md5=cb106caaed42db9c228416a4965a80ad","Korea Advanced Institute of Science and Technology, Daejeon, South Korea; NEC Laboratories America, Inc., Princeton, United States","Lee, Geon, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Yu, Wenchao, NEC Laboratories America, Inc., Princeton, United States; Shin, Kijung, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Cheng, Wei, NEC Laboratories America, Inc., Princeton, United States; Chen, Haifeng, NEC Laboratories America, Inc., Princeton, United States","Time series data is essential in various applications, including climate modeling, healthcare monitoring, and financial analytics. Understanding the contextual information associated with real-world time series data is often essential for accurate and reliable event predictions. In this paper, we introduce TimeCAP, a time-series processing framework that creatively employs Large Language Models (LLMs) as contextualizers of time series data, extending their typical usage as predictors. TimeCAP incorporates two independent LLM agents: one generates a textual summary capturing the context of the time series, while the other uses this enriched summary to make more informed predictions. In addition, TimeCAP employs a multi-modal encoder that synergizes with the LLM agents, enhancing predictive performance through mutual augmentation of inputs with in-context examples. Experimental results on real-world datasets demonstrate that TimeCAP outperforms state-of-the-art methods for time series event prediction, including those utilizing LLMs as predictors, achieving an average improvement of 28.75% in F1 score. © 2025 Elsevier B.V., All rights reserved.","Contextual Information; Contextualize; Event Prediction; Healthcare Monitoring; Language Model; Model Agents; Real-world Time Series; Time Series Processing; Time-series Data; Time-series Events","Contextual information; Contextualize; Event prediction; Healthcare monitoring; Language model; Model agents; Real-world time series; Time series processing; Time-series data; Time-series events","","","This work was partly supported by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. RS-2024-00438638, EntireDB2AI: Foundations and Software for Comprehensive Deep Representation Learning and Prediction on Entire Relational Databases, 50%) (No. 2019-0-00075/RS-2019-II190075, Artificial Intelligence Graduate School Program (KAIST), 10%). This work was partly supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. RS-2024-00406985, 40%).","Gpt 4 Technical Report, (2023); Palm 2 Technical Report, (2023); Chronos Learning the Language of Time Series, (2024); Aaai 94 Workshop on Knowledge Discovery in Databases, (1994); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Tempo Prompt Based Generative Pre Trained Transformer for Time Series Forecasting, (2023); Llm4ts Two Stage Fine Tuning for Time Series Forecasting with Pre Trained Llms, (2023); Chen, Sian, TSMixer: An All-MLP Architecture for Time Series Forecasting, Transactions on Machine Learning Research, 2023, (2023); Introduction to Modern Information Retrieval, (2004); Leveraging Large Language Models for Pre Trained Recommender Systems, (2023)","Walsh, T.; Shah, J.; Kolter, Z.","Association for the Advancement of Artificial Intelligence","Association for the Advancement of Artificial Intelligence","39th Annual AAAI Conference on Artificial Intelligence, AAAI 2025","","Philadelphia; PA","208400","23743468; 21595399","9781577358879; 157735897X; 9781577358978; 1577358872; 9781577358800","","","English","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105004169893"
"Z., Zhao, Zhe; P., Wang, Pengkun; H., Wen, Haibin; S., Wang, Shuang; L., Yu, Liheng; Y., Wang, Yang","Zhao, Zhe (57866913400); Wang, Pengkun (57212167571); Wen, Haibin (58972278700); Wang, Shuang (35211669300); Yu, Liheng (59390338000); Wang, Yang (56103302800)","57866913400; 57212167571; 58972278700; 35211669300; 59390338000; 56103302800","STEM-LTS: Integrating Semantic-Temporal Dynamics in LLM-driven Time Series Analysis","2025","Proceedings of the AAAI Conference on Artificial Intelligence","39","21","","22858","22866","0","1","10.1609/aaai.v39i21.34447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003993412&doi=10.1609%2Faaai.v39i21.34447&partnerID=40&md5=0e6760f6a78e7dd559e2387d51f138d1","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; City University of Hong Kong, Hong Kong, Hong Kong; Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Key Laboratory of Precision and Intelligent Chemistry, Hefei, China","Zhao, Zhe, University of Science and Technology of China, Hefei, China, City University of Hong Kong, Hong Kong, Hong Kong; Wang, Pengkun, University of Science and Technology of China, Hefei, China, University of Science and Technology of China, Hefei, China; Wen, Haibin, Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Wang, Shuang, University of Science and Technology of China, Hefei, China; Yu, Liheng, University of Science and Technology of China, Hefei, China; Wang, Yang, University of Science and Technology of China, Hefei, China, University of Science and Technology of China, Hefei, China, Key Laboratory of Precision and Intelligent Chemistry, Hefei, China","Time series forecasting plays a crucial role in domains such as finance, healthcare, and climate science. However, as modern time series data become increasingly complex, featuring high dimensionality, intricate spatiotemporal dependencies, and multi-scale evolutionary patterns, traditional analytical methods and existing predictive models face significant challenges. Although Large Language Models (LLMs) excel in capturing long-range dependencies, they still struggle with multi-scale dynamics and seasonal patterns. Moreover, while LLMs’ semantic representation capabilities are rich, they often lack explicit alignment with the numerical patterns and temporal structures of time series data, leading to limitations in predictive accuracy and interpretability. To address these challenges, this paper proposes a novel framework, STEM-LTS (Semantic-TEmporal Modeling for Large-scale Time Series). STEM-LTS enhances the ability to capture complex spatiotemporal dependencies by integrating time series decomposition techniques with LLM-based modeling. The semantic-temporal alignment mechanism within the framework significantly improves LLMs’ ability to interpret and forecast time series data. Additionally, we develop an adaptive multi-task learning strategy to optimize the model’s performance across multiple dimensions. Through extensive experiments on various real-world datasets, we demonstrate that STEM-LTS achieves significant improvements in prediction accuracy, robustness to noise, and interpretability. Our work not only advances LLM-based time series analysis but also offers new perspectives on handling complex temporal data. © 2025 Elsevier B.V., All rights reserved.","Time Series Analysis; Interpretability; Language Model; Large-scale Time Series; Model-based Opc; Model-driven; Spatio-temporal Dependencies; Temporal Dynamics; Temporal Models; Time-series Analysis; Time-series Data; Multi-task Learning","Time series analysis; Interpretability; Language model; Large-scale time series; Model-based OPC; Model-driven; Spatio-temporal dependencies; Temporal dynamics; Temporal models; Time-series analysis; Time-series data; Multi-task learning","","","This work was supported by the Natural Science Foundation of China Youth Project (No. 62402472), the Natural Science Foundation of Jiangsu Province of China Youth Project (No. BK20240461,BK20240460), the Research Grants Council of the Hong Kong Special Administrative Region, China (GRF Project No. CityU 11215723), National Natural Science Foundation of China (No.62072427, No.12227901), the Project of Stable Support for Youth Team in Basic Research Field, CAS (No.YSBR-005), Academic Leaders Cultivation Program, USTC and the Key Basic Research Foundation of Shenzhen, China (JCYJ20220818100005011).","International Conference on Learning Representations, (2018); Time Series Analysis Forecasting and Control, (2015); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Cao, Defu, TEMPO: PROMPT-BASED GENERATIVE PRE-TRAINED TRANSFORMER FOR TIME SERIES FORECASTING, (2024); Journal of Official Statistics, (2024); De Livera, Alysha M., Forecasting time series with complex seasonal patterns using exponential smoothing, Journal of the American Statistical Association, 106, 496, pp. 1513-1527, (2011); Time Series Analysis by State Space Methods, (2001); Hochreiter, Sepp, Long Short-Term Memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Jia, Furong, GPT4MTS: Prompt-Based Large Language Model for Multimodal Time-Series Forecasting, Proceedings of the AAAI Conference on Artificial Intelligence, 38, 21, pp. 23343-23351, (2024); International Joint Conference on Artificial Intelligence, (2019)","Walsh, T.; Shah, J.; Kolter, Z.","Association for the Advancement of Artificial Intelligence","Association for the Advancement of Artificial Intelligence","39th Annual AAAI Conference on Artificial Intelligence, AAAI 2025","","Philadelphia; PA","208400","23743468; 21595399","9781577358879; 157735897X; 9781577358978; 1577358872; 9781577358800","","","English","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105003993412"
"S., Bi, Shuochen; J., Xiao, Jue; T., Deng, Tingting","Bi, Shuochen (59124614800); Xiao, Jue (59124614900); Deng, Tingting (59124330700)","59124614800; 59124614900; 59124330700","The Role of AI in Financial Forecasting: ChatGPT’s Potential and Challenges","2025","","","","","1064","1070","0","4","10.1145/3718491.3718663","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002689657&doi=10.1145%2F3718491.3718663&partnerID=40&md5=435207699d79b1a8c4021c269153a427","D'Amore-McKim School of Business, Boston, United States; University of Connecticut, Jersey City, United States; Northeastern University, Boston, United States","Bi, Shuochen, D'Amore-McKim School of Business, Boston, United States; Xiao, Jue, School of Business, University of Connecticut, Jersey City, United States; Deng, Tingting, Northeastern University, Boston, United States","The outlook for the future of artificial intelligence (AI) in the financial sector, especially in financial forecasting, the challenges and implications. The dynamics of AI technology, including deep learning, reinforcement learning, and integration with blockchAIn and the Internet of Things, also highlight the continued improvement in data processing capabilities. Explore how AI is reshaping financial services with precisely tAIlored services that can more precisely meet the diverse needs of individual investors. The integration of AI challenges regulatory and ethical issues in the financial sector, as well as the implications for data privacy protection. Analyze the limitations of current AI technology in financial forecasting and its potential impact on the future financial industry landscape, including changes in the job market, the emergence of new financial institutions, and user interface innovations. Emphasizing the importance of increasing investor understanding and awareness of AI and looking ahead to future trends in AI tools for user experience to drive wider adoption of AI in financial decision making. The huge potential, challenges, and future directions of AI in the financial sector highlight the critical role of AI technology in driving transformation and innovation in the financial sector. © 2025 Elsevier B.V., All rights reserved.","Artificial Intelligence; Chatgpt; Financial Forecasting; Multimodal Language Model; Risklabs; Differential Privacy; Artificial Intelligence Technologies; Chatgpt; Financial Forecasting; Financial Sectors; Language Model; Learning Reinforcements; Multi-modal; Multimodal Language Model; Reinforcement Learnings; Risklab; Decentralized Finance","Differential privacy; Artificial intelligence technologies; ChatGPT; Financial forecasting; Financial sectors; Language model; Learning reinforcements; Multi-modal; Multimodal language model; Reinforcement learnings; Risklab; Decentralized finance","","","","Karamoozian, Amirhossein, An Approach for Risk Prioritization in Construction Projects Using Analytic Network Process and Decision Making Trial and Evaluation Laboratory, IEEE Access, 7, pp. 159842-159854, (2019); Dowling, Michael Mark, ChatGPT for (Finance) research: The Bananarama Conjecture, Finance Research Letters, 53, (2023); Partners Universal International Innovation Journal, (2023); Democratizing Financial Knowledge with Chatgpt by Openai Unleashing the Power of Technology, (2023); Gong, Yulu, Utilizing Deep Learning for Enhancing Network Resilience in Finance, pp. 987-991, (2024); Fritz-Morgenthal, Sebastian G., Financial Risk Management and Explainable, Trustworthy, Responsible AI, Frontiers in Artificial Intelligence, 5, (2022); Iot Traffic Classification and Anomaly Detection Method Based on Deep Autoencoder, (2024); Strategic Long Term Financial Risks Intermediate Report, (2000)","","Association for Computing Machinery, Inc","","4th Asia-Pacific Artificial Intelligence and Big Data Forum, AIBDF 2024","","Ganzhou","208037","","9798400710865","","","English","Conference paper","Final","All Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-105002689657"
"S., Lu, Sarah; K.S., Nietsch, Katrina S.; A.H., Duey, Akiro H.; B., Zaidat, Bashar; L.C., Mazudie Ndjonko, Laura Chelsea; N., Shrestha, Nancy; J., Kim, Jun; S.K.W., Cho, Samuel Kang Wook","Lu, Sarah (59170466700); Nietsch, Katrina S. (57284543500); Duey, Akiro H. (57355466400); Zaidat, Bashar (57899329300); Mazudie Ndjonko, Laura Chelsea (58789750600); Shrestha, Nancy (58558902000); Kim, Jun (59868417400); Cho, Samuel Kang Wook (40161150300)","59170466700; 57284543500; 57355466400; 57899329300; 58789750600; 58558902000; 59868417400; 40161150300","Management of lower extremity traumas: Comparing appropriate use criteria ChatGPT recommendations","2025","American Journal of Surgery","242","","116229","","","0","0","10.1016/j.amjsurg.2025.116229","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217415854&doi=10.1016%2Fj.amjsurg.2025.116229&partnerID=40&md5=2ce710644a8524d53a57d29f4de595fa","California University of Science and Medicine, Colton, United States; Icahn School of Medicine at Mount Sinai, New York, United States; Northwestern University, Evanston, United States; Rosalind Franklin University of Medicine and Science, North Chicago, United States","Lu, Sarah, California University of Science and Medicine, Colton, United States; Nietsch, Katrina S., Icahn School of Medicine at Mount Sinai, New York, United States; Duey, Akiro H., Icahn School of Medicine at Mount Sinai, New York, United States; Zaidat, Bashar, Icahn School of Medicine at Mount Sinai, New York, United States; Mazudie Ndjonko, Laura Chelsea, Northwestern University, Evanston, United States; Shrestha, Nancy, Rosalind Franklin University of Medicine and Science, North Chicago, United States; Kim, Jun, Icahn School of Medicine at Mount Sinai, New York, United States; Cho, Samuel Kang Wook, Icahn School of Medicine at Mount Sinai, New York, United States","Background: High-energy lower extremity injury presents with difficult clinical decisions because successful limb salvage is the best scenario for complex traumas, but early amputation may be necessary to limit complications. Artificial Intelligence is a tool rising in popularity to help make clinical judgements. Purpose/questions: The aim of this study is to determine whether ChatGPT-4 can produce accurate recommendations for limb salvage or amputation given various patient scenarios. Methods: Various lower leg trauma scenarios were given to the appropriate use criteria for limb salvage made by AAOS or ChatGPT-4. A recommendation score for limb salvage and early amputation were collected. Tests to determine statistical significance between AAOS and ChatGPT-4 were performed. Results: A total of 196 patient scenario combinations were utilized. The mean error for limb salvage and early amputation were −0.3 and −0.2 respectively. AAOS and ChatGPT had significant positive correlations when predicting limb salvage and early amputation scores. The effect size of limb salvage and early amputation was −0.094 and −0.14, respectively. Conclusion: ChatGPT-4 generally under-estimates appropriateness scores for both limb salvage and early amputation treatment options, but produces similar scores. ChatGPT-4 may be used to aid physicians in choosing between limb salvage and early amputation, though with caution. © 2025 Elsevier B.V., All rights reserved.","Adult; Amputation; Article; Artificial Intelligence; Bone Injury; Chatgpt; Clinical Outcome; Comparative Study; Contamination; Decision Making; High Risk Patient; Human; Limb Salvage; Lower Leg; Major Clinical Study; Muscle Injury; Clinical Decision Making; Female; Leg Injury; Male; Procedures; Surgery; Therapy; Adult; Amputation, Surgical; Artificial Intelligence; Clinical Decision-making; Female; Humans; Leg Injuries; Limb Salvage; Male","adult; amputation; Article; artificial intelligence; bone injury; ChatGPT; clinical outcome; comparative study; contamination; decision making; high risk patient; human; limb salvage; lower leg; major clinical study; muscle injury; clinical decision making; female; leg injury; male; procedures; surgery; therapy; Adult; Amputation, Surgical; Artificial Intelligence; Clinical Decision-Making; Female; Humans; Leg Injuries; Limb Salvage; Male","","","One or more of the authors (Samuel Cho) has received funding from Cerapedics, Globus Medical, and AO Spine","Limb Salvage or Early Amputation Evidence Based Clinical Practice Guideline, (2019); Schirò, Giuseppe Rosario, Primary amputation vs limb salvage in mangled extremity: A systematic review of the current scoring system, BMC Musculoskeletal Disorders, 16, 1, (2015); Dave, Tirth, ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations, Frontiers in Artificial Intelligence, 6, (2023); Ren, Yuanfang, Performance of a Machine Learning Algorithm Using Electronic Health Record Data to Predict Postoperative Complications and Report on a Mobile Platform, JAMA Network Open, 5, 5, (2022); Ziegler-Graham, Kathryn, Estimating the Prevalence of Limb Loss in the United States: 2005 to 2050, Archives of Physical Medicine and Rehabilitation, 89, 3, pp. 422-429, (2008); Jovanović, Mladen J., Principles of management of high-energy injuries of the leg, Medicinski Pregled, 55, 9-10, pp. 437-442, (2002); Dischinger, Patricia C., Consequences and costs of lower extremity injuries, Annual proceedings / Association for the Advancement of Automotive Medicine. Association for the Advancement of Automotive Medicine, pp. 339-353, (2004); Res Sq, (2023); Kung, Tiffany H., Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models, PLOS Digital Health, 2, 2 February, (2023); Daraz, Lubna, Can Patients Trust Online Health Information? A Meta-narrative Systematic Review Addressing the Quality of Health Information on the Internet, Journal of General Internal Medicine, 34, 9, pp. 1884-1891, (2019)","","Elsevier Inc.","","","","","","18791883; 00029610","","AJSUA","39939215","English","Article","Final","","Scopus","2-s2.0-85217415854"
"I.C., Chiu, I. Chan; M., Hung, Mao-wei","Chiu, I. Chan (59224679900); Hung, Mao-wei (7202454394)","59224679900; 7202454394","Finance-specific large language models: Advancing sentiment analysis and return prediction with LLaMA 2","2025","Pacific Basin Finance Journal","90","","102632","","","0","3","10.1016/j.pacfin.2024.102632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212046024&doi=10.1016%2Fj.pacfin.2024.102632&partnerID=40&md5=a6bce3476100f063a04ce8b44dc27af5","National Taiwan University, Taipei, Taiwan; National Taiwan University, Taipei, Taiwan","Chiu, I. Chan, National Taiwan University, Taipei, Taiwan; Hung, Mao-wei, Department of International Business, National Taiwan University, Taipei, Taiwan","In this study, we develop an AI-driven summarization process for lengthy financial texts to improve our self-trained, finance-specific LLaMA-2 model. This approach allows for precise sentiment analysis, leading to more accurate return predictions on disclosures in the Management Discussion and Analysis sections of 10-K filings. Empirical results indicate that trading strategies based on LLaMA-2 sentiments produce significantly higher buy-and-hold returns (BHRs) compared to those derived from FinBERT (Huang et al., 2023) and traditional models. Furthermore, LLaMA-2 sentiment signals show a strong correlation with cumulative abnormal returns (CARs) and surpass traditional methods in predictive accuracy. The summarization process also enhances traditional models, generating significantly higher BHRs with summarized texts than with full texts. Both BHR and CAR results in our approach show robustness during periods of financial turbulence. These findings underscore the value of generative AI in finance and set a new standard for textual analysis. © 2024 Elsevier B.V., All rights reserved.","Ai-driven Summarization; Disclosures; Generative Ai; Large Language Model; Sentiment Analysis; Textual Analysis","","","","","Azimi, Mehran, Is Positive Sentiment in Corporate Annual Reports Informative? Evidence from Deep Learning, Review of Asset Pricing Studies, 11, 4, pp. 762-805, (2021); Journal of Accounting Research, (1968); Swiss Finance Institute Research Paper, (2022); Bochkay, Khrystyna, Hyperbole or reality? Investor response to extreme language in earnings conference calls, Accounting Review, 95, 2, pp. 31-60, (2020); Bochkay, Khrystyna, Textual Analysis in Accounting: What's Next?*, Contemporary Accounting Research, 40, 2, pp. 765-805, (2023); Bollen, Johan, Twitter mood predicts the stock market, Journal of Computational Science, 2, 1, pp. 1-8, (2011); undefined, (2023); Chang, Eric C., Ex-day returns of stock distributions: An anchoring explanation, Management Science, 65, 3, pp. 1076-1095, (2019); Chen, Hailiang, Wisdom of crowds: The value of stock opinions transmitted through social media, Review of Financial Studies, 27, 5, pp. 1367-1403, (2014); Cole, Cathy J., The Usefulness of MD&A Disclosures in the Retail Industry, Journal of Accounting, Auditing and Finance, 19, 4, pp. 361-388, (2004)","","Elsevier B.V.","","","","","","0927538X","","PBFJE","","English","Article","Final","","Scopus","2-s2.0-85212046024"
"A., Maarouf, Abdurahman; S., Feuerriegel, Stefan; N., Pröllochs, Nicolas","Maarouf, Abdurahman (57956250400); Feuerriegel, Stefan (53881265200); Pröllochs, Nicolas (56902630900)","57956250400; 53881265200; 56902630900","A fused large language model for predicting startup success","2025","European Journal of Operational Research","322","1","","198","214","0","8","10.1016/j.ejor.2024.09.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203497919&doi=10.1016%2Fj.ejor.2024.09.011&partnerID=40&md5=8e3a05c66d596d05c5d0d3356cb5a52e","Munich Center for Machine Learning, Munich, Germany; Justus-Liebig-Universität Gießen, Giessen, Germany","Maarouf, Abdurahman, Munich Center for Machine Learning, Munich, Germany; Feuerriegel, Stefan, Munich Center for Machine Learning, Munich, Germany; Pröllochs, Nicolas, Justus-Liebig-Universität Gießen, Giessen, Germany","Investors are continuously seeking profitable investment opportunities in startups and, hence, for effective decision-making, need to predict a startup's probability of success. Nowadays, investors can use not only various fundamental information about a startup (e.g., the age of the startup, the number of founders, and the business sector) but also textual description of a startup's innovation and business model, which is widely available through online venture capital (VC) platforms such as Crunchbase. To support the decision-making of investors, we develop a machine learning approach with the aim of locating successful startups on VC platforms. Specifically, we develop, train, and evaluate a tailored, fused large language model to predict startup success. Thereby, we assess to what extent self-descriptions on VC platforms are predictive of startup success. Using 20,172 online profiles from Crunchbase, we find that our fused large language model can predict startup success, with textual self-descriptions being responsible for a significant part of the predictive power. Our work provides a decision support tool for investors to find profitable investment opportunities. © 2025 Elsevier B.V., All rights reserved.","Deep Learning; Large Language Models; Machine Learning; Text Mining; Venture Capital; Decentralized Finance; Business Sector; Decisions Makings; Deep Learning; Investment Opportunities; Language Model; Large Language Model; Machine-learning; Probability Of Success; Text-mining; Venture Capital; Adversarial Machine Learning","Decentralized finance; Business sector; Decisions makings; Deep learning; Investment opportunities; Language model; Large language model; Machine-learning; Probability of success; Text-mining; Venture Capital; Adversarial machine learning","","","","Aggarwal, Rohit, Differential influence of blogs across different stages of decision making: The case of venture capitalists, MIS Quarterly: Management Information Systems, 37, 4, pp. 1093-1112, (2013); Alamsyah, Andry, Predictive modelling for startup and investor relationship based on crowdfunding platform data, Journal of Physics: Conference Series, 971, 1, (2018); Arroyo, Javier, Assessment of machine learning performance for decision support in venture capital investments, IEEE Access, 7, pp. 124233-124243, (2019); Bastani, Hamsa, Applied Machine Learning in Operations Management, Springer Series in Supply Chain Management, 11, pp. 189-222, (2022); Baum, Joel A. C., Picking winners or building them? Alliance, intellectual, and human capital as selection criteria in venture financing and performance of biotechnology startups, Journal of Business Venturing, 19, 3, pp. 411-436, (2004); In Context Learning with Long Context Models an in Depth Exploration, (2024); Business Model DNA Towards an Approach for Predicting Business Model Success, (2017); Bolukbasi, Tolga, Man is to computer programmer as woman is to homemaker? Debiasing word embeddings, Advances in Neural Information Processing Systems, pp. 4356-4364, (2016); Borchert, Philipp, Extending business failure prediction models with textual website content using deep learning, European Journal of Operational Research, 306, 1, pp. 348-357, (2023); Butler, John Sibley, Social networks, funding, and regional advantages in technology entrepreneurship: An empirical analysis, Information Systems Research, 31, 1, pp. 198-216, (2020)","","Elsevier B.V.","","","","","","03772217","","EJORD","","English","Article","Final","All Open Access; Green Accepted Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85203497919"
"X., Zhu, Xuanrong; H., Li, Hui","Zhu, Xuanrong (59730662200); Li, Hui (57060911000)","59730662200; 57060911000","Heating, Ventilation, and Air Conditioning (HVAC) Temperature and Humidity Control Optimization Based on Large Language Models (LLMs)","2025","Energies","18","7","1813","","","0","1","10.3390/en18071813","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002274621&doi=10.3390%2Fen18071813&partnerID=40&md5=f814c79f24409dce1edaf344181cec0b","Shanghai University of Electric Power, Shanghai, China","Zhu, Xuanrong, College of Automation Engineering, Shanghai University of Electric Power, Shanghai, China; Li, Hui, College of Automation Engineering, Shanghai University of Electric Power, Shanghai, China","Heating, Ventilation, and Air Conditioning (HVAC) systems primarily consist of pre-cooling air handling units (PAUs), air handling units (AHUs), and air ducts. Existing HVAC control methods, such as Proportional–Integral–Derivative (PID) control or Model Predictive Control (MPC), face limitations in understanding high-level information, handling rare events, and optimizing control decisions. Therefore, to address the various challenges in temperature and humidity control, a more sophisticated control approach is required to make high-level decisions and coordinate the operation of HVAC components. This paper utilizes Large Language Models (LLMs) as a core component for interpreting complex operational scenarios and making high-level decisions. A chain-of-thought mechanism is designed to enable comprehensive reasoning through LLMs, and an algorithm is developed to convert LLM decisions into executable HVAC control commands. This approach leverages adaptive guidance through parameter matrices to seamlessly integrate LLMs with underlying MPC controllers. Simulated experimental results demonstrate that the improved control strategy, optimized through LLM-enhanced Model Predictive Control (MPC), significantly enhances the energy efficiency and stability of HVAC system control. During the summer conditions, energy consumption is reduced by 33.3% compared to the on–off control strategy and by 6.7% relative to the conventional low-level MPC strategy. Additionally, during the system startup phase, energy consumption is slightly reduced by approximately 17.1% compared to the on–off control strategy. Moreover, the proposed method achieves superior temperature stability, with the mean squared error (MSE) reduced by approximately 35% compared to MPC and by 45% relative to on–off control. © 2025 Elsevier B.V., All rights reserved.","Hvac; Large Language Models; Model Predictive Control; Adaptive Control Systems; Air Conditioning Ducts; Hvac; Problem Oriented Languages; Three Term Control Systems; Ventilation Ducts; Air Conditioning Controls; Air-handling Unit; Conditioning Systems; Control Strategies; Heating Ventilation And Air Conditioning; Language Model; Large Language Model; Model-predictive Control; On/off Control; Temperature And Humidity Control; Predictive Control Systems","Adaptive control systems; Air conditioning ducts; HVAC; Problem oriented languages; Three term control systems; Ventilation ducts; Air conditioning controls; Air-handling unit; Conditioning systems; Control strategies; Heating ventilation and air conditioning; Language model; Large language model; Model-predictive control; On/off control; Temperature and humidity control; Predictive control systems","","","This research was funded by the Shanghai Committee of Science and Technology, number 20dz1206100.","Wang, Xinli, Model-based optimization strategy of chiller driven liquid desiccant dehumidifier with genetic algorithm, Energy, 82, pp. 939-948, (2015); undefined; Mandel, Tim, Balancing heat saving and supply in local energy planning: Insights from 1970-1989 buildings in three European countries, Smart Energy, 12, (2023); Shen, Chenyao, Analysis of building energy consumption in a hospital in the hot summer and cold winter area, Energy Procedia, 158, pp. 3735-3740, (2019); Doboși, Ioan Silviu, Building energy modelling for the energy performance analysis of a hospital building in various locations, E3S Web of Conferences, 111, (2019); Silva, Brenda V.F., Sustainable, green, or smart? Pathways for energy-efficient healthcare buildings, Sustainable Cities and Society, 100, (2024); Teke, Ahmet, Assessing the energy efficiency improvement potentials of HVAC systems considering economic and environmental aspects at the hospitals, Renewable and Sustainable Energy Reviews, 33, pp. 224-235, (2014); Stockwell, Rebecca E., Indoor hospital air and the impact of ventilation on bioaerosols: a systematic review, Journal of Hospital Infection, 103, 2, pp. 175-184, (2019); Papadopoulos, Sokratis, Rethinking HVAC temperature setpoints in commercial buildings: The potential for zero-cost energy savings and comfort improvement in different climates, Building and Environment, 155, pp. 350-359, (2019); J Pathog, (2013)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","19961073","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105002274621"
"J.A., Logan, Julia A.; S., Sadhu, Sriya; C., Hazlewood, Cameo; M., Denton, Melissa; S.E., Burke, Sara E.; C.A., Simone-Soule, Christina A.; C., Black, Caroline; C., Ciaverelli, Corey; J., Stulb, Jacqueline; H., Nourzadeh, Hamidreza","Logan, Julia A. (59013917500); Sadhu, Sriya (59730351300); Hazlewood, Cameo (58819752000); Denton, Melissa (57927787300); Burke, Sara E. (59283050900); Simone-Soule, Christina A. (59730351400); Black, Caroline (59729411100); Ciaverelli, Corey (35769158200); Stulb, Jacqueline (59730353700); Nourzadeh, Hamidreza (35587354600)","59013917500; 59730351300; 58819752000; 57927787300; 59283050900; 59730351400; 59729411100; 35769158200; 59730353700; 35587354600","Bridging Gaps in Cancer Care: Utilizing Large Language Models for Accessible Dietary Recommendations","2025","Nutrients","17","7","1176","","","0","1","10.3390/nu17071176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002222811&doi=10.3390%2Fnu17071176&partnerID=40&md5=5f5f79ce32b54faa981d4ad2c73fbc85","Sidney Kimmel Medical College, Philadelphia, United States; Thomas Jefferson University, Philadelphia, United States; Sidney Kimmel Medical College, Philadelphia, United States","Logan, Julia A., Sidney Kimmel Medical College, Philadelphia, United States; Sadhu, Sriya, Sidney Kimmel Medical College, Philadelphia, United States; Hazlewood, Cameo, Sidney Kimmel Medical College, Philadelphia, United States; Denton, Melissa, Thomas Jefferson University, Philadelphia, United States; Burke, Sara E., Sidney Kimmel Medical College, Philadelphia, United States; Simone-Soule, Christina A., Sidney Kimmel Medical College, Philadelphia, United States; Black, Caroline, Thomas Jefferson University, Philadelphia, United States; Ciaverelli, Corey, Thomas Jefferson University, Philadelphia, United States; Stulb, Jacqueline, Thomas Jefferson University, Philadelphia, United States; Nourzadeh, Hamidreza, Sidney Kimmel Medical College, Philadelphia, United States","Background/Objectives: Weight management is directly linked to cancer recurrence and survival, but unfortunately, nutritional oncology counseling is not typically covered by insurance, creating a disparity for patients without nutritional education and food access. Novel ways of imparting personalized nutrition advice are needed to address this issue. Large language models (LLMs) offer a promising path toward tailoring dietary advice to individual patients. This study aimed to assess the capacity of LLMs to offer personalized dietary advice to patients with breast cancer. Methods: Thirty-one prompt templates were designed to evaluate dietary recommendations generated by ChatGPT and Gemini with variations within eight categorical variables: cancer stage, comorbidity, location, culture, age, dietary guideline, budget, and store. Seven prompts were selected for four board-certified oncology dietitians to also respond to. Responses were evaluated based on nutritional content and qualitative observations. A quantitative comparison of the calories and macronutrients of the LLM- and dietitian-generated meal plans via the Acceptable Macronutrient Distribution Ranges and United States Department of Agriculture’s estimated calorie needs was performed. Conclusions: The LLMs generated personalized grocery lists and meal plans adapting to location, culture, and budget but not age, disease stage, comorbidities, or dietary guidelines. Gemini provided more comprehensive responses, including visuals and specific prices. While the dietitian-generated diets offered more adherent total daily calorie contents to the United States Department of Agriculture’s estimated calorie needs, ChatGPT and Gemini offered more adherent macronutrient ratios to the Acceptable Macronutrient Distribution Range. Overall, the meal plans were not significantly different between the LLMs and dietitians. LLMs can provide personalized dietary advice to cancer patients who may lack access to this care. Grocery lists and meal plans generated by LLMs are applicable to patients with variable food access, socioeconomic means, and cultural preferences and can be a tool to increase health equity. © 2025 Elsevier B.V., All rights reserved.","Artificial Intelligence; Breast Cancer; Cancer; Diet; Weight Management; Adult; Article; Body Weight Gain; Breast Cancer; Calorie; Cancer Patient; Cancer Staging; Chatgpt; Cohort Analysis; Communication Barrier; Comorbidity; Controlled Study; Cultural Background; Diet Therapy; Dietary Intake; Dietitian; Female; Financial Stress; Government; Human; Insurance; Large Language Model; Macronutrient; Major Clinical Study; Male; Nutrition Education; Nutritional Counseling; Personalized Nutrition; Prevalence; Zero Shot Prompting; Breast Tumor; Counseling; Diet; Language; Nutrition Policy; United States; Breast Neoplasms; Counseling; Diet; Female; Humans; Language; Large Language Models; Nutrition Policy; Nutritionists","adult; Article; body weight gain; breast cancer; calorie; cancer patient; cancer staging; ChatGPT; cohort analysis; communication barrier; comorbidity; controlled study; cultural background; diet therapy; dietary intake; dietitian; female; financial stress; government; human; insurance; large language model; macronutrient; major clinical study; male; nutrition education; nutritional counseling; personalized nutrition; prevalence; zero shot prompting; breast tumor; counseling; diet; language; nutrition policy; United States; Breast Neoplasms; Counseling; Diet; Female; Humans; Language; Large Language Models; Nutrition Policy; Nutritionists","","","Adam Dicker performs advisory activities for Roche, Janssen, Oncohost, and CVS and he has additional support provided by the American Association of Cancer Research, NRG Oncology, and the Prostate Cancer Foundation Challenge Grant. Yevgeniy Vinogradskiy has current grants from MIM Software, the National Institutes of Health, and the Agency for Healthcare Research and Quality. The funders had no role in the design of this study; in the collection, analyses, or interpretation of data; in the writing of the manuscript; or in the decision to publish the results. Nicole Simone has grants from the National Institutes of Health.","Castro-Espin, Carlota, The Role of Diet in Prognosis among Cancer Survivors: A Systematic Review and Meta-Analysis of Dietary Patterns and Diet Interventions, Nutrients, 14, 2, (2022); Chan, Doris S.M., Postdiagnosis body fatness, weight change and breast cancer prognosis: Global Cancer Update Program (CUP global) systematic literature review and meta-analysis, International Journal of Cancer, 152, 4, pp. 572-599, (2023); Di Meglio, Antonio, Unhealthy behaviors after breast cancer: Capitalizing on a teachable moment to promote lifestyle improvements, Cancer, 127, 15, pp. 2774-2787, (2021); Anand, Uttpal, Cancer chemotherapy and beyond: Current status, drug candidates, associated risks and progress in targeted therapeutics, Genes and Diseases, 10, 4, pp. 1367-1401, (2023); D'Andre, Stacy D., Cancer and Stress: Understanding the Connections and Interventions, American Journal of Lifestyle Medicine, (2024); Jung, Heewon, Effect of muscle mass on toxicity and survival in patients with colon cancer undergoing adjuvant chemotherapy, Supportive Care in Cancer, 23, 3, pp. 687-694, (2015); Hoy, Mary Katherine, Implementing a Low-Fat Eating Plan in the Women's Intervention Nutrition Study, Journal of the American Dietetic Association, 109, 4, pp. 688-696, (2009); Raber, Margaret R., Food Insecurity among People with Cancer: Nutritional Needs as an Essential Component of Care, Journal of the National Cancer Institute, 114, 12, pp. 1577-1583, (2022); Diekman, Connie B., Misinformation and Disinformation in Food Science and Nutrition: Impact on Practice, Journal of Nutrition, 153, 1, pp. 3-9, (2023); Liposits, Gábor, Nutrition in cancer care: A brief, practical guide with a focus on clinical practice, JCO Oncology Practice, 17, 1, pp. E992-E998, (2021)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","20726643","","","40218934","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-105002222811"
"S., Gao, Shen; S., Wang, Shijie; Y., Wang, Yuanzhi; Q., Zhang, Qunzi","Gao, Shen (59531112800); Wang, Shijie (36703716700); Wang, Yuanzhi (57996828200); Zhang, Qunzi (57197835688)","59531112800; 36703716700; 57996828200; 57197835688","ChatGPT and Commodity Return","2025","Journal of Futures Markets","45","3","","161","175","0","2","10.1002/fut.22568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216245831&doi=10.1002%2Ffut.22568&partnerID=40&md5=9f6b7c768c825a4b901e1efdb89dd63a","University of Electronic Science and Technology of China, Chengdu, China; Shandong University, Jinan, China","Gao, Shen, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Wang, Shijie, School of Economics, Shandong University, Jinan, China; Wang, Yuanzhi, School of Economics, Shandong University, Jinan, China; Zhang, Qunzi, School of Economics, Shandong University, Jinan, China","This paper investigates the ability of a ChatGPT-based indicator to forecast excess returns of the commodity futures index. Using ChatGPT to extract information from over 2.5 million articles from nine international newspapers, we demonstrate that our constructed commodity news ratio index significantly predicts future commodity returns, both in-sample and out-of-sample. Furthermore, it outperforms traditional textual analysis methods, including Bidirectional Encoder Representations from Transformers (BERT) and Bag-of-Words (BoW), while indicating economic significance within an asset allocation framework. The results highlight the critical role of ChatGPT in forecasting commodity market dynamics and provide valuable insights for both financial market participants and researchers. © 2025 Elsevier B.V., All rights reserved.","Chatgpt; Commodity Return Analysis; Textual Analysis","","","","Qunzi Zhang acknowledges the financial support from the National Natural Science Foundation of China [No. 72222013], the National Key R&D Program of China [No. 2023YFA1009200], and the National Social Science Foundation [22&ZD117]. Yuanzhi Wang acknowledges the financial support from the National Natural Science Foundation of China [No. 723B2016]. Shen Gao acknowledges the financial support from the National Natural Science Foundation of China [Nos. 62432002, 62406061], the Natural Science Foundation of Shandong Province [ZR2023QF159].","Baker, Steven D., The financialization of storable commodities, Management Science, 67, 1, pp. 471-499, (2021); Baker, Scott R., Measuring economic policy uncertainty, Quarterly Journal of Economics, 131, 4, pp. 1593-1636, (2016); Black, Angela J., Forecasting stock returns: Do commodity prices help?, Journal of Forecasting, 33, 8, pp. 627-639, (2014); Brown, Stephen P.A., Energy prices and aggregate economic activity: An interpretative survey, Quarterly Review of Economics and Finance, 42, 2, pp. 193-208, (2002); Browne, Francis X., Commodity prices, money and inflation, Journal of Economics and Business, 62, 4, pp. 331-345, (2010); Bybee, Leland, Business News and Business Cycles, Journal of Finance, 79, 5, pp. 3105-3147, (2024); Caldara, Dario, Measuring Geopolitical Risk, American Economic Review, 112, 4, pp. 1194-1225, (2022); Campbell, John Y., Predicting excess stock returns out of sample: Can anything beat the historical average?, Review of Financial Studies, 21, 4, pp. 1509-1531, (2008); undefined, (2023); Chen, Jian, Global Disaster Risk Matters, Management Science, 69, 1, pp. 576-597, (2023)","","John Wiley and Sons Inc","","","","","","10969934; 02707314","","","","English","Article","Final","","Scopus","2-s2.0-85216245831"
"D., Vallarino, Diego","Vallarino, Diego (58605708000)","58605708000","Understanding the Market Trends: A Hybrid Approach to Stock Price Prediction Using RNNs and Transformer-Based Sentiment Analysis","2025","Journal of Applied Economic Sciences","20","1","","21","33","0","0","10.57017/jaes.v20.1(87).02","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005521669&doi=10.57017%2Fjaes.v20.1%2887%29.02&partnerID=40&md5=93b92484001e62f40f9b376079974772","Independent Researcher, Atlanta, United States","Vallarino, Diego, Independent Researcher, Atlanta, United States","Stock price prediction is a critical yet challenging task in financial markets due to the complexity and volatility of asset movements. This paper presents a hybrid approach that combines Recurrent Neural Networks (RNN), particularly Long Short-Term Memory (LSTM) models, for time-series prediction with Transformer-based text analysis to capture sentiment from financial news. The study focuses on predicting Apple Inc.'s (AAPL) stock price, using three years of historical data alongside news sentiment analysis. The LSTM model captures temporal dependencies in the stock prices, while the Transformer model extracts relevant features from unstructured textual data, offering insights into market sentiment and external events. The results demonstrate that integrating sentiment data with stock price predictions significantly improves model accuracy, as reflected by a reduction in mean squared error (MSE) compared to models based solely on price data. This hybrid model offers a more holistic approach to financial forecasting, combining quantitative and qualitative data for enhanced prediction. The paper contributes to the field of machine learning in finance by highlighting the benefits of hybrid modelling approaches, and it opens avenues for future research on broader applications in other asset classes and more diverse data sources. © 2025 Elsevier B.V., All rights reserved.","Financial Forecasting; Lstm; Rnn; Sentiment Analysis; Stock Price Prediction; Transformers","","","","","Cui, Peng, Causal Inference Meets Machine Learning, pp. 3527-3528, (2020); Fischer, Thomas Günter, Deep learning with long short-term memory networks for financial market predictions, European Journal of Operational Research, 270, 2, pp. 654-669, (2018); Hochreiter, Sepp, Long Short-Term Memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Jiang, Fuwei, Fundamental characteristics, machine learning, and stock price crash risk, Journal of Financial Markets, 69, (2024); Lim, Bryan, Temporal Fusion Transformers for interpretable multi-horizon time series forecasting, International Journal of Forecasting, 37, 4, pp. 1748-1764, (2021); Münster, Markus, Robinhood, Reddit, and the news: The impact of traditional and social media on retail investor trading, Journal of Financial Markets, 71, (2024); Pradeep, Parvathi, A Transformer-Based Stock Market Price Prediction by Incorporating BERT Embedding, Lecture Notes in Networks and Systems, 964 LNNS, pp. 95-107, (2024); Sun, Yu, ET: Edge-Enhanced Transformer for Image Splicing Detection, IEEE Signal Processing Letters, 29, pp. 1232-1236, (2022); Nguyen, Thien Hai, Sentiment analysis on social media for stock movement prediction, Expert Systems with Applications, 42, 24, pp. 9603-9611, (2015); Dynamic Portfolio Rebalancing A Hybrid New Model Using Gnns and Pathfinding for Cost Efficiency, (2024)","","RITHA Publishing House","","","","","","23935162; 18436110","","","","English","Article","Final","","Scopus","2-s2.0-105005521669"
"J., Lin, Jinlin; S., Lai, Sirui; H., Yu, Hao; R., Liang, Rui; J., Yen, Jerome","Lin, Jinlin (58938186100); Lai, Sirui (58067784300); Yu, Hao (59716554000); Liang, Rui (59717003000); Yen, Jerome (57216413467)","58938186100; 58067784300; 59716554000; 59717003000; 57216413467","ChatGPT based credit rating and default forecasting","2025","Journal of Data, Information and Management","7","1","","69","92","0","0","10.1007/s42488-025-00143-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003103576&doi=10.1007%2Fs42488-025-00143-6&partnerID=40&md5=b48b4514835fce424f7da17574f66c30","University of Macau, Taipa, Macao; University of Macau, Taipa, Macao; Faculty of Business Administration, Taipa, Macao","Lin, Jinlin, Institute of Collaborative Innovation, University of Macau, Taipa, Macao; Lai, Sirui, Faculty of Science and Technology, University of Macau, Taipa, Macao; Yu, Hao, Faculty of Business Administration, Taipa, Macao; Liang, Rui, Faculty of Science and Technology, University of Macau, Taipa, Macao; Yen, Jerome, Faculty of Science and Technology, University of Macau, Taipa, Macao","Credit rating is a key element to reflect the level of credit risk in order to maintain the stability of financial markets. For enterprises, it supports the estimation of default risk to generate the credit rating and the associated funding costs. With the increase in credit risks over the past few years, for example, the falling of Silicon Valley Bank (SVB) and the Credit Suisse (CS), the demand for a more responsive and effective rating system is increasing. Although traditional models use structured data such as financial metrics, they are generally considered to have a time lag and incomprehensive, certain key elements that reflect the overall market environment, which might be generated from the unstructured data such as the changes in laws and policies as well as those that discussed in social media. Developing a more comprehensive and responsive credit rating system is a challenge to both practitioners and researchers. This study uses ChatGPT, a powerful LLM (Large Language Model), to collect a large set of multi-dimensional unstructured data and integrate such unstructured data with structured data to develop a comprehensive corporate rating model. Though the set of testing samples is small, the research results indicated that such an approach provides satisfactory accuracy and predictability. Even in the absence of some structured data from non-public financial reports, reasonable rating can be generated to provide the investors or business partners a reference, so this study shed the light to develop more suitable credit rating methodology for small and medium-sized enterprises, which were difficult to be rated with those traditional rating models. © 2025 Elsevier B.V., All rights reserved.","Chatgpt; Credit Rating; Default Forecast; Risk Management","","","","This work was supported in part by the Shenzhen Science and Technology Innovation Committee under Grant EF2023-00073-FST, and in part by the Guangdong Basic and Applied Basic Research Foundation under Grant EF2023-00210-FST.","Altman, Edward I., FINANCIAL RATIOS, DISCRIMINANT ANALYSIS AND THE PREDICTION OF CORPORATE BANKRUPTCY, Journal of Finance, 23, 4, pp. 589-609, (1968); Altman, Edward I., The link between default and recovery rates: Theory, empirical evidence, and implications, Journal of Business, 78, 6, pp. 2203-2227, (2005); Moodys Analytics Risk Perspectives, (2017); Issn, (2011); Beneish, Messod Daniel, The Detection of Earnings Manipulation, Financial Analysts Journal, 55, 5, pp. 24-36, (1999); Bernstein, Shai, Private equity and industry performance, Management Science, 63, 4, pp. 1198-1213, (2017); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Machine Learning at Central Banks, (2017); Chen, Jiahui, Rational eutectic solvent design by linking regular solution theory with QSAR modelling, Chemical Engineering Science, 262, (2022); Moodyvs Global Corporate Finance, (2008)","","Springer International Publishing","","","","","","25246356; 25246364","","","","English","Article","Final","","Scopus","2-s2.0-105003103576"
"P., Schoenegger, Philipp; P.S., Park, Peter S.; E., Karger, Ezra; S., Trott, Sean; P.E., Tetlock, Philip E.","Schoenegger, Philipp (57223426293); Park, Peter S. (57220731647); Karger, Ezra (57225214678); Trott, Sean (57189005241); Tetlock, Philip E. (7004674985)","57223426293; 57220731647; 57225214678; 57189005241; 7004674985","AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy","2025","ACM Transactions on Interactive Intelligent Systems","15","1","4","","","0","1","10.1145/3707649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003091602&doi=10.1145%2F3707649&partnerID=40&md5=56fe22b01ea88e650397f7de111dc779","London School of Economics and Political Science, London, United Kingdom; Massachusetts Institute of Technology, Cambridge, United States; Federal Reserve Bank of Chicago, Chicago, United States; University of California, San Diego, La Jolla, United States; University of Pennsylvania, Philadelphia, United States","Schoenegger, Philipp, London School of Economics and Political Science, London, United Kingdom; Park, Peter S., Massachusetts Institute of Technology, Cambridge, United States; Karger, Ezra, Federal Reserve Bank of Chicago, Chicago, United States; Trott, Sean, University of California, San Diego, La Jolla, United States; Tetlock, Philip E., University of Pennsylvania, Philadelphia, United States","Large language models (LLMs) match and sometimes exceed human performance in many domains. This study explores the potential of LLMs to augment human judgment in a forecasting task. We evaluate the effect on human forecasters of two LLM assistants: one designed to provide high-quality (""superforecasting"") advice, and the other designed to be overconfident and base-rate neglecting, thus providing noisy forecasting advice. We compare participants using these assistants to a control group that received a less advanced model that did not provide numerical predictions or engage in explicit discussion of predictions. Participants (N 991) answered a set of six forecasting questions and had the option to consult their assigned LLM assistant throughout. Our preregistered analyses show that interacting with each of our frontier LLM assistants significantly enhances prediction accuracy by between 24% and 28% compared to the control group. Exploratory analyses showed a pronounced outlier effect in one forecasting item, without which we find that the superforecasting assistant increased accuracy by 41%, compared with 29% for the noisy assistant. We further examine whether LLM forecasting augmentation disproportionately benefits less skilled forecasters, degrades the wisdom-of-The-crowd by reducing prediction diversity, or varies in effectiveness with question difficulty. Our data do not consistently support these hypotheses. Our results suggest that access to a frontier LLM assistant, even a noisy one, can be a helpful decision aid in cognitively demanding tasks compared to a less powerful model that does not provide specific forecasting advice. However, the effects of outliers suggest that further research into the robustness of this pattern is needed. © 2025 Elsevier B.V., All rights reserved.","Ai Augmentation; Forecasting; Human-ai Interaction; Large Language Models; Digital Elevation Model; Ai Augmentation; Base Rate; Control Groups; Forecasting Accuracy; High Quality; Human Judgments; Human Performance; Human-ai Interaction; Language Model; Large Language Model; Prediction Models","Digital elevation model; AI augmentation; Base rate; Control groups; Forecasting accuracy; High quality; Human judgments; Human performance; Human-AI interaction; Language model; Large language model; Prediction models","","","","Harms of AI, (2021); Combining Human Expertise with Artificial Intelligence Experimental Evidence from Radiology, (2023); Antony, Victor Nikhil, ID.8: Co-Creating Visual Stories with Generative AI, ACM Transactions on Interactive Intelligent Systems, 14, 3, (2024); A Theory for Emergence of Complex Skills in Language Models, (2023); Atanasov, Pavel, Distilling the wisdom of crowds: Prediction markets vs. prediction polls, Management Science, 63, 3, pp. 691-706, (2017); Which Humans, (2023); Bender, Emily M., On the dangers of stochastic parrots: Can language models be too big?, pp. 610-623, (2021); Benjamin, Daniel M., Hybrid forecasting of geopolitical events†, AI Magazine, 44, 1, pp. 112-128, (2023); Forecasting Long Run Causal Effects, (2024); Emergent and Predictable Memorization in Large Language Models, (2023)","","Association for Computing Machinery","","","","","","21606455; 21606463","","","","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-105003091602"
"W., Chou, Wenhsiu; Z., Feng, Zifeng; B., Li, Bingxin; F., Liu, Feng","Chou, Wenhsiu (37107083900); Feng, Zifeng (57200546256); Li, Bingxin (57193127744); Liu, Feng (57194061128)","37107083900; 57200546256; 57193127744; 57194061128","A First Look at Financial Data Analysis Using ChatGPT-4o","2025","Journal of Risk and Financial Management","18","2","99","","","0","0","10.3390/jrfm18020099","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218906911&doi=10.3390%2Fjrfm18020099&partnerID=40&md5=706041ccaecbec393835e8b12e346ec7","Florida International University College of Business, Miami, United States; Woody L. Hunt College of Business, El Paso, United States; John Chambers College of Business and Economics, Morgantown, United States","Chou, Wenhsiu, Florida International University College of Business, Miami, United States; Feng, Zifeng, Woody L. Hunt College of Business, El Paso, United States; Li, Bingxin, John Chambers College of Business and Economics, Morgantown, United States; Liu, Feng, Woody L. Hunt College of Business, El Paso, United States","OpenAI’s new flagship model, ChatGPT-4o, released on 13 May 2024, offers enhanced natural language understanding and more coherent responses. This paper investigates ChatGPT-4o’s capabilities in financial data analysis, including zero-shot prompting, time series analysis, risk and return analysis, and ARMA-GARCH estimation. ChatGPT-4o’s performance is generally comparable to traditional statistical software like Stata, though some errors and discrepancies arise due to differences in implementation. Despite these issues, our findings indicate that ChatGPT-4o has significant potential for real-world financial analysis. Integrating ChatGPT-4o into financial research and practice may lead to more efficient data processing, improved analytical capabilities, and better-informed investment decisions. © 2025 Elsevier B.V., All rights reserved.","Academia; Artificial Intelligence (ai); Chatgpt; Data Analysis; Finance Research; Financial Analysis; Generative Ai (genai); Large Language Models; Stock Return","","","","","Aldridge, Irene, The AI Revolution: From Linear Regression to ChatGPT and Beyond and How It All Connects to Finance, Journal of Portfolio Management, 49, 10, (2023); Modern Finance, (2023); Cureus, (2023); Exploring the Role of Artificial Intelligence in Enhancing Academic Performance A Case Study of Chatgpt, (2022); Anders, Brent A., Is using ChatGPT cheating, plagiarism, both, neither, or forward thinking?, Patterns, 4, 3, (2023); A Multitask Multilingual Multimodal Evaluation of Chatgpt on Reasoning Hallucination and Interactivity, (2023); Arxiv, (2024); A Categorical Archive of Chatgpt Failures, (2023); Cao, Yi, Bridging the gap–the impact of ChatGPT on financial research, Journal of Chinese Economic and Business Studies, 21, 2, pp. 177-191, (2023); Chen, Boyang, From fiction to fact: the growing role of generative AI in business and finance, Journal of Chinese Economic and Business Studies, 21, 4, pp. 471-496, (2023)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","19118074","","","","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85218906911"
"K., Shan, Kevin; M.A., Patel, Mahi A.; M.C., McCreary, Morgan C.; T.G., Punnen, Tom G.; F., Villalobos, Francisco; L.M., Tardo, Lauren M.; L.A., Horton, Lindsay A.; P.V., Sguigna, Peter V.; K.M., Blackburn, Kyle M.; S.B., Munoz, Shanan B.","Shan, Kevin (58994806400); Patel, Mahi A. (59211663100); McCreary, Morgan C. (57202375265); Punnen, Tom G. (59460172400); Villalobos, Francisco (59846848200); Tardo, Lauren M. (57227378600); Horton, Lindsay A. (57204658754); Sguigna, Peter V. (37108571700); Blackburn, Kyle M. (57190391276); Munoz, Shanan B. (58106428700)","58994806400; 59211663100; 57202375265; 59460172400; 59846848200; 57227378600; 57204658754; 37108571700; 57190391276; 58106428700","Faster and better than a physician?: Assessing diagnostic proficiency of ChatGPT in misdiagnosed individuals with neuromyelitis optica spectrum disorder","2025","Journal of the Neurological Sciences","468","","123360","","","0","0","10.1016/j.jns.2024.123360","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213210734&doi=10.1016%2Fj.jns.2024.123360&partnerID=40&md5=cc581b1b0fe6795c439fc66c4648ecbe","UT Southwestern Medical School, Dallas, United States; UT Southwestern Medical Center, Dallas, United States; UT Southwestern Medical Center, Dallas, United States; TTUHSC School of Medicine, Lubbock, United States","Shan, Kevin, UT Southwestern Medical School, Dallas, United States; Patel, Mahi A., Department of Neurology, UT Southwestern Medical Center, Dallas, United States, UT Southwestern Medical Center, Dallas, United States; McCreary, Morgan C., Department of Neurology, UT Southwestern Medical Center, Dallas, United States, UT Southwestern Medical Center, Dallas, United States; Punnen, Tom G., Department of Neurology, UT Southwestern Medical Center, Dallas, United States, UT Southwestern Medical Center, Dallas, United States; Villalobos, Francisco, Department of Neurology, UT Southwestern Medical Center, Dallas, United States, UT Southwestern Medical Center, Dallas, United States; Tardo, Lauren M., Department of Neurology, UT Southwestern Medical Center, Dallas, United States, UT Southwestern Medical Center, Dallas, United States; Horton, Lindsay A., Department of Neurology, UT Southwestern Medical Center, Dallas, United States, UT Southwestern Medical Center, Dallas, United States; Sguigna, Peter V., Department of Neurology, UT Southwestern Medical Center, Dallas, United States, UT Southwestern Medical Center, Dallas, United States; Blackburn, Kyle M., Department of Neurology, UT Southwestern Medical Center, Dallas, United States, UT Southwestern Medical Center, Dallas, United States; Munoz, Shanan B., Department of Neurology, UT Southwestern Medical Center, Dallas, United States, UT Southwestern Medical Center, Dallas, United States","Background: Neuromyelitis optica spectrum disorder (NMOSD) is a commonly misdiagnosed condition. Driven by cost-consciousness and technological fluency, distinct generations may gravitate towards healthcare alternatives, including artificial intelligence (AI) models, such as ChatGPT (Generative Pre-trained Transformer). Our objective was to evaluate the speed and accuracy of ChatGPT-3.5 (GPT-3.5) in the diagnosis of people with NMOSD (PwNMOSD) initially misdiagnosed. Methods: Misdiagnosed PwNMOSD were retrospectively identified with clinical symptoms and time line of medically related events processed through GPT-3.5. For each subject, seven digital derivatives representing different races, ethnicities, and sexes were created and processed identically to evaluate the impact of these variables on accuracy. Scoresheets were used to track diagnostic success and time to diagnosis. Diagnostic speed of GPT-3.5 was evaluated against physicians using a Cox proportional hazards model, clustered by subject. Logistical regression was used to estimate the diagnostic accuracy of GPT-3.5 compared with the estimated accuracy of physicians. Results: Clinical time lines for 68 individuals (59 female, 42 Black/African American, 13 White, 11 Hispanic, 2 Asian; mean age at first symptoms 34.4 years (y) (standard deviation = 15.5y)) were analyzed and 476 digital simulations created, yielding 544 conversations for analysis. The instantaneous probability of correct diagnosis was 70.65% less for physicians relative to GPT-3.5 within 240 days of symptom onset (p < 0.0001). The estimated probability of correct diagnosis for GPT-3.5 was 80.88% [95% CI = (76.35%, 99.81%)]. Conclusion: GPT-3.5 may be of value in recognizing NMOSD. However, the manner in which medical information is conveyed, combined with the potential for inaccuracies may result in unnecessary psychological stress. © 2024 Elsevier B.V., All rights reserved.","Chatgpt; Generation Z; Generative Ai; Misdiagnosis; Neuromyelitis Optica Spectrum Disorder; Aquaporin 4; Aquaporin 4; Article; Chatgpt; Cohort Analysis; Controlled Study; Data Processing; Demographics; Diagnosis Time; Diagnostic Accuracy; Diagnostic Error; Ethnic Difference; Female; Hispanic; Human; Major Clinical Study; Male; Myelooptic Neuropathy; Neuroimmunology; Nuclear Magnetic Resonance Imaging; Physician; Proportional Hazards Model; Retrospective Study; Sex Difference; Adolescent; Adult; Artificial Intelligence; Diagnosis; Middle Aged; Time Factor; Young Adult; Adolescent; Adult; Artificial Intelligence; Diagnostic Errors; Female; Humans; Male; Middle Aged; Neuromyelitis Optica; Physicians; Retrospective Studies; Time Factors; Young Adult","aquaporin 4; Article; ChatGPT; cohort analysis; controlled study; data processing; demographics; diagnosis time; diagnostic accuracy; diagnostic error; ethnic difference; female; Hispanic; human; major clinical study; male; myelooptic neuropathy; neuroimmunology; nuclear magnetic resonance imaging; physician; proportional hazards model; retrospective study; sex difference; adolescent; adult; artificial intelligence; diagnosis; middle aged; time factor; young adult; Adolescent; Adult; Artificial Intelligence; Diagnostic Errors; Female; Humans; Male; Middle Aged; Neuromyelitis Optica; Physicians; Retrospective Studies; Time Factors; Young Adult","","aquaporin 4, 175960-54-0","","Royston, Minying, Neuromyelitis Optica Spectrum Disorder: Clinical Burden and Cost of Relapses and Disease-Related Care in US Clinical Practice, Neurology and Therapy, 10, 2, pp. 767-783, (2021); Mealy, Maureen A., Long-term disability in neuromyelitis optica spectrum disorder with a history of myelitis is associated with age at onset, delay in diagnosis/preventive treatment, MRI lesion length and presence of symptomatic brain lesions, Multiple Sclerosis and Related Disorders, 28, pp. 64-68, (2019); Rosenthal, Jacqueline F., CNS inflammatory demyelinating disorders: MS, NMOSD and MOG antibody associated disease, Journal of Investigative Medicine, 68, 2, pp. 321-330, (2020); Mealy, Maureen A., Epidemiology of neuromyelitis optica in the United States: A multicenter analysis, Archives of Neurology, 69, 9, pp. 1176-1180, (2012); Smith, Alexander D., Factors associated with the misdiagnosis of neuromyelitis optica spectrum disorder, Multiple Sclerosis and Related Disorders, 70, (2023); Cai, Linjun, Clinical characteristics of very late-onset neuromyelitis optica spectrum disorder, Multiple Sclerosis and Related Disorders, 46, (2020); Dave, Tirth, ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations, Frontiers in Artificial Intelligence, 6, (2023); Yu, Ping, Leveraging Generative AI and Large Language Models: A Comprehensive Roadmap for Healthcare Integration, Healthcare (Switzerland), 11, 20, (2023); Newman-Toker, David E., Burden of serious harms from diagnostic error in the USA, BMJ Quality and Safety, 33, 2, pp. 109-120, (2023); Hansen, Madison R., Multiple Sclerosis in the Contemporary Age: Understanding the Millennial Patient with Multiple Sclerosis to Create Next-Generation Care, Neurologic Clinics, 36, 1, pp. 219-230, (2018)","","Elsevier B.V.","","","","","","18785883; 0022510X","","JNSCA","39733714","English","Article","Final","","Scopus","2-s2.0-85213210734"
"A., Alhamadani, Abdulaziz; K., Althubiti, Khadija; J., He, Jianfeng; S., Sarkar, Shailik; L., AlKulaib, Lulwah; A.R., Shaik, Abdul Raheem; S.“., Lee, Seungwon “Shawn”; M.A., Khan, Mahmood A.; L., Chang-Tien, Lu","Alhamadani, Abdulaziz (57216827977); Althubiti, Khadija (58990352400); He, Jianfeng (57219735432); Sarkar, Shailik (57348868200); AlKulaib, Lulwah (57202916297); Shaik, Abdul Raheem (59585910400); Lee, Seungwon “Shawn” (55486919400); Khan, Mahmood A. (56132130500); Chang-Tien, Lu (7404804653)","57216827977; 58990352400; 57219735432; 57348868200; 57202916297; 59585910400; 55486919400; 56132130500; 7404804653","Empowering Airline Route Decisions with LLM-Generated Pseudo-labels and Zero-Shot Review Prediction","2025","Lecture Notes in Computer Science","15214 LNCS","","","119","136","0","0","10.1007/978-3-031-78554-2_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218464322&doi=10.1007%2F978-3-031-78554-2_8&partnerID=40&md5=307bf24776ccd688c6f6954b0de38659","Florida Polytechnic University, Lakeland, United States; Virginia Polytechnic Institute and State University, Blacksburg, United States; Virginia Tech College of Engineering, Blacksburg, United States; Kuwait University, Kuwait City, Kuwait; Virginia Tech College of Engineering, Blacksburg, United States; George Mason University - Science and Technology Campus, Manassas, United States","Alhamadani, Abdulaziz, Department of Data Science and Business Analytics, Florida Polytechnic University, Lakeland, United States; Althubiti, Khadija, Department of Hospitality and Tourism Management, Virginia Polytechnic Institute and State University, Blacksburg, United States; He, Jianfeng, Virginia Tech College of Engineering, Blacksburg, United States; Sarkar, Shailik, Virginia Tech College of Engineering, Blacksburg, United States; AlKulaib, Lulwah, Department of Computer Science, Kuwait University, Kuwait City, Kuwait; Shaik, Abdul Raheem, Virginia Tech College of Engineering, Blacksburg, United States; Lee, Seungwon “Shawn”, Tourism and Events Management, George Mason University - Science and Technology Campus, Manassas, United States; Khan, Mahmood A., Department of Hospitality and Tourism Management, Virginia Polytechnic Institute and State University, Blacksburg, United States; Chang-Tien, Lu, Virginia Tech College of Engineering, Blacksburg, United States","The airline industry has suffered a severe impact due to the COVID-19 pandemic. It resulted in significant financial losses. Strategic route planning is now an urgent need to mitigate the ongoing crisis. Motivated by the importance of customer sentiment in informing airline route decisions, this paper presents EAGLE (Enhancing Airline Groundtruth Labels and rEview rating prediction), a novel two-stage framework that leverages the power of Large Language Models (LLMs) to address the limitations of current works, which often rely on manual labeling and traditional machine learning models. In the first phase, EAGLE introduces a pseudo-labeling approach using LLMs to automatically label customer reviews to reduce the need for manual annotation and mitigate potential biases that exist in human labeling. The second phase employs a zero-shot LLM-based text classification method to predict customer sentiment and preferences from online reviews to provide a more accurate and context-aware analysis of customer feedback. Through extensive experiments, we demonstrate the effectiveness and robustness of EAGLE to demonstrate its superior performance compared to existing techniques. The proposed framework empowers airline companies to make data-driven decisions about route expansions, considering customer preferences and sentiments. Our contribution fibs in enhancing the objectivity of sentiment analysis and providing a comprehensive and scalable solution for airline route planning in the post-pandemic era, eventually leading to improved customer satisfaction and optimized operations. © 2025 Elsevier B.V., All rights reserved.","Airline Industry; Large Language Model; Social Media Data Mining; Text Generation; Air Transportation; Customer Satisfaction; Labeled Data; Sentiment Analysis; Strategic Planning; Transportation Routes; Zero-shot Learning; 'current; Airline Industry; Airline Routes; Financial Loss; Language Model; Large Language Model; Power; Route Planning; Social Media Data Minings; Text Generations; Sales","Air transportation; Customer satisfaction; Labeled data; Sentiment analysis; Strategic planning; Transportation routes; Zero-shot learning; 'current; Airline industry; Airline routes; Financial loss; Language model; Large language model; Power; Route planning; Social media data minings; Text generations; Sales","","","","Alanazi, Mohammed Saad M., Multiclass Sentiment Prediction of Airport Service Online Reviews Using Aspect-Based Sentimental Analysis and Machine Learning, Mathematics, 12, 5, (2024); Covid I I U Financial Impacts Relief Measures Needed Press Release, (2020); Dube, Kaitano, Major Global Aircraft Manufacturers and Emerging Responses to the SDGs Agenda, Sustainable Development Goals Series, Part F2656, pp. 99-113, (2020); Dube, Kaitano, COVID-19 pandemic and prospects for recovery of the global aviation industry, Journal of Air Transport Management, 92, (2021); Gitto, Simone, Improving airport services using sentiment analysis of the websites, Tourism Management Perspectives, 22, pp. 132-136, (2017); Gössling, Stefan, Pandemics, tourism and global change: a rapid assessment of COVID-19, Journal of Sustainable Tourism, pp. 1-20, (2020); Gupta, Meenu Satyanarayana, Airlines based Twitter Sentiment Analysis Using Deep Learning, (2021); Halpern, Nigel, Airport route development: A survey of current practice, Tourism Management, 46, pp. 213-221, (2015); Homaid, Mohammed Salih, Analysing the Sentiment of Air-Traveller: A Comparative Analysis, International Journal of Computer Theory and Engineering, 14, 2, pp. 48-53, (2022); Huse, Cristian, Investigating business traveller heterogeneity: Low-cost vs full-service airline users?, Transportation Research Part E: Logistics and Transportation Review, 43, 3, pp. 259-268, (2007)","Aiello, L.M.; Chakraborty, T.; Gaito, S.","Springer Science and Business Media Deutschland GmbH","ACM/IEEE","16th International Conference on Social Networks Analysis and Mining, ASONAM 2024","","Rende","325979","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference paper","Final","","Scopus","2-s2.0-85218464322"
"Y., Zhang, Yiming; X., Ao, Xiang; G., Yu, Guoxin; Q., He, Qing","Zhang, Yiming (59292528900); Ao, Xiang (57197191379); Yu, Guoxin (57219527740); He, Qing (26643590900)","59292528900; 57197191379; 57219527740; 26643590900","Improving Event-Level Financial Sentiment Analysis with Retrieval-Augmented Multipath Chain-of-Thought Prompting","2025","Communications in Computer and Information Science","2301","","","232","246","0","0","10.1007/978-981-96-1024-2_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218457349&doi=10.1007%2F978-981-96-1024-2_17&partnerID=40&md5=a53b32b9d1e8ec7bb36f5e9d989f6451","Zhengzhou University, Zhengzhou, China; Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology Chinese Academy of Sciences, Beijing, China","Zhang, Yiming, Henan Institute of Advanced Technology, Zhengzhou University, Zhengzhou, China, Key Laboratory of Al Safety, Chinese Academy of Sciences, Beijing, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology Chinese Academy of Sciences, Beijing, China; Ao, Xiang, Henan Institute of Advanced Technology, Zhengzhou University, Zhengzhou, China, Key Laboratory of Al Safety, Chinese Academy of Sciences, Beijing, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology Chinese Academy of Sciences, Beijing, China; Yu, Guoxin, Key Laboratory of Al Safety, Chinese Academy of Sciences, Beijing, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology Chinese Academy of Sciences, Beijing, China; He, Qing, Henan Institute of Advanced Technology, Zhengzhou University, Zhengzhou, China, Key Laboratory of Al Safety, Chinese Academy of Sciences, Beijing, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology Chinese Academy of Sciences, Beijing, China","Event-level Financial Sentiment Analysis (EFSA) aims to extract all the quintuples containing five sentiment elements from a given financial news text, which has gained prominence as an emerging domain recently. The present study utilizes a 4-hop Chain-of-Thought (CoT) prompting based on LLMs to predict sentiment elements in a fixed order, which neglects the interdependencies among the sentiment elements within a quintuple. Inspired by recent multi-view prompting (MvP) and CoT ideas, we propose a novel framework termed Retrieval-Augmented Multipath Chain-of-Thought (RMP-CoT) that aggregates quintuples generated by LLMs through different reasoning paths, leveraging a retrieval-augmented mechanism. Specifically, RMP-CoT integrates different element orders into CoT prompting to guide LLMs in generating multiple sentiment quintuples through the utilization of retrieval-augmented mechanism, and then selects the most plausible quintuples by voting. To investigate the effectiveness of our framework, we conduct extensive experiments on four benchmark tasks of EFSA. RMP-CoT pushes the state-of-the-art by over 6% F1 on the EFSA task and also performs quite effectively on the other sub-tasks of EFSA. © 2025 Elsevier B.V., All rights reserved.","Chain-of-thought; Event-level Sentiment Analysis; Financial Sentiment Analysis; Chain-of-thought; Emerging Domains; Event-level Sentiment Analyze; Financial News; Financial Sentiment Analyze; Fixed-order; Multi-views; Multipath; Sentiment Analysis","Chain-of-thought; Emerging domains; Event-level sentiment analyze; Financial news; Financial sentiment analyze; Fixed-order; Multi-views; Multipath; Sentiment analysis","","","The research work is supported by the National Key R&D Plan No. 2022YFC3303303, the National Natural Science Foundation of China under Grant No.61976204, U2436209. Xiang Ao is also supported by the Project of Youth Innovation Promotion Association CAS, and Beijing Nova Program 20230484430.","Efsa Towards Event Level Financial Sentiment Analysis, (2024); Proceedings of the 11th International Workshop on Semantic Evaluation Semeval 2017, (2017); Du, Kelvin, Financial Sentiment Analysis: Techniques and Applications, ACM Computing Surveys, 56, 9, (2024); Ebrahimi, Monireh, Challenges of Sentiment Analysis for Dynamic Events, IEEE Intelligent Systems, 32, 5, pp. 70-75, (2017); Fukuhara, Tomohiro, Understanding sentiment of people from news articles: Temporal sentiment analysis of social events, (2007); Gou, Zhibin, MVP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction, Proceedings of the Annual Meeting of the Association for Computational Linguistics, 1, pp. 4380-4397, (2023); Lora Low Rank Adaptation of Large Language Models, (2021); Kearney, Colm, Textual sentiment in finance: A survey of methods and models, International Review of Financial Analysis, 33, pp. 171-185, (2014); Lewis, Patrick, Retrieval-augmented generation for knowledge-intensive NLP tasks, Advances in Neural Information Processing Systems, 2020-December, (2020); Luo, Ling, Beyond polarity: Interpretable financial Sentiment analysis with hierarchical query-driven attention, IJCAI International Joint Conference on Artificial Intelligence, 2018-July, pp. 4244-4250, (2018)","Zhu, W.; Xiong, H.; Cheng, X.; Cui, L.; Dou, Z.; Dong, J.; Pang, S.; Wang, L.; Kong, L.; Chen, Z.","Springer Science and Business Media Deutschland GmbH","","12th CCF Conference on BigData, BigData 2024","","Qingdao","326029","18650937; 18650929","9789819671748; 9789819664610; 9783032026743; 9783032008831; 9783032026712; 9789819671779; 9783031949425; 9789819666874; 9783031936968; 9783031941207","","","English","Conference paper","Final","","Scopus","2-s2.0-85218457349"
"Z., Xu, Zhiyu; Y., Liu, Yi; Y., Wang, Yuchi; R., Bao, Ruihan; K., Harimoto, Keiko; X., Sun, Xu","Xu, Zhiyu (59557361100); Liu, Yi (57090049200); Wang, Yuchi (58666429500); Bao, Ruihan (57219500286); Harimoto, Keiko (57219500814); Sun, Xu (55744667900)","59557361100; 57090049200; 58666429500; 57219500286; 57219500814; 55744667900","Modeling Interactions Between Stocks Using LLM-Enhanced Graphs for Volume Prediction","2025","Proceedings - International Conference on Computational Linguistics, COLING","","","","153","163","0","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217810699&partnerID=40&md5=a084c17542c3d7ca63ae806d1e2e5b3d","Peking University, Beijing, China; Ltd., Mizuho, Japan","Xu, Zhiyu, School of Computer Science, Peking University, Beijing, China; Liu, Yi, School of Computer Science, Peking University, Beijing, China; Wang, Yuchi, School of Computer Science, Peking University, Beijing, China; Bao, Ruihan, Mizuho Securities Co., Ltd., Mizuho, Japan; Harimoto, Keiko, Mizuho Securities Co., Ltd., Mizuho, Japan; Sun, Xu, School of Computer Science, Peking University, Beijing, China","Accurate trading volume prediction is essential for portfolio optimization, market regulation, and financial risk control. An effective method for predicting trading volume involves building a graph to model relations between stocks. Recent research has enhanced these models by integrating stock news to improve forecasting ability. However, existing approaches primarily integrate news data as auxiliary features for nodes in Graph Neural Networks (GNNs), often overlooking the relational information between stocks embedded in news. To address this, we propose LLM-Enhanced Dynamic Graph Neural Network (LED-GNN), a framework that constructs dynamic graphs using inter-stock relationships extracted from news via a large language model (LLM)-centered pipeline. The news graph is then combined with graphs learned from historical price-volume data and fed into a dynamic GNN to generate predictions. Evaluated on a real-world dataset, TOPIX, with Reuters Financial News, LED-GNN consistently outperformed all baseline models, achieving a 2% improvement over the strongest baseline. © 2025 Elsevier B.V., All rights reserved.","Graph Neural Networks; Dynamic Graph; Financial Risks; Language Model; Market Regulation; Model Interaction; Portfolio Optimization; Risks Controls; Trading Volumes; Volume Predictions; Prediction Models","Graph neural networks; Dynamic graph; Financial risks; Language model; Market regulation; Model interaction; Portfolio optimization; Risks controls; Trading volumes; Volume predictions; Prediction models","","","We thank all the anonymous reviewers for their valuable suggestions. This work is supported by a Research Grant from Mizuho Securities Co., Ltd. We sincerely thank Mizuho Securities for valuable domain expert suggestions. Ruihan Bao and Xu Sun are the corresponding authors.","Allaoui, Mebarka, Considerably improving clustering algorithms using umap dimensionality reduction technique: A comparative study, Lecture Notes in Computer Science, 12119 LNCS, pp. 317-325, (2020); An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling, (2018); Białkowski, Jȩdrzej, Improving VWAP strategies: A dynamic volume approach, Journal of Banking and Finance, 32, 9, pp. 1709-1722, (2008); Brody, Shaked, HOW ATTENTIVE ARE GRAPH ATTENTION NETWORKS?, (2022); Brownlees, Christian T., Intra-daily volume modeling and prediction for algorithmic trading, Journal of Financial Econometrics, 9, 3, pp. 489-518, (2011); Review of Financial Studies, (1992); Journal of the Anthropological Institute, (1886); Gao, Jianliang, Graph-Based Stock Recommendation by Time-Aware Relational Attention Network, ACM Transactions on Knowledge Discovery from Data, 16, 1, (2021); Bertopic Neural Topic Modeling with A Class Based Tf Idf Procedure, (2022); Hochreiter, Sepp, Long Short-Term Memory, Neural Computation, 9, 8, pp. 1735-1780, (1997)","Chen, C.-C.; Moreno-Sandoval, A.; Huang, J.; Xie, Q.; Ananiadou, S.; Chen, H.-H.","Association for Computational Linguistics (ACL)","","Joint Workshop of the 9th Financial Technology and Natural Language Processing, FinNLP 2025, the 6th Financial Narrative Processing, FNP 2025, and the 1st Workshop on Large Language Models for Finance and Legal, LLMFinLegal 2025, co-located with the 31st International Conference on Computational Linguistics, COLING 2025","","Abu Dhabi","206513","29512093","9798891762053; 9798891762114; 9798891762060; 9798891761964; 9798891762022; 9798891762039; 9798891762015; 9798891762152; 9798891762077; 9781713861928","","","English","Conference paper","Final","","Scopus","2-s2.0-85217810699"
"A., Dmonte, Alphaeus; R., Oruche, Roland; M., Zampieri, Marcos; E., Ko, Eunmi; P.P., Calyam, Prasad P.","Dmonte, Alphaeus (57217277894); Oruche, Roland (57207993528); Zampieri, Marcos (8948587300); Ko, Eunmi (57434587700); Calyam, Prasad P. (6507285722)","57217277894; 57207993528; 8948587300; 57434587700; 6507285722","GMU-MU at the Financial Misinformation Detection Challenge Task: Exploring LLMs for Financial Claim Verification","2025","Proceedings - International Conference on Computational Linguistics, COLING","","","","308","312","0","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217771948&partnerID=40&md5=6a79698f71779fff24e35a8ef31b0b60","George Mason University, Fairfax, United States; University of Missouri, Columbia, United States; Rochester Institute of Technology, Rochester, United States","Dmonte, Alphaeus, George Mason University, Fairfax, United States; Oruche, Roland, University of Missouri, Columbia, United States; Zampieri, Marcos, George Mason University, Fairfax, United States; Ko, Eunmi, Rochester Institute of Technology, Rochester, United States; Calyam, Prasad P., University of Missouri, Columbia, United States","This paper describes the team GMU-MU submission to the Financial Misinformation Detection challenge. The goal of this challenge is to identify financial misinformation and generate explanations justifying the predictions by developing or adapting LLMs. The participants were provided with a dataset of financial claims that were categorized into six financial domain categories. We experiment with the Llama model using two approaches; instruction-tuning the model with the training dataset, and a prompting approach that directly evaluates the off-the-shelf model. Our best system was placed 5th among the 12 systems, achieving an overall evaluation score of 0.6682. © 2025 Elsevier B.V., All rights reserved.","Contrastive Learning; Decentralized Finance; Finance; Financial Domains; Training Dataset; Computational Linguistics","Contrastive Learning; Decentralized finance; Finance; Financial domains; Training dataset; Computational linguistics","","","","Gpt 4 Technical Report, (2023); Claude 3 Model Family Opus Sonnet Haiku, (2024); Chen, Canyu, Combating misinformation in the age of LLMs: Opportunities and challenges, AI Magazine, 45, 3, pp. 354-368, (2024); Team Trifecta at Factify5wqa Setting the Standard in Fact Verification with Fine Tuning, (2025); Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019); Claim Verification in the Age of Large Language Models A Survey, (2024); Classifying Human Generated and AI Generated Election Claims in Social Media, (2024); Llama 3 Herd of Models, (2024); Kaliyar, Rohit Kumar, FakeBERT: Fake news detection in social media with a BERT-based deep learning approach, Multimedia Tools and Applications, 80, 8, pp. 11765-11788, (2021); Kamal, Ashraf, Financial Misinformation Detection via RoBERTa and Multi-channel Networks, Lecture Notes in Computer Science, 14301 LNCS, pp. 646-653, (2023)","Chen, C.-C.; Moreno-Sandoval, A.; Huang, J.; Xie, Q.; Ananiadou, S.; Chen, H.-H.","Association for Computational Linguistics (ACL)","","Joint Workshop of the 9th Financial Technology and Natural Language Processing, FinNLP 2025, the 6th Financial Narrative Processing, FNP 2025, and the 1st Workshop on Large Language Models for Finance and Legal, LLMFinLegal 2025, co-located with the 31st International Conference on Computational Linguistics, COLING 2025","","Abu Dhabi","206513","29512093","9798891762053; 9798891762114; 9798891762060; 9798891761964; 9798891762022; 9798891762039; 9798891762015; 9798891762152; 9798891762077; 9781713861928","","","English","Conference paper","Final","","Scopus","2-s2.0-85217771948"
"F., Drinkall, Felix; J.B., Pierrehumbert, Janet B.; S., Zohren, Stefan","Drinkall, Felix (57286198500); Pierrehumbert, Janet B. (6602501744); Zohren, Stefan (14057447500)","57286198500; 6602501744; 14057447500","Forecasting Credit Ratings: A Case Study where Traditional Methods Outperform Generative LLMs","2025","Proceedings - International Conference on Computational Linguistics, COLING","","","","118","133","0","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217739767&partnerID=40&md5=d935a052a2dee636131b3f4ae896419d","University of Oxford, Oxford, United Kingdom; The Alan Turing Institute, London, United Kingdom; University of Oxford, Oxford, United Kingdom","Drinkall, Felix, University of Oxford, Oxford, United Kingdom; Pierrehumbert, Janet B., University of Oxford, Oxford, United Kingdom, Department of Linguistics, University of Oxford, Oxford, United Kingdom; Zohren, Stefan, University of Oxford, Oxford, United Kingdom, The Alan Turing Institute, London, United Kingdom","Large Language Models (LLMs) have been shown to perform well for many downstream tasks. Transfer learning can enable LLMs to acquire skills that were not targeted during pretraining. In financial contexts, LLMs can sometimes beat well-established benchmarks. This paper investigates how well LLMs perform at forecasting corporate credit ratings. We show that while LLMs are very good at encoding textual information, traditional methods are still very competitive when it comes to encoding numeric and multimodal data. For our task, current LLMs perform worse than a more traditional XGBoost architecture that combines fundamental and macroeconomic data with high-density text-based embedding features. We investigate the degree to which the text encoding methodology affects performance and interpretability. The dataset reconstruction and model code from this paper is provided1. © 2025 Elsevier B.V., All rights reserved.","Benchmarking; Natural Language Processing Systems; Transfer Learning; Case-studies; Corporate Credit Ratings; Credit Ratings; Down-stream; Encodings; Language Model; Multi-modal; Pre-training; Textual Information; Computational Linguistics","Benchmarking; Natural language processing systems; Transfer learning; Case-studies; Corporate credit ratings; Credit ratings; Down-stream; Encodings; Language model; Multi-modal; Pre-training; Textual information; Computational linguistics","","","","Deep Learning Using Rectified Linear Units Relu, (2018); Aharoni, Roee, Unsupervised domain clusters in pretrained language models, Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 7747-7763, (2020); An, Wuyue, Text-based soybean futures price forecasting: A two-stage deep learning approach, Journal of Forecasting, 42, 2, pp. 312-330, (2023); Ayyappa, Yalanati, Forecasting Equity Prices using LSTM and BERT with Sentiment Analysis, pp. 643-648, (2023); Machine Learning with Applications, (2024); Balloccu, Simone, Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs, 1, pp. 67-93, (2024); Barbaglia, Luca, Forecasting with Economic News, Journal of Business and Economic Statistics, 41, 3, pp. 708-719, (2023); Utms Journal of Economics, (2012); Longformer the Long Document Transformer, (2020); Bender, Emily M., On the dangers of stochastic parrots: Can language models be too big?, pp. 610-623, (2021)","Chen, C.-C.; Moreno-Sandoval, A.; Huang, J.; Xie, Q.; Ananiadou, S.; Chen, H.-H.","Association for Computational Linguistics (ACL)","","Joint Workshop of the 9th Financial Technology and Natural Language Processing, FinNLP 2025, the 6th Financial Narrative Processing, FNP 2025, and the 1st Workshop on Large Language Models for Finance and Legal, LLMFinLegal 2025, co-located with the 31st International Conference on Computational Linguistics, COLING 2025","","Abu Dhabi","206513","29512093","9798891762053; 9798891762114; 9798891762060; 9798891761964; 9798891762022; 9798891762039; 9798891762015; 9798891762152; 9798891762077; 9781713861928","","","English","Conference paper","Final","","Scopus","2-s2.0-85217739767"
"C.Y., Lin, Cheng Yu; J.S.R., Jang, Jyh Shing Roger","Lin, Cheng Yu (59556541900); Jang, Jyh Shing Roger (57269304000)","59556541900; 57269304000","Concept-Based RAG Models: A High-Accuracy Fact Retrieval Approach","2025","Proceedings - International Conference on Computational Linguistics, COLING","","","","96","100","0","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217737988&partnerID=40&md5=d731bc8729a8c149ed0906d9b03b634a","National Taiwan University, Taipei, Taiwan","Lin, Cheng Yu, National Taiwan University, Taipei, Taiwan; Jang, Jyh Shing Roger, National Taiwan University, Taipei, Taiwan","This study introduces a concept-based methodology to optimize Retrieval-Augmented Generation (RAG) tasks by assessing dataset certainty using entropy-based metrics and concept extraction techniques. Unlike traditional methods focused on reducing LLM hallucinations or modifying data structures, this approach evaluates inherent knowledge uncertainty from an LLM perspective. By pre-processing documents with LLMs, the concept-based method significantly enhances precision in tasks demanding high accuracy, such as legal, finance, or formal document responses. © 2025 Elsevier B.V., All rights reserved.","Content Based Retrieval; Data Structures; Concept Extraction; Concept-based; Concept-based Retrieval; Entropy Based Metrics; Extraction Techniques; High-accuracy; Pre-processing; Uncertainty; Computational Linguistics","Content based retrieval; Data structures; Concept extraction; Concept-based; Concept-based retrieval; Entropy based metrics; Extraction techniques; High-accuracy; Pre-processing; Uncertainty; Computational linguistics","","","","From Local to Global A Graph Rag Approach to Query Focused Summarization, (2024); Retrieval Augmented Generation for Knowledge Intensive Nlp Tasks, (2020); Language Models are Unsupervised Multitask Learners, (2019); Agentic Retrieval Augmented Generation for Time Series Analysis, (2024); Robertson, Stephen E., The probabilistic relevance framework: BM25 and beyond, Foundations and Trends in Information Retrieval, 3, 4, pp. 333-389, (2009); Shannon, Claude E., A Mathematical Theory of Communication, The Bell System Technical Journal, 27, 3, pp. 379-423, (1948); 2023 Finance Question Answering Competition; Attention is all You Need, (2023); Garlic Llm Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document Qa, (2024); Corrective Retrieval Augmented Generation, (2024)","Chen, C.-C.; Moreno-Sandoval, A.; Huang, J.; Xie, Q.; Ananiadou, S.; Chen, H.-H.","Association for Computational Linguistics (ACL)","","Joint Workshop of the 9th Financial Technology and Natural Language Processing, FinNLP 2025, the 6th Financial Narrative Processing, FNP 2025, and the 1st Workshop on Large Language Models for Finance and Legal, LLMFinLegal 2025, co-located with the 31st International Conference on Computational Linguistics, COLING 2025","","Abu Dhabi","206513","29512093","9798891762053; 9798891762114; 9798891762060; 9798891761964; 9798891762022; 9798891762039; 9798891762015; 9798891762152; 9798891762077; 9781713861928","","","English","Conference paper","Final","","Scopus","2-s2.0-85217737988"
"T., Tojima, Tatsuya; M., Yoshida, Mitsuo","Tojima, Tatsuya (59531452600); Yoshida, Mitsuo (57171240600)","59531452600; 57171240600","Zero-Shot Classification of Art with Large Language Models","2025","IEEE Access","13","","","17426","17439","0","1","10.1109/ACCESS.2025.3532995","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216264991&doi=10.1109%2FACCESS.2025.3532995&partnerID=40&md5=8e61a92ebcf3d2ba368219d8e3c89fd1","University of Tsukuba, Tsukuba, Japan; University of Tsukuba, Tsukuba, Japan","Tojima, Tatsuya, Degree Programs in Systems and Information Engineering, University of Tsukuba, Tsukuba, Japan; Yoshida, Mitsuo, Faculty of Business Sciences, University of Tsukuba, Tsukuba, Japan","Art has become an important new investment vehicle. Thus, interest is growing in art price prediction as a tool for assessing the returns and risks of art investments. Both traditional statistical methods and machine learning methods have been used to predict art prices. However, both methods incur substantial human costs for data preprocessing for the construction of prediction models, necessitating a reduction in the workload. In this study, we propose the zero-shot classification method to perform automatic annotation in data processing for art price prediction by leveraging large language models (LLMs). The proposed method can perform annotation without new training data. Thus, it minimizes human costs. Our experiments demonstrated that the 4-bit quantized Llama-3 70B model, which can run on a local server, achieved the most accurate (over 0.9) automatic annotation of different art forms using LLMs, performing slightly better than the GPT-4o model from OpenAI. These results are practical for data preprocessing and comparable with the results of previous machine learning methods. © 2025 Elsevier B.V., All rights reserved.","Art; Auction Price; Chatgpt; Classification; Data Preprocessing; Gemma; Large Language Model; Llama; Llm; Machine Learning; Zero-shot Learning; Adversarial Machine Learning; Contrastive Learning; Network Security; Prediction Models; Risk Assessment; Art; Auction Price; Chatgpt; Data Preprocessing; Gemma; Language Model; Large Language Model; Llama; Machine-learning; Zero-shot Learning","Adversarial machine learning; Contrastive Learning; Network security; Prediction models; Risk assessment; Art; Auction price; ChatGPT; Data preprocessing; Gemma; Language model; Large language model; Llama; Machine-learning; Zero-shot learning","","","","Journal of Economic Literature, (1994); Wealth Report 2023, (2023); Li, Yuexin, Pricing art and the art of pricing: On returns and risk in art auction markets, European Financial Management, 28, 5, pp. 1139-1198, (2022); Intercom, (2018); Dimson, Elroy, The price of wine, Journal of Financial Economics, 118, 2, pp. 431-449, (2015); MacEda, Lany L., Classifying Sentiments on Social Media Texts: A GPT-4 Preliminary Study, pp. 19-24, (2023); Ashenfelter, Orley C., Auctions and the price of art, Journal of Economic Literature, 41, 3, pp. 763-787, (2003); Zhukova, Anna, Hedonic pricing on the fine art market, Information (Switzerland), 11, 5, (2020); Li, Bin, An Analysis of Multi-Modal Deep Learning for Art Price Appraisal, pp. 1509-1513, (2021); Kim, Kyoungok, Two-step model based on XGBoost for predicting artwork prices in auction markets, International Journal of Knowledge-Based and Intelligent Engineering Systems, 28, 1, pp. 133-147, (2024)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85216264991"
"K.S., Eljil, Khouloud Safi; E., Hamouda, Essia; F., Naït-Abdesselam, Farid","Eljil, Khouloud Safi (55812737600); Hamouda, Essia (26024970700); Naït-Abdesselam, Farid (55952572800)","55812737600; 26024970700; 55952572800","Initial Coin Offerings Success Prediction Using Social Media and Large Language Models","2025","Journal of Advances in Information Technology","16","1","","12","20","0","1","10.12720/jait.16.1.12-20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215769988&doi=10.12720%2Fjait.16.1.12-20&partnerID=40&md5=684b40d7681130b2cf79c5e868bab6c7","Université Paris Cité, Paris, France; University of Carthage, Ecole Supérieure des Communications de Tunis, Ariana, Tunisia; California State University, San Bernardino, San Bernardino, United States","Eljil, Khouloud Safi, Department of Computer Science, Université Paris Cité, Paris, France, University of Carthage, Ecole Supérieure des Communications de Tunis, Ariana, Tunisia; Hamouda, Essia, Department of Information and Decision Sciences, California State University, San Bernardino, San Bernardino, United States; Naït-Abdesselam, Farid, Department of Computer Science, Université Paris Cité, Paris, France","Initial Coin Offering (ICO) is a fundraising method utilized by blockchain startups to raise capital by issuing and selling digital tokens to investors. ICOs have become widely popular for cryptocurrency fundraising, often generating millions of dollars, and surpassing traditional crowdfunding methods like Initial Public Offerings. However, ICO is a risky way of investing and raising capital due to the lack of regulations and standardisation. In this research, we delve into the impact of social media and sentiment analysis on the success of ICOs, employing various machine learning models and Large Language Models. Our analysis is based on data from over 1,000 ICOs gathered from diverse ICO information platforms, coupled with a corpus of 910,478 tweets associated with these ICOs. We extend our investigation to include other social media platforms such as BitcoinTalk, Telegram, Facebook, and Medium. Our analysis revealed that valuable insights regarding the success of ICOs can be derived by examining text sentiment and investigating metadata across these diverse social media channels. © 2025 Elsevier B.V., All rights reserved.","Bidirectional Encoder Representations From Transformers (bert); Sentiment Analysis; Social Media; Token Sales; Web Scraping","","","","","Blockchain and Artificial Intelligence, (2018); Weking, Jörg, The impact of blockchain technology on business models – a taxonomy and archetypal patterns, Electronic Markets, 30, 2, pp. 285-305, (2020); International Conference Information Systems 2017, (2017); Cryptoasset Market Coverage Initiation Network Creation, (2018); Czaja, Daniel, Signalling in Initial Coin Offerings: The Key Role of Entrepreneurs’ Self-efficacy and Media Presence, Abacus, 58, 1, pp. 24-61, (2022); Ern Foreign Exchange Models Topic, (2019); Adhami, Saman, Why do businesses go crypto? An empirical analysis of initial coin offerings, Journal of Economics and Business, 100, pp. 64-75, (2018); Ssrn Electronic Journal, (2017); Bert Pre Training of Deep Bidirectional Transformers for Language Understanding, (2018); Ecis 2020, (2020)","","Engineering and Technology Publishing","","","","","","17982340","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85215769988"
"","","","26th International Conference on Information Integration and Web Intelligence, iiWAS 2024","2025","Lecture Notes in Computer Science","15343 LNCS","","","","","599","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212494941&partnerID=40&md5=fa2aecd7173d4fed3f498bd4793aadb2","","","The proceedings contain 52 papers. The special focus in this conference is on Information Integration and Web Intelligence. The topics include: Financial News Classification Using Language Learning Models and Reinforcement Learning; ExtractGPT: Exploring the Potential of Large Language Models for Product Attribute Value Extraction; Feature Extraction for Claim Check-Worthiness Prediction Tasks Using LLM; training Data for Dialogue Generation Considering Philosophies; Finding Adequate Additional Layer of Auxiliary Task in BERT-Based Multi-task Learning; ponzi Scheme Detection and Prevention in Blockchain Platforms Using Machine Learning: A Systematic Literature Review; Cross-Chain Personal Data Exchange on EVM Platforms: Enhancing Transparency, and Equity; Incentivize Peer Review Without Rewarding: Using OSS-Like Citation Pull Request; towards Website X-Ray for Europe’s Municipalities: Unveiling Digital Transformation with Multimodal Embeddings; evolving Applications of Conversational Agents in Healthcare: A Literature Review; hybrid Edge-Cloud Federated Learning: The Case of Lightweight Smoking Detection; anonymization of Unstructured Health Data in Spanish; when Good Enough is the Best Option: Use of Digital Sufficiency to Fight Climate Change; multi-target Feature Selection Method for Predicting User-Level Psychological Status from Text; FIEAP: A Machine Learning Approach for Fair and Interpretable Employee Attrition Prediction; HOCON34k: A Corpus of Hate Speech in Online Comments from German Newspapers; SISIS: Sequence Indexing for SImilarity Search; top-k on Sequences: A New Approach to Enhanced Similarity Search; exploratory Data Analysis of Time Series Using Pre-segmented Clustering; a Data Science Approach for Predicting Soccer Passes Using Positional Data; a Method for Integrating Heterogeneous Data into a Knowledge Graph; predicting Knowledge Graph Updates from Edit Histories; Automatic Extraction of RML-star Mappings from Property Graphs; Exploring the Role of UML in Data Modelling for NoSQL Databases: Position Paper; railway Systems’ Ontologies: A Literature Review and an Alignment Proposal; Combining GraphSAGE and Label Propagation for Node Classification in Graphs. © 2024 Elsevier B.V., All rights reserved.","","","","","","","Delir Haghighi, P.; Greguš, M.; Kotsis, G.; Khalil, I.","Springer Science and Business Media Deutschland GmbH","","26th International Conference on Information Integration and Web Intelligence, iiWAS 2024","","Bratislava","323819","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference review","Final","","Scopus","2-s2.0-85212494941"
"","","","26th International Conference on Information Integration and Web Intelligence, iiWAS 2024","2025","Lecture Notes in Computer Science","15342 LNCS","","","","","599","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212253172&partnerID=40&md5=5f4500486ebf9c039d0e8b8e9d3f35af","","","The proceedings contain 52 papers. The special focus in this conference is on Information Integration and Web Intelligence. The topics include: Financial News Classification Using Language Learning Models and Reinforcement Learning; ExtractGPT: Exploring the Potential of Large Language Models for Product Attribute Value Extraction; Feature Extraction for Claim Check-Worthiness Prediction Tasks Using LLM; training Data for Dialogue Generation Considering Philosophies; Finding Adequate Additional Layer of Auxiliary Task in BERT-Based Multi-task Learning; ponzi Scheme Detection and Prevention in Blockchain Platforms Using Machine Learning: A Systematic Literature Review; Cross-Chain Personal Data Exchange on EVM Platforms: Enhancing Transparency, and Equity; Incentivize Peer Review Without Rewarding: Using OSS-Like Citation Pull Request; towards Website X-Ray for Europe’s Municipalities: Unveiling Digital Transformation with Multimodal Embeddings; evolving Applications of Conversational Agents in Healthcare: A Literature Review; hybrid Edge-Cloud Federated Learning: The Case of Lightweight Smoking Detection; anonymization of Unstructured Health Data in Spanish; when Good Enough is the Best Option: Use of Digital Sufficiency to Fight Climate Change; multi-target Feature Selection Method for Predicting User-Level Psychological Status from Text; FIEAP: A Machine Learning Approach for Fair and Interpretable Employee Attrition Prediction; HOCON34k: A Corpus of Hate Speech in Online Comments from German Newspapers; SISIS: Sequence Indexing for SImilarity Search; top-k on Sequences: A New Approach to Enhanced Similarity Search; exploratory Data Analysis of Time Series Using Pre-segmented Clustering; a Data Science Approach for Predicting Soccer Passes Using Positional Data; a Method for Integrating Heterogeneous Data into a Knowledge Graph; predicting Knowledge Graph Updates from Edit Histories; Automatic Extraction of RML-star Mappings from Property Graphs; Exploring the Role of UML in Data Modelling for NoSQL Databases: Position Paper; railway Systems’ Ontologies: A Literature Review and an Alignment Proposal; Combining GraphSAGE and Label Propagation for Node Classification in Graphs. © 2024 Elsevier B.V., All rights reserved.","","","","","","","Delir Haghighi, P.; Greguš, M.; Kotsis, G.; Khalil, I.","Springer Science and Business Media Deutschland GmbH","","26th International Conference on Information Integration and Web Intelligence, iiWAS 2024","","Bratislava","323819","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference review","Final","","Scopus","2-s2.0-85212253172"
"C., Bian, Chong; X., Han, Xue; Z., Duan, Zhiyu; C., Deng, Chao; S., Yang, Shunkun; J., Feng, Junlan","Bian, Chong (57193312957); Han, Xue (57211136492); Duan, Zhiyu (57947414900); Deng, Chao (57196881165); Yang, Shunkun (54958512500); Feng, Junlan (57190813028)","57193312957; 57211136492; 57947414900; 57196881165; 54958512500; 57190813028","Hybrid Prompt-Driven Large Language Model for Robust State-of-Charge Estimation of Multitype Li-ion Batteries","2025","IEEE Transactions on Transportation Electrification","11","1","","426","437","0","6","10.1109/TTE.2024.3391938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191317031&doi=10.1109%2FTTE.2024.3391938&partnerID=40&md5=a9d832f84a71e9c5127d505805575122","Artificial Intelligence and Intelligent Operation Center, Beijing, China; Beihang University, Beijing, China","Bian, Chong, Artificial Intelligence and Intelligent Operation Center, Beijing, China; Han, Xue, Artificial Intelligence and Intelligent Operation Center, Beijing, China; Duan, Zhiyu, Beihang University, Beijing, China; Deng, Chao, Artificial Intelligence and Intelligent Operation Center, Beijing, China; Yang, Shunkun, Beihang University, Beijing, China; Feng, Junlan, Artificial Intelligence and Intelligent Operation Center, Beijing, China","State-of-charge (SOC) estimation is critical for reliable operation of Li-ion batteries (LIBs). However, the distinct electrochemical characteristics coupled with harsh low-temperature environments make a single estimator struggle to robustly estimate the volatile SOC of multitype LIBs. To address these issues, this article proposes a hard-soft hybrid prompt learning method to unleash the potential of a pretrained large language model (LLM) for SOC estimation. A textual encoder is introduced to convert LIB measurements into hard text prompts for language modeling, naturally eliciting the pretrained LLM to capture the intrarelations of measured values over time and their interrelations with contextual semantics for accurate estimates. A side adapter network is constructed to reparameterize model adaptation towards different LIB tasks into optimizations within a low-dimensional subspace, strengthening the estimation generalization of the pretrained LLM in a parameter-efficient manner. A knowledge infusion mechanism is designed to encapsulate task-specific information as soft prompt vectors for model integration along forward propagation, dynamically conditioning the hidden states inside the pretrained LLM to enhance the estimation robustness against SOC volatilities. Extensive experiments verify that the hybrid prompt-driven LLM can simultaneously perform estimations for multitype LIBs under diverse operations and sub-zero temperatures with superior accuracy, generalization, and robustness. © 2025 Elsevier B.V., All rights reserved.","Hybrid Prompt Learning; Large Language Model (llm); Multitype Li-ion Batteries (libs); State-of-charge (soc) Estimation; Charging (batteries); Computational Linguistics; Ions; Learning Systems; Lithium-ion Batteries; Modeling Languages; Semantics; Temperature Measurement; Generalisation; Hybrid Prompt Learning; Language Model; Large Language Model; Multi-type Li-ion Battery; Robustness; State-of-charge Estimation; States Of Charges; Task Analysis; Transformer; Temperature","Charging (batteries); Computational linguistics; Ions; Learning systems; Lithium-ion batteries; Modeling languages; Semantics; Temperature measurement; Generalisation; Hybrid prompt learning; Language model; Large language model; Multi-type li-ion battery; Robustness; State-of-charge estimation; States of charges; Task analysis; Transformer; Temperature","","","","Shen, Liyuan, Transfer Learning-Based State of Charge and State of Health Estimation for Li-Ion Batteries: A Review, IEEE Transactions on Transportation Electrification, 10, 1, pp. 1465-1481, (2024); Ren, Zhong, A review of machine learning state-of-charge and state-of-health estimation algorithms for lithium-ion batteries, Energy Reports, 9, pp. 2993-3021, (2023); Liu, Yuefeng, A review of lithium-ion battery state of charge estimation based on deep learning: Directions for improvement and future trends, Journal of Energy Storage, 52, (2022); Wang, Yujie, A comprehensive review of battery modeling and state estimation approaches for advanced battery management systems, Renewable and Sustainable Energy Reviews, 131, (2020); Chemali, Ephrem, State-of-charge estimation of Li-ion batteries using deep neural networks: A machine learning approach, Journal of Power Sources, 400, pp. 242-255, (2018); How, Dickshon Neoh Tze, State-of-Charge Estimation of Li-Ion Battery in Electric Vehicles: A Deep Neural Network Approach, IEEE Transactions on Industry Applications, 56, 5, pp. 5565-5574, (2020); Chemali, Ephrem, Long Short-Term Memory Networks for Accurate State-of-Charge Estimation of Li-ion Batteries, IEEE Transactions on Industrial Electronics, 65, 8, pp. 6730-6739, (2018); Ren, Xiaoqing, A method for state-of-charge estimation of lithium-ion batteries based on PSO-LSTM, Energy, 234, (2021); Yang, Fangfang, State-of-charge estimation of lithium-ion batteries based on gated recurrent neural network, Energy, 175, pp. 66-75, (2019); Li, Chaoran, An approach to state of charge estimation of lithium-ion batteries based on recurrent neural networks with gated recurrent unit, Energies, 12, 9, (2019)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","23327782","","","","English","Article","Final","","Scopus","2-s2.0-85191317031"
"D.P.M., Abellana, Dharyll Prince M.","Abellana, Dharyll Prince M. (57213603444)","57213603444","Zero-Shot Time Series Forecasting of the Online Gig Economy Using the CHRONOS Pretrained Language Model","2025","","","","","","","0","0","10.1109/ITC-CSCC66376.2025.11137629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016396580&doi=10.1109%2FITC-CSCC66376.2025.11137629&partnerID=40&md5=b2a7bff10d4415aa88988c9a754dc9f9","University of the Philippines Cebu, Cebu, Philippines","Abellana, Dharyll Prince M., Department of Computer Science, University of the Philippines Cebu, Cebu, Philippines","This study introduces a zero-shot forecasting method for the online gig economy applying the CHRONOS pre-trained language model to the online labor index (OLI) data. The paper concentrates on forecasting demand for six freelance job categories using historical weekly data from January 2017 to August 2024, without retraining the model specifically for these tasks. Although the one-step-ahead (weekly) forecasts demonstrate highly satisfactory accuracy, with a mean absolute scaled error below 1 for most freelance occupations, there is a decline in performance for multi-step forecasts (at least one month ahead), shown by increased errors. This result underscores the importance of pre-trained models in learning semantic information that can be easily transferred to other applications, especially in zero-shot setups. This paper makes a substantial contribution to the field by using OLI to enhance our understanding of predicting the demand for freelance jobs based on structural patterns in economic indicators. This is crucial given the volatility and distinct behaviors of the online gig economy. Furthermore, it illustrates the potential of using pre-trained transformer-based language models in time series forecasting, even with limited historical data, proving that advanced pre-trained models can still produce valuable predictions. © 2025 Elsevier B.V., All rights reserved.","Online Gig Economy; Online Labor Index; Pre-trained Language Model; Zero-shot Time Series Forecasting; Employment; Forecasting; Time Series; Forecasting Demand; Forecasting Methods; Language Model; Multisteps; Online Gig Economy; Online Labor Index; Performance; Pre-trained Language Model; Time Series Forecasting; Zero-shot Time Series Forecasting; Semantics","Employment; Forecasting; Time series; Forecasting demand; Forecasting methods; Language model; Multisteps; Online gig economy; Online labor index; Performance; Pre-trained language model; Time series forecasting; Zero-shot time series forecasting; Semantics","","","","Fulker, Zachary, Cooperation in the Gig Economy: Insights from Upwork Freelancers, Proceedings of the ACM on Human-Computer Interaction, 8, CSCW1, (2024); Cauffman, Caroline, Towards better working conditions for persons performing services through digital labour platforms, Maastricht Journal of European and Comparative Law, 29, 1, pp. 3-8, (2022); Malik, Zeeshan Haider, Usability Evaluation of Freelance Platforms, Lecture Notes in Networks and Systems, 814 LNNS, pp. 42-58, (2023); Peters, Pascale (c P.)., The impact of work-related values and work control on the career satisfaction of female freelancers, Small Business Economics, 55, 2, pp. 493-506, (2020); Flexible Work Arrangement and Employee Performance an Evidence of Work Life Balance Practices, (2022); Emerald Open Research, (2019); Gupta, Varun, Freelancing models for fostering innovation and problem solving in software startups: An empirical comparative study, Sustainability (Switzerland), 12, 23, pp. 1-29, (2020); Online Labour Observatory, (2016); Kässi, Otto, Online labour index: Measuring the online gig economy for policy and research, Technological Forecasting and Social Change, 137, pp. 241-248, (2018); Ansari, Abdul Fatir, Chronos: Learning the Language of Time Series, Transactions on Machine Learning Research, 2024, (2024)","","Institute of Electrical and Electronics Engineers Inc.","","2025 International Technical Conference on Circuits/Systems, Computers, and Communications, ITC-CSCC 2025","","Seoul","211960","","9798331553630","","","English","Conference paper","Final","","Scopus","2-s2.0-105016396580"
"","; Siddavatam, Asma Parveen I. (57202775959)","60103554900; 60103346000; 60103608000; 60103346100; 57202775959","MediFlow - AI and Blockchain in Pharmaceutical Supply Chain: Enhancing Traceability and Decision-Making","2025","","","","","896","902","0","0","10.1109/ACCESS65134.2025.11135599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016311505&doi=10.1109%2FACCESS65134.2025.11135599&partnerID=40&md5=a3f1cf135390019133992c4d019d15d5","Vivekanand Education Society's Institute of Technology, Mumbai, India","null, null, Vivekanand Education Society's Institute of Technology, Mumbai, India; null, null, Vivekanand Education Society's Institute of Technology, Mumbai, India; null, null, Vivekanand Education Society's Institute of Technology, Mumbai, India; null, null, Vivekanand Education Society's Institute of Technology, Mumbai, India; Siddavatam, Asma Parveen I., Vivekanand Education Society's Institute of Technology, Mumbai, India","MediFlow is an advanced pharmaceutical supply-chain management platform leveraging blockchain technology to enhance efficiency and transparency in drug distribution. By integrating Ethereum blockchain with predictive analytics powered by the TIME LLM model, MediFlow facilitates secure and streamlined drug procurement and delivery processes. The system utilizes smart contracts to automate transactions, optimize vendor collaboration, and eliminate unnecessary intermediaries, leading to improved efficiency and stakeholder trust. Real-time inventory and shipment tracking capabilities reduce logistical delays and errors, while predictive demand analysis helps mitigate stock shortages and minimize waste. Furthermore, the immutable nature of blockchain technology ensures the authenticity of medicines, thereby reducing the prevalence of counterfeit drugs in the market. Implementation results indicate notable improvements in transparency, cost-effectiveness, and overall healthcare service delivery, making MediFlow a transformative solution for pharmaceutical supplychain management. © 2025 Elsevier B.V., All rights reserved.","Blockchain; Drug Supply Chain; Predictive Analytics; Smart Contracts; Time Llm Model; Big Data; Chains; Controlled Drug Delivery; Cost Effectiveness; Decision Making; Drug Discovery; Predictive Analytics; Smart Contract; Supply Chain Management; Supply Chains; Targeted Drug Delivery; Block-chain; Chain Management; Decisions Makings; Drug Distribution; Drug Supply; Drug Supply Chain; Management Platforms; Pharmaceutical Supply Chains; Platform Leveraging; Time Llm Model; Blockchain","Big data; Chains; Controlled drug delivery; Cost effectiveness; Decision making; Drug discovery; Predictive analytics; Smart contract; Supply chain management; Supply chains; Targeted drug delivery; Block-chain; Chain management; Decisions makings; Drug distribution; Drug supply; Drug supply chain; Management platforms; Pharmaceutical supply chains; Platform leveraging; TIME LLM model; Blockchain","","","","Pathak, Agya, Blockchain Technology in Pharmaceutical Supply Chain Management, pp. 723-727, (2022); Musamih, Ahmad, A blockchain-based approach for drug traceability in healthcare supply chain, IEEE Access, 9, pp. 9728-9743, (2021); Omar, Ilhaam Aziz, Supply Chain Inventory Sharing Using Ethereum Blockchain and Smart Contracts, IEEE Access, 10, pp. 2345-2356, (2022); Ma, Jinhua, A Blockchain-Based Application System for Product Anti-Counterfeiting, IEEE Access, 8, pp. 77642-77652, (2020); Zhu, Peng, A blockchain based solution for medication anti-counterfeiting and traceability, IEEE Access, 8, pp. 184256-184272, (2020); Kulkarni, Aseem, Enhancing Pharmaceutical Security: SecureMeds -A Robust Drug Traceability Platform, pp. 846-851, (2024); Artificial Intelligence in Pharmaceutical Sales Marketing A Conceptual Overview, (2022); Fourkiotis, Konstantinos Panagiotis, Applying Machine Learning and Statistical Forecasting Methods for Enhancing Pharmaceutical Sales Predictions, Forecasting, 6, 1, pp. 170-186, (2024); Acadlore Trans Mach Learn, (2023); Dutta, Sushama Rani, Smart Sales Prediction of Pharmaceutical Products, (2022)","","Institute of Electrical and Electronics Engineers Inc.","Ministry of Electronics and Information Technology (MeitY), Govt. of India","4th International Conference on Advances in Computing, Communication, Embedded and Secure Systems, ACCESS 2025","","Ernakulam","211773","","9798331536237","","","English","Conference paper","Final","","Scopus","2-s2.0-105016311505"
"A., Horn, Adam; T., Schlippe, Tim","Horn, Adam (60092990800); Schlippe, Tim (42062203500)","60092990800; 42062203500","Investigating the Predictive Capabilities of Large Language Models in Day Trading by Leveraging Multimodal Data","2025","","","","","34","38","0","0","10.1109/ICNLP65360.2025.11108638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015746549&doi=10.1109%2FICNLP65360.2025.11108638&partnerID=40&md5=42e4df25e25affda3913e9c58674ede8","IU Internationale Hochschule GmbH, Erfurt, Germany","Horn, Adam, IU Internationale Hochschule GmbH, Erfurt, Germany; Schlippe, Tim, IU Internationale Hochschule GmbH, Erfurt, Germany","This paper evaluates the predictive capabilities of six LLMs-GPT-4, GPT-4o, Llama 3, Claude 3.5, Mistral 0.3, and Gemma 2-in day trading using multimodal data. The LLMs process diverse inputs, including text-based price histories, news titles, and images. The lowest Mean Absolute Percentage Errors (MAPEs) (1.4%) were achieved by Claude 3.5 and Gemma 2 using only price history text and by Claude 3.5 and Mistral 0.3 with combined price and news history inputs, demonstrating LLMs' potential for accurate financial predictions through prompting without advanced technical expertise. Remarkably, GPT-4 and Claude 3.5 achieve MAPEs of just 1.7% and 1.5%, respectively, by processing only price history images. Furthermore, Gemma 2 achieves a MAPE of 1.5% using only news history inputs, without any information from the price history. © 2025 Elsevier B.V., All rights reserved.","Large Language Models; Llms; Multimodal; Natural Language Processing; Nlp; Artificial Intelligence; Commerce; Electronic Trading; Financial Prediction; Language Model; Language Processing; Large Language Model; Llm; Multi-modal; Natural Language Processing; Natural Languages; Percentage Error; Predictive Capabilities; Costs","Artificial intelligence; Commerce; Electronic trading; Financial prediction; Language model; Language processing; Large language model; LLM; Multi-modal; Natural language processing; Natural languages; Percentage error; Predictive capabilities; Costs","","","This research was supported by the IU International University of Applied Sciences (IU Incubator) through internal initial funding for the period from October 2023 to September 2025.","Proceedings of the ACM Conference, (2024); Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Automate Strategy Finding with Llm in Quant Investment, (2024); Fine Tuning Large Language Models for Stock Return Prediction Using Newsflow, (2024); Llmfactor Extracting Profitable Factors Through Prompts for Explainable Stock Movement Prediction, (2024); Kaur, Jasleen, Data mining–based stock price prediction using hybridization of technical and fundamental analysis, Data Technologies and Applications, 57, 5, pp. 780-800, (2023); Zbw Leibniz Information Centre for Economics, (2024); Enhancing Few Shot Stock Trend Prediction with Large Language Models, (2024); Harnessing Earnings Reports for Stock Predictions A Qlora Enhanced Llm Approach, (2024); How can We Use Chatgpt Better A Research of API Enhanced Chatgpt in Stock Prediction, (2024)","","Institute of Electrical and Electronics Engineers Inc.","","7th International Conference on Natural Language Processing, ICNLP 2025","","Guangzhou","211542","","9798331521875","","","English","Conference paper","Final","","Scopus","2-s2.0-105015746549"
"Y., Fathullah, Yassir; M.J.F., Gales, Mark John Francis","Fathullah, Yassir (57218454650); Gales, Mark John Francis (7004447872)","57218454650; 7004447872","Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge","2025","Proceedings of Machine Learning Research","286","","","1266","1276","0","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014724824&partnerID=40&md5=a3782e5d07fa419e284979af14df2145","Department of Engineering, Cambridge, United Kingdom","Fathullah, Yassir, Department of Engineering, Cambridge, United Kingdom; Gales, Mark John Francis, Department of Engineering, Cambridge, United Kingdom","This paper explores generalised probabilistic modelling and uncertainty estimation in comparative LLM-as-a-judge frameworks. We show that existing Product-of-Experts methods are specific cases of a broader framework, enabling diverse modelling options. Furthermore, we propose improved uncertainty estimates for individual comparisons, enabling more efficient selection and achieving strong performance with fewer evaluations. We also introduce a method for estimating overall ranking uncertainty. Finally, we demonstrate that combining absolute and comparative scoring improves performance. Experiments show that the specific expert model has a limited impact on final rankings but our proposed uncertainty estimates, especially the probability of reordering, significantly improve the efficiency of systems reducing the number of needed comparisons by ∼ 50%. Furthermore, ranking-level uncertainty metrics can be used to identify low-performing predictions, where the nature of the probabilistic model has a notable impact on the quality of the overall uncertainty. © 2025 Elsevier B.V., All rights reserved.","Prediction Models; Expert Modeling; Improve Performance; Model Estimation; Performance; Probabilistic Models; Probabilistic Uncertainty; Product Of Experts; Uncertainty; Uncertainty Estimates; Uncertainty Estimation; Uncertainty Analysis","Prediction models; Expert modeling; Improve performance; Model estimation; Performance; Probabilistic models; Probabilistic uncertainty; Product of experts; Uncertainty; Uncertainty estimates; Uncertainty estimation; Uncertainty analysis","","","","Gpt 4 Technical Report, (2023); Categorical Data Analysis, (2002); Beaudoin, David, A computationally intensive ranking system for paired comparison data, Operations Research Perspectives, 5, pp. 105-112, (2018); Biometrika, (1952); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Sparks of Artificial General Intelligence Early Experiments with Gpt 4, (2023); Cao, Zhe, Learning to rank: From pairwise approach to listwise approach, ACM International Conference Proceeding Series, 227, pp. 129-136, (2007); Caron, François, Efficient Bayesian inference for generalized Bradley-Terry models, Journal of Computational and Graphical Statistics, 21, 1, pp. 174-196, (2012); Models for Paired Comparison Data A Review with Emphasis on Dependent Data, (2012); Premise Order Matters in Reasoning with Large Language Models, (2024)","Chiappa, S.; Magliacane, S.","ML Research Press","","41st Conference on Uncertainty in Artificial Intelligence, UAI 2025","","Rio de Janeiro; Rio Othon Palace","211200","26403498","9781713845065","","","English","Conference paper","Final","","Scopus","2-s2.0-105014724824"
"K., He, Kaijian; Y., Li, Yishuai; Z., Peng, Zihuan; Y., Zou, Yingchao","He, Kaijian (7202010698); Li, Yishuai (60069078000); Peng, Zihuan (60069179600); Zou, Yingchao (56141534000)","7202010698; 60069078000; 60069179600; 56141534000","Prediction of Crude Oil Price using LLM: An Empirical Analysis","2025","Procedia Computer Science","266","","","594","602","0","0","10.1016/j.procs.2025.08.075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014190692&doi=10.1016%2Fj.procs.2025.08.075&partnerID=40&md5=f1e64e199528bdbf9714f6d11a68fb27","Hunan Normal University, Changsha, China; South China University of Technology, Guangzhou, China","He, Kaijian, College of Tourism, Hunan Normal University, Changsha, China; Li, Yishuai, College of Tourism, Hunan Normal University, Changsha, China; Peng, Zihuan, South China University of Technology, Guangzhou, China; Zou, Yingchao, College of Tourism, Hunan Normal University, Changsha, China","In this paper we conducted empirical studies to investigate the application of large language model to evaluate and estimate investment sentiment from the news text on the internet. We further proposed a crude oil price forecasting model with the estimated investment sentiment scores using LLM. Empirical evaluations using the crude oil spot prices demonstrate the superior forecasting accuracy of the large language model-based approach to forecast the future crude oil price movements. This result suggests that the large language model extracts valuable information from the news text, enhancing the predictive modeling of the crude oil price movements. © 2025 Elsevier B.V., All rights reserved.","Crude Oil Price Forecasting; Large Language Model; Time Series Forecasting; Transformer Model; Costs; Crude Oil Price; Forecasting; Investments; Petroleum Analysis; Prediction Models; Sentiment Analysis; Time Series Analysis; Crude Oil Price Forecasting; Crude Oil Prices; Empirical Analysis; Empirical Studies; Forecasting Models; Language Model; Large Language Model; Price Movement; Time Series Forecasting; Transformer Modeling; Modeling Languages","Costs; Crude oil price; Forecasting; Investments; Petroleum analysis; Prediction models; Sentiment analysis; Time series analysis; Crude oil price forecasting; Crude oil prices; Empirical analysis; Empirical studies; Forecasting models; Language model; Large language model; Price movement; Time series forecasting; Transformer modeling; Modeling languages","","","The work described in this paper was supported by a grant from National Natural Science Foundation of China (Grant no.72271089), the Key Program of National Natural Science Foundation of China (Grant no.72331007),and Hunan Province College Students Research Learning and Innovative Experiment Project (Grant no. 202410542175).","Movagharnejad, Kamyar, Forecasting the differences between various commercial oil prices in the Persian Gulf region by neural network, Energy, 36, 7, pp. 3979-3984, (2011); Zhang, Yaojie, Forecasting crude oil futures market returns: A principal component analysis combination approach, International Journal of Forecasting, 39, 2, pp. 659-673, (2023); undefined; undefined; Ji, Qiang, System analysis approach for the identification of factors driving crude oil prices, Computers and Industrial Engineering, 63, 3, pp. 615-625, (2012); Du, Limin, Extreme risk spillovers between crude oil and stock markets, Energy Economics, 51, pp. 455-465, (2015); Li, Xuerong, Text-based crude oil price forecasting: A deep learning approach, International Journal of Forecasting, 35, 4, pp. 1548-1560, (2019); undefined; undefined; undefined","Shi, Y.; Shi, Y.; Shi, Y.","Elsevier B.V.","","12th International Conference on Information Technology and Quantitative Management, ITQM 2025","","Rutgers Business School","211145","18770509","9781510849914","","","English","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105014190692"
"D., Herrera-Poyatos, David; C., Peláez-González, Carlos; C., Zuheros, Cristina; A., Herrera-Poyatos, Andrés; V., Tejedor, Virilo; F.P., Herrera, Francisco P.; R., Montes, Rosana","Herrera-Poyatos, David (58968825800); Peláez-González, Carlos (59387498300); Zuheros, Cristina (57205647609); Herrera-Poyatos, Andrés (57194105375); Tejedor, Virilo (59772919700); Herrera, Francisco P. (7102347190); Montes, Rosana (59772493900)","58968825800; 59387498300; 57205647609; 57194105375; 59772919700; 7102347190; 59772493900","An overview of model uncertainty and variability in LLM-based sentiment analysis: challenges, mitigation strategies, and the role of explainability","2025","Frontiers in Artificial Intelligence","8","","1609097","","","0","0","10.3389/frai.2025.1609097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014010527&doi=10.3389%2Ffrai.2025.1609097&partnerID=40&md5=9a3d3b1a99be863fbf42e3ecb79ceeb0","Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence, Granada, Spain; Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence, Granada, Spain","Herrera-Poyatos, David, Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence, Granada, Spain; Peláez-González, Carlos, Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence, Granada, Spain; Zuheros, Cristina, Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence, Granada, Spain; Herrera-Poyatos, Andrés, Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence, Granada, Spain; Tejedor, Virilo, Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence, Granada, Spain; Herrera, Francisco P., Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence, Granada, Spain; Montes, Rosana, Department of Software Engineering, Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence, Granada, Spain","Large Language Models (LLMs) have significantly advanced sentiment analysis, yet their inherent uncertainty and variability pose critical challenges to achieving reliable and consistent outcomes. This paper systematically explores the Model Variability Problem (MVP) in LLM-based sentiment analysis, characterized by inconsistent sentiment classification, polarization, and uncertainty arising from stochastic inference mechanisms, prompt sensitivity, and biases in training data. We present illustrative examples and two case studies to highlight its impact and analyze the core causes of MVP, discussing a dozen fundamental reasons for model variability. We pay especial atenttion to explainabily, with an analysis of its importance in LLMs from the MVP perspective. In addition, we investigate key challenges and mitigation strategies, paying particular attention to the role of temperature as a driver of output randomness and highlighting the crucial role of explainability in improving transparency and user trust. By providing a structured perspective on stability, reproducibility, and trustworthiness, this study helps develop more reliable, explainable, and robust sentiment analysis models, facilitating their deployment in high-risk domains such as finance, healthcare and policy making, among others. © 2025 Elsevier B.V., All rights reserved.","Large Language Models; Llm-based Sentiment Analysis; Model Variability Problem; Sentiment Analysis; Uncertainty","","","","The author(s) declare that financial support was received for the research and/or publication of this article. This research results from the Strategic Project IAFER-Cib (C074/23), as a result of the collaboration agreement signed between the National Institute of Cybersecurity (INCIBE) and the University of Granada. This initiative is carried out within the framework of the Recovery, Transformation and Resilience Plan funds, financed by the European Union (Next Generation).","Generative Ai Text Classification Using Ensemble Llm Approaches, (2023); Afroogh, Saleh, Trust in AI: progress, challenges, and future directions, Humanities and Social Sciences Communications, 11, 1, (2024); undefined, (2024); Ali, Sajid, Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence, Information Fusion, 99, (2023); Transformer Circuits Thread, (2025); Urgency of Interpretability, (2025); Barredo-Arrieta, Alejandro, Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI, Information Fusion, 58, pp. 82-115, (2020); Llm Stability A Detailed Analysis with Some Surprises, (2024); González Barman, Kristian, Beyond transparency and explainability: on the need for adequate and contextualized user guidelines for LLM use, Ethics and Information Technology, 26, 3, (2024); Rethinking the Uncertainty A Critical Review and Analysis in the Era of Large Language Models, (2024)","","Frontiers Media SA","","","","","","26248212","","","","English","Review","Final","","Scopus","2-s2.0-105014010527"
"C., Zhou, Chengjie; Y., Wang, Yufeng; J., Ma, Jianhua; Q., Jin, Qun","Zhou, Chengjie (60055948100); Wang, Yufeng (8777845900); Ma, Jianhua (8700280300); Jin, Qun (59642985900)","60055948100; 8777845900; 8700280300; 59642985900","STCA-LLM: Spatial-Temporal Cross-Attention Large Language Model for Wind Speed Forecasting","2025","IEEE Internet of Things Journal","","","","","","0","0","10.1109/JIOT.2025.3599836","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013742239&doi=10.1109%2FJIOT.2025.3599836&partnerID=40&md5=13466a2d529cf51123df30fa7ef3ab40","Nanjing University of Post and TeleCommunications, Nanjing, China; Hosei University, Tokyo, Japan; Waseda University, Tokyo, Japan","Zhou, Chengjie, Nanjing University of Post and TeleCommunications, Nanjing, China; Wang, Yufeng, Nanjing University of Post and TeleCommunications, Nanjing, China; Ma, Jianhua, Hosei University, Tokyo, Japan; Jin, Qun, Waseda University, Tokyo, Japan","Accurately forecasting wind speed is crucial for efficiently utilizing the renewable energy, stabilizing the energy system and advancing the progress of the decarbonization of our society. However, due to its inherently temporal volatility and intermittency, accurate wind speed forecasting in a wind farm is challenging. Recently, Large Language Models (LLMs) have demonstrated notable performance in abundant natural language processing and computer vision tasks. However, the conventional LLMs fail to learn the complex spatial and temporal correlations of the wind speed data at multiple turbines in a wind farm, which makes wind speed forecasting cant fully benefit from the significant breakthroughs of LLM. To fill in this gap, we propose a novel spatial-temporal cross-attention LLM framework for wind speed forecasting, namely STCA-LLM, composed of alignment phase, and fine-tuning phase. In detail, our contributions are given as follows. First, the alignment phase aligns the general-purpose LLM with task-specific data, i.e., training the LLM with wind speed data. Second, in the fine-tuning phase, two representation learning modules, i.e., convolution network and graph neural network (GNN) are respectively used to extract temporal features of intra time series in each turbine, and the correlation of inter time-series at multiple turbines in a wind farm. Moreover, the cross-attention module is innovatively proposed to establish the connections between spatial and temporal embeddings. Then, the spatial-temporal representation modules and the aligned LLM are fine-tuned in two-stage way. Finally, thorough experiments on real wind speed dataset demonstrate that our proposed STCA-LLM outperforms state-of-the-art time series forecasting models including Transformer-based models, spatial-temporal GNN-based models, and pertained LLM-based models. © 2025 Elsevier B.V., All rights reserved.","Graph Attention Network; Large Language Model (llm); Spatial-temporal Cross-attention; Wind Speed Forecasting; Forecasting; Natural Language Processing Systems; Neural Networks; Spatio-temporal Data; Time Series; Tuning; Wind Effects; Wind Forecasting; Wind Power; Wind Turbines; Fine Tuning; Graph Attention Network; Language Model; Large Language Model; Spatial Temporals; Spatial-temporal Cross-attention; Wind Farm; Wind Speed; Wind Speed Data; Wind Speed Forecasting; Electric Utilities","Forecasting; Natural language processing systems; Neural networks; Spatio-temporal data; Time series; Tuning; Wind effects; Wind forecasting; Wind power; Wind turbines; Fine tuning; Graph attention network; Language model; Large language model; Spatial temporals; Spatial-temporal cross-attention; Wind farm; Wind speed; Wind speed data; Wind speed forecasting; Electric utilities","","","","Wang, Yun, A review of wind speed and wind power forecasting with deep neural networks, Applied Energy, 304, (2021); Liu, Hui, Data processing strategies in wind energy forecasting models and applications: A comprehensive review, Applied Energy, 249, pp. 392-408, (2019); Chen, Yaoran, 2-D regional short-term wind speed forecast based on CNN-LSTM deep learning model, Energy Conversion and Management, 244, (2021); Zhou, Tian, One Fits All: Power General Time Series Analysis by Pretrained LM, Advances in Neural Information Processing Systems, 36, (2023); Jin, Ming, TIME-LLM: TIME SERIES FORECASTING BY REPROGRAMMING LARGE LANGUAGE MODELS, (2024); Chang, Ching, LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series Forecasters, ACM Transactions on Intelligent Systems and Technology, 16, 3, (2025); Wang, Yufeng, Artificial intelligence of things (AIoT) data acquisition based on graph neural networks: A systematical review, Concurrency and Computation: Practice and Experience, 35, 23, (2023); Cheng, Haoyuan, TF-MVGNN: an accurate traffic forecasting framework based on spatial–temporal graph neural network through exploiting multiple-view graph construction and learning, Neural Computing and Applications, 37, 20, pp. 14657-14671, (2025); Wang, Yufeng, A wind speed forecasting framework for multiple turbines based on adaptive gate mechanism enhanced multi-graph attention networks, Applied Energy, 372, (2024); Bentsen, Lars Ødegaard, Spatio-temporal wind speed forecasting using graph networks and novel Transformer architectures, Applied Energy, 333, (2023)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","23274662","9781728176055","","","English","Article","aip","","Scopus","2-s2.0-105013742239"
"A.E., Jaya Santhiyaa, A. E.; S., Shadhir Mohamed, S.; S., Shalini, S.; R.K., Meena, R. Kumari; T., Kalaiselvi, T.","Jaya Santhiyaa, A. E. (60054151200); Shadhir Mohamed, S. (60054471600); Shalini, S. (60053841100); Meena, R. Kumari (57214244199); Kalaiselvi, T. (60054151300)","60054151200; 60054471600; 60053841100; 57214244199; 60054151300","Real-Time Employee Attrition Monitoring and Recommendation System","2025","","","","","1444","1451","0","0","10.1109/ICIRCA65293.2025.11089919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013617616&doi=10.1109%2FICIRCA65293.2025.11089919&partnerID=40&md5=45ff52c018f51829d27dd8996ecc3489","Easwari Engineering College, Chennai, India","Jaya Santhiyaa, A. E., Department of Artificial Intelligence and Data Science, Easwari Engineering College, Chennai, India; Shadhir Mohamed, S., Department of Artificial Intelligence and Data Science, Easwari Engineering College, Chennai, India; Shalini, S., Department of Artificial Intelligence and Data Science, Easwari Engineering College, Chennai, India; Meena, R. Kumari, Department of Artificial Intelligence and Data Science, Easwari Engineering College, Chennai, India; Kalaiselvi, T., Department of Artificial Intelligence and Data Science, Easwari Engineering College, Chennai, India","Employee attrition is an important challenge that impacts organizational productivity, staff morale, and financial stability. Increased attrition rates result in higher costs of recruitment, workflow disturbances, and reduced efficiency overall. The paper presents a Real-Time Employee Attrition Monitoring and Recommendation System that combines rule-based scoring and AIanalysis through GPT-4 for forecasting and avoiding attrition risks. The system captures employee survey responses, assigns quantifiable scores along predetermined metrics such as job satisfaction, work-life balance, and career development, and processes structured scores through GPT-4 to create tailored recommendations for both employees and HR teams. A Firebase backend provides secure data storage, real-time updating, authentication, and visualization in the form of interactive dashboards, allowing HR teams to study workforce trends and undertake proactive retention measures. The results show that this hybrid model enhances early attrition detection by 30% over conventional approaches, enabling timely HR interventions and enhanced workforce retention. The performance of the system is measured on the basis of attrition prediction accuracy, response time, and intervention success rate. © 2025 Elsevier B.V., All rights reserved.","Authentication; Employee Attrition; Firebase; Gpt-4; Interactive Dashboards; Recommendation System; Rule-based Scoring; Workforce Management; Digital Storage; Employment; Human Resource Management; Information Systems; Information Use; Job Satisfaction; Employee Attrition; Financial Stability; Firebase; Gpt-4; Interactive Dashboard; Organisational; Real- Time; Rule Based; Rule-based Scoring; Workforce Management; Recommender Systems","Digital storage; Employment; Human resource management; Information systems; Information use; Job satisfaction; Employee attrition; Financial stability; Firebase; GPT-4; Interactive dashboard; Organisational; Real- time; Rule based; Rule-based scoring; Workforce management; Recommender systems","","","","Proceedings of International Conference on Data Science and Applications Icdsa 2021, (2025); Alduayj, Sarah S., Predicting Employee Attrition using Machine Learning, pp. 93-98, (2018); Yahia, Nesrine Ben, From Big Data to Deep Data to Support People Analytics for Employee Attrition Prediction, IEEE Access, 9, pp. 60447-60458, (2021); Al-Alawi, Adel Ismail, Predicting Employee Attrition Using Machine Learning: A Systematic Literature Review, pp. 526-530, (2024); Ariffa Begum, S. Ariffa, Predictive HR: Ensemble & Deep Learning Methods for Strategic Employee Retention, (2024); Al-Shammari, Minwir M., A Systematic Literature Review of Quantitative Models for Predicting Employee Attrition, (2024); Mansor, Norsuhada, Machine Learning for Predicting Employee Attrition, International Journal of Advanced Computer Science and Applications, 12, 11, pp. 435-445, (2021); Mhatre, Apurva, Predicting Employee Attrition along with Identifying High Risk Employees using Big Data and Machine Learning, pp. 269-276, (2020); Intelligent Systems and Applications Proceedings of the 2018 Intelligent Systems Conference Intellisys; Garg, Umang, Classification and Prediction of Employee Attrition Rate using Machine Learning Classifiers, pp. 608-613, (2024)","","Institute of Electrical and Electronics Engineers Inc.","","6th International Conference on Inventive Research in Computing Applications, ICIRCA 2025","","Coimbatore","210955","","9798331521424","","","English","Conference paper","Final","","Scopus","2-s2.0-105013617616"
"B., Plaut, Benjamin; K., Nguyen, Khanh; T., Trinh, Tu","Plaut, Benjamin (58903191800); Nguyen, Khanh (56970502700); Trinh, Tu (57813839900)","58903191800; 56970502700; 57813839900","Probabilities of Chat LLMs Are Miscalibrated but Still Predict Correctness on Multiple-Choice Q&A","2025","Transactions on Machine Learning Research","2025-August","","","","","0","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013190863&partnerID=40&md5=330252f7fdaf4cb360d1a5b39b33278b","University of California, Berkeley, Berkeley, United States","Plaut, Benjamin, Center for Human-Compatible AI, University of California, Berkeley, Berkeley, United States; Nguyen, Khanh, Center for Human-Compatible AI, University of California, Berkeley, Berkeley, United States; Trinh, Tu, Center for Human-Compatible AI, University of California, Berkeley, Berkeley, United States","We evaluate 15 large language models (LLMs) fine-tuned for chat on multiple-choice Q&A. Consistent with prior work, we find that their maximum softmax probabilities (MSPs) are consistently miscalibrated on multiple-choice Q&A. However, those MSPs might still encode useful uncertainty information. Specifically, we hypothesized that wrong answers would be associated with smaller MSPs compared to correct answers. Via rigorous statistical testing, we show that this hypothesis holds for models which perform well on the underlying Q&A task. We also find a strong direct correlation between Q&A accuracy and MSP correctness prediction, while finding no correlation between Q&A accuracy and calibration error. This suggests that within the current fine-tuning paradigm, we can expect correctness prediction but not calibration to improve as LLM capabilities progress. To demonstrate the utility of correctness prediction, we show that when models have the option to abstain, performance can be improved by selectively abstaining based on the MSP of the initial model response, using only a small amount of labeled data to choose the MSP threshold. © 2025 Elsevier B.V., All rights reserved.","","","","","This work was supported in part by a gift from Open Philanthropy to the Center for Human-Compatible AI (CHAI) at UC Berkeley. We would like to thank (in alphabetical order) Cassidy Laidlaw, Katie Kang, Peter Hase, and Yaodong Yu for helpful discussions and feedback.","AI Yi 6b Chat · Hugging Face, (2023); Llama 3 Model Card, (2024); Falcon 40b an Open Large Language Model with State of the Art Performance, (2023); Open Llm Leaderboard, (2023); Lessons from the Trenches on Reproducible Evaluation of Language Models, (2024); Teoria Statistica Delle Classi E Calcolo Delle Probabilita, (1936); Bradley, Andrew P., The use of the area under the ROC curve in the evaluation of machine learning algorithms, Pattern Recognition, 30, 7, pp. 1145-1159, (1997); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); First Token Probability Guided Rag for Telecom Question Answering, (2025); Chow, C. K., On Optimum Recognition Error and Reject Tradeoff, IEEE Transactions on Information Theory, 16, 1, pp. 41-46, (1970)","","Transactions on Machine Learning Research","","","","","","28358856","","","","English","Article","Final","","Scopus","2-s2.0-105013190863"
"H., Xue, Haochen; C., Liu, Chenghao; C., Zhang, Chong; Y., Chen, Yuxuan; A., Zong, Angxiao; Z., Wu, Zhaodong; Y., Li, Yulong; J., Liu, Jiayi; K., Liang, Kaiyu; Z., Lu, Zhixiang","Xue, Haochen (58481092500); Liu, Chenghao (59936768800); Zhang, Chong (58605687700); Chen, Yuxuan (59801181100); Zong, Angxiao (59936672200); Wu, Zhaodong (58509206600); Li, Yulong (59374687700); Liu, Jiayi (59936696400); Liang, Kaiyu (59348576000); Lu, Zhixiang (59067574100)","58481092500; 59936768800; 58605687700; 59801181100; 59936672200; 58509206600; 59374687700; 59936696400; 59348576000; 59067574100","LLM-Enhanced Feature Engineering for Multi-factor Electricity Price Predictions","2025","Communications in Computer and Information Science","2572 CCIS","","","89","100","0","0","10.1007/978-981-96-9986-5_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013049166&doi=10.1007%2F978-981-96-9986-5_8&partnerID=40&md5=23a53bebe178be862b041a60ef258293","Xi'an Jiaotong-Liverpool University, Suzhou, China; Columbia University, New York, United States; Tongji University, Shanghai, China","Xue, Haochen, School of AI and Advanced Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China; Liu, Chenghao, Tongji University, Shanghai, China; Zhang, Chong, School of AI and Advanced Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China; Chen, Yuxuan, Columbia University, New York, United States; Zong, Angxiao, School of AI and Advanced Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China; Wu, Zhaodong, School of AI and Advanced Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China; Li, Yulong, School of AI and Advanced Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China; Liu, Jiayi, School of AI and Advanced Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China; Liang, Kaiyu, School of AI and Advanced Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China; Lu, Zhixiang, School of AI and Advanced Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China","Accurately forecasting electricity price volatility is crucial for effective risk management and decision-making. Traditional forecasting models often fall short in capturing the complex, non-linear dynamics of electricity markets, particularly when external factors like weather conditions and market volatility are involved. These limitations hinder their ability to provide reliable predictions in markets with high volatility, such as the New South Wales (NSW) electricity market. To address these challenges, we introduce FAEP, a Feature-Augmented Electricity Price Prediction framework, FAEP leverages Large Language Models (LLMs) combined with advanced feature engineering to enhance prediction accuracy. By incorporating external features such as weather data and price volatility jumps, and utilizing Retrieval-Augmented Generation (RAG) for effective feature extraction, FAEP overcomes the shortcomings of traditional approaches. A hybrid XGBoost-LSTM model in FAEP further refines these augmented features, resulting in a more robust prediction framework. Experimental results demonstrate that FAEP achieves state-of-art (SOTA) performance compared to other electricity price prediction models in the Australian New South Wale electricity market, showcasing the efficiency of LLM-enhanced feature engineering and hybrid machine learning architectures. © 2025 Elsevier B.V., All rights reserved.","Electricity Price Prediction; Feature Engineering; Llm; Costs; Decision Making; Electric Industry; Meteorology; Power Markets; Prediction Models; Weather Forecasting; Electricity Price Prediction; Electricity Price Volatilities; Electricity Prices; Feature Engineerings; Forecasting Electricity; Language Model; Large Language Model; Multi-factor; New South Wales; Price Prediction; Risk Management","Costs; Decision making; Electric industry; Meteorology; Power markets; Prediction models; Weather forecasting; Electricity price prediction; Electricity price volatilities; Electricity prices; Feature engineerings; Forecasting electricity; Language model; Large language model; Multi-factor; New South Wales; Price prediction; Risk management","","","","undefined, (2018); Journal of Financial Econometrics, (2004); Time Series Analysisforecasting and Control, (1976); Journal of Advanced Studies in Finance, (2017); undefined, (2023); Diebold, Francis X., Comparing predictive accuracy, Journal of Business and Economic Statistics, 20, 1, pp. 134-144, (2002); Du, Baigang, Deep learning with long short-term memory neural networks combining wavelet transform and principal component analysis for daily urban water demand forecasting, Expert Systems with Applications, 171, (2021); Haugom, Erik, Forecasting spot price volatility using the short-term forward curve, Energy Economics, 34, 6, pp. 1826-1833, (2012); Heydari, Azim, Short-term electricity price and load forecasting in isolated power grids based on composite neural network and gravitational search optimization algorithm, Applied Energy, 277, (2020); First Conference on Language Modeling, (2024)","Huang, D.-S.; Zhang, C.; Zhang, Q.; Pan, Y.","Springer Science and Business Media Deutschland GmbH","International Neural Network Society and the National Science Foundation of China","21st International Conference on Intelligent Computing, ICIC 2025","","Ningbo","335459","18650937; 18650929","9789819671748; 9789819664610; 9783032026743; 9783032008831; 9783032026712; 9789819671779; 9783031949425; 9789819666874; 9783031936968; 9783031941207","","","English","Conference paper","Final","","Scopus","2-s2.0-105013049166"
"W., Kuryłek, Wojciech","Kuryłek, Wojciech (6506362067)","6506362067","Can Large Language Models Forecast Time Series of Earnings per Share? Case from Poland","2025","Eastern European Economics","","","","","","0","0","10.1080/00128775.2025.2534144","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012468483&doi=10.1080%2F00128775.2025.2534144&partnerID=40&md5=0f2e9fb72f18caf30dd84d75ae14bf65","Wydział Zarządzania Uniwersytetu Warszawskiego, Warsaw, Poland","Kuryłek, Wojciech, Wydział Zarządzania Uniwersytetu Warszawskiego, Warsaw, Poland","This research evaluates the predictive accuracy of the cutting-edge LAG-LLaMA Large Language Model for earnings forecasts of Warsaw Stock Exchange-listed firms, comparing it with a seasonal random walk benchmark. The study uses two methods: zero-shot generalization, where the model leverages extensive pre-trained data, and fine-tuning, where historical EPS data specifically train the model. While the seasonal random walk yielded the lowest error rates, fine-tuning the LAG-LLaMA model produced comparable results in terms of MAAPE metric. The fine-tuned LAG-LLaMA model achieves the lowest RMSE and MAE errors but performs statistically equivalent to the simpler seasonal random walk model. This conclusion is specific to the Polish market and the studied period. The findings suggest LAG-LLaMA’s adaptability for longer datasets, while the simpler random walk remains effective for shorter timeframes, especially in emerging markets like Poland. © 2025 Elsevier B.V., All rights reserved.","Earnings Per Share; Lag-llama; Large Language Model; Large Language Model Meta Ai; Llama; Llm; Seasonal Random Walk; Warsaw Stock Exchange","","","","","Abarbanell, Jeffery S., Fundamental analysis, future earnings, and stock prices, Journal of Accounting Research, 35, 1, pp. 1-24, (1997); Arxiv Preprint, (2023); Etemadi, Hossein, Earnings Per Share Forecast Using Extracted Rules from Trained Neural Network by Genetic Algorithm, Computational Economics, 46, 1, pp. 55-63, (2015); Efficient Training and Inference Techniques for Large Language Models Using Llama, (2024); Atiya, Amir F., An efficient stock market forecasting model using neural networks, IEEE International Conference on Neural Networks - Conference Proceedings, 4, pp. 2112-2115, (1997); Arxiv Preprint, (2023); Ball, Ryan T., Automated Earnings Forecasts: Beat Analysts or Combine and Conquer?, Management Science, 64, 10, pp. 4936-4952, (2018); Ball, Ray, SOME TIME SERIES PROPERTIES OF ACCOUNTING INCOME, Journal of Finance, 27, 3, pp. 663-681, (1972); Accounting Review, (1984); Bradshaw, Mark T., A re-examination of analysts' superiority over time-series forecasts of annual earnings, Review of Accounting Studies, 17, 4, pp. 944-968, (2012)","","Routledge","","","","","","15579298; 00128775","","","","English","Article","aip","","Scopus","2-s2.0-105012468483"
"R., Wang, Renjie; M., Sun, Minghui; L., Wang, Limin","Wang, Renjie (59187311700); Sun, Minghui (54795933200); Wang, Limin (57137061300)","59187311700; 54795933200; 57137061300","From news to trends: a financial time series forecasting framework with LLM-driven news sentiment analysis and selective state spaces","2025","Journal of Intelligent Information Systems","","","","","","0","0","10.1007/s10844-025-00971-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012401844&doi=10.1007%2Fs10844-025-00971-3&partnerID=40&md5=ab7eacf17eda5a1395818e2ca388c94e","Jilin University, Changchun, China; Jilin University, Changchun, China; Jilin University, Changchun, China; Jilin University, Changchun, China","Wang, Renjie, College of Software, Jilin University, Changchun, China, Jilin University, Changchun, China; Sun, Minghui, College of Computer Science and Technology, Jilin University, Changchun, China, Jilin University, Changchun, China; Wang, Limin, College of Computer Science and Technology, Jilin University, Changchun, China, Jilin University, Changchun, China","Stock price prediction is inherently challenging due to market volatility and the influence of external factors. Traditional forecasting methods primarily rely on historical price data, limiting their ability to capture market sentiment embedded in financial news. To address this limitation, we propose MambaMoE, a novel model that integrates historical stock prices with sentiment information extracted from financial news. Specifically, we fine-tune a DeepSeek-based large language model (LLM) for financial sentiment classification and incorporate the extracted sentiment information into our predictive framework. At the core of our approach is MambaMoE layer, which leverages the efficiency of state space models (SSMs) to model long-range dependencies while maintaining linear computational complexity, making it well-suited for financial time series forecasting. Additionally, the Mixture of Experts (MoE) mechanism improves the model’s ability to capture diverse market behaviors by dynamically selecting specialized experts based on stock data patterns. Experimental results demonstrate that MambaMoE outperforms LSTM-based models by 23.7% and Transformer-based models by 6.3%, highlighting its superior performance in short-term stock prediction. © 2025 Elsevier B.V., All rights reserved.","Llm; Mamba; Sentiment Analysis; Time Series Forecasting; Classification (of Information); Commerce; Costs; Electronic Trading; Financial Markets; Forecasting; State Space Methods; Time Series; Time Series Analysis; Financial News; Financial Time Series Forecasting; Language Model; Large Language Model; Mamba; Model-driven; Sentiment Analysis; State-space; Stock Price Prediction; Time Series Forecasting","Classification (of information); Commerce; Costs; Electronic trading; Financial markets; Forecasting; State space methods; Time series; Time series analysis; Financial news; Financial time series forecasting; Language model; Large language model; Mamba; Model-driven; Sentiment analysis; State-space; Stock price prediction; Time series forecasting","","","This study has been partially supported by Grant 20240101374JC and Shenzhen Science and Technology Program (JCYJ20230807150300001).","Ainslie, Joshua, GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints, pp. 4895-4901, (2023); Blackmamba Mixture of Experts for State Space Models, (2024); Chen, Qizhao, Stock Price Prediction Using LLM-Based Sentiment Analysis, pp. 4846-4853, (2024); Chen, Sian, TSMixer: An All-MLP Architecture for Time Series Forecasting, Transactions on Machine Learning Research, 2023, (2023); Cheng, Dawei, Financial time series forecasting with multi-modality graph neural network, Pattern Recognition, 121, (2022); Cho, Kyunghyun, Learning phrase representations using RNN encoder-decoder for statistical machine translation, pp. 1724-1734, (2014); Dai, Damai, DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models, Proceedings of the Annual Meeting of the Association for Computational Linguistics, 1, pp. 1280-1297, (2024); Deepseek R1 Incentivizing Reasoning Capability in Llms Via Reinforcement Learning, (2025); Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019); An Image is Worth 16x16 Words Transformers for Image Recognition at Scale, (2020)","","Springer","","","","","","09259902; 15737675","","JIISE","","English","Article","aip","","Scopus","2-s2.0-105012401844"
"W., Liang, Weixin; Y., Zhang, Yaohui; Z., Wu, Zhengxuan; H., Lepp, Haley; W., Ji, Wenlong; X., Zhao, Xuandong; H., Cao, Hancheng; S., Liu, Sheng; S., He, Siyu; Z., Huang, Zhi","Liang, Weixin (59638464900); Zhang, Yaohui (58954058200); Wu, Zhengxuan (57209060863); Lepp, Haley (57189950866); Ji, Wenlong (57310089600); Zhao, Xuandong (57552407600); Cao, Hancheng (57209896240); Liu, Sheng (59157685100); He, Siyu (59820874700); Huang, Zhi (57191036750)","59638464900; 58954058200; 57209060863; 57189950866; 57310089600; 57552407600; 57209896240; 59157685100; 59820874700; 57191036750","Quantifying large language model usage in scientific papers","2025","Nature Human Behaviour","","","","","","0","1","10.1038/s41562-025-02273-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012397263&doi=10.1038%2Fs41562-025-02273-8&partnerID=40&md5=b4001c647739fdd92679e52a32cac187","Stanford Engineering, Stanford, United States; Stanford Engineering, Stanford, United States; Stanford Graduate School of Education, Stanford, United States; Stanford University, Stanford, United States; UC Santa Barbara College of Engineering, Santa Barbara, United States; Goizueta Business School, Atlanta, United States; Stanford University, Stanford, United States; Stanford University, Stanford, United States","Liang, Weixin, Stanford Engineering, Stanford, United States; Zhang, Yaohui, Stanford Engineering, Stanford, United States; Wu, Zhengxuan, Stanford Engineering, Stanford, United States; Lepp, Haley, Stanford Graduate School of Education, Stanford, United States; Ji, Wenlong, Department of Statistics, Stanford University, Stanford, United States; Zhao, Xuandong, UC Santa Barbara College of Engineering, Santa Barbara, United States; Cao, Hancheng, Stanford Engineering, Stanford, United States, Goizueta Business School, Atlanta, United States; Liu, Sheng, Department of Biomedical Data Science, Stanford University, Stanford, United States; He, Siyu, Department of Biomedical Data Science, Stanford University, Stanford, United States; Huang, Zhi, Department of Biomedical Data Science, Stanford University, Stanford, United States","Scientific publishing is the primary means of disseminating research findings. There has been speculation about how extensively large language models (LLMs) are being used in academic writing. Here we conduct a systematic analysis across 1,121,912 preprints and published papers from January 2020 to September 2024 on arXiv, bioRxiv and Nature portfolio journals, using a population-level framework based on word frequency shifts to estimate the prevalence of LLM-modified content over time. Our findings suggest a steady increase in LLM usage, with the largest and fastest growth estimated for computer science papers (up to 22%). By comparison, mathematics papers and the Nature portfolio showed lower evidence of LLM modification (up to 9%). LLM modification estimates were higher among papers from first authors who post preprints more frequently, papers in more crowded research areas and papers of shorter lengths. Our findings suggest that LLMs are being broadly used in scientific writing. © 2025 Elsevier B.V., All rights reserved.","","","","","We thank D. A. McFarland, D. Jurafsky, Y. Yin, Z. Izzo, X. V. Lin, L. Chen and H. Ye for their helpful comments and discussions. J.Z. is supported by the National Science Foundation (grant nos. CCF 1763191 and CAREER 1942926), the US National Institutes of Health (grant nos. P30AG059307 and U01MH098953) and grants from the Silicon Valley Foundation and the Chan-Zuckerberg Initiative. H.L. is supported by the National Science Foundation (grant nos. 2244804 and 2022435) and the Stanford Institute for Human-Centered Artificial Intelligence (HAI).","Cybernews, (2023); Popular Science, (2024); Papers and Peer Reviews with Evidence of Chatgpt Writing, (2024); Nature, (2023); Conroy, Gemma, How ChatGPT and other AI tools could disrupt scientific publishing, Nature, 622, 7982, pp. 234-236, (2023); Verge, (2023); Liang, Weixing, GPT detectors are biased against non-native English writers, Patterns, 4, 7, (2023); Neurips Safe Generative AI Workshop, (2025); Forty First International Conference on Machine Learning, (2024); Icml, (2023)","","Nature Research","","","","","","23973374","","","","English","Article","aip","","Scopus","2-s2.0-105012397263"
"S., Alvarez-Diez, Susana; J.S., Baixauli-Soler, Juan Samuel; A., Kondratenko, Anna; G., Lozano-Reina, Gabriel","Alvarez-Diez, Susana (35880866800); Baixauli-Soler, Juan Samuel (35271056700); Kondratenko, Anna (58237768800); Lozano-Reina, Gabriel (57195230713)","35880866800; 35271056700; 58237768800; 57195230713","Intraday Stock Prediction Using Sentiment Analysis: Evidence from Dividend Announcements","2025","Journal of Behavioral Finance","","","","","","0","0","10.1080/15427560.2025.2538879","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012281629&doi=10.1080%2F15427560.2025.2538879&partnerID=40&md5=53d5b7b56eea9089851c6bee965a8d37","Universidad de Murcia, Murcia, Spain","Alvarez-Diez, Susana, Universidad de Murcia, Murcia, Spain; Baixauli-Soler, Juan Samuel, Universidad de Murcia, Murcia, Spain; Kondratenko, Anna, Universidad de Murcia, Murcia, Spain; Lozano-Reina, Gabriel, Universidad de Murcia, Murcia, Spain","This study explores whether sentiment extracted from financial news using large language models (LLMs) can predict abnormal intraday stock returns following dividend announcements. Drawing on 4,682 news items linked to 1,258 announcements from 394 S&P 500 companies (January 2023–January 2024), we use ChatGPT to extract sentiment polarity scores and we apply different models to forecast cumulative abnormal returns (CARs) in 30-minute intervals. Our findings reveal that sentiment–especially when captured immediately after news releases–has significant predictive power over intraday price movements. Strategies based on ChatGPT-derived sentiment consistently outperform benchmark models, particularly within the first two hours of trading. These results remain robust across alternative specifications and placebo tests, highlighting the value of LLMs for real-time market prediction. This research advances the literature on sentiment analysis and behavioral finance by linking emotion-driven news interpretation to high-frequency trading performance. © 2025 Elsevier B.V., All rights reserved.","Financial News; Intraday Trading; Investment Strategies; Market Reaction; Sentiment Analysis","","","","","Aldi, Febri, STANDARDSCALER'S POTENTIAL IN ENHANCING BREAST CANCER ACCURACY USING MACHINE LEARNING, Journal of Applied Engineering and Technological Science, 5, 1, pp. 401-413, (2023); Alvarez-Diez, Susana, Dividend announcement and the value of sentiment analysis, Journal of Management Analytics, 11, 2, pp. 161-181, (2024); Azar, Pablo Daniel, The wisdom of twitter crowds: Predicting stock market reactions to FOMC meetings via twitter feeds, Journal of Portfolio Management, 42, 5, pp. 123-134, (2016); Baker, Malcolm P., Investor sentiment and the cross-section of stock returns, Journal of Finance, 61, 4, pp. 1645-1680, (2006); Banerjee, Abhijit V., A simple model of heed behavior, Quarterly Journal of Economics, 107, 3, pp. 797-817, (1992); Bell Journal of Economics, (1979); Bikhchandani, Sushil, A theory of fads, fashion, custom, and cultural change as informational cascades, Journal of Political Economy, 100, 5, pp. 992-1026, (1992); Birjali, Marouane, A comprehensive survey on sentiment analysis: Approaches, challenges and trends, Knowledge-Based Systems, 226, (2021); Bollen, Johan, Twitter mood predicts the stock market, Journal of Computational Science, 2, 1, pp. 1-8, (2011); Chatgpt Stock Market Predictability and Links to the Macroeconomy, (2023)","","Institute of Behavioral Finance","","","","","","15427560; 15427579","","","","English","Article","aip","","Scopus","2-s2.0-105012281629"
"S., Bie, Siyu; G., Feng, Guanhao; N., Guo, Naixin; J., He, Jingyu","Bie, Siyu (59327885000); Feng, Guanhao (57194340199); Guo, Naixin (59485736000); He, Jingyu (57193993776)","59327885000; 57194340199; 59485736000; 57193993776","Can news predict firm bankruptcy?","2025","Journal of Financial Markets","","","101002","","","0","0","10.1016/j.finmar.2025.101002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012228582&doi=10.1016%2Fj.finmar.2025.101002&partnerID=40&md5=445467bf06ed40322909b2be55a5d080","East China Normal University, Shanghai, China; City University of Hong Kong, Hong Kong, Hong Kong","Bie, Siyu, East China Normal University, Shanghai, China, City University of Hong Kong, Hong Kong, Hong Kong; Feng, Guanhao, City University of Hong Kong, Hong Kong, Hong Kong; Guo, Naixin, City University of Hong Kong, Hong Kong, Hong Kong; He, Jingyu, City University of Hong Kong, Hong Kong, Hong Kong","We examine whether real-time business news predicts firm bankruptcy. Using full-text daily articles from the Dow Jones Newswires database, we generate firm-level predictors with ChatGPT and benchmark against FinBERT and dictionary-based models. ChatGPT-based variables outperform alternatives, with sentiment scores showing predictive power across horizons. Full-text news significantly enhance predictive accuracy over headlines. News-based measures add explanatory power beyond financial variables. Finally, we show that news captures timely information on macroeconomic conditions relevant to bankruptcy prediction, such as VIX, real GDP growth, and recession probability. © 2025 Elsevier B.V., All rights reserved.","Bankruptcy Prediction; Chatgpt; Generative Ai; News Data; Sentiment","","","","We thank two anonymous referees, the editor (Liyan Yang), and Gustavo Schwenkler, Zhan Shi, Junbo Wang, Chunchi Wu, and seminar participants at the City University of Hong Kong for constructive comments and suggestions. Bie is at East China Normal University and City University of Hong Kong. Feng, Guo, and He are at City University of Hong Kong. He acknowledges financial support from the Hong Kong Research Grants Council ( ECS21504921 , GRF11507022 , GRF11509224 ), and the Natural Science Foundation of China ( NSFC72403214 ) and NSFC/RGC Joint Research Scheme ( N_CityU105/21 ). Feng acknowledges financial support from the Hong Kong Research Grants Council ( GRF11502721 , GRF11502023 ) and the Natural Science Foundation of China ( NSFC72203190 ). Bie acknowledges financial support from the National Natural Science Foundation of China ( NSFC12271168 ). Bie, He, and Feng are partially supported by the InnoHK initiative of the Innovation and Technology Commission of the HKSAR and the Laboratory for AI-Powered Financial Technologies.","Alanis, Emmanuel, Benchmarking machine learning models to predict corporate bankruptcy, Journal of Credit Risk, 19, 2, pp. 77-110, (2023); Altman, Edward I., FINANCIAL RATIOS, DISCRIMINANT ANALYSIS AND THE PREDICTION OF CORPORATE BANKRUPTCY, Journal of Finance, 23, 4, pp. 589-609, (1968); Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Journal of Accounting Research, (1966); Journal of Accounting Research, (1968); Bharath, Sreedhar T., Forecasting default with the Merton distance to default model, Review of Financial Studies, 21, 3, pp. 1339-1369, (2008); Breiman, Leo, Random forests, Machine Learning, 45, 1, pp. 5-32, (2001); undefined, (2024); Ghost in the Machine Generating Beliefs with Large Language Models, (2023); Bybee, Leland, Business News and Business Cycles, Journal of Finance, 79, 5, pp. 3105-3147, (2024)","","Elsevier B.V.","","","","","","13864181","","","","English","Article","aip","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-105012228582"
"W., Feng, Wanyong; P., Tran, Peter; S.G., Sireci, Stephen G.; A.S., Lan, Andrew S.","Feng, Wanyong (58339215500); Tran, Peter (59714675600); Sireci, Stephen G. (6701491909); Lan, Andrew S. (55967012900)","58339215500; 59714675600; 6701491909; 55967012900","Reasoning and Sampling-Augmented MCQ Difficulty Prediction via LLMs","2025","Lecture Notes in Computer Science","15880 LNAI","","","31","45","0","0","10.1007/978-3-031-98459-4_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012022154&doi=10.1007%2F978-3-031-98459-4_3&partnerID=40&md5=05343542bcbf82a8ba22b73fa4dc916e","University of Massachusetts Amherst, Amherst, United States","Feng, Wanyong, University of Massachusetts Amherst, Amherst, United States; Tran, Peter, University of Massachusetts Amherst, Amherst, United States; Sireci, Stephen G., University of Massachusetts Amherst, Amherst, United States; Lan, Andrew S., University of Massachusetts Amherst, Amherst, United States","The difficulty of multiple-choice questions (MCQs) is a crucial factor for educational assessments. Predicting MCQ difficulty is challenging since it requires understanding both the complexity of reaching the correct option and the plausibility of distractors, i.e., incorrect options. In this paper (This work is partially supported by Renaissance Philanthropy via the learning engineering virtual institute (LEVI) and NSF grants 2118706, 2237676, and 2341948.), we propose a novel, two-stage method to predict the difficulty of MCQs. First, to better estimate the complexity of each MCQ, we use large language models (LLMs) to augment the reasoning steps required to reach each option. We use not just the MCQ itself but also these reasoning steps as input to predict the difficulty. Second, to capture the plausibility of distractors, we sample knowledge levels from a distribution to account for variation among students responding to the MCQ. This setup, inspired by item response theory (IRT), enable us to estimate the likelihood of students selecting each (both correct and incorrect) option. We align these predictions with their ground truth values, using a Kullback-Leibler (KL) divergence-based regularization objective, and use estimated likelihoods to predict MCQ difficulty. We evaluate our method on two real-world math MCQ and response datasets with ground truth difficulty values estimated using IRT. Experimental results show that our method outperforms all baselines, up to a 28.3% reduction in mean squared error and a 34.6% improvement in the coefficient of determination. We also qualitatively discuss how our novel method results in higher accuracy in predicting MCQ difficulty. © 2025 Elsevier B.V., All rights reserved.","Large Language Models; Multiple Choice Questions; Question Difficulty Prediction; Student Selection Likelihood; Engineering Education; Forecasting; Learning Systems; Prediction Models; Students; Educational Assessment; Ground Truth; Item Response Theory; Language Model; Large Language Model; Multiple-choice Questions; Question Difficulty Prediction; Student Selection Likelihood; Student Selections; Virtual Institutes; Mean Square Error","Engineering education; Forecasting; Learning systems; Prediction models; Students; Educational assessment; Ground truth; Item response theory; Language model; Large language model; Multiple-choice questions; Question difficulty prediction; Student selection likelihood; Student selections; Virtual institutes; Mean square error","","","","600 V Power Device Technologies for Highly Efficient Power Supplies º in 2021 23rd European Conference on Power Electronics and Applications; International Journal of Artificial Intelligence in Education, (2023); Benedetto, Luca, On the application of Transformers for estimating the difficulty of Multiple-Choice Questions from text, pp. 147-157, (2021); Introducing A Framework to Assess Newly Created Questions with Natural Language Processing; Benedetto, Luca, R2DE: A NLP approach to estimating IRT parameters of newly generated questions, ACM International Conference Proceeding Series, pp. 412-421, (2020); Chicco, Davide, The coefficient of determination R-squared is more informative than SMAPE, MAE, MAPE, MSE and RMSE in regression analysis evaluation, PeerJ Computer Science, 7, pp. 1-24, (2021); Choi, Innchull, Predicting the Difficulty of EFL Tests Based on Corpus Linguistic Features and Expert Judgment, Language Assessment Quarterly, 17, 1, pp. 18-42, (2020); Proceedings of the 19th Workshop on Innovative Use of Nlp for Building Educational Applications Bea 2024, (2024); Standards for Educational and Psychological Testing, (2013); Feng, Wanyong, Balancing Test Accuracy and Security in Computerized Adaptive Testing, Lecture Notes in Computer Science, 13916 LNAI, pp. 708-713, (2023)","Cristea, A.I.; Walker, E.; Lu, Y.; Santos, O.C.; Isotani, S.","Springer Science and Business Media Deutschland GmbH","Google#Gates Foundation#Hewlett Packard Enterprise#Eedi#VitalSource# duolingo english test#Springer#","26th International Conference on Artificial Intelligence in Education, AIED 2025","","Palermo","335679","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference paper","Final","","Scopus","2-s2.0-105012022154"
"","","","Proceedings - 2025 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology, USBEREIT 2025","2025","","","","","","","443","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011288552&partnerID=40&md5=47f94744636aac046add405f3f6f814c","","","The proceedings contain 109 papers. The topics discussed include: improving the security of network services by changing the transport protocol port; high sensitivity and compact microwave sensor based on metamaterial and coupled DSRR for iron content in lubricating oils; from data to insights: LightGBM approach in DGA family classification; predicting agricultural commodity stock prices: a comparison of statistical methods and machine learning algorithms; development of an automated system for generating assignments in mathematical disciplines using LLMs; time series forecasting method based on the ensemble of finite state machines; and powerful microwave pulse radio transmitter of coherent aerological radar. © 2025 Elsevier B.V., All rights reserved.","","","","","","","Korotkov, A.N.; Khazankin, G.R.","Institute of Electrical and Electronics Engineers Inc.","","2025 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology, USBEREIT 2025","","Yekaterinburg","210170","","9798350392708","","","English","Conference review","Final","","Scopus","2-s2.0-105011288552"
"D., Qin, Dayu; Y., Yi, Yan; E.E., Kuruoǧlu, Ercan Engin","Qin, Dayu (59259685600); Yi, Yan (60008927000); Kuruoǧlu, Ercan Engin (6701914177)","59259685600; 60008927000; 6701914177","Graph LLM-Based Portfolio Management Algorithm","2025","","","","","157","160","0","0","10.1109/CAI64502.2025.00032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011266311&doi=10.1109%2FCAI64502.2025.00032&partnerID=40&md5=6d0fbc34f242f4c68f2f3f3092ba1546","Tsinghua University, Beijing, China; Tsinghua University, Beijing, China","Qin, Dayu, Institute of Data and Information, Tsinghua University, Beijing, China; Yi, Yan, Institute of Data and Information, Tsinghua University, Beijing, China, Tsinghua University, Beijing, China; Kuruoǧlu, Ercan Engin, Institute of Data and Information, Tsinghua University, Beijing, China","This paper explores the integration of large language models (LLMs) with graph-based financial networks for quantitative trading. By leveraging GPT-3 for stock network return predictions, we develop a Graph-LLM trading strategy. Experimental results demonstrate that the proposed strategy achieves lower volatility and more stable performance than traditional baselines. Our findings highlight the potential of combining LLMs with financial complex networks to enhance quantitative trading strategies. © 2025 Elsevier B.V., All rights reserved.","Financial Complex Networks; Graph-based Trading Strategies; Large Language Models; Quantitative Trading; Commerce; Decentralized Finance; Electronic Trading; Financial Markets; Graph Algorithms; Graphic Methods; Investments; Financial Complex Network; Financial Networks; Graph-based; Graph-based Trading Strategy; Language Model; Large Language Model; Model-based Opc; Portfolio Managements; Quantitative Trading; Trading Strategies; Complex Networks","Commerce; Decentralized finance; Electronic trading; Financial markets; Graph algorithms; Graphic methods; Investments; Financial complex network; Financial networks; Graph-based; Graph-based trading strategy; Language model; Large language model; Model-based OPC; Portfolio managements; Quantitative trading; Trading strategies; Complex networks","","","This work is supported by the Tsinghua Shenzhen International Graduate School Start-up fund under Grant QD2022024C, Shenzhen Science and Technology Innovation Commission under Grant JCYJ20220530143002005, and Shenzhen Ubiquitous Data Enabling Key Lab under Grant ZDSYS20220527171406015.","Zhong, Xingyu, Large Language Model for Dynamic Strategy Interchange in Financial Markets, pp. 306-312, (2024); Zhang, Wentao, A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 4314-4325, (2024); Qin, Dayu, Graph Learning Based Financial Market Crash Identification and Prediction, pp. 650-651, (2024); IEEE Transactions on Signal Processing, (2019); Hong, Junping, Multivariate Time Series Forecasting with GARCH Models on Graphs, IEEE Transactions on Signal and Information Processing over Networks, 9, pp. 557-568, (2023); Peng, Changran, Adaptive Graph Normalized Sign Algorithm, pp. 102-103, (2024); Yan, Yi, Adaptive sign algorithm for graph signal processing, Signal Processing, 200, (2022); Tumminello, Michele, A tool for filtering information in complex systems, Proceedings of the National Academy of Sciences of the United States of America, 102, 30, pp. 10421-10426, (2005); Qin, Dayu, LLM-based Online Prediction of Time-varying Graph Signals, Proceedings of the AAAI Conference on Artificial Intelligence, 39, 28, pp. 29472-29474, (2025); Llm Online Spatial Temporal Signal Reconstruction Under Noise, (2024)","","Institute of Electrical and Electronics Engineers Inc.","IEEE; IEEE Computational Intelligence Society (CIS); IEEE Computer Society (CS); IEEE Signal Processing Society (SPS); IEEE Systems, Man, and Cybernetics Society (SMC)","3rd IEEE Conference on Artificial Intelligence, CAI 2025","","Santa Clara; CA; Hyatt Regency in Santa Clara","210217","","9798331524005","","","English","Conference paper","Final","","Scopus","2-s2.0-105011266311"
"M., Kmak, Mateusz; K., Chmurzyński, Kamil; K., Matejuk, Kamil; P., Kotzbach, Paweł; J., Kocoń, Jan","Kmak, Mateusz (60002521800); Chmurzyński, Kamil (60003439500); Matejuk, Kamil (60002153600); Kotzbach, Paweł (60002521900); Kocoń, Jan (55345399800)","60002521800; 60003439500; 60002153600; 60002521900; 55345399800","Predicting Stock Prices with ChatGPT-Annotated Reddit Sentiment: Hype or Reality?","2025","Lecture Notes in Computer Science","15909 LNCS","","","307","322","0","0","10.1007/978-3-031-97564-6_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010828259&doi=10.1007%2F978-3-031-97564-6_24&partnerID=40&md5=1788ebe27a11dd982d69bac9989d454c","Politechnika Wrocławska, Wroclaw, Poland","Kmak, Mateusz, Department of Artificial Intelligence, Politechnika Wrocławska, Wroclaw, Poland; Chmurzyński, Kamil, Department of Artificial Intelligence, Politechnika Wrocławska, Wroclaw, Poland; Matejuk, Kamil, Department of Artificial Intelligence, Politechnika Wrocławska, Wroclaw, Poland; Kotzbach, Paweł, Department of Artificial Intelligence, Politechnika Wrocławska, Wroclaw, Poland; Kocoń, Jan, Department of Artificial Intelligence, Politechnika Wrocławska, Wroclaw, Poland","The surge of retail investor activity on social media, exemplified by the 2021 GameStop short squeeze, raised questions about the influence of online sentiment on stock prices. This paper explores whether sentiment derived from social media discussions can meaningfully predict stock market movements. We focus on Reddit’s r/wallstreetbets and analyze sentiment related to two companies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment’s role, we employ two existing text-based sentiment analysis methods and introduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model designed to better interpret the informal language and emojis prevalent in social media discussions. We use correlation and causality metrics to determine these models’ predictive power. Surprisingly, our findings suggest that social media sentiment has only a weak correlation with stock prices. At the same time, simpler metrics, such as the volume of comments and Google search trends, exhibit stronger predictive signals. These results highlight the complexity of retail investor behavior and suggest that traditional sentiment analysis may not fully capture the nuances of market-moving online discussions. © 2025 Elsevier B.V., All rights reserved.","Chatgpt; Sentiment; Social Media; Stock Market; Commerce; Costs; Data Mining; Electronic Trading; Investments; Sales; Sentiment Analysis; Social Networking (online); Analysis Method; Chatgpt; Model Predictive; Predictive Power; Sentiment; Simple Metrics; Social Media; Stock Price; Weak Correlation; Financial Markets","Commerce; Costs; Data mining; Electronic trading; Investments; Sales; Sentiment analysis; Social networking (online); Analysis method; ChatGPT; Model predictive; Predictive power; Sentiment; Simple metrics; Social media; Stock price; Weak correlation; Financial markets","","","Financed by: (1) the National Science Centre, Poland (2021/41/B/ST6/04471, JK); (2) CLARIN ERIC (2024\u20132026), funded by the Polish Minister of Science (agreement no. 2024/WK/01); (3) CLARIN-PL, the European Regional Development Fund, FENG programme (FENG.02.04-IP.040004/24); (4) statutory funds of the Department of Artificial Intelligence, Wroclaw Tech; (5) the Polish Ministry of Education and Science (\u201CInternational Projects Co-Funded\u201D pro-gramme); (6) the European Union, Horizon Europe (grant no. 101086321, OMINO); (7) the EU project \u201CDARIAH-PL\u201D, under investment A2.4.1 of the National Recovery and Resilience Plan. The views expressed are those of the authors and do not necessarily reflect those of the EU or the European Research Executive Agency.","Anand, Abhinav, The role of Reddit in the GameStop short squeeze, Economics Letters, 211, (2022); Betzer, André, How online discussion board activity affects stock trading: the case of GameStop, Financial Markets and Portfolio Management, 36, 4, pp. 443-472, (2022); Rep, (2022); Econometrica, (1969); Daniel, Kent D., Investor psychology in capital markets: Evidence and policy implications, Journal of Monetary Economics, 49, 1, pp. 139-209, (2002); Rise of Reddit how Social Media Affects Retail Investors and Short Sellers Roles in Price Discovery, (2021); Broadstock, David C., Social-media and intraday stock returns: The pricing power of sentiment, Finance Research Letters, 30, pp. 116-123, (2019); Campbell, Gareth, The role of the media in a bubble, Explorations in Economic History, 49, 4, pp. 461-481, (2012); Gawron, Karol, Deep Neural Language-agnostic Multi-task Text Classifier, IEEE International Conference on Data Mining Workshops, ICDMW, 2021-December, pp. 136-142, (2021); Lyócsa, Štefan, YOLO trading: Riding with the herd during the GameStop episode, Finance Research Letters, 46, (2022)","Paszynski, M.; Barnard, A.S.; Zhang, Y.J.","Springer Science and Business Media Deutschland GmbH","","Workshops on Computational Science, which were co-organized with the 25th International Conference on Computational Science, ICCS 2025","","Singapore","335009","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference paper","Final","","Scopus","2-s2.0-105010828259"
"Y., Zhou, Yi","Zhou, Yi (55796971300)","55796971300","Using Generative AI to predict the weather impact on future stock returns","2025","Review of Quantitative Finance and Accounting","","","","","","0","0","10.1007/s11156-025-01437-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010649402&doi=10.1007%2Fs11156-025-01437-x&partnerID=40&md5=f95a6252f23d277903a01e50e3b33203","San Francisco State University, San Francisco, United States","Zhou, Yi, Department of Finance, San Francisco State University, San Francisco, United States","This study explores the use of Generative AI, specifically OpenAI’s ChatGPT, for forecasting the impacts of severe weather events on stock returns. Employing prompts that assess textual weather descriptions, ChatGPT, a powerful generative AI large language model (LLM), provides predictions incorporated into econometric models. Results show that when ChatGPT forecasts negative stock impacts from storms, larger, more profitable firms with lower leverage and higher liquidity experience lower subsequent returns, suggesting investor underreaction to weather risk. ChatGPT’s predictive abilities are stronger during favorable economic conditions like uptrends, low volatility, and robust employment growth, implying investor underreaction amid bullish sentiment. © 2025 Elsevier B.V., All rights reserved.","Chatgpt; Generative Ai; Large Language Model (llm); Stock Returns; Weather Risk","","","","","Addoum, Jawad M., Temperature shocks and industry earnings news, Journal of Financial Economics, 150, 1, pp. 1-45, (2023); Bartram, Söhnke M., Real effects of climate policy: Financial constraints and spillovers, Journal of Financial Economics, 143, 2, pp. 668-696, (2022); Unusual Financial Communication Evidence from Chatgpt Earnings Calls and the Stock Market, (2024); Bertomeu, Jeremy, The impact of generative AI on information processing: Evidence from the ban of ChatGPT in Italy, Journal of Accounting and Economics, 80, 1, (2025); Large Language Models and Financial Market Sentiment, (2023); Expected Returns and Large Language Models, (2022); Chatgpt and Deepseek can They Predict the Stock Market and Macroeconomy, (2025); Temperature Sensitivity Mispricing and Predictable Returns, (2023); Ai Powered Trading Algorithmic Collusion and Price Efficiency, (2024); Engle, Robert F., Hedging climate change news, Review of Financial Studies, 33, 3, pp. 1184-1216, (2020)","","Springer","","","","","","0924865X; 15737179","","","","English","Article","aip","","Scopus","2-s2.0-105010649402"
"K., van der Leij, Koen; G., Manias, George; Y., Leung, Yikkiu; W.J., Van den Heuvel, W. J.","van der Leij, Koen (59985058400); Manias, George (57217107959); Leung, Yikkiu (59841401200); Van den Heuvel, W. J. (7005472245)","59985058400; 57217107959; 59841401200; 7005472245","Comparative Analysis and Evaluation of SLMs and LLMs for Stock Price Movement Prediction","2025","IFIP Advances in Information and Communication Technology","758 IFIPAICT","","","284","298","0","0","10.1007/978-3-031-96235-6_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010217438&doi=10.1007%2F978-3-031-96235-6_21&partnerID=40&md5=04d8359c28ffc3f6cdaff86b8e6161ba","Tilburg University, Tilburg, Netherlands","van der Leij, Koen, Tilburg University, Tilburg, Netherlands; Manias, George, Tilburg University, Tilburg, Netherlands; Leung, Yikkiu, Tilburg University, Tilburg, Netherlands; Van den Heuvel, W. J., Tilburg University, Tilburg, Netherlands","This paper investigates the performance disparities between Small Language Models (SLMs) and Large Language Models (LLMs) in predicting stock price movements using data from two different datasets containing news articles and tweets. The study emphasizes the potential of SLMs as a more accessible and resource-efficient alternative to LLMs, enabling local and in-house deployment. Critical gaps are addressed, including the lack of direct price movement predictions, the utilization and comparison of State-of-the-Art (SotA) models, and the integration of diverse data sources. The research employed a fundamental trading strategy based on predicted stock price movement as the sole trading signal. The Phi-2 model, fine-tuned with Quantized Low-Rank Adaptation (QLoRA) on consumer-grade hardware, was compared with GPT-4, serving as a SotA benchmark. Performance was evaluated using accuracy, precision, recall, and F1-score. The results indicate that the fine-tuned SML (Phi-2) outperformed the LLM (GPT-4), albeit by a small margin, demonstrating the potential of a trained SML over a general LLM. © 2025 Elsevier B.V., All rights reserved.","Algorithmic Trading; Artificial Intelligence; Large Language Models; Small Language Models; Stock Price Prediction; Benchmarking; Commerce; Computation Theory; Costs; Electronic Trading; Financial Markets; Forecasting; Information Management; Information Systems; Information Use; Large Datasets; Prediction Models; Algorithmic Trading; Comparative Analyzes; Language Model; Large Language Model; Performance; Small Language Model; State Of The Art; Stock Price Movements; Stock Price Prediction; Artificial Intelligence","Benchmarking; Commerce; Computation theory; Costs; Electronic trading; Financial markets; Forecasting; Information management; Information systems; Information use; Large datasets; Prediction models; Algorithmic trading; Comparative analyzes; Language model; Large language model; Performance; Small language model; State of the art; Stock price movements; Stock price prediction; Artificial intelligence","","","","undefined; undefined; Awan, Mazhar Javed, Social Media and Stock Market Prediction: A Big Data Approach, Computers, Materials and Continua, 67, 2, pp. 2569-2583, (2021); E A Language Models are Few Shot Learners, (2020); undefined; Open Science Foundation, (2023); Ml Energy Leaderboard, (2023); Can Large Language Models Beat Wall Street Unveiling the Potential of Ai in Stock Selection, (2024); E A Textbooks are all You Need, (2023); Llm Perf Leaderboard, (2023)","Maglogiannis, I.; Iliadis, L.; Papaleonidas, A.; Andreou, A.","Springer Science and Business Media Deutschland GmbH","","21st IFIP WG 12.5 International Conference on Artificial Intelligence Applications and Innovations, AIAI 2025","","Limassol","334209","1868422X; 18684238","9783032007766; 9783031962301; 9783031949234; 9783031971143; 9783031962387; 9783031965210; 9780387291215; 9783319900223; 9783319162737; 1402080697","","","English","Conference paper","Final","","Scopus","2-s2.0-105010217438"
"R., Saqur, Raeid; A., Kratsios, Anastasis; F., Krach, Florian; Y., Limmer, Yannick; J.J., Tian, Jacob Junqi; J., Willes, John; B.N., Horvath, Blanka N.; F., Rudzicz, Frank","Saqur, Raeid (57208671498); Kratsios, Anastasis (57214886865); Krach, Florian (57215674195); Limmer, Yannick (57327669700); Tian, Jacob Junqi (58484605700); Willes, John (56960634000); Horvath, Blanka N. (57191824923); Rudzicz, Frank (24072071000)","57208671498; 57214886865; 57215674195; 57327669700; 58484605700; 56960634000; 57191824923; 24072071000","FILTERED NOT MIXED: FILTERING-BASED ONLINE GATING FOR MIXTURE OF LARGE LANGUAGE MODELS","2025","","","","","31568","31601","0","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010209602&partnerID=40&md5=b1ab607d8838c7467bbf3cae61672951","Oxford-Man Institute of Quantitative Finance, Oxford, United Kingdom; University of Toronto, Toronto, Canada; McMaster University, Hamilton, Canada; Vector Institute, Toronto, Canada; Dalhousie University, Halifax, Canada; ETH Zürich, Zurich, Switzerland","Saqur, Raeid, University of Toronto, Toronto, Canada, Vector Institute, Toronto, Canada; Kratsios, Anastasis, Department of Mathematics, McMaster University, Hamilton, Canada, Vector Institute, Toronto, Canada; Krach, Florian, Department of Mathematics, ETH Zürich, Zurich, Switzerland; Limmer, Yannick, Department of Mathematics, Oxford-Man Institute of Quantitative Finance, Oxford, United Kingdom; Tian, Jacob Junqi, Vector Institute, Toronto, Canada; Willes, John, Vector Institute, Toronto, Canada; Horvath, Blanka N., Department of Mathematics, Oxford-Man Institute of Quantitative Finance, Oxford, United Kingdom; Rudzicz, Frank, Vector Institute, Toronto, Canada, Faculty of Computer Science, Dalhousie University, Halifax, Canada","We propose MoE-F - a formalized mechanism for combining N pre-trained expert Large Language Models (LLMs) in online time-series prediction tasks. MoE-F adaptively forecasts the optimal weighting of LLM predictions at each time step by leveraging the conditional information in each expert's running performance, enabling the best combination of experts for the next step prediction. Diverging from static (learned) Mixture of Experts (MoE) methods, our approach employs time-adaptive stochastic filtering techniques to combine experts. By framing the expert selection problem as a finite state-space, continuous-time Hidden Markov model (HMM), we can leverage the Wonham-Shiryaev filter. Our approach first constructs N parallel filters corresponding to each N individual LLMs. Each filter proposes its best combination of LLMs, given the information that they have access to. Subsequently, the N filter outputs are optimally aggregated to maximize their robust predictive power, and this update is computed efficiently via a closed-form expression, thus generating our ensemble predictor. Our contributions are: (I) the MoE-F algorithm - deployable as a plug-and-play filtering harness over any heterogenous mixture of LLMs or specialized models, (II) theoretical optimality guarantees of the proposed filtering-based gating algorithm (via optimality guarantees for its parallel Bayesian filtering and its robust aggregation steps), and (III) empirical evaluation and ablative results using state of the art foundational and MoE LLMs on a real-world Financial Market Movement task based on streaming news where MoE-F attains a 17% absolute and 48.5% relative F1-score improvement over the best performing individual LLM expert. Further, we provide empirical evidence of substantial performance gains with MoE-F over specialized models in the long-horizon time-series forecasting domain using electricity-grid datasets. Supplementary materials available at: https://github.com/raeidsaqur/moe-f. © 2025 Elsevier B.V., All rights reserved.","","","","","Anastasis Kratsios acknowledges financial support from an NSERC Discovery Grant No. RGPIN-2023-04482 and their McMaster Startup Funds. Raeid Saqur is supported by Canada NSERC CGS-D Doctoral Grant. The authors acknowledge that resources used in preparing this research were provided, in part, by the Province of Ontario, the Government of Canada through CIFAR, and companies sponsoring the Vector Institute https://vectorinstitute.ai/partnerships/current-partners/. The authors would like to thank Marshall Wang for helping with reference code for computing DBRX experiments.","Alquier, Pierre, PAC-Bayesian bounds for randomized empirical risk minimizers, Mathematical Methods of Statistics, 17, 4, pp. 279-304, (2008); Alquier, Pierre, On the properties of variational approximations of Gibbs posteriors, Journal of Machine Learning Research, 17, pp. 1-41, (2016); Andrychowicz, Marcin, Learning to learn by gradient descent by gradient descent, Advances in Neural Information Processing Systems, pp. 3988-3996, (2016); Annals of Mathematical Statistics, (1951); Beneŝ, Václav E., EXACT FINITE-DIMENSIONAL FILTERS FOR CERTAIN DIFFUSIONS WITH NONLINEAR DRIFT., Stochastics, 5, 1-2, pp. 65-92, (1981); Binette, Olivier, A Note on Reverse Pinsker Inequalities, IEEE Transactions on Information Theory, 65, 7, pp. 4094-4096, (2019); American Mathematical Soc, (1987); Caltrans Performance Measurement System Pems, (2023); Challú, Cristian, NHITS: Neural Hierarchical Interpolation for Time Series Forecasting, 37, pp. 6989-6997, (2023); Evaluating Large Language Models Trained on Code, (2021)","","International Conference on Learning Representations, ICLR","","13th International Conference on Learning Representations, ICLR 2025","","Singapore","209472","","9798331320850","","","English","Conference paper","Final","","Scopus","2-s2.0-105010209602"
"H., Nouri, Hicham; H., Nassera, Habbat","Nouri, Hicham (57835835600); Nassera, Habbat (57222403589)","57835835600; 57222403589","From text to trade: harnessing the potential of generative AI for investor sentiment analysis in financial markets through large language models","2025","International Journal of Information Technology (Singapore)","","","","","","0","1","10.1007/s41870-025-02622-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009894355&doi=10.1007%2Fs41870-025-02622-w&partnerID=40&md5=fbe66b7c820778082458d848a1fa267b","Faculté des Sciences Juridique Économique et Sociale Ain Sebaâ Casablanca, Casablanca, Morocco; Université Hassan 1er, Settat, Morocco","Nouri, Hicham, Faculté des Sciences Juridique Économique et Sociale Ain Sebaâ Casablanca, Casablanca, Morocco; Nassera, Habbat, Faculty of Science and Technology, Université Hassan 1er, Settat, Morocco","This study explores the integration of generative artificial intelligence (AI) into financial sentiment analysis, focusing on enhancing market behavior predictions using advanced large language models (LLMs). A novel sentiment analysis framework is developed, leveraging cutting-edge LLMs and generative AI for data augmentation. The approach incorporates optimized word embeddings and fine-tuning techniques such as Few-shot Learning and Low-Rank Adaptation (LoRA) to handle the linguistic complexities of financial discourse. The framework is evaluated using five performance metrics, demonstrating improved accuracy and efficiency. These findings highlight the transformative potential of LLMs in financial decision-making and sentiment-driven trading strategies. © 2025 Elsevier B.V., All rights reserved.","Financial Markets; Generative Ai; Large Language Models; Sentiment Analysis","","","","","Nyakurukwa, Kingstone, Investor sentiment networks: mapping connectedness in DJIA stocks, Financial Innovation, 11, 1, (2025); Chawla, Swati, Technology enabled communication during COVID 19: analysis of tweets from top ten Indian IT companies using NVIVO, International Journal of Information Technology (Singapore), 15, 4, pp. 2063-2075, (2023); Vazirani, Krish, Evaluating the economic disparities in the world: sentiment analysis on central bank speeches from third world and first world countries, International Journal of Information Technology (Singapore), 16, 1, pp. 69-76, (2024); Nouri, Hicham, Customer sentiment analysis for Arabic social media using a novel ensemble machine learning approach, International Journal of Electrical and Computer Engineering, 13, 4, pp. 4504-4515, (2023); Banerjee, Saikat, An ingenious method for estimating future crop prices that emphasises machine learning and deep learning models, International Journal of Information Technology (Singapore), 15, 8, pp. 4291-4313, (2023); Singh, Gargi, Predicting earnings per share using feature-engineered extreme gradient boosting models and constructing alpha trading strategies, International Journal of Information Technology (Singapore), 15, 8, pp. 3999-4012, (2023); Nouri, Hicham, Towards Improving E-Commerce Customer Review Analysis for Arabic Language Opinion Mining, International Journal of Computing, 23, 3, pp. 387-395, (2024); Diqi, Mohammad, StockGAN: robust stock price prediction using GAN algorithm, International Journal of Information Technology (Singapore), 14, 5, pp. 2309-2315, (2022); Nouri, Hicham, Improving emotion classification in e-commerce customer review analysis using GPT and meta‑ensemble deep learning technique for multilingual system, Multimedia Tools and Applications, 83, 39, pp. 87323-87367, (2024); Leveraging Chatgpt as Text Annotation Tool for Sentiment Analysis, (2023)","","Springer Science and Business Media B.V.","","","","","","25112104; 25112112","","","","English","Article","aip","","Scopus","2-s2.0-105009894355"
"","","","18th International Conference on Information Technology and Applications, ICITA 2024","2025","Lecture Notes in Networks and Systems","1248 LNNS","","","","","719","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009402610&partnerID=40&md5=1bd51838b376f29e7d80488c499499b4","","","The proceedings contain 59 papers. The special focus in this conference is on Information Technology and Applications. The topics include: Comparison of Machine Learning Models for Early Prediction of Diabetes with LIME Interpretability; pattern Recognition in Disaster Response: Leveraging Machine Learning for Twitter Analysis; TTL: Transformer and Transfer Learning Approach to Detect Sunflower Disease; The Moderating Role of Risk Aversion in an Extended UTAUT Cryptocurrency Adoption Model; NLP on Text Messages Using Sentimentality Investigation; audio-Visual Features-Based Framework for Advertisement Detection from Sports Videos; Context-Aware Medical Question-Answering: An Extended Transformers-Based Approach with BioBERT Encoding for Restricted Domain Queries; Enhancing Seabass Detection in Aquaculture: A Step Toward Automated Behavioral Analysis Using AI; information Technology at the University of Turin: A Disruptive Method for Exams with the Safe Exam Browser; usability Assessment of Virtual Reality Applications to Support the Care of Older Adults: A Scoping Review; predicting Commodity Prices in Futures Market Using Machine Learning; A Hybrid Approach to Music Recommendations for Improving ADHD Productivity; hyper-chaotic Nonlinear Artificial Hummingbird Algorithm; an Efficient Voice Replay Antispoofing Method; deep Spatiotemporal Network-Based Spontaneous Macro- and Micro-facial Expression Recognition; Face Sketch Image Generation from Facial Attributes Using StyleGAN2; building a Usability and Accessibility Evaluation Method for Small Software Development Companies; Forex Price Prediction: A Multi-model Approach Integrating Sentiment Analysis Using LLMs with LSTM, XGBoost, Transformer Models; predicting New Zealand’s Stock Market Trends: Combining Sentiment Analysis and Deep Learning; netFlow-Based Network Intrusion Prevention System Using Machine Learning; data-Driven Demand Forecasting in Fast Fashion Using Integrated Deep Learning Models; early Detection of Cardiovascular Diseases. © 2025 Elsevier B.V., All rights reserved.","","","","","","","Ullah, A.; Anwar, S.","Springer Science and Business Media Deutschland GmbH","","18th International Conference on Information Technology and Applications, ICITA 2024","","Sydney; NSW","333819","23673389; 23673370","9789819652372; 9783031931055; 9789819662968; 9783031999963; 9783031950162; 9783031947698; 9783032004406; 9783031910074; 9783031926105; 9789819639410","","","English","Conference review","Final","","Scopus","2-s2.0-105009402610"
"M., Darwish, Mahmoud; E.E., Hassanien, Ehab Ezzat; A.H.B., Eissa, Amany H.B.","Darwish, Mahmoud (59968091100); Hassanien, Ehab Ezzat (6701498500); Eissa, Amany H.B. (59368374300)","59968091100; 6701498500; 59368374300","Stock Market Forecasting: From Traditional Predictive Models to Large Language Models","2025","Computational Economics","","","","","","0","0","10.1007/s10614-025-11024-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009347237&doi=10.1007%2Fs10614-025-11024-w&partnerID=40&md5=1db847160cb75df59a6a2aed35f5916f","Faculty of Computers and Artificial Intelligence, Giza, Egypt; Faculty of Computing and Information Sciences, Cairo, Egypt","Darwish, Mahmoud, Faculty of Computers and Artificial Intelligence, Giza, Egypt; Hassanien, Ehab Ezzat, Faculty of Computers and Artificial Intelligence, Giza, Egypt; Eissa, Amany H.B., Faculty of Computers and Artificial Intelligence, Giza, Egypt, Faculty of Computing and Information Sciences, Cairo, Egypt","Stock market forecasting is a complex research problem due to the complexity of the factors influencing stock market trends. This survey provides a comprehensive overview of recent advancements in stock market forecasting, focusing on the impact of large language models (LLMs) in financial analytics. The survey explores the strengths and challenges of feature engineering, ensemble methods, hybrid models, text-based prediction and reinforcement learning. It then presents the transformative impact of LLMs, highlighting their capabilities in utilizing transfer learning and few-shot learning to understand complex financial information, enhancing sentiment analysis, improving portfolio management, and stock forecasting accuracy. A key novelty of this survey lies in presenting comprehensive analysis of the strengths and weaknesses of LLMs for different financial tasks in addition to exploring how LLMs can be combined with machine learning and reinforcement learning approaches to overcome their limitations in handling unstructured data, improving model explainability, and enhancing generalizability. Finally, this survey identifies existing research gaps and limitations, proposing future research directions aimed at improving prediction accuracy and utilizing both LLMs and predictive models’ capabilities in stock market forecasting. © 2025 Elsevier B.V., All rights reserved.","Feature Engineering; Large Language Models; Llm-based Financial Agents; Machine Learning; Reinforcement Learning; Stock Market Forecasting","","","","","Abdelfattah, Bassant A., Enhancing the Prediction of Stock Market Movement Using Neutrosophic-Logic-Based Sentiment Analysis, Journal of Theoretical and Applied Electronic Commerce Research, 19, 1, pp. 116-134, (2024); Gpt 4 Technical Report, (2025); Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Ashtiani, Matin N., News-based intelligent prediction of financial markets using text mining and machine learning: A systematic literature review, Expert Systems with Applications, 217, (2023); Bagalkot, Sneha S., Novel grey wolf optimizer based parameters selection for GARCH and ARIMA models for stock price prediction, PeerJ Computer Science, 10, (2024); Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia Pacific Chapter of the Association for Computational Linguistics Volume 1 Long Papers, (2023); Beniwal, Mohit, Forecasting multistep daily stock prices for long-term investment decisions: A study of deep learning models on global indices, Engineering Applications of Artificial Intelligence, 129, (2024); Berradi, Zahra, COMBINATION OF DEEP-LEARNING MODELS TO FORECAST STOCK PRICE OF AAPL AND TSLA, Jordanian Journal of Computers and Information Technology, 8, 4, pp. 345-356, (2022); Bouadjenek, Mohamed Reda, A User-Centric Analysis of Social Media for Stock Market Prediction, ACM Transactions on the Web, 17, 2, (2023); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020)","","Springer","","","","","","15729974; 09277099","069112549X; 9780691125497","","","English","Review","aip","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-105009347237"
"M., Akpan, Mfon","Akpan, Mfon (59163467100)","59163467100","CAN CHATGPT PREDICT STOCK PRICES? EVALUATING ARTIFICIAL INTELLIGENCE-DRIVEN FINANCIAL FORECASTING AND RISK MANAGEMENT","2025","Risk Governance and Control: Financial Markets and Institutions","15","2","","148","160","0","0","10.22495/rgcv15i2p13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008538760&doi=10.22495%2Frgcv15i2p13&partnerID=40&md5=2979414d6f1ae7ca1e67172720a0f83c","Northeastern State University, Tahlequah, United States","Akpan, Mfon, Northeastern State University, Tahlequah, United States","The use of artificial intelligence (AI) in financial forecasting has become increasingly significant in finance and accounting, offering improved precision in predicting key financial indicators such as revenue and net income. The purpose of this study is to explore the relationship between AI models’ benchmark scores and their predictive accuracy, addressing a gap in the literature regarding comprehensive evaluations of AI performance across financial metrics. Recent research highlights AI’s potential to outperform traditional statistical methods, with deep learning and ensemble models demonstrating notable accuracy in predicting stock prices and financial ratios (Khattak et al., 2023; Cao, 2021). By analyzing the 2020–2022 financial records of ten publicly listed corporations this research implements zero-shot prompt approaches for forecasting 2023 revenue and net income. Research findings demonstrate AI models can effectively boost financial prediction accuracy and such accuracy remains essential for business choices and risk protocols. Practical steps for AI reliability enhancement focus on using top-quality data with transparency and methods to control algorithmic biases. The research is relevant because it adds to AI finance understanding in academia while generating practical applications that guide industry professionals toward future exploration of financial AI applications. © 2025 Elsevier B.V., All rights reserved.","Artificial Intelligence; Benchmarking; Financial Forecasting; Net Income Prediction; Predictive Analytics; Revenue Prediction","","","","","International Journal of Analytical and Experimental Modal Analysis, (2025); AI in Finance Challenges Techniques and Opportunities, (2021); Think You have Solved Question Answering Try Arc the Ai2 Reasoning Challenge, (2018); Hendrycks, Dan, MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING, (2021); Khattak, Bilal Hassan Ahmed, A Systematic Survey of AI Models in Financial Market Forecasting for Profitability Analysis, IEEE Access, 11, pp. 125359-125380, (2023); Lu, Pan, A Survey of Deep Learning for Mathematical Reasoning, Proceedings of the Annual Meeting of the Association for Computational Linguistics, 1, pp. 14605-14631, (2023); Okuda, Katsumi, AskIt: Unified Programming Interface for Programming with Large Language Models, pp. 41-54, (2024); Purwar, Mitali, Data-Driven Insights: Leveraging Analytics for Predictive Modeling in Finance, pp. 687-693, (2024); Ranaldi, Leonardo, CryptoNet: Using Auto-Regressive Multi-Layer Artificial Neural Networks to Predict Financial Time Series, Information (Switzerland), 13, 11, (2022); Rudin, Cynthia D., Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead, Nature Machine Intelligence, 1, 5, pp. 206-215, (2019)","","Virtus Interpress","","","","","","20774303; 2077429X","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105008538760"
"","","","7th International Conference on Adaptive Instructional Systems, AIS 2025, held as part of the 27th HCI International Conference, HCII 2025","2025","Lecture Notes in Computer Science","15812 LNCS","","","","","601","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007848472&partnerID=40&md5=e5128df3756c8517fa6afc67fe6c9eda","","","The proceedings contain 40 papers. The special focus in this conference is on Adaptive Instructional Systems. The topics include: Evaluating Adaptive Training for Nautical Rules of the Road; from Standardization to Personalization: Leveraging Learner Profiles to Tailor Education; an Adaptive Simulated Startup Financial Modeling Mentor Using a Large Language Model to Address Shortages in Skilled Advisors: Architecture and Design Considerations; integrating Adaptive Interventions into Learning Engineering Workflows; leveraging Deterministic Algorithms to Personalize Education and Enhance Student Success: The Story of an Engineered Learning Experience; curriculum Sequencing as a Generalised Travelling Salesperson Problem: A Novel Perspective on Learning Path Generation; evaluation of Difficulty-Based Adaptive Training Strategies on Simulator Flight Training Performance; designing an Adaptive Mobile Application for Learning Programming Among Computing Students from Marginalized Backgrounds; architecture for a Large Scale Learning Ecosystem; automated Response Generation Using Language Models: An Approach to Enhancing User Interaction; Metacognition in HCI: Designing Systems for Planning and Flexibility; stress and Performance: Understanding the Effect of Appraisal and Coping on Performance in Complex Tasks; exploring the Potential of Large Language Models for Estimating the Reading Comprehension Question Difficulty; macrocognition in Simulation Based Training: A Practical Application of Learning Engineering in a Complex Training Environment; public Safety Personnel Readiness Prediction: A Hybrid Model of Neurophysiological and Psychometric Data; understanding the Complexity of Music Improvisation: Leveraging Cognitive Models to Inform Adaptive Instruction Design; advancing Cognitive State Monitoring: Diagnosing Cognitive Control States Under Varying Automation Reliability Level; the Weaponization of Critical Thinking: Understanding the Dynamics of Human Memory. © 2025 Elsevier B.V., All rights reserved.","","","","","","","Sottilare, R.A.; Schwarz, J.","Springer Science and Business Media Deutschland GmbH","","7th International Conference on Adaptive Instructional Systems, AIS 2025, held as part of the 27th HCI International Conference, HCII 2025","","Gothenburg","332889","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference review","Final","","Scopus","2-s2.0-105007848472"
"","","","7th International Conference on Adaptive Instructional Systems, AIS 2025, held as part of the 27th HCI International Conference, HCII 2025","2025","Lecture Notes in Computer Science","15813 LNCS","","","","","601","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007761709&partnerID=40&md5=f22bfbcd529a7aecc5f763b22dd580fe","","","The proceedings contain 40 papers. The special focus in this conference is on Adaptive Instructional Systems. The topics include: Evaluating Adaptive Training for Nautical Rules of the Road; from Standardization to Personalization: Leveraging Learner Profiles to Tailor Education; an Adaptive Simulated Startup Financial Modeling Mentor Using a Large Language Model to Address Shortages in Skilled Advisors: Architecture and Design Considerations; integrating Adaptive Interventions into Learning Engineering Workflows; leveraging Deterministic Algorithms to Personalize Education and Enhance Student Success: The Story of an Engineered Learning Experience; curriculum Sequencing as a Generalised Travelling Salesperson Problem: A Novel Perspective on Learning Path Generation; evaluation of Difficulty-Based Adaptive Training Strategies on Simulator Flight Training Performance; designing an Adaptive Mobile Application for Learning Programming Among Computing Students from Marginalized Backgrounds; architecture for a Large Scale Learning Ecosystem; automated Response Generation Using Language Models: An Approach to Enhancing User Interaction; Metacognition in HCI: Designing Systems for Planning and Flexibility; stress and Performance: Understanding the Effect of Appraisal and Coping on Performance in Complex Tasks; exploring the Potential of Large Language Models for Estimating the Reading Comprehension Question Difficulty; macrocognition in Simulation Based Training: A Practical Application of Learning Engineering in a Complex Training Environment; public Safety Personnel Readiness Prediction: A Hybrid Model of Neurophysiological and Psychometric Data; understanding the Complexity of Music Improvisation: Leveraging Cognitive Models to Inform Adaptive Instruction Design; advancing Cognitive State Monitoring: Diagnosing Cognitive Control States Under Varying Automation Reliability Level; the Weaponization of Critical Thinking: Understanding the Dynamics of Human Memory. © 2025 Elsevier B.V., All rights reserved.","","","","","","","Sottilare, R.A.; Schwarz, J.","Springer Science and Business Media Deutschland GmbH","","7th International Conference on Adaptive Instructional Systems, AIS 2025, held as part of the 27th HCI International Conference, HCII 2025","","Gothenburg","332889","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference review","Final","","Scopus","2-s2.0-105007761709"
"","","","12th International Conference on HCI in Business, Government and Organizations, held as part of the 27th HCI International Conference, HCII 2025","2025","Lecture Notes in Computer Science","15804 LNCS","","","","","666","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007166117&partnerID=40&md5=2746445e0bb2f9cc917cdcd2fed6cbad","","","The proceedings contain 41 papers. The special focus in this conference is on HCI in Business, Government and Organizations. The topics include: Apology or Gratitude: The Impact of Verbal Recovery Strategies of AI-Powered Virtual Tourism Assistants on Tourists’ Post-Recovery Satisfaction; enhancing the Omnichannel Retailing Customer Experience in the Pre-purchase Phase: Evaluation and Improvement of a Digital Grocery Brochure; investigating Users’ Responses to Blurred Boundary Advertisements in Short Video Websites; RoBuddy – An Innovative Research Project on AI in Office Environments; a Method of Assembly Guidance Information Delivery in Augmented Reality Considering Users’ Proficiency Levels; Once More with (the Right) Feeling: How Historical Fiction Writing Processes of Character Design, Plot Outline, and Context Checking Are Affected by Co-Writing with ChatGPT; Using CNN Models to Predict the Future Trends of Listed Stocks on the Taiwan Stock Exchange; Integrating AI-Driven Personas and Procedural Visualization for Complete Communities Design and Urban Planning for Large-Scale Urban Development; Generative AI and Changing Work: Systematic Review of Practitioner-Led Work Transformations Through the Lens of Job Crafting; Follow My Logic: Generative AI Workflows in Designing for Serious Table-Top Games; AI Integration in ERP Systems: Optimizing Knowledge Management and Business Process Re-engineering for Strategic Outcomes; rethink the Way of Conducting Research: It is Time to Change to the Artificial Intelligence Era for Reliable Outcomes; augmenting Student Startups’ Customer Validation Efforts Through Adaptive Coaching Using Large Language Models; skilled Labor Shortage and Artificial Intelligence: Challenges and Opportunities for the Regional Labor Market; LLM-Assisted Collaborative Change Specification of Industrial Control Software; ChatGPT and Financial Investing: The Advantages, the Disadvantages, and the Perils. © 2025 Elsevier B.V., All rights reserved.","","","","","","","Siau, K.L.; Nah, F.F.-H.","Springer Science and Business Media Deutschland GmbH","","12th International Conference on HCI in Business, Government and Organizations, held as part of the 27th HCI International Conference, HCII 2025","","Gothenburg","332659","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference review","Final","","Scopus","2-s2.0-105007166117"
"","","","12th International Conference on HCI in Business, Government and Organizations, held as part of the 27th HCI International Conference, HCII 2025","2025","Lecture Notes in Computer Science","15805 LNCS","","","","","666","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007143427&partnerID=40&md5=de4ce4c850bdc6d0606868cf982ed7f1","","","The proceedings contain 41 papers. The special focus in this conference is on HCI in Business, Government and Organizations. The topics include: Apology or Gratitude: The Impact of Verbal Recovery Strategies of AI-Powered Virtual Tourism Assistants on Tourists’ Post-Recovery Satisfaction; enhancing the Omnichannel Retailing Customer Experience in the Pre-purchase Phase: Evaluation and Improvement of a Digital Grocery Brochure; investigating Users’ Responses to Blurred Boundary Advertisements in Short Video Websites; RoBuddy – An Innovative Research Project on AI in Office Environments; a Method of Assembly Guidance Information Delivery in Augmented Reality Considering Users’ Proficiency Levels; Once More with (the Right) Feeling: How Historical Fiction Writing Processes of Character Design, Plot Outline, and Context Checking Are Affected by Co-Writing with ChatGPT; Using CNN Models to Predict the Future Trends of Listed Stocks on the Taiwan Stock Exchange; Integrating AI-Driven Personas and Procedural Visualization for Complete Communities Design and Urban Planning for Large-Scale Urban Development; Generative AI and Changing Work: Systematic Review of Practitioner-Led Work Transformations Through the Lens of Job Crafting; Follow My Logic: Generative AI Workflows in Designing for Serious Table-Top Games; AI Integration in ERP Systems: Optimizing Knowledge Management and Business Process Re-engineering for Strategic Outcomes; rethink the Way of Conducting Research: It is Time to Change to the Artificial Intelligence Era for Reliable Outcomes; augmenting Student Startups’ Customer Validation Efforts Through Adaptive Coaching Using Large Language Models; skilled Labor Shortage and Artificial Intelligence: Challenges and Opportunities for the Regional Labor Market; LLM-Assisted Collaborative Change Specification of Industrial Control Software; ChatGPT and Financial Investing: The Advantages, the Disadvantages, and the Perils. © 2025 Elsevier B.V., All rights reserved.","","","","","","","Siau, K.L.; Nah, F.F.-H.","Springer Science and Business Media Deutschland GmbH","","12th International Conference on HCI in Business, Government and Organizations, held as part of the 27th HCI International Conference, HCII 2025","","Gothenburg","332659","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference review","Final","","Scopus","2-s2.0-105007143427"
"M.R.S., Al-Saidat, Mohammed Rasol Saleem; K.F., Shaalan, Khaled F.; S., Yemria, Suliman","Al-Saidat, Mohammed Rasol Saleem (57189049718); Shaalan, Khaled F. (6507669702); Yemria, Suliman (59918854300)","57189049718; 6507669702; 59918854300","Advancing Interpretability in Sequential Models Through Generative AI Rationalization Using GPT-4","2025","Lecture Notes in Civil Engineering","587","","","31","42","0","0","10.1007/978-3-031-84371-6_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006850802&doi=10.1007%2F978-3-031-84371-6_3&partnerID=40&md5=24f169bb76de2fe4d5cc0709aaa123d2","British University in Dubai, Dubai, United Arab Emirates","Al-Saidat, Mohammed Rasol Saleem, Faculty of Engineering and IT, British University in Dubai, Dubai, United Arab Emirates; Shaalan, Khaled F., Faculty of Engineering and IT, British University in Dubai, Dubai, United Arab Emirates; Yemria, Suliman, Faculty of Engineering and IT, British University in Dubai, Dubai, United Arab Emirates","In this study, we investigate the role of Generative Pre-trained Transformer 4 (GPT-4) in enhancing interpretability of sequential predictions in Natural Language Processing (NLP). Our study introduces a hybrid model that integrates traditional sequential prediction models with GPT-4, aiming to generate detailed, context-sensitive explanations for model outputs. This approach is rooted in the use of advanced transformer architectures and a specialized tokenization method that maintains semantic coherence, allowing for deep contextual analysis by GPT-4. Additionally, we devise a rationale generation algorithm that achieves a balance between succinctness and informativeness. Our experimental validation spans across various high-dimensional datasets, including financial time-series and multilingual texts, employing both qualitative and quantitative metrics to evaluate the model’s performance. These metrics focus on the plausibility and consistency of the rationales, as well as the model’s predictive accuracy. Preliminary results demonstrate that our approach not only enhances the accuracy of sequential predictions but also significantly improves their interpretability. This finding highlights the potential of generative AI to bridge the gap between complex AI decision-making processes. This research underscores the viability of employing generative AI to elucidate the underlying mechanisms of sequential prediction models, paving the way for more transparent AI systems. © 2025 Elsevier B.V., All rights reserved.","Explainable Ai (xai); Generative Ai; Sequential Predictions; Explainable Ai (xai); Generative Ai; Hybrid Model; Interpretability; Language Processing; Natural Languages; Prediction Modelling; Rationalisation; Sequential Modeling; Sequential Prediction; Natural Language Processing Systems","Explainable AI (XAI); Generative AI; Hybrid model; Interpretability; Language processing; Natural languages; Prediction modelling; Rationalisation; Sequential modeling; Sequential prediction; Natural language processing systems","","","","undefined; Al-Saidat, Mohammed Rasol Saleem, Exploring the Interpretability of Sequential Predictions Through Rationale Model, Studies in Big Data, 144, pp. 11-22, (2024); Towards A Rigorous Science of Interpretable Machine Learning Arxiv Preprint Arxiv, (2017); El-Mousa, Ali H., The design of a secure SIP-based architecture for broadband service providers, pp. 89-94, (2015); Kar, Arpan Kumar, Unravelling the Impact of Generative Artificial Intelligence (GAI) in Industrial Applications: A Review of Scientific and Grey Literature, Global Journal of Flexible Systems Management, 24, 4, pp. 659-689, (2023); AI Revolution in Medicine Gpt 4 and Beyond, (2023); Lipton, Zachary Chase, The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery., Queue, 16, 3, (2018); Journal of Computer Information Systems, (2025); Malo, Pekka, Good debt or bad debt: Detecting semantic orientations in economic texts, Journal of the Association for Information Science and Technology, 65, 4, pp. 782-796, (2014)","Al Marri, K.; Mir, F.A.; Awad, A.; Abubakar, A.","Springer Science and Business Media Deutschland GmbH","","8th BUiD Doctoral Research Conference, BDRC 2024","","Dubai","332149","23662565; 23662557","9789819620951; 9789819674879; 9789819616053; 9783031988929; 9783031927539; 9783031920431; 9789819652051; 9789819620333; 9789811613029; 9789819798308","","","English","Conference paper","Final","","Scopus","2-s2.0-105006850802"
"G., Zhang, Ge; D., Yin, David; T., Kim, Tae-wook; A.R., Kovscek, Anthony Robert","Zhang, Ge (59910378000); Yin, David (59909746800); Kim, Tae-wook (57059559800); Kovscek, Anthony Robert (7005383765)","59910378000; 59909746800; 57059559800; 7005383765","Leveraging Language Models for Carbon Market Insights: News Sentiment and Price Dynamics","2025","SPE Western Regional Meeting Proceedings","2025-April","","","","","0","0","10.2118/224146-MS","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005856642&doi=10.2118%2F224146-MS&partnerID=40&md5=d12b739166806c5f951428fdd800d174","Department of Energy Science and Engineering, Stanford, United States; Stanford Engineering, Stanford, United States","Zhang, Ge, Department of Energy Science and Engineering, Stanford, United States; Yin, David, Stanford Engineering, Stanford, United States; Kim, Tae-wook, Department of Energy Science and Engineering, Stanford, United States; Kovscek, Anthony Robert, Department of Energy Science and Engineering, Stanford, United States","The carbon credit system plays a pivotal role in offsetting emissions, mitigating climate change, and enabling trading opportunities. We examine California's Low Carbon Fuel Standard (LCFS) using time series data from 2013 to 2024 to analyze carbon credit price dynamics and improve predictive capability with machine learning and large language models (LLMs). Technical analysis is employed to capture short-term trends (using monthly LCFS transaction data). While effective in identifying general price trends, these models struggle to adapt to shifts caused by policy changes or supply-demand fluctuations and offer limited insight into market dynamics. To address this, we incorporate news articles covering general carbon market topics. LLMs are employed for sentiment analysis, generating sentiment scores ranging from -1 (extremely negative) to 1 (extremely positive) and categorizing influence into short-term, mid-term, or long-term. The aggregated sentiment scores achieve over 60% alignment with price change. We further enhance prediction performance by integrating news data directly with trading data into advanced LLMs, including Gemini 1.5 Pro, Claude 3.5 Sonnet, GPT-4o, and o1-preview, resulting in higher F1 scores and improved accuracy. These LLMs demonstrated the ability to synthesize diverse information and provided clear market insights. For long-term forecasting, we integrate news data and LCFS trading data with California’s gasoline and diesel prices, annual CO<inf>2</inf> emissions, electric vehicle sales, Cap-and-Trade (CaT) carbon tax prices, EU Emissions Trading Scheme (ETS) carbon prices, and Canada’s federal fuel charge into LLMs. The long-term prediction achieves F1 score up to 0.8, capturing price transitions and providing reasoned insights. This study highlights the potential of LLMs in carbon market forecasting, especially in enhancing interpretability and decision-making. © 2025 Elsevier B.V., All rights reserved.","","","","","","Gpt 4 Technical Report, (2023); undefined, (2024); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Lcfs Data Dashboard; Low Carbon Fuel Standard News; Current California Ghg Emission Inventory Data; Cap and Trade Program Data; undefined, (2024); Callas, Catherine, Criteria and workflow for selecting depleted hydrocarbon reservoirs for carbon storage, Applied Energy, 324, (2022); Chen, Tianqi, XGBoost: A scalable tree boosting system, 13-17-August-2016, pp. 785-794, (2016)","","Society of Petroleum Engineers (SPE)","","2025 SPE Western Regional Meeting, WRM 2025","","Garden Grove; CA","208903","26937131; 26937115","9781959025603","","","English","Conference paper","Final","","Scopus","2-s2.0-105005856642"
"M., Fan, Menghua; C., Lv, Chen; H., Fan, Hang; M., Li, Mingxuan; L., Yang, Liuqing; Z., Zhang, Zuhan; S., Wang, Shuaikang; X., Tan, Xiaowei","Fan, Menghua (56366845200); Lv, Chen (58975695700); Fan, Hang (55899843500); Li, Mingxuan (59844978200); Yang, Liuqing (58834885300); Zhang, Zuhan (59529213600); Wang, Shuaikang (59767704900); Tan, Xiaowei (59907775700)","56366845200; 58975695700; 55899843500; 59844978200; 58834885300; 59529213600; 59767704900; 59907775700","Distributed photovoltaic power prediction based on Solar-LLM","2025","Proceedings of SPIE - The International Society for Optical Engineering","13632","","136321F","","","0","0","10.1117/12.3060936","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005721008&doi=10.1117%2F12.3060936&partnerID=40&md5=4f2d41677d22faac76bf3fd25a85fecd","State Grid Corporation of China, Beijing, China; North China Electric Power University, Beijing, China; Tsinghua University, Beijing, China","Fan, Menghua, State Grid Corporation of China, Beijing, China; Lv, Chen, State Grid Corporation of China, Beijing, China; Fan, Hang, School of Economics and Management, North China Electric Power University, Beijing, China; Li, Mingxuan, Department of Electrical Engineering and Applied Electronic Technology, Tsinghua University, Beijing, China; Yang, Liuqing, School of Economics and Management, North China Electric Power University, Beijing, China; Zhang, Zuhan, School of Economics and Management, North China Electric Power University, Beijing, China; Wang, Shuaikang, School of Economics and Management, North China Electric Power University, Beijing, China; Tan, Xiaowei, School of Economics and Management, North China Electric Power University, Beijing, China","Distributed photovoltaic power generation has volatility and intermittently, and its power generation is usually difficult to predict accurately. Previous studies have mostly focused on physical or mathematical modeling methods, and it is difficult to grasp the complexity and variability of historical data, and the prediction accuracy is limited. This paper presents a distributed PV power prediction method Solar-LLM, firstly, introduced the technical principles of the model, and then introduced the Solar-LLM model architecture and multistep photovoltaic power prediction method, the large language model, by reprogramming the input and output layer, can effectively consider the complexity and versatility of historical data. Finally, the performance of the model is demonstrated by example analysis and compared with existing methods. The experiment is based on the datasets of five photovoltaic power stations in Hebei Province, China, and the results show that the performance of Solar-LLM is better than that of GRU, LSTM, TCN, Transformer and Informer in different prediction periods, which is a feasible and effective method for power generation prediction. © 2025 Elsevier B.V., All rights reserved.","Large Language Model; Photovoltaic Power Prediction; Time Series Prediction; Historical Data; Language Model; Large Language Model; Performance; Photovoltaic Power; Photovoltaic Power Prediction; Power Predictions; Power- Generations; Prediction Methods; Time Series Prediction; Problem Oriented Languages","Historical data; Language model; Large language model; Performance; Photovoltaic power; Photovoltaic power prediction; Power predictions; Power- generations; Prediction methods; Time series prediction; Problem oriented languages","","","This paper is mainly supported by Project Supported by Science and Technology Project of SGCC \""Research and application of key technologies for deepening the operation of inter provincial medium and long-term electricity trading to adapt to a multi-level unified electricity market\""(5108-202340063A-1-1-ZN).","Journal of Electric Power Science and Technology; Wang, Xiaoxia, FEW-SHOT PHOTOVOLTAIC POWER SHORT-TERM FORECASTING BASED ON INSTANCE TRANSFER LEARNING, Taiyangneng Xuebao/Acta Energiae Solaris Sinica, 45, 6, pp. 325-333, (2024); Proceedings of the Csu Epsa, (2023); Ma, Zhengjing, A hybrid attention-based deep learning approach for wind power prediction, Applied Energy, 323, (2022); Ye, Lin, Photovoltaic power forecasting model based on genetic algorithm and fuzzy radial basis function neural network, Dianli Xitong Zidonghua/Automation of Electric Power Systems, 39, 16, pp. 16-22, (2015); Power Construction, (2017); Attention is all You Need, (2017); Time Llm Time Series Forecasting by Reprogramming Large Language Models, (2023); International Conference on Learning Representations, (2021); Yao, Tiechui, A photovoltaic power output dataset: Multi-source photovoltaic power output dataset with Python toolkit, Solar Energy, 230, pp. 122-130, (2021)","Mu, Y.; Kolhe, M.L.; Cheng, Z.; Xiao, Q.","SPIE","Academic Exchange Information Centre (AEIC)","9th International Conference on Energy System, Electricity, and Power, ESEP 2024","","Tianjin","208804","0277786X; 1996756X","9781510692657; 9781510690561; 9781510693302; 9781510692251; 9781510692275; 9781510693081; 9781510688728; 9781510688629; 9781510692671; 9781510693326","PSISD","","English","Conference paper","Final","","Scopus","2-s2.0-105005721008"
"","","","2025 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics, CiFer 2025","2025","","","","","","","114","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004809261&partnerID=40&md5=6c5798609985a55466cf96dae192df2d","","","The proceedings contain 11 papers. The topics discussed include: novel financial network models using neuro correlations and applications; the superiority of direct neuro volatility forecasts over GARCH and machine learning forecasts for financial assets; innovative pattern extraction and synthetic high-frequency data generation in European carbon emission markets using GAN networks; robust European call option pricing via linear regression; simulating illiquid markets: insights from fractional ownership trading and agent-based models; enhancing forecasting with a 2D time series approach for cohort-based data; stock prediction by signal decomposition-driven multivariate feature extractor and executor-based mixture of experts; a deep ensemble learning approach for imbalanced data in bankruptcy prediction; and leveraging large language models and retrieval-augmented generation for enhanced multi-asset portfolio construction. © 2025 Elsevier B.V., All rights reserved.","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","2025 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics, CiFer 2025","","Trondheim","208542","","9798331508319","","","English","Conference review","Final","","Scopus","2-s2.0-105004809261"
"X., Wang, Xiaochen; F., Bai, Fan; Y., Cai, Yuntong","Wang, Xiaochen (59812460600); Bai, Fan (57219564684); Cai, Yuntong (59812460700)","59812460600; 57219564684; 59812460700","Electricity load forecasting using large language models","2025","Proceedings of SPIE - The International Society for Optical Engineering","13555","","135552U","","","0","0","10.1117/12.3064969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004649040&doi=10.1117%2F12.3064969&partnerID=40&md5=788e9f6e6046184651e5b8b0b8a26a8c","Shenyang Ligong University, Shenyang, China","Wang, Xiaochen, Shenyang Ligong University, Shenyang, China; Bai, Fan, Shenyang Ligong University, Shenyang, China; Cai, Yuntong, Shenyang Ligong University, Shenyang, China","With the increasing global energy demand and the widespread deployment of renewable energy sources, the operation and management of power systems face unprecedented challenges. Electricity load forecasting is a critical component of power system planning and operation, playing a significant role in ensuring the reliability of power supply, optimizing resource allocation, and enhancing economic benefits. This study proposes a deep learning-based electricity load forecasting framework that integrates two large language models, Qwen2.5-14B and Lag-Llama, to improve the accuracy and robustness of predictive models through meticulously designed prompt engineering, LoRA fine-tuning strategies, and data fusion tactics. The experiment utilized hourly electricity consumption data from May 1, 2004, to April 30, 2009, to forecast hourly electricity consumption from May 1 to October 31, 2009, and included the Shanghai Composite Index, CSI 300, CSI 500, and CSI 1000 as auxiliary financial data for prediction. The results demonstrate that our approach shows certain advantages in predictive accuracy, especially in handling multi-source data and considering spatiotemporal correlations. This provides valuable insights for power operators to optimize power generation plans and scheduling decisions, thereby improving economic efficiency and reducing environmental impact. © 2025 Elsevier B.V., All rights reserved.","Data Fusion; Deep Learning; Electricity Load Forecasting; Large Language Models; Power Systems; Energy Supply; Energy Utilization; Deep Learning; Electricity Load Forecasting; Electricity-consumption; Global Energy Demand; Language Model; Large Language Model; Operation And Management; Power; Power System; Renewable Energy Source; Power Management","Energy supply; Energy utilization; Deep learning; Electricity load forecasting; Electricity-consumption; Global energy demand; Language model; Large language model; Operation and management; Power; Power system; Renewable energy source; Power management","","","","Energies, (2018); Lag Llama Towards Foundation Models for Time Series Forecasting, (2023); Forecasting Principles and Practice, (2018); Hochreiter, Sepp, Long Short-Term Memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); IEEE Transactions on Smart Grid, (2019); Salinas, David, DeepAR: Probabilistic forecasting with autoregressive recurrent networks, International Journal of Forecasting, 36, 3, pp. 1181-1191, (2020); Advances in Neural Information Processing Systems, (2020); IEEE Transactions on Industrial Informatics, (2020); International Journal of Electrical Power Energy Systems, (2022); Renewable and Sustainable Energy Reviews, (2021)","Hu, L.","SPIE","AEIC�Academic Exchange Information Centre","2024 International Conference on Mechatronic Engineering and Artificial Intelligence, MEAI 2024","","Shenyang","208575","0277786X; 1996756X","9781510692657; 9781510690561; 9781510693302; 9781510692251; 9781510692275; 9781510693081; 9781510688728; 9781510688629; 9781510692671; 9781510693326","PSISD","","English","Conference paper","Final","","Scopus","2-s2.0-105004649040"
"S., Gupta, Sudip; H., Yan, Hanboya","Gupta, Sudip (57220632288); Yan, Hanboya (59781294700)","57220632288; 59781294700","Using Large Language Models to Estimate Novel Risk: Impact on Volatility","2025","Journal of Portfolio Management","51","7","","230","247","0","0","10.3905/jpm.2025.1.710","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004471218&doi=10.3905%2Fjpm.2025.1.710&partnerID=40&md5=a7fb458cbd5480efcfdd223add6dd470","Johns Hopkins Carey Business School, Baltimore, United States; Johns Hopkins University, Baltimore, United States","Gupta, Sudip, Johns Hopkins Carey Business School, Baltimore, United States; Yan, Hanboya, Johns Hopkins University, Baltimore, United States","This article presents an integrated framework to estimate hard to measure (novel) financial risk for volatility forecasting. Recognizing the limitations of traditional models—which often overlook emerging “novel risks”—the article leverages advanced large language models (LLMs) to extract and quantify key risk factors, including ESG, geopolitical, and supply chain disruption risks, from corporate disclosures. These LLM-derived risk scores are then combined with conventional financial indicators such as leverage, beta, and short interest, and incorporated into a long short-term memory (LSTM) neural network to predict firm-specific (idiosyncratic) volatility. Empirical analysis, conducted on over 18,000 regulatory filings spanning 2015 to 2024, demonstrates that the integrated model significantly improves volatility forecasting, as evidenced by enhanced R2 values and reduced mean squared error. Additionally, feature importance analyses confirm the pivotal role of novel risk measures. Overall, the findings underscore the benefits of merging unstructured and hard to quantify data with quantitative models to offer a more nuanced approach to estimation of novel financial risk. © 2025 Elsevier B.V., All rights reserved.","","","","","","Alan, Nazli Sila, Impact of Language Complexity on Volatility in Financial Markets: Evidence from Textual Analysis of Earnings Calls, Journal of Portfolio Management, 50, 2, pp. 27-57, (2023); Corporate Social Responsibility and Firm Risk Theory and Empirical Evidence, (2018); Fat Tail the Power of Political Knowledge for Strategic Investing, (2009); Risklabs Predicting Financial Risk Using Large Language Model Based on Multi Sources Data, (2024); Cheng, Beiting, Corporate social responsibility and access to finance, Strategic Management Journal, 35, 1, pp. 1-23, (2014); Engle, Robert F., News and Idiosyncratic Volatility: The Public Information Processing Hypothesis, Journal of Financial Econometrics, 19, 1, pp. 1-38, (2021); Long Short Term Memory Neural Network for Financial Time Series, (2022); Hochreiter, Sepp, Long Short-Term Memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Ilhan, Emirhan, Carbon Tail Risk, Review of Financial Studies, 34, 3, pp. 1540-1571, (2021); Inoue, Hiroyasu, Firm-level propagation of shocks through supply-chain networks, Nature Sustainability, 2, 9, pp. 841-847, (2019)","","Portfolio Management Research","","","","","","00954918","","","","English","Article","Final","","Scopus","2-s2.0-105004471218"
"Q., Chen, Qizhao","Chen, Qizhao (59560720800)","59560720800","Comparing Vision-Instruct LLMs, Vision-Based Deep Learning, and Numeric Models for Stock Movement Prediction","2025","International Journal of Advanced Computer Science and Applications","16","4","","11","18","0","0","10.14569/IJACSA.2025.0160402","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004064224&doi=10.14569%2FIJACSA.2025.0160402&partnerID=40&md5=6efad17433cd9021d66e5df80294117f","University of Hyogo, Kobe, Japan","Chen, Qizhao, Graduate School of Information Science, University of Hyogo, Kobe, Japan","This research conducts a comparative study of several stock movement prediction approaches, evaluating large language models (LLMs) and vision-based deep learning models with stock image as input, as well as models that utilize numerical data. Specifically, the study investigates a prompt-based LLM framework that processes candlestick charts, comparing its performance with image-based models such as MobileNetV2, Vision Transformer, and Convolutional Neural Network (CNN), as well as models with numerical inputs including Support Vector Machine (SVM), Random Forest, LSTM, and CNN-LSTM. Although LLMs have demonstrated promising results in stock prediction, directly applying them to stock images poses challenges compared to numerical approaches. To address this, this study further improves LLM performance with post-hoc calibration, reducing prediction biases. Experimental results demonstrate that post-hoc calibrated LLMs with visual input achieve competitive performance compared to other models, highlighting their potential as a viable alternative to traditional stock prediction methods while simplifying the prediction process. © 2025 Elsevier B.V., All rights reserved.","Convolutional Neural Network (cnn); Large Language Model (llm); Mobilenetv2; Stock Price Prediction; Time Series Forecasting; Vision Transformer; Cellular Neural Networks; Deep Learning; Financial Markets; Motion Estimation; Motion Tracking; Convolutional Neural Network; Language Model; Large Language Model; Learning Models; Mobilenetv2; Stock Price Prediction; Time Series Forecasting; Vision Based; Vision Transformer; Convolutional Neural Networks","Cellular neural networks; Deep learning; Financial markets; Motion estimation; Motion tracking; Convolutional neural network; Language model; Large language model; Learning models; Mobilenetv2; Stock price prediction; Time series forecasting; Vision based; Vision transformer; Convolutional neural networks","","","","Kamble, Rupesh A., Short and long term stock trend prediction using decision tree, 2018-January, pp. 1371-1375, (2017); Cheng, Shotj Hsiung, Predicting stock returns by decision tree combining neural network, Lecture Notes in Computer Science, 8398 LNAI, PART 2, pp. 352-360, (2014); Ananthakumar, Usha, Application of Logistic Regression in Assessing Stock Performances, 2018-January, pp. 1242-1247, (2017); Shobayo, Olamilekan, Innovative Sentiment Analysis and Prediction of Stock Price Using FinBERT, GPT-4 and Logistic Regression: A Data-Driven Approach, Big Data and Cognitive Computing, 8, 11, (2024); Gao, Ya, Stock Prediction Based on Optimized LSTM and GRU Models, Scientific Programming, 2021, (2021); Sayavong, Lounnapha, Research on stock price prediction method based on convolutional neural network, pp. 173-176, (2019); Hidformer Transformer Style Neural Network in Stock Price Forecasting, (2025); Fingpt Open Source Financial Large Language Models, (2023); Proceedings of the IEEE Bigdata 2024, (2024); International Journal of Modeling and Optimization, (2025)","","Science and Information Organization","","","","","","21565570; 2158107X","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105004064224"
"F., Hidayat, Fiki; A.H., Nasution, Arbi Haza; F., Ambia, Fajril; D.F., Putra, Dike Fitriansyah; Mulyandri","Hidayat, Fiki (57194537548); Nasution, Arbi Haza (6701746699); Ambia, Fajril (55601384900); Putra, Dike Fitriansyah (57191728533); Mulyandri (59740602400)","57194537548; 6701746699; 55601384900; 57191728533; 59740602400","Leveraging Large Language Models for Discrepancy Value Prediction in Custody Transfer Systems: A Comparative Analysis of Probabilistic and Point Forecasting Approaches","2025","IEEE Access","13","","","65643","65658","0","3","10.1109/ACCESS.2025.3560254","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003156632&doi=10.1109%2FACCESS.2025.3560254&partnerID=40&md5=7bb20dc13cd0efc852fe2cff0ddce268","Universitas Islam Riau, Pekanbaru, Indonesia; Universitas Islam Riau, Pekanbaru, Indonesia; PT Pertamina Hulu Rokan, Pekanbaru, Indonesia","Hidayat, Fiki, Department of Petroleum Engineering, Universitas Islam Riau, Pekanbaru, Indonesia; Nasution, Arbi Haza, Department of Informatics Engineering, Universitas Islam Riau, Pekanbaru, Indonesia; Ambia, Fajril, Department of Petroleum Engineering, Universitas Islam Riau, Pekanbaru, Indonesia; Putra, Dike Fitriansyah, Department of Petroleum Engineering, Universitas Islam Riau, Pekanbaru, Indonesia; Mulyandri, null, PT Pertamina Hulu Rokan, Pekanbaru, Indonesia","Discrepancies in custody transfer systems in the oil and gas industry pose significant financial, regulatory, and operational risks. Accurate prediction of these discrepancies is critical to optimizing operations and minimizing potential losses. This study evaluates the effectiveness of Large Language Models (LLMs), specifically the Chronos-FineTuning Amazon Chronos T5 Small model, alongside statistical, machine learning, and deep learning models, in both probabilistic and point forecasting tasks. The evaluation covers metrics such as Weighted Quantile Loss (WQL), Scaled Quantile Loss (SQL), Mean Absolute Error (MAE), Symmetric Mean Absolute Percentage Error (SMAPE), and Root Mean Square Error (RMSE). The results highlight the superior performance of the Chronos model in both forecasting paradigms, demonstrating its ability to capture uncertainty and deliver precise predictions. This research offers valuable insights into selecting forecasting methodologies to improve custody transfer operations, underscoring the transformative potential of LLMs in industrial applications. © 2025 Elsevier B.V., All rights reserved.","Custody Transfer System; Discrepancy; Large Language Models; Probabilistic Time-series Forecasting; Losses; Prediction Models; Custody Transfer; Custody Transfer System; Discrepancy; Language Model; Large Language Model; Probabilistic Time-series Forecasting; Probabilistics; Quantile Loss; Time Series Forecasting; Transfer Systems; Gas Industry","Losses; Prediction models; Custody transfer; Custody transfer system; Discrepancy; Language model; Large language model; Probabilistic time-series forecasting; Probabilistics; Quantile loss; Time series forecasting; Transfer systems; Gas industry","","","This work was supported by the Ministry of Education, Culture, Research, and Technology\u2019s Direktorat Riset, Teknologi, dan Pengabdian kepada Masyarakat (DRTPM) under Grant Number 112//E5/PG.02.00.PL/2024; 043/LL10/PG..AK/2024; 005/DPPM-UIR/HN-P/2024.","A Comprehensive Overview of Large Language Models, (2023); Mahjour, Seyed Kourosh, Geosystems risk and uncertainty: The application of ChatGPT with targeted prompting, Geoenergy Science and Engineering, 238, (2024); Jiang, Gang, EPlus-LLM: A large language model-based computing platform for automated building energy modeling, Applied Energy, 367, (2024); Wang, Xingzhi, ChatGPT for design, manufacturing, and education, Procedia CIRP, 119, pp. 7-14, (2023); Wei, Qian, Exploring the Application of Large Language Models Based AI Agents in Leakage Detection of Natural Gas Valve Chambers, Energies, 17, 22, (2024); Ghodake, Mrunali, Mutual Fund Analysis Using Large Language Model, (2024); Yan, Ziming, Probabilistic PV Power Forecasting by a Multi-Modal Method using GPT-Agent to Interpret Weather Conditions, (2024); Guo, Xusen, Towards explainable traffic flow prediction with large language models, Communications in Transportation Research, 4, (2024); Daud, Nurul Shaidatul Shima Mohamad, ELMA (Export Loading Monitoring & Analysis): Transformative Innovations in Custody Transfer Monitoring and Analysis at PETRONAS Export Terminals, (2024); Maru, Wessenu A., Oil-water flow measurement for custody transfer applications, (2019)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105003156632"
"C., Li, Caixia; Y., Zhao, Yina; Y., Bai, Yang; B., Zhao, Baoquan; Y.O., Tola, Yetunde Oluwafunmilayo; C.Y.W.H., Chan, Carmen Yip Wing Han; M., Zhang, Meifen; X., Fu, Xia","Li, Caixia (55387535700); Zhao, Yina (59470312300); Bai, Yang (59655560500); Zhao, Baoquan (56241289100); Tola, Yetunde Oluwafunmilayo (57223155268); Chan, Carmen Yip Wing Han (25959492800); Zhang, Meifen (55981559300); Fu, Xia (56066384800)","55387535700; 59470312300; 59655560500; 56241289100; 57223155268; 25959492800; 55981559300; 56066384800","Unveiling the Potential of Large Language Models in Transforming Chronic Disease Management: Mixed Methods Systematic Review","2025","Journal of Medical Internet Research","27","","e70535","","","0","5","10.2196/70535","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003077048&doi=10.2196%2F70535&partnerID=40&md5=744b6380989a115f653d9bc5f08ee573","Sun Yat-Sen University, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China; Conestoga College, Canada, Kitchener, Canada; Chinese University of Hong Kong, Hong Kong, Hong Kong","Li, Caixia, Department of Nursing, Sun Yat-Sen University, Guangzhou, China; Zhao, Yina, Department of Nursing, Sun Yat-Sen University, Guangzhou, China; Bai, Yang, School of Nursing, Sun Yat-Sen University, Guangzhou, China; Zhao, Baoquan, School of Artificial Intelligence, Sun Yat-Sen University, Guangzhou, China; Tola, Yetunde Oluwafunmilayo, Department of Clinical Research, Conestoga College, Canada, Kitchener, Canada; Chan, Carmen Yip Wing Han, The Nethersole School of Nursing, Chinese University of Hong Kong, Hong Kong, Hong Kong; Zhang, Meifen, School of Nursing, Sun Yat-Sen University, Guangzhou, China; Fu, Xia, Department of Nursing, Sun Yat-Sen University, Guangzhou, China","Background: Chronic diseases are a major global health burden, accounting for nearly three-quarters of the deaths worldwide. Large language models (LLMs) are advanced artificial intelligence systems with transformative potential to optimize chronic disease management; however, robust evidence is lacking. Objective: This review aims to synthesize evidence on the feasibility, opportunities, and challenges of LLMs across the disease management spectrum, from prevention to screening, diagnosis, treatment, and long-term care. Methods: Following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analysis) guidelines, 11 databases (Cochrane Central Register of Controlled Trials, CINAHL, Embase, IEEE Xplore, MEDLINE via Ovid, ProQuest Health & Medicine Collection, ScienceDirect, Scopus, Web of Science Core Collection, China National Knowledge Internet, and SinoMed) were searched on April 17, 2024. Intervention and simulation studies that examined LLMs in the management of chronic diseases were included. The methodological quality of the included studies was evaluated using a rating rubric designed for simulation-based research and the risk of bias in nonrandomized studies of interventions tool for quasi-experimental studies. Narrative analysis with descriptive figures was used to synthesize the study findings. Random-effects meta-analyses were conducted to assess the pooled effect estimates of the feasibility of LLMs in chronic disease management. Results: A total of 20 studies examined general-purpose (n=17) and retrieval-augmented generation-enhanced LLMs (n=3) for the management of chronic diseases, including cancer, cardiovascular diseases, and metabolic disorders. LLMs demonstrated feasibility across the chronic disease management spectrum by generating relevant, comprehensible, and accurate health recommendations (pooled accurate rate 71%, 95% CI 0.59-0.83; I2=88.32%) with retrieval-augmented generation-enhanced LLMs having higher accuracy rates compared to general-purpose LLMs (odds ratio 2.89, 95% CI 1.83-4.58; I2=54.45%). LLMs facilitated equitable information access; increased patient awareness regarding ailments, preventive measures, and treatment options; and promoted self-management behaviors in lifestyle modification and symptom coping. Additionally, LLMs facilitate compassionate emotional support, social connections, and health care resources to improve the health outcomes of chronic diseases. However, LLMs face challenges in addressing privacy, language, and cultural issues; undertaking advanced tasks, including diagnosis, medication, and comorbidity management; and generating personalized regimens with real-time adjustments and multiple modalities. Conclusions: LLMs have demonstrated the potential to transform chronic disease management at the individual, social, and health care levels; however, their direct application in clinical settings is still in its infancy. A multifaceted approach that incorporates robust data security, domain-specific model fine-tuning, multimodal data integration, and wearables is crucial for the evolution of LLMs into invaluable adjuncts for health care professionals to transform chronic disease management. © 2025 Elsevier B.V., All rights reserved.","Artificial Intelligence; Chronic Disease; Health Management; Large Language Model; Systematic Review; Adult; Article; Asthma; Awareness; Cardiovascular Disease; Chatgpt; Chronic Disease; Chronic Disease Management; Cohort Analysis; Colorectal Cancer; Comorbidity; Coping; Cultural Factor; Diabetes Mellitus; Drug Dependence; Emotional Support; Feasibility Study; Glaucoma; Health Care Utilization; Health Outcome; Health Promotion; Hearing Impairment; Human; Kidney Failure; Knowledge; Language; Large Language Model; Lifestyle Modification; Liver Cirrhosis; Long Term Care; Male; Malignant Neoplasm; Mental Disease; Meta Analysis; Metabolic Disorder; Multidisciplinary Team; Musculoskeletal Disease; Non Communicable Disease; Osteoarthritis; Personalized Medicine; Physical Activity; Privacy; Prostate Hypertrophy; Quasi Experimental Study; Respiratory Tract Disease; Retrieval Augmented Generation; Self Care; Social Connectedness; Social Support; Systematic Review; Artificial Intelligence; Disease Management; Therapy; Artificial Intelligence; Chronic Disease; Disease Management; Humans; Language; Large Language Models","adult; Article; asthma; awareness; cardiovascular disease; ChatGPT; chronic disease; chronic disease management; cohort analysis; colorectal cancer; comorbidity; coping; cultural factor; diabetes mellitus; drug dependence; emotional support; feasibility study; glaucoma; health care utilization; health outcome; health promotion; hearing impairment; human; kidney failure; knowledge; language; large language model; lifestyle modification; liver cirrhosis; long term care; male; malignant neoplasm; mental disease; meta analysis; metabolic disorder; multidisciplinary team; musculoskeletal disease; non communicable disease; osteoarthritis; personalized medicine; physical activity; privacy; prostate hypertrophy; quasi experimental study; respiratory tract disease; retrieval augmented generation; self care; social connectedness; social support; systematic review; artificial intelligence; disease management; therapy; Artificial Intelligence; Chronic Disease; Disease Management; Humans; Language; Large Language Models","","","The authors thank the librarians from the Chinese University of Hong Kong (Ms Kendy Lau) and Sun Yat-sen University (Ms Hongjuan Zhang) for refining the search strategy for this review. This review was supported by the National Natural Science Foundation of China (72404286), the Shenzhen Medical Research Fund (A2403034), the Shenzhen Science and Technology Program (JCYJ20240813150722029), and the Futian Healthcare Research Project (FTWS026). The funders played no role in the study design, data collection, analysis, and interpretation of the data, or writing of the manuscript.","Noncommunicable Diseases Fact Sheet, (2023); Chowdhury, Saifur Rahman, Global and regional prevalence of multimorbidity in the adult population in community settings: a systematic review and meta-analysis, eClinicalMedicine, 57, (2023); Cordova, Reynalda, Consumption of ultra-processed foods and risk of multimorbidity of cancer and cardiometabolic diseases: a multinational cohort study, The Lancet Regional Health - Europe, 35, (2023); Vollset, Stein Emil, Burden of disease scenarios for 204 countries and territories, 2022–2050: a forecasting analysis for the Global Burden of Disease Study 2021, The Lancet, 403, 10440, pp. 2204-2256, (2024); Santos, Andreia Costa, The cost of inaction on physical inactivity to public health-care systems: a population-attributable fraction analysis, The Lancet Global Health, 11, 1, pp. e32-e39, (2023); Transforming Our World the 2030 Agenda for Sustainable Development, (2025); Badr, Yara, The Use of Big Data in Personalized Healthcare to Reduce Inventory Waste and Optimize Patient Treatment, Journal of Personalized Medicine, 14, 4, (2024); Stefanicka-Wojtas, Dorota, Personalised Medicine—Implementation to the Healthcare System in Europe (Focus Group Discussions), Journal of Personalized Medicine, 13, 3, (2023); Burnier, Michel, The role of adherence in patients with chronic diseases, European Journal of Internal Medicine, 119, pp. 1-5, (2024); Treatment adherence: Can fixed-dose combinations help?, The Lancet Diabetes and Endocrinology, 3, 2, (2015)","","JMIR Publications Inc.","","","","","","14388871","","","40239198","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-105003077048"
"I., Rodríguez-Muñoz-De-Baena, Inés; M., Coronado-Vaca, María; E., Vaquero-Lafuente, Esther","Rodríguez-Muñoz-De-Baena, Inés (59731863400); Coronado-Vaca, María (58243166200); Vaquero-Lafuente, Esther (57209713699)","59731863400; 58243166200; 57209713699","Fine-tuning transformer models for M&A target prediction in the U.S. ENERGY sector","2025","Cogent Business and Management","12","1","2487219","","","0","0","10.1080/23311975.2025.2487219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002336145&doi=10.1080%2F23311975.2025.2487219&partnerID=40&md5=d3def273b16ba5ba438605ed263ccd59","Universidad Pontificia Comillas, Madrid, Spain; Universidad Pontificia Comillas, Escuela Técnica Superior de Ingeniería, Instituto de Investigación Tecnológica, Madrid, Spain","Rodríguez-Muñoz-De-Baena, Inés, Faculty of Economics and Business Administration, Universidad Pontificia Comillas, Madrid, Spain; Coronado-Vaca, María, Faculty of Economics and Business Administration, Universidad Pontificia Comillas, Madrid, Spain; Vaquero-Lafuente, Esther, Faculty of Economics and Business Administration, Universidad Pontificia Comillas, Madrid, Spain, Universidad Pontificia Comillas, Escuela Técnica Superior de Ingeniería, Instituto de Investigación Tecnológica, Madrid, Spain","This study explores the application of transformer models directly for classification in predicting mergers and acquisitions (M&A) targets within the U.S. energy sector. The primary objective is to evaluate the capability and performance of various transformer-based models in directly predicting M&A target companies, while the secondary objective investigates the relationship between target companies and renewable energy terminology in their annual reports. We present a novel approach to predicting M&A targets by utilizing cutting-edge Natural Language Processing (NLP) techniques, such as fine-tuned transformer LLMs (Large Language Models) for direct classification. We analyze textual data from 200 publicly-listed US energy companies’ SEC-filings and employ FinBERT, ALBERT, and GPT-3-babage-002 as predictive models of M&A targets. We provide empirical evidence on LLMs’ capability in the direct classification of M&A target companies, with FinBERT utilizing oversampling, being the top-performing model due to its high precision and minimized false positives, critical for precise financial decision-making. Additionally, while the study revealed key differences in target and non-target report characteristics, it finds no significant evidence that M&A target companies use more renewable energy-related terminology. It is the first paper applying fine-tuned transformer-LLMs to predict M&A targets, effectively showcasing their capability for this task of direct classification as predictive models. © 2025 Elsevier B.V., All rights reserved.","Algorithms & Complexity; Artificial Intelligence; Business, Management And Accounting; Computer Science (general); Corporate Finance; Environmental Economics; Finance; Green M&a; Large Language Models (llm); Mergers And Acquisitions (m&a); Natural Language Processing (nlp); Renewable Energy; Takeover Target Prediction; Transformer Models","","","","","Aaldering, Lukas Jan, Uncovering the dynamics of market convergence through M&A, Technological Forecasting and Social Change, 138, pp. 95-114, (2019); International Journal of Finance and Accounting, (2016); Ahmad, Tanveer, A critical review of comparative global historical energy consumption and future demand: The story told so far, Energy Reports, 6, pp. 1973-1991, (2020); An, Shi, Measurement of merger and acquisition performance based on artificial neural network, 1, pp. 502-506, (2006); Anagnostopoulos, Yiannis, Confining value from neural networks: A sectoral study prediction of takeover targets in the US technology sector, Managerial Finance, 45, 10-11, pp. 1433-1457, (2019); Anagnostopoulos, Yiannis, Conventional and neural network target-matching methods dynamics: The information technology mergers and acquisitions market in the USA, Intelligent Systems in Accounting, Finance and Management, 28, 2, pp. 97-118, (2021); Andriuškevičius, Karolis, Developments and trends of mergers and acquisitions in the energy industry, Energies, 14, 8, (2021); Prediction of M A Targets to Generate Portfolio Returns, (2021); Predicting M A Targets Using ml Unlocking the Potential of Nlp Based Variables, (2022); Barros, Victor, M&A activity as a driver for better ESG performance, Technological Forecasting and Social Change, 175, (2022)","","Cogent OA","","","","","","23311975","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-105002336145"
"M., Wawer, Michał; J.A., Chudziak, Jarosław A.","Wawer, Michał (59489436100); Chudziak, Jarosław A. (6507651188)","59489436100; 6507651188","Integrating Traditional Technical Analysis with AI: A Multi-Agent LLM-Based Approach to Stock Market Forecasting","2025","International Conference on Agents and Artificial Intelligence","1","","","100","111","0","1","10.5220/0013191200003890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001682256&doi=10.5220%2F0013191200003890&partnerID=40&md5=7ee35b15938d3b7d1e71bfd906156883","Politechnika Warszawska, Warsaw, Poland","Wawer, Michał, Institute of Computer Science, Politechnika Warszawska, Warsaw, Poland; Chudziak, Jarosław A., Institute of Computer Science, Politechnika Warszawska, Warsaw, Poland","Traditional technical analysis methods face limitations in accurately predicting trends in today’s complex f inancial markets. This paper introduces ElliottAgents, an multi-agent system that integrates the Elliott Wave Principle with AI for stock market forecasting. The inherent complexity of financial markets, characterized by non-linear dynamics, noise, and susceptibility to unpredictable external factors, poses significant challenges for accurate prediction. To address these challenges, the system employs LLMs to enhance natural language understanding and decision-making capabilities within a multi-agent framework. By leveraging technologies such as Retrieval-Augmented Generation (RAG) and Deep Reinforcement Learning (DRL), ElliottAgents performs continuous, multi-faceted analysis of market data to identify wave patterns and predict future price movements. The research explores the system’s ability to process historical stock data, recognize Elliott wave patterns, and generate actionable insights for traders. Experimental results, conducted on historical data from major U.S. companies, validate the system’s effectiveness in pattern recognition and trend forecasting across various time frames. This paper contributes to the field of AI-driven financial analysis by demonstrating how traditional technical analysis methods can be effectively combined with modern AI approaches to create more reliable and interpretable market prediction systems. © 2025 Elsevier B.V., All rights reserved.","","","","","","Abrishami, Soheila, Enhancing profit by predicting stock prices using deep neural networks, 2019-November, pp. 1551-1556, (2019); Ire J, (2021); Generative AI with Langchain Build Large Language Model Llm Apps with Python Chatgpt and Other Llms, (2023); Fibonacci Trading how to Master the Time and Price Advantage, (2008); Understand the Llm Agent Orchestration, (2024); Chateval Towards Better Llm Based Evaluators Through Multi Agent Debate, (2023); Chudziak, Adam, Predictability of stock returns using neural networks: Elusive in the long term, Expert Systems with Applications, 213, (2023); Proceedings of the 38th Pacific Asia Conference on Language Information and Computation, (2024); Exploring Large Language Model Based Intelligent Agents Definitions Methods and Prospects, (2024); Retrieval Augmented Generation for Knowledge Intensive Nlp Tasks, (2020)","Rocha, A.P.; Steels, L.; van den Herik, H.J.","Science and Technology Publications, Lda","","17th International Conference on Agents and Artificial Intelligence, ICAART 2025","","Porto","328949","21843589; 2184433X","9789897583957; 9789897586231; 9789897583506; 9789897585470; 9789897584848","","","English","Conference paper","Final","All Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-105001682256"
"D., Wang, Dawei; G., Zhou, Geng; L., Chen, Li; D., Li, Dan; Y., Miao, Yukai","Wang, Dawei (59341243100); Zhou, Geng (59341279700); Chen, Li (58606223300); Li, Dan (58363591300); Miao, Yukai (57195626178)","59341243100; 59341279700; 58606223300; 58363591300; 57195626178","ProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations with Only Documentation via Large Language Model","2024","","","","","735","749","0","1","10.1145/3658644.3690231","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215500890&doi=10.1145%2F3658644.3690231&partnerID=40&md5=6ef475a41f9980d9bd29c3101c081e5a","Zhongguancun Laboratory, Beijing, China; Tsinghua University, Beijing, China","Wang, Dawei, Zhongguancun Laboratory, Beijing, China; Zhou, Geng, Zhongguancun Laboratory, Beijing, China; Chen, Li, Zhongguancun Laboratory, Beijing, China; Li, Dan, Tsinghua University, Beijing, China; Miao, Yukai, Zhongguancun Laboratory, Beijing, China","Vulnerabilities related to option combinations pose a significant challenge in software security testing due to their vast search space. Previous research primarily addressed this challenge through mutation or filtering techniques, which inefficiently treated all option combinations as having equal potential for vulnerabilities, thus wasting considerable time on non-vulnerable targets and resulting in low testing efficiency. In this paper, we utilize carefully designed prompt engineering to drive the large language model (LLM) to predict high-risk option combinations (i.e., more likely to contain vulnerabilities) and perform fuzz testing automatically without human intervention. We developed a tool called ProphetFuzz and evaluated it on a dataset comprising 52 programs collected from three related studies. The entire experiment consumed 10.44 CPU years. ProphetFuzz successfully predicted 1748 high-risk option combinations at an average cost of only $8.69 per program. Results show that after 72 hours of fuzzing, ProphetFuzz discovered 364 unique vulnerabilities associated with 12.30% of the predicted high-risk option combinations, which was 32.85% higher than that found by state-of-the-art in the same timeframe. Additionally, using ProphetFuzz, we conducted persistent fuzzing on the latest versions of these programs, uncovering 140 vulnerabilities, with 93 confirmed by developers and 21 awarded CVE numbers. © 2025 Elsevier B.V., All rights reserved.","Fuzzing; Large Language Model; Option-aware; Vulnerability; Program Processors; Filtering Technique; Fully Automated; Fuzzing; Language Model; Large Language Model; Option-aware; Search Spaces; Software Security Testing; Testing Efficiency; Vulnerability; Software Testing","Program processors; Filtering technique; Fully automated; Fuzzing; Language model; Large language model; Option-aware; Search spaces; Software security testing; Testing efficiency; Vulnerability; Software testing","","","","Gpt 4 Technical Report, (2023); Akgul, Omer, Bug Hunters' Perspectives on the Challenges and Benefits of the Bug Bounty Ecosystem, 4, pp. 2275-2291, (2023); Böhme, Marcel, Coverage-Based Greybox Fuzzing as Markov Chain, IEEE Transactions on Software Engineering, 45, 5, pp. 489-506, (2019); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Deng, Yinlin, Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models, pp. 423-435, (2023); Deng, Yinlin, Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries, Proceedings - International Conference on Software Engineering, (2024); Testcase of Pdf, (2019); Covrl Fuzzing Javascript Engines with Coverage Guided Reinforcement Learning for Llm Based Mutation, (2024); Fioraldi, Andrea, AFL++: Combining incremental steps of fuzzing research, (2020); Proceedings of the International Conference on Learning Representations Iclr, (2022)","","Association for Computing Machinery, Inc","ACM SIGSAC","31st ACM SIGSAC Conference on Computer and Communications Security, CCS 2024","","Salt Lake City; UT","205272","","9798400706363","","","English","Conference paper","Final","All Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-85215500890"
"","","","ICoMS 2024 - Proceedings of 2024 7th International Conference on Mathematics and Statistics","2024","","","","","","","130","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216098698&partnerID=40&md5=ad47e1ed456cc0e6545f0532122821dd","","","The proceedings contain 21 papers. The topics discussed include: spike it up: enhancing STL with spike detection for intraday volatility and liquidity forecasting; enhancing spatially-disaggregated simulations with large language models; the pricing of mortgage loan guarantee insurance under fractional Brownian motion; robust covariance matrix estimator with change points for multivariate jump diffusion process; development and validation of an automated weight window generator for reactor Monte Carlo programs; comparison of machine learning methods for binary classification of multicollinearity data; revisiting the problem of uniqueness in sparse reconstruction; and Lagrange multipliers applied to constrained maximization of volume of frustum of a right circular cone. © 2025 Elsevier B.V., All rights reserved.","","","","","","","","Association for Computing Machinery","","7th International Conference on Mathematics and Statistics, ICoMS 2024","","Amarante","205772","","9798400712838; 9798400707254; 9798400717802; 9798400710919; 9798400710063; 9798400707223","","","English","Conference review","Final","","Scopus","2-s2.0-85216098698"
"S., Sanduleanu, Sebastian; K., Ersahin, Koray; J., Bremm, Johannes; N., Talibova, Narmin; T., Damer, Tim; M., Erdogan, Merve; J., Kottlors, Jonathan; L., Goertz, Lukas; C.J., Bruns, Christiane Josephine; D., Maintz, David","Sanduleanu, Sebastian (57202113771); Ersahin, Koray (59361485900); Bremm, Johannes (57216528112); Talibova, Narmin (57201704938); Damer, Tim (59360648600); Erdogan, Merve (59361320500); Kottlors, Jonathan (55699264200); Goertz, Lukas (57202376929); Bruns, Christiane Josephine (57216057302); Maintz, David (7003929179)","57202113771; 59361485900; 57216528112; 57201704938; 59360648600; 59361320500; 55699264200; 57202376929; 57216057302; 7003929179","Feasibility of GPT-3.5 versus Machine Learning for Automated Surgical Decision-Making Determination: A Multicenter Study on Suspected Appendicitis","2024","AI (Switzerland)","5","4","","1942","1954","0","2","10.3390/ai5040096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213433064&doi=10.3390%2Fai5040096&partnerID=40&md5=ec7558f4a78f986219ffed6d55ed2324","Universität Bonn, Bonn, Germany; Medizinische Fakultät, Koln, Germany; Universitätsklinikum Ulm, Ulm, Germany; Universität Bonn, Bonn, Germany; Uniklinik Köln, Koln, Germany; Centrum für Integrierte Onkologie, Aachen, Germany","Sanduleanu, Sebastian, ; Ersahin, Koray, Department of General and Visceral Surgery, Universität Bonn, Bonn, Germany; Bremm, Johannes, Institute for Diagnostic and Interventional Radiology, Medizinische Fakultät, Koln, Germany; Talibova, Narmin, Department of Internal Medicine, Universitätsklinikum Ulm, Ulm, Germany; Damer, Tim, Department of General and Visceral Surgery, Universität Bonn, Bonn, Germany; Erdogan, Merve, Department of Radiology/Neuroradiology, Universität Bonn, Bonn, Germany; Kottlors, Jonathan, Institute for Diagnostic and Interventional Radiology, Medizinische Fakultät, Koln, Germany; Goertz, Lukas, Institute for Diagnostic and Interventional Radiology, Medizinische Fakultät, Koln, Germany; Bruns, Christiane Josephine, Department of Genetics, Uniklinik Köln, Koln, Germany, Centrum für Integrierte Onkologie, Aachen, Germany; Maintz, David, Institute for Diagnostic and Interventional Radiology, Medizinische Fakultät, Koln, Germany","Background: Nonsurgical treatment of uncomplicated appendicitis is a reasonable option in many cases despite the sparsity of robust, easy access, externally validated, and multimodally informed clinical decision support systems (CDSSs). Developed by OpenAI, the Generative Pre-trained Transformer 3.5 model (GPT-3) may provide enhanced decision support for surgeons in less certain appendicitis cases or those posing a higher risk for (relative) operative contra-indications. Our objective was to determine whether GPT-3.5, when provided high-throughput clinical, laboratory, and radiological text-based information, will come to clinical decisions similar to those of a machine learning model and a board-certified surgeon (reference standard) in decision-making for appendectomy versus conservative treatment. Methods: In this cohort study, we randomly collected patients presenting at the emergency department (ED) of two German hospitals (GFO, Troisdorf, and University Hospital Cologne) with right abdominal pain between October 2022 and October 2023. Statistical analysis was performed using R, version 3.6.2, on RStudio, version 2023.03.0 + 386. Overall agreement between the GPT-3.5 output and the reference standard was assessed by means of inter-observer kappa values as well as accuracy, sensitivity, specificity, and positive and negative predictive values with the “Caret” and “irr” packages. Statistical significance was defined as p < 0.05. Results: There was agreement between the surgeon’s decision and GPT-3.5 in 102 of 113 cases, and all cases where the surgeon decided upon conservative treatment were correctly classified by GPT-3.5. The estimated model training accuracy was 83.3% (95% CI: 74.0, 90.4), while the validation accuracy for the model was 87.0% (95% CI: 66.4, 97.2). This is in comparison to the GPT-3.5 accuracy of 90.3% (95% CI: 83.2, 95.0), which did not perform significantly better in comparison to the machine learning model (p = 0.21). Conclusions: This study, the first study of the “intended use” of GPT-3.5 for surgical treatment to our knowledge, comparing surgical decision-making versus an algorithm found a high degree of agreement between board-certified surgeons and GPT-3.5 for surgical decision-making in patients presenting to the emergency department with lower abdominal pain. © 2024 Elsevier B.V., All rights reserved.","Appendectomy; Artificial Intelligence; Surgical Decision-making","","","","This study received partial funding from NUM 2 (Netzwerk Universit\u00E4tsmedizin, Berlin, Germany) (FKZ: 01KX2121).","Di Saverio, S., Diagnosis and treatment of acute appendicitis: 2020 update of the WSES Jerusalem guidelines, World Journal of Emergency Surgery, 15, 1, (2020); Sceats, Lindsay Anne, Nonoperative Management of Uncomplicated Appendicitis among Privately Insured Patients, JAMA Surgery, 154, 2, (2019); Ilves, Imre, Seasonal variations of acute appendicitis and nonspecific abdominal pain in Finland, World Journal of Gastroenterology, 20, 14, pp. 4037-4042, (2014); Viniol, Annika, Studies of the symptom abdominal pain - A systematic review and meta-analysis, Family Practice, 31, 5, pp. 517-529, (2014); Bhangu, Aneel Amir, Acute appendicitis: Modern understanding of pathogenesis, diagnosis, and management, The Lancet, 386, 10000, pp. 1278-1287, (2015); Gomes, Carlos Augusto, Management of Appendicitis Globally Based on Income of Countries (MAGIC) Study, World Journal of Surgery, 42, 12, pp. 3903-3910, (2018); Livingston, Edward H., Disconnect between incidence of nonperforated and perforated appendicitis: Implications for pathophysiology and management, Annals of Surgery, 245, 6, pp. 886-892, (2007); Potey, Ketika, Study of outcomes of perforated appendicitis in adults: a prospective cohort study, Annals of Medicine and Surgery, 85, 4, pp. 694-700, (2023); Mulita, Francesk, Comparison of intra-abdominal abscess formation after laparoscopic and open appendectomy for complicated and uncomplicated appendicitis: A retrospective study, Wideochirurgia I Inne Techniki Maloinwazyjne, 16, 3, pp. 560-565, (2021); Burini, Gloria, Aspiration versus peritoneal lavage in appendicitis: a meta-analysis, World Journal of Emergency Surgery, 16, 1, (2021)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","26732688","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85213433064"
"Y., Li, Yi; H., Li, Hao; X., Xu, Xiaozhe; Y., Yang, Yifan","Li, Yi (59460582100); Li, Hao (59460346700); Xu, Xiaozhe (59459867700); Yang, Yifan (59459376600)","59460582100; 59460346700; 59459867700; 59459376600","CFB：Financial Large Models Evaluation Methods; CFB：金融领域大模型评估方法","2024","Journal of Frontiers of Computer Science and Technology","18","12","","3272","3287","0","1","10.3778/j.issn.1673-9418.2406055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211137669&doi=10.3778%2Fj.issn.1673-9418.2406055&partnerID=40&md5=b0924071f99441c5aa8f0bcb88d6c56d","Shanxi University of Finance and EcoNomics, Taiyuan, China; Shanxi University of Finance and EcoNomics, Taiyuan, China; Taiyuan University of Technology, Taiyuan, China; Zhongnan University of Economics and Law, Wuhan, China","Li, Yi, School of Information, Shanxi University of Finance and EcoNomics, Taiyuan, China; Li, Hao, School of Statistics, Shanxi University of Finance and EcoNomics, Taiyuan, China; Xu, Xiaozhe, College of Mechanical Engineering, Taiyuan University of Technology, Taiyuan, China; Yang, Yifan, School of Information Engineering, Zhongnan University of Economics and Law, Wuhan, China","As the potential applications of large language models (LLMs) in the financial sector continue to emerge, evaluating the performance of financial LLMs becomes increasingly important. However, current financial evaluation methods face limitations such as singular evaluation tasks, insufficient coverage of evaluation datasets, and contamination of benchmark data. Consequently, the potential of LLMs in the financial domain has not been fully explored. To address these issues, this paper proposes the Chinese financial benchmark (CFB) for evaluating financial LLMs. The CFB encompasses 36 datasets, covers 24 financial tasks, and involves 7 evaluation tasks: question answering, terminology explanation, text generation, text translation, classification task, voice recognition, and predictive decision. It also establishes corresponding benchmarks. The new approach of the CFB includes a broader range of tasks and data, the introduction of a benchmark decontamination method based on LLMs, and three evaluation methods: instruction fine- tuning, knowledge retrieval enhancement, and prompt engineering. The evaluation of 12 LLMs, including GPT- 4o, ChatGPT, and Gemini, reveals that though LLMs excel in information extraction and text analysis, they struggle with advanced reasoning and complex tasks. GPT- 4o performs exceptionally in information extraction and stock trading, whereas Gemini excels in text generation and prediction. Instruction fine- tuning improves LLMs’performance in text analysis but offers limited benefits for complex tasks. © 2024 Elsevier B.V., All rights reserved.","Evaluation Benchmark; Financial Large Models; Instruction Fine-tuning; Knowledge Retrieval Enhancement; Prompt Engineering","","","","Funding text 1: This work was supported by the Humanities and Social Sciences Research Planning Fund of the Ministry of Education of China (20YJA910004), the National Statistical Science Research Program (2022LZ14), the Basic Research Program for Outstanding Youth of Shanxi Province (202303021223010), the National Natural Science Foundation of China for Young Scientists (72304176), the Key Project of Shanxi Province for the Preferential Support of Scientific Activities by Returned Overseas Students (20220025), and the Central Guiding Local Science and Technology Development Fund (YDZJSX20231A057).; Funding text 2: This work was supported by the Humanities and Social Sciences Research PlanningDFundFoftheMinistryofEducationofChina (20YJA910004), the National Statistical Science Research Program (2022LZ14), the Basic Research Program for Outstanding Youth of","Gpt 4 Technical Report, (2023); Sparks of Artificial General Intelligence Early Experiments with Gpt 4, (2023); Laiw A Chinese Legal Large Language Models Benchmark A Technical Report; undefined; Empowering Many Biasing A Few Generalist Credit Scoring Through Large Language Models, (2023); Pixiu A Large Language Model Instruction Data and Evaluation Benchmark for Finance; undefined; Fineval A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models, (2023); Rethinking Benchmark and Contamination for Language Models with Rephrased Samples, (2023); A Careful Examination of Large Language Model Performance on Grade School Arithmetic, (2024)","","Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press","","","","","","16739418","","","","Chinese","Article","Final","","Scopus","2-s2.0-85211137669"
"O., Musbahi, Omar; M., Nurek, Martine; K., Pouris, Kyriacos; M., Vella-Baldacchino, Martinique; A., Bottle, Alex; C.B., Hing, Caroline B.; O., Kostopoulou, Olga; J.P., Cobb, Justin Peter; G.G., Jones, Gareth G.","Musbahi, Omar (56928322400); Nurek, Martine (56433376900); Pouris, Kyriacos (59921479500); Vella-Baldacchino, Martinique (56094439400); Bottle, Alex (6701752249); Hing, Caroline B. (16834495600); Kostopoulou, Olga (6602915394); Cobb, Justin Peter (7202728836); Jones, Gareth G. (57050720700)","56928322400; 56433376900; 59921479500; 56094439400; 6701752249; 16834495600; 6602915394; 7202728836; 57050720700","Can ChatGPT make surgical decisions with confidence similar to experienced knee surgeons?","2024","Knee","51","","","120","129","0","3","10.1016/j.knee.2024.08.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203407552&doi=10.1016%2Fj.knee.2024.08.015&partnerID=40&md5=4425fedef6cd8a1134439618047f9ddd","Imperial College London, London, United Kingdom; Imperial College London, London, United Kingdom; Imperial College London, London, United Kingdom; St George's University Hospitals NHS Foundation Trust, London, United Kingdom; Imperial College London, London, United Kingdom","Musbahi, Omar, Imperial College London, London, United Kingdom; Nurek, Martine, Imperial College London, London, United Kingdom; Pouris, Kyriacos, Imperial College London, London, United Kingdom; Vella-Baldacchino, Martinique, Imperial College London, London, United Kingdom; Bottle, Alex, School of Public Health, Imperial College London, London, United Kingdom; Hing, Caroline B., St George's University Hospitals NHS Foundation Trust, London, United Kingdom; Kostopoulou, Olga, Imperial College London, London, United Kingdom, Institute of Global Health Innovation, Imperial College London, London, United Kingdom; Cobb, Justin Peter, Imperial College London, London, United Kingdom; Jones, Gareth G., Imperial College London, London, United Kingdom","Background: Unicompartmental knee replacements (UKRs) have become an increasingly attractive option for end-stage single-compartment knee osteoarthritis (OA). However, there remains controversy in patient selection. Natural language processing (NLP) is a form of artificial intelligence (AI). We aimed to determine whether general-purpose open-source natural language programs can make decisions regarding a patient's suitability for a total knee replacement (TKR) or a UKR and how confident AI NLP programs are in surgical decision making. Methods: We conducted a case-based cohort study using data from a separate study, where participants (73 surgeons and AI NLP programs) were presented with 32 fictitious clinical case scenarios that simulated patients with predominantly medial knee OA who would require surgery. Using the overall UKR/TKR judgments of the 73 experienced knee surgeons as the gold standard reference, we calculated the sensitivity, specificity, and positive predictive value of AI NLP programs to identify whether a patient should undergo UKR. Results: There was disagreement between the surgeons and ChatGPT in only five scenarios (15.6%). With the 73 surgeons’ decision as the gold standard, the sensitivity of ChatGPT in determining whether a patient should undergo UKR was 0.91 (95% confidence interval (CI): 0.71 to 0.98). The positive predictive value for ChatGPT was 0.87 (95% CI: 0.72 to 0.94). ChatGPT was more confident in its UKR decision making (surgeon mean confidence = 1.7, ChatGPT mean confidence = 2.4). Conclusions: It has been demonstrated that ChatGPT can make surgical decisions, and exceeded the confidence of experienced knee surgeons with substantial inter-rater agreement when deciding whether a patient was most appropriate for a UKR. © 2024 Elsevier B.V., All rights reserved.","Artificial Intelligence; Decision Making; Knee Arthroplasty; Natural Language Processing; Adult; Article; Calculation; Chatgpt; Clinical Article; Clinical Decision Making; Cohort Analysis; Confidence Interval; Controlled Study; Diagnostic Test Accuracy Study; Gold Standard; Human; Interrater Reliability; Knee Osteoarthritis; Medial Meniscus; Middle Aged; Natural Language Processing; Orthopedic Surgeon; Patient Selection; Predictive Value; Sensitivity And Specificity; Total Knee Arthroplasty; Artificial Intelligence; Clinical Competence; Female; Knee Replacement; Male; Procedures; Surgeon; Surgery; Arthroplasty, Replacement, Knee; Artificial Intelligence; Clinical Competence; Clinical Decision-making; Female; Humans; Male; Middle Aged; Natural Language Processing; Osteoarthritis, Knee; Patient Selection; Surgeons","adult; Article; calculation; ChatGPT; clinical article; clinical decision making; cohort analysis; confidence interval; controlled study; diagnostic test accuracy study; gold standard; human; interrater reliability; knee osteoarthritis; medial meniscus; middle aged; natural language processing; orthopedic surgeon; patient selection; predictive value; sensitivity and specificity; total knee arthroplasty; artificial intelligence; clinical competence; female; knee replacement; male; procedures; surgeon; surgery; Arthroplasty, Replacement, Knee; Artificial Intelligence; Clinical Competence; Clinical Decision-Making; Female; Humans; Male; Middle Aged; Natural Language Processing; Osteoarthritis, Knee; Patient Selection; Surgeons","","","Funding text 1: The authors gratefully acknowledge infrastructure support from the NIHR Academy, NIHR Imperial Patient Safety Translational Research Centre, the NIHR Imperial Biomedical Research Centre, and the NIHR Clinical Research Network. The views expressed are those of the authors and not necessarily those of the NIHR or the Department of Health and Social Care. Members of the UNITES Consortium are also acknowledged for supporting this research: Barry Andrews, Tony Smith, P. J. Walmsley, David W. Elson, Alex Anderson, Chloe E. H. Scott, Alasdair J. A. Santini, Benedict J. A. Lankester, J. William Tice, Reza Mansouri, Arjuna Imbuldeniya, Tarek Boutefnouchet, Nathanael Ahearn, Stefan Bajada, James R. A. Smith, Pregash Ellapparadja, Alan R. Norrish, Sean O'Leary, Jon Campion, Benjamin V. Bloch, Ricardo J. Pacheco, Simon B. Barton, Adrian Cassar-Gheiti, David Selvan, Jonathan Phillips, Sushrut Kulkarni, Randeep S. Aujla, Philip G. Turner, Amit Patel, Rahul S. Kotwal, Ashim Mannan, Rahul Bhattacharyya, Ahmed Mabrouk Aaron Biing Yann, Keshav Mathur, Muhammad Adeel Akhtar, Robert William Walker, Rakesh Kucheria, A. D. Liddle, Lebur Rohman, Ravikumar Pydisetty, Manish Divekar, Manish Kiran, David Houlihan-Burne, N. D. Rossiter, Sanjeev Agarwal, N. J. London, A. D. Toms, Zuhair Nawaz, Phil Hopgood, Ghias Bhattee, Moez Zeiton, Khalid Al-DadahHywel Davies, Oliver S. Schindler, H. B. Waterson, S. P. White, A. J. Kelly, Yuvraj Agrawal, Christopher Wilson, Nicholas E. Ohly, Andrew Lavender, Morgan Bayley, Fazal Ali, Nivraj Singh Bhamber, Tarique Parwez, Christopher Buckle, Zameer Shah, Jeremy Rushbrook, Damon Simmons, Amit Bishnoi, Reshid Berber, Richard Parkinson, D. Prakash, James R. D. Murray, Sujit Agarwal.; Funding text 2: O.M. is sponsored by NIHR grant (NIHR ID 302632). M.N. was supported by an NIHR Imperial Patient Safety Translational Research Centre grant (award number PSTRC-2016-004). All surgeons who took part were reimbursed \u00A350 for their time (NIHR Imperial PSTRC grant, award number PSTRC-2016-004). A.B.\u2019s Unit at Imperial is affiliated with the National Institute of Health Research (NIHR) Imperial Patient Safety Translational Research Centre. The NIHR Imperial Patient Safety Translational Centre is a partnership between the Imperial College Healthcare NHS Trust and Imperial College London.","Vos, Theo, Years lived with disability (YLDs) for 1160 sequelae of 289 diseases and injuries 1990-2010: A systematic analysis for the Global Burden of Disease Study 2010, The Lancet, 380, 9859, pp. 2163-2196, (2012); Long, Huibin, Prevalence Trends of Site-Specific Osteoarthritis From 1990 to 2019: Findings From the Global Burden of Disease Study 2019, Arthritis and Rheumatology, 74, 7, pp. 1172-1183, (2022); undefined; Mittal, Anurag, Unicompartmental knee arthroplasty, an enigma, and the ten enigmas of medial UKA, Journal of Orthopaedics and Traumatology, 21, 1, (2020); undefined, (2020); Liddle, Alexander D., Adverse outcomes after total and unicompartmental knee replacement in 101330 matched patients: A study of data from the National Joint Registry for England and Wales, The Lancet, 384, 9952, pp. 1437-1445, (2014); Zuiderbaan, Hendrik Aernout, Unicompartmental knee arthroplasty versus total knee arthroplasty: Which type of artificial joint do patients forget?, Knee Surgery, Sports Traumatology, Arthroscopy, 25, 3, pp. 681-686, (2017); Wiik, Anatole Vilhelm, Unicompartmental knee arthroplasty enables near normal gait at higher speeds, unlike total knee arthroplasty, Journal of Arthroplasty, 28, 9 SUPPL, pp. 176-178, (2013); Beard, David John, The clinical and cost-effectiveness of total versus partial knee replacement in patients with medial compartment osteoarthritis (TOPKAT): 5-year outcomes of a randomised controlled trial, The Lancet, 394, 10200, pp. 746-756, (2019); Kozinn, Stuart C., Current concepts review unicondylar knee arthroplasty, Journal of Bone and Joint Surgery, 71, 1, pp. 145-150, (1989)","","Elsevier B.V.","","","","","","09680160; 18735800","","KNEEF","39255525","English","Article","Final","","Scopus","2-s2.0-85203407552"
"L.T., Maloney, Laurence T.; M.F., Dal Martello, Maria F.; V., Fei, Vivian; V., Ma, Valerie","Maloney, Laurence T. (7005595017); Dal Martello, Maria F. (9434447500); Fei, Vivian (58699940500); Ma, Valerie (58666573300)","7005595017; 9434447500; 58699940500; 58666573300","A comparison of human and GPT-4 use of probabilistic phrases in a coordination game","2024","Scientific Reports","14","1","6835","","","0","3","10.1038/s41598-024-56740-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188322551&doi=10.1038%2Fs41598-024-56740-9&partnerID=40&md5=1ead2dac212d0002c9ae304dbd806af5","New York University, New York, United States; New York University, New York, United States; Università degli Studi di Padova, Padua, Italy","Maloney, Laurence T., Department of Psychology, New York University, New York, United States, New York University, New York, United States; Dal Martello, Maria F., Department of Psychology, New York University, New York, United States, Dipartmento di Psicologia Generale, Università degli Studi di Padova, Padua, Italy; Fei, Vivian, Department of Psychology, New York University, New York, United States; Ma, Valerie, Department of Psychology, New York University, New York, United States","English speakers use probabilistic phrases such as likely to communicate information about the probability or likelihood of events. Communication is successful to the extent that the listener grasps what the speaker means to convey and, if communication is successful, individuals can potentially coordinate their actions based on shared knowledge about uncertainty. We first assessed human ability to estimate the probability and the ambiguity (imprecision) of twenty-three probabilistic phrases in a coordination game in two different contexts, investment advice and medical advice. We then had GPT-4 (OpenAI), a Large Language Model, complete the same tasks as the human participants. We found that GPT-4’s estimates of probability both in the Investment and Medical Contexts were as close or closer to that of the human participants as the human participants’ estimates were to one another. However, further analyses of residuals disclosed small but significant differences between human and GPT-4 performance. Human probability estimates were compressed relative to those of GPT-4. Estimates of probability for both the human participants and GPT-4 were little affected by context. We propose that evaluation methods based on coordination games provide a systematic way to assess what GPT-4 and similar programs can and cannot do. © 2024 Elsevier B.V., All rights reserved.","Ambiguity; Gpt-4; Llm; Pragmatics; Probabilistic Phrases; Probability; Human; Interpersonal Communication; Investment; Knowledge; Language; Probability; Communication; Humans; Investments; Knowledge; Language; Probability","human; interpersonal communication; investment; knowledge; language; probability; Communication; Humans; Investments; Knowledge; Language; Probability","","","LTM: Partial support from the Institut d’études avancées de Paris, Paris, France. We thank Garrison Cottrell, Catherine Hanson, Stephen Hanson, Boris Power, and Edwin Williams for comments on earlier drafts.","O'Brien, B. J., Words or numbers? The evaluation of probability expressions in general practice., Journal of the Royal College of General Practitioners, 39, 320, pp. 98-100, (1989); Strategy of Conflict, (1960); Convention, (2002); Franke, Michael, Game theoretic pragmatics, Philosophy Compass, 8, 3, pp. 269-284, (2013); Language Games and Evolution, (2011); Game Theory and Pragmatics, (2005); Benz, Anton, Game-theoretic approaches to pragmatics, Annual Review of Linguistics, 4, pp. 173-191, (2018); undefined; How to do Things with Words, (1962); Studies in the Way of Words, (1989)","","Nature Research","","","","","","20452322","","","38514688","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85188322551"
"K., Venkatesh Raja, K.; R., Siddharth, R.; S., Yuvaraj, S.; K.A., Ramesh Kumar, Kandasamy Athiyanan","Venkatesh Raja, K. (37117669900); Siddharth, R. (58909906400); Yuvaraj, S. (57191173586); Ramesh Kumar, Kandasamy Athiyanan (58585472100)","37117669900; 58909906400; 57191173586; 58585472100","An Artificial Intelligence based automated case-based reasoning (CBR) system for severity investigation and root-cause analysis of road accidents – Comparative analysis with the predictions of ChatGPT","2024","Journal of Engineering Research (Kuwait)","12","4","","895","903","0","10","10.1016/j.jer.2023.09.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186253328&doi=10.1016%2Fj.jer.2023.09.019&partnerID=40&md5=fb5a6cfa2feeee1dcbc3d6af03055e26","Sona College of Technology, Salem, India; National Institute of Ocean Technology India, Chennai, India; Periyar University, Salem, India","Venkatesh Raja, K., Department of Mechanical Engineering, Sona College of Technology, Salem, India; Siddharth, R., Department of Mechanical Engineering, Sona College of Technology, Salem, India; Yuvaraj, S., National Institute of Ocean Technology India, Chennai, India; Ramesh Kumar, Kandasamy Athiyanan, Department of Energy Science and Technology, Periyar University, Salem, India","Road accidents have been progressively causing havoc in our society and certain preventive measures must be taken to reduce or possibly eliminate road accidents. The derivative of a road accident ranges from a mild injury to casualty. This research work mainly focusses on developing a novel case-based reasoning system to investigate and troubleshoot the cause of road accidents on a war-foot basis. First, the dominant attributes contributing to the cause of road accidents are identified and finalized as 28. A unique road accident dataset is developed which comprises of 1028 data collected from web resources, popular news magazines and extended further to large scale database of one-million cases by biased random number simulation. Each attribute is given a severity weightage of 1,2 and 3 for computing the net weighted score for a case in the database. Also, non-weighted scores are computed by introduction of a primary number dataset to maintain the uniqueness of the score which is further used for similarity analytics. Now, an accident news is randomly selected, and Rapid automatic keyword extraction (RAKE) schema is used as Natural language processor (NLP) for extracting the dominant keywords from the news articles. The extracted keywords are compared and further mapped into a factor-matrix comprising 28 attributes causing road accidents. Further, similarity analytics is performed to evaluate the severity scores and comparison of new cases. The system demonstrated high retrieval accuracy with all road accident cases collected from real world scenarios. This research has great prospects on troubleshooting road accident cases effectively and provides instant promising troubleshooting measures to prevent such accidents in the future. Also, the proposed framework might be useful for intelligent decision-making systems and automated driving systems. Based on the final outlook, a comprehensive framework for national road safety could be developed and passed as a valid law for implementation. Finally, the forecasted results of the proposed algorithm are compared with the predictions of Chat GPT program. © 2024 Elsevier B.V., All rights reserved.","Accident Analysis; Artificial Intelligence; Case-based Reasoning; Chat Gpt; Natural Language Processing; Root Cause Analysis","","","","","Chen, Mengqi, Case-based reasoning system for fault diagnosis of aero-engines, Expert Systems with Applications, 202, (2022); Adi Journal on Recent Innovation, (2022); Guerrero, J. I., Decision support system in health care building design based on case-based reasoning and reinforcement learning, Expert Systems with Applications, 187, (2022); Zhao, Tingting, Case-Based Reasoning and Attribute Features Mining for Posting-Popularity Prediction: A Case Study in the Online Automobile Community, Mathematics, 10, 16, (2022); Xu, Che, A supervised case-based reasoning approach for explainable thyroid nodule diagnosis, Knowledge-Based Systems, 251, (2022); Quant Financ, (2022); Chattopadhyay, Subhagata, A Case-Based Reasoning system for complex medical diagnosis, Expert Systems, 30, 1, pp. 12-20, (2013); Chuang, Chunling, Case-based reasoning support for liver disease diagnosis, Artificial Intelligence in Medicine, 53, 1, pp. 15-23, (2011); Mohammed, Mazin Abed, Genetic case-based reasoning for improved mobile phone faults diagnosis, Computers and Electrical Engineering, 71, pp. 212-222, (2018); Khosravani, Mohammad Reza, Application of case-based reasoning in a fault detection system on production of drippers, Applied Soft Computing, 75, pp. 227-232, (2019)","","Elsevier B.V.","","","","","","23071877; 23071885","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85186253328"
"A., Sideras, Andreas; K., Bougiatiotis, Konstantinos; E., Zavitsanos, Elias; G., Paliouras, Georgios; G.A., Vouros, George A.","Sideras, Andreas (59156271500); Bougiatiotis, Konstantinos (57191094398); Zavitsanos, Elias (24484322500); Paliouras, Georgios (6602657411); Vouros, George A. (6603683157)","59156271500; 57191094398; 24484322500; 6602657411; 6603683157","Bankruptcy Prediction: Data Augmentation, LLMs and the Need for Auditor's Opinion","2024","","","","","453","460","0","2","10.1145/3677052.3698627","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214941370&doi=10.1145%2F3677052.3698627&partnerID=40&md5=f9dcd7cc75dbc26c24e23b0de0c14b49","National Centre for Scientific Research ""DEMOKRITOS"", Athens, Greece; University of Piraeus, Piraeus, Greece","Sideras, Andreas, Institute of Informatics and Telecommunications, National Centre for Scientific Research ""DEMOKRITOS"", Athens, Greece; Bougiatiotis, Konstantinos, Institute of Informatics and Telecommunications, National Centre for Scientific Research ""DEMOKRITOS"", Athens, Greece; Zavitsanos, Elias, Institute of Informatics and Telecommunications, National Centre for Scientific Research ""DEMOKRITOS"", Athens, Greece; Paliouras, Georgios, Institute of Informatics and Telecommunications, National Centre for Scientific Research ""DEMOKRITOS"", Athens, Greece; Vouros, George A., Department of Digital Systems, University of Piraeus, Piraeus, Greece","Predicting bankruptcy is crucial for managing financial risk in corporations. This study emphasizes incorporating the auditor's opinion text into prediction models to improve their ability to assess financial health. These opinions provide essential insights as they offer an independent assessment, complementing other predictive inputs like the management's discussion and analysis. However, the rarity of bankruptcy cases in the data introduces a challenging issue due to severe class imbalance. To address this, we propose a method to generate synthetic positive samples using a variational autoencoder and integrate the multi-source input in a late fusion setting. We showcase that both data augmentation and using multiple textual sources improve the performance of existing models on a related benchmark dataset. Additionally, we evaluate LLMs when used for data augmentation in the proposed method and in a zero-shot prediction setting, discussing important aspects to consider when incorporating them in a predictive pipeline. © 2025 Elsevier B.V., All rights reserved.","Auditor's Opinion; Bankruptcy Prediction; Data Augmentation; Llms; Nlp; Auditor's Opinions; Auto Encoders; Bankruptcy Prediction; Class Imbalance; Data Augmentation; Financial Health; Financial Risks; Independent Assessment; Llm; Prediction Modelling; Prediction Models","Auditor's opinions; Auto encoders; Bankruptcy prediction; Class imbalance; Data augmentation; Financial health; Financial risks; Independent assessment; LLM; Prediction modelling; Prediction models","","","We would like to acknowledge the financial support of Qualco SA. The opinions of the authors expressed herein do not necessarily state or reflect those of Qualco SA.","Alexeyeva, Irina, Do going concern disclosures in the management report and audit report signal bankruptcy risk? Evidence from privately held firms, International Journal of Auditing, 26, 2, pp. 171-192, (2022); Journal of Accounting Auditing and Finance, (1982); Journal of Accountancy, (1974); Altman, Edward I., FINANCIAL RATIOS, DISCRIMINANT ANALYSIS AND THE PREDICTION OF CORPORATE BANKRUPTCY, Journal of Finance, 23, 4, pp. 589-609, (1968); From Numbers to Words Multi Modal Bankruptcy Prediction Using the Ecl Dataset, (2024); Veganzones, David, An investigation of bankruptcy prediction in imbalanced datasets, Decision Support Systems, 112, pp. 111-124, (2018); Bao, Yang, Detecting Accounting Fraud in Publicly Traded U.S. Firms Using a Machine Learning Approach, Journal of Accounting Research, 58, 1, pp. 199-235, (2020); Journal of Accounting Research, (1966); Bougiatiotis, Konstantinos, DICE @ ML-ESG-3: ESG Impact Level and Duration Inference Using LLMs for Augmentation and Contrastive Learning, pp. 234-243, (2024); Bougiatiotis, Konstantinos, Identifying going concern issues in auditor opinions: link to bankruptcy events, pp. 2805-2813, (2023)","","Association for Computing Machinery, Inc","","5th ACM International Conference on AI in Finance, ICAIF 2024","","Brooklyn; NY","205273","","9798400710810","","","English","Conference paper","Final","All Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85214941370"
"Y., Cao, Yupeng; Z., Chen, Zhi; Q., Pei, Qingyun; N., Lee, Nathan; K.P., Subbalakshmi, Koduvayur P.Suba; P.M., Ndiaye, Papa Momar","Cao, Yupeng (57344157600); Chen, Zhi (58605681600); Pei, Qingyun (59005665600); Lee, Nathan (59373476900); Subbalakshmi, Koduvayur P.Suba (6602342476); Ndiaye, Papa Momar (7006665118)","57344157600; 58605681600; 59005665600; 59373476900; 6602342476; 7006665118","ECC Analyzer: Extracting Trading Signal from Earnings Conference Calls using Large Language Model for Stock Volatility Prediction","2024","","","","","257","265","0","3","10.1145/3677052.3698689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214883095&doi=10.1145%2F3677052.3698689&partnerID=40&md5=faeaf5880aa1b6968005d5c915cc03ad","Stevens Institute of Technology, Hoboken, United States; Hunter College, New York, United States","Cao, Yupeng, Stevens Institute of Technology, Hoboken, United States; Chen, Zhi, Stevens Institute of Technology, Hoboken, United States; Pei, Qingyun, Stevens Institute of Technology, Hoboken, United States; Lee, Nathan, Hunter College, New York, United States; Subbalakshmi, Koduvayur P.Suba, Stevens Institute of Technology, Hoboken, United States; Ndiaye, Papa Momar, Stevens Institute of Technology, Hoboken, United States","In the realm of financial analytics, leveraging unstructured data, such as earnings conference calls (ECCs), to forecast stock volatility is a critical challenge that has attracted both academics and investors. While previous studies have used multimodal deep learning-based models to obtain a general view of ECCs for volatility predicting, they often fail to capture detailed, complex information. Our research introduces a novel framework: ECC Analyzer, which utilizes large language models (LLMs) to extract richer, more predictive content from ECCs to aid the model's prediction performance. We use the pre-trained large models to extract textual and audio features from ECCs and implement a hierarchical information extraction strategy to extract more fine-grained information. This strategy first extracts paragraph-level general information by summarizing the text and then extracts fine-grained focus sentences using Retrieval-Augmented Generation (RAG). These features are then fused through multimodal feature fusion to perform volatility prediction. Experimental results demonstrate that our model outperforms traditional analytical benchmarks, confirming the effectiveness of advanced LLM techniques in financial analysis. © 2025 Elsevier B.V., All rights reserved.","Earnings Conference Call Analysis; Large Language Model; Retrieval-augmented Generation; Volatility Forecasting; Prediction Models; Critical Challenges; Earning Conference Call Analyze; Fine Grained; Language Model; Large Language Model; Learning Based Models; Multi-modal; Retrieval-augmented Generation; Unstructured Data; Volatility Forecasting; Deep Learning","Prediction models; Critical challenges; Earning conference call analyze; Fine grained; Language model; Large language model; Learning Based Models; Multi-modal; Retrieval-augmented generation; Unstructured data; Volatility forecasting; Deep learning","","","","Proceedings of the Third Workshop on Financial Technology and Natural Language Processing, (2021); Advances in Neural Information Processing Systems, (2020); Bollen, Johan, Twitter mood predicts the stock market, Journal of Computational Science, 2, 1, pp. 1-8, (2011); Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, (2014); Cox, John C., The valuation of options for alternative stochastic processes, Journal of Financial Economics, 3, 1-2, pp. 145-166, (1976); Cramer, Jason, Look, Listen, and Learn More: Design Choices for Deep Audio Embeddings, Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing, 2019-May, pp. 3852-3856, (2019); Ding, Xiao, Deep learning for event-driven stock prediction, IJCAI International Joint Conference on Artificial Intelligence, 2015-January, pp. 2327-2333, (2015); Dumas, Bernard, Equilibrium portfolio strategies in the presence of sentiment risk and excess volatility, Journal of Finance, 64, 2, pp. 579-629, (2009); Accounting Review, (1984); Franses, Philip Hans, Forecasting stock market volatility using (non-linear) Garch models, Journal of Forecasting, 15, 3, pp. 229-235, (1996)","","Association for Computing Machinery, Inc","","5th ACM International Conference on AI in Finance, ICAIF 2024","","Brooklyn; NY","205273","","9798400710810","","","English","Conference paper","Final","","Scopus","2-s2.0-85214883095"
"K., Papasotiriou, Kassiani; S., Sood, Srijan; S., Reynolds, Shayleen; T.H., Balch, Tucker Hybinette","Papasotiriou, Kassiani (57222468894); Sood, Srijan (57226134048); Reynolds, Shayleen (58765452100); Balch, Tucker Hybinette (7003813842)","57222468894; 57226134048; 58765452100; 7003813842","AI in Investment Analysis: LLMs for Equity Stock Ratings","2024","","","","","419","427","0","5","10.1145/3677052.3698694","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214871009&doi=10.1145%2F3677052.3698694&partnerID=40&md5=058e1b1e9c91675b79f6263bc94dbf2d","JPMorgan Chase & Co., New York, United States; Goizueta Business School, Atlanta, United States","Papasotiriou, Kassiani, AI Research, JPMorgan Chase & Co., New York, United States; Sood, Srijan, AI Research, JPMorgan Chase & Co., New York, United States; Reynolds, Shayleen, AI Research, JPMorgan Chase & Co., New York, United States; Balch, Tucker Hybinette, AI Research, JPMorgan Chase & Co., New York, United States, Goizueta Business School, Atlanta, United States","Investment Analysis is a cornerstone of the Financial Services industry. The rapid integration of advanced machine learning techniques, particularly Large Language Models (LLMs), offers opportunities to enhance the equity stock rating process. This paper explores the application of LLMs to predict stock performance and generate stock ratings by ingesting diverse datasets. Traditional stock rating methods rely heavily on the expertise of financial analysts, and face several challenges such as data overload, inconsistencies in filings, and delayed reactions to market events. Our study addresses these issues by leveraging LLMs to improve the accuracy and consistency of stock ratings. Additionally, we assess the efficacy of using different data modalities with LLMs for the financial domain. We utilize varied datasets comprising fundamental financial, market, and news data from January 2022 to June 2024, along with GPT-4-32k (v0613) (with a training cutoff in Sep. 2021 to prevent information leakage). Our results show that our benchmark method outperforms traditional stock rating methods when assessed by forward returns. Specifically, incorporating financial fundamentals enhances ratings accuracy. While integrating news data improves short-term performance, substituting detailed news summaries with sentiment scores reduces token use without loss of performance. In many cases, omitting news data entirely enhances performance by reducing bias. Our research shows that LLMs can be leveraged to effectively utilize large amounts of multimodal financial data, as showcased by their effectiveness at the stock rating prediction task. Our work provides a reproducible framework for generating consistent and accurate stock ratings, offering a cost-effective and efficient alternative to traditional methods. Future work will extend the analysis to longer time horizons, incorporating more diverse data, and utilizing newer models to enhance detailed investment analysis and reports. © 2025 Elsevier B.V., All rights reserved.","Cost Effectiveness; Data Accuracy; Financial Markets; Data Overload; Financial Analysts; Financial Domains; Financial News; Financial Services Industries; Investment Analysis; Language Model; Machine Learning Techniques; Performance; Stock Performance","Cost effectiveness; Data accuracy; Financial markets; Data overload; Financial analysts; Financial domains; Financial news; Financial services industries; Investment analysis; Language model; Machine learning techniques; Performance; Stock performance","","","","Yfinance Yahoo Finance Market Data Downloader; Baccianella, Stefano, Evaluation measures for ordinal regression, pp. 283-287, (2009); Barber, Brad M., Buys, holds, and sells: The distribution of investment banks' stock ratings and the implications for the profitability of analysts' recommendations, Journal of Accounting and Economics, 41, 1-2, pp. 87-117, (2006); Barber, Brad M., Ratings Changes, Ratings Levels, and the Predictive Value of Analysts' Recommendations, Financial Management, 39, 2, pp. 533-553, (2010); Brown, Nerissa C., Analyst recommendations, mutual fund herding, and overreaction in stock prices, Management Science, 60, 1, pp. 1-20, (2014); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Risklabs Predicting Financial Risk Using Large Language Model Based on Multi Sources Data, (2024); undefined, (2022); Extracting Structured Insights from Financial News an Augmented Llm Driven Approach, (2024); Can Large Language Models Beat Wall Street Unveiling the Potential of Ai in Stock Selection, (2024)","","Association for Computing Machinery, Inc","","5th ACM International Conference on AI in Finance, ICAIF 2024","","Brooklyn; NY","205273","","9798400710810","","","English","Conference paper","Final","All Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-85214871009"
"J., Gu, Jingyi; J., Ye, Junyi; G.G., Wang, Guiling Grace; W., Yin, Wenpeng","Gu, Jingyi (57991757400); Ye, Junyi (57224852493); Wang, Guiling Grace (55738657700); Yin, Wenpeng (55418415800)","57991757400; 57224852493; 55738657700; 55418415800","Adaptive and Explainable Margin Trading via Large Language Models on Portfolio Management","2024","","","","","248","256","0","2","10.1145/3677052.3698681","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210382485&doi=10.1145%2F3677052.3698681&partnerID=40&md5=83e58d1624d0f8f4abae6ee793ec8971","New Jersey Institute of Technology, Newark, United States; Pennsylvania State University, University Park, United States","Gu, Jingyi, New Jersey Institute of Technology, Newark, United States; Ye, Junyi, New Jersey Institute of Technology, Newark, United States; Wang, Guiling Grace, New Jersey Institute of Technology, Newark, United States; Yin, Wenpeng, Pennsylvania State University, University Park, United States","Recent strategies for portfolio management often lack flexibility to adjust funds between long and short positions throughout trading periods. This prevents adapting portfolios to the market, which mitigates risks and seizes opportunities. To address these gaps, we propose an adaptive and explainable framework that integrates Large Language Models (LLMs) with Reinforcement Learning (RL) for dynamic long-short position adjustment in response to evolving market conditions. This approach leverages the recent advancements in LLMs for processing unstructured data and their capacity for explainable reasoning. The framework includes two stages: an Explainable Market Forecasting/Reasoning Pipeline, and a Position Reallocation stage. The Market Forecasting/Reasoning Pipeline allows various LLMs to learn market trends from diverse external data sources and determine optimal adjustment ratios with a clear reasoning path. The Portfolio Reallocation stage interacts with the sequential trading process from a pre-trained RL model to enhance decision-making and transparency. Our framework is flexible to accommodate various external data sources from microeconomics to macroeconomics data, diverse data types including time series and news text, along with multiple LLMs. Experiments demonstrate that our framework effectively achieves three times the return and doubles the Sharpe ratio compared to benchmarks. All the data and code are publicly available under NJIT FinTech Lab's GitHub1. © 2025 Elsevier B.V., All rights reserved.","Explainable Ai; Large Language Model; Market Trend Forecasting; Portfolio Management; Reinforcement Learning; Decision Making; Financial Data Processing; Financial Markets; Fintech; Investments; Marketplaces; Pipeline Codes; Reinforcement Learning; Explainable Ai; Language Model; Large Language Model; Market Forecasting; Market Trend Forecasting; Market Trends; Portfolio Managements; Reinforcement Learnings; Short Position; Trend Forecasting","Decision making; Financial data processing; Financial markets; Fintech; Investments; Marketplaces; Pipeline codes; Reinforcement learning; Explainable AI; Language model; Large language model; Market forecasting; Market trend forecasting; Market trends; Portfolio managements; Reinforcement learnings; Short position; Trend forecasting","","","","Phi 3 Technical Report A Highly Capable Language Model Locally on Your Phone, (2024); Gpt 4 Technical Report, (2023); Mistral AI, (2024); Introducing Meta Llama 3 the Most Capable Openly Available Llm to Date, (2024); Introducing Claude 3 5 Sonnet, (2024); Claude 3 Model Card, (2024); Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Deng, Xiang, What do LLMs Know about Financial Markets? A Case Study on Reddit Market Sentiment Analysis, pp. 107-110, (2023); Gallegos, Isabel O., Bias and Fairness in Large Language Models: A Survey, Computational Linguistics, 50, 3, pp. 1097-1179, (2024); Stock Broad Index Trend Patterns Learning Via Domain Knowledge Informed Generative Network, (2023)","","Association for Computing Machinery, Inc","","5th ACM International Conference on AI in Finance, ICAIF 2024","","Brooklyn; NY","205273","","9798400710810","","","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85210382485"
"O., Shobayo, Olamilekan; S., Adeyemi-Longe, Sidikat; O.J., Popoola, Olusogo Joshua; B., Ogunleye, Bayode","Shobayo, Olamilekan (57204632324); Adeyemi-Longe, Sidikat (59441684700); Popoola, Olusogo Joshua (57195674817); Ogunleye, Bayode (58070023000)","57204632324; 59441684700; 57195674817; 58070023000","Innovative Sentiment Analysis and Prediction of Stock Price Using FinBERT, GPT-4 and Logistic Regression: A Data-Driven Approach","2024","Big Data and Cognitive Computing","8","11","143","","","0","17","10.3390/bdcc8110143","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210428400&doi=10.3390%2Fbdcc8110143&partnerID=40&md5=7583450a30ccf1dfdbe524ab4af2cb16","Sheffield Hallam University, Sheffield, United Kingdom; University of Brighton, Brighton, United Kingdom","Shobayo, Olamilekan, School of Computing and Digital Technologies, Sheffield Hallam University, Sheffield, United Kingdom; Adeyemi-Longe, Sidikat, School of Computing and Digital Technologies, Sheffield Hallam University, Sheffield, United Kingdom; Popoola, Olusogo Joshua, School of Computing and Digital Technologies, Sheffield Hallam University, Sheffield, United Kingdom; Ogunleye, Bayode, Department of Mathematics and Computer Science, University of Brighton, Brighton, United Kingdom","This study explores the comparative performance of cutting-edge AI models, i.e., Finaance Bidirectional Encoder representations from Transsformers (FinBERT), Generatice Pre-trained Transformer GPT-4, and Logistic Regression, for sentiment analysis and stock index prediction using financial news and the NGX All-Share Index data label. By leveraging advanced natural language processing models like GPT-4 and FinBERT, alongside a traditional machine learning model, Logistic Regression, we aim to classify market sentiment, generate sentiment scores, and predict market price movements. This research highlights global AI advancements in stock markets, showcasing how state-of-the-art language models can contribute to understanding complex financial data. The models were assessed using metrics such as accuracy, precision, recall, F1 score, and ROC AUC. Results indicate that Logistic Regression outperformed the more computationally intensive FinBERT and predefined approach of versatile GPT-4, with an accuracy of 81.83% and a ROC AUC of 89.76%. The GPT-4 predefined approach exhibited a lower accuracy of 54.19% but demonstrated strong potential in handling complex data. FinBERT, while offering more sophisticated analysis, was resource-demanding and yielded a moderate performance. Hyperparameter optimization using Optuna and cross-validation techniques ensured the robustness of the models. This study highlights the strengths and limitations of the practical applications of AI approaches in stock market prediction and presents Logistic Regression as the most efficient model for this task, with FinBERT and GPT-4 representing emerging tools with potential for future exploration and innovation in AI-driven financial analytics. © 2024 Elsevier B.V., All rights reserved.","Finbert; Finbert Model; Logistic Regression; Optuna; Time Series Cross-validation; Electronic Trading; Financial Markets; Prediction Models; Cross Validation; Data-driven Approach; Finaance Bidirectional Encoder Representation From Transsformer; Finaance Bidirectional Encoder Representation From Transsformer Model; Logistics Regressions; Optuna; Sentiment Analysis; Stock Price; Time Series Cross-validation; Times Series; Logistic Regression","Electronic trading; Financial markets; Prediction models; Cross validation; Data-driven approach; Finaance bidirectional encoder representation from transsformer; Finaance bidirectional encoder representation from transsformer model; Logistics regressions; Optuna; Sentiment analysis; Stock price; Time series cross-validation; Times series; Logistic regression","","","","Machine Learning with Applications, (2023); Shapiro, Adam Hale, Measuring news sentiment, Journal of Econometrics, 228, 2, pp. 221-243, (2022); Proceedings of the Twenty Ninth International Joint Conference on Artificial Intelligence Ijcai, (2021); Leippold, Markus, Sentiment spin: Attacking financial sentiment with GPT-3, Finance Research Letters, 55, (2023); Yang, Junwen, Prediction of stock price direction using the LASSO-LSTM model combines technical indicators and financial sentiment analysis, PeerJ Computer Science, 8, (2022); Proceedings of the 2021 IEEE International Conference Systems Man and Cybernetics; Gigerenzer, Gerd, Simple heuristics to run a research group, PsyCh Journal, 11, 2, pp. 275-280, (2022); A Context Aware Lemmatization Model for Setswana Language Using Machine Learning, (2022); Journal of Management Science Engineering Research, (2022); J Eng Sci Appl, (2024)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","25042289","","","","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-85210428400"
"M.D., Sidwell, MacKenzie D.; L.W., Bonner, Landon W.; K.E., Bates-Brantley, Kayla E.; S., Wu, Shengtian","Sidwell, MacKenzie D. (57230139700); Bonner, Landon W. (58940912400); Bates-Brantley, Kayla E. (57200389383); Wu, Shengtian (57201323266)","57230139700; 58940912400; 57200389383; 57201323266","Utilizing Text-Generative AI for Creating Oral Reading Fluency Probes","2024","Intervention in School and Clinic","60","2","","119","125","0","3","10.1177/10534512241235896","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187900869&doi=10.1177%2F10534512241235896&partnerID=40&md5=e509c82439b3b8e15e18bb6756b059cd","Mississippi State University, Mississippi State, United States; Illinois State University, Chicago, United States","Sidwell, MacKenzie D., Mississippi State University, Mississippi State, United States; Bonner, Landon W., Mississippi State University, Mississippi State, United States; Bates-Brantley, Kayla E., Mississippi State University, Mississippi State, United States; Wu, Shengtian, Illinois State University, Chicago, United States","Oral reading fluency probes are essential for reading assessment, intervention, and progress monitoring. Due to the limited options for choosing oral reading fluency probes, it is important to utilize all available resources such as generative artificial intelligence (AI) like ChatGPT to create oral reading fluency probes. The purpose of this article is to describe how to use AI through ChatGPT to create customizable reading passages comparable with that of oral reading fluency probes. Using readability estimates, the ChatGPT-generated passages can be tailored to suit for specific grade levels, similar to how current publishers design oral reading fluency probes for the market. The implication of ChatGPT-generated passages is that researchers and practitioners alike could use ChatGPT to be able to create a seemingly unlimited amount of reading passages tailored to the skill level and interests of the learner for intervention material and potentially assessment material, while reducing cost and time investment. © 2024 Elsevier B.V., All rights reserved.","Academic Intervention; Artificial Intelligence; Oral Reading Fluency","","","","","Ardoin, Scott P., Curriculum-based measurement of oral reading: Standard errors associated with progress monitoring outcomes from DIBELS, AIMSweb, and an experimental passage set, School Psychology Review, 38, 2, pp. 266-283, (2009); Chatgpt for Higher Education and Professional Development A Guide to Conversational AI, (2023); Bakken, Linda, Early Childhood Education: The Long-Term Benefits, Journal of Research in Childhood Education, 31, 2, pp. 255-269, (2017); Begeny, John C., Can readability formulas be used to successfully gauge difficulty of reading materials?, Psychology in the Schools, 51, 2, pp. 198-215, (2014); Benjamin, Rebekah George, Reconstructing Readability: Recent Developments and Recommendations in the Analysis of Text Difficulty, Educational Psychology Review, 24, 1, pp. 63-88, (2012); Dibels 8th Edition Administration and Scoring Guide, (2023); Chatterjee, Joyjit, This new conversational AI model can be your friend, philosopher, and guide. and even your worst enemy, Patterns, 4, 1, (2023); Cunningham, James W., Investigating the validity of two widely used quantitative text tools, Reading and Writing, 31, 4, pp. 813-833, (2018); Educational Research Bulletin, (1931); Elementary English, (1949)","","SAGE Publications Ltd","","","","","","15384810; 10534512","","","","English","Article","Final","","Scopus","2-s2.0-85187900869"
"Z., Xue, Zhiyi; L., Li, Liangguo; S., Tian, Senyue; X., Chen, Xiaohong; P., Li, Pingping; L., Chen, Liangyu; T., Jiang, Tingting; M., Zhang, Min","Xue, Zhiyi (57994374900); Li, Liangguo (59152006300); Tian, Senyue (59151518900); Chen, Xiaohong (35236403100); Li, Pingping (59151840700); Chen, Liangyu (55739230800); Jiang, Tingting (59151519000); Zhang, Min (59619795200)","57994374900; 59152006300; 59151518900; 35236403100; 59151840700; 55739230800; 59151519000; 59619795200","LLM4Fin: Fully Automating LLM-Powered Test Case Generation for FinTech Software Acceptance Testing","2024","","","","","1643","1655","0","4","10.1145/3650212.3680388","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205529439&doi=10.1145%2F3650212.3680388&partnerID=40&md5=27c8d4cd1ea00cb049db6e579968fcbb","East China Normal University, Shanghai, China; Guotai Junan Securities Co. Ltd., Shanghai, China; Dishui Lake International Software Engineering Institute, Shanghai, China","Xue, Zhiyi, ECNU, East China Normal University, Shanghai, China; Li, Liangguo, ECNU, East China Normal University, Shanghai, China; Tian, Senyue, ECNU, East China Normal University, Shanghai, China; Chen, Xiaohong, ECNU, East China Normal University, Shanghai, China; Li, Pingping, Software Testing Center, Guotai Junan Securities Co. Ltd., Shanghai, China; Chen, Liangyu, ECNU, East China Normal University, Shanghai, China; Jiang, Tingting, Software Testing Center, Guotai Junan Securities Co. Ltd., Shanghai, China; Zhang, Min, Ecnu, Dishui Lake International Software Engineering Institute, Shanghai, China","FinTech software, crucial for both safety and timely market deployment, presents a compelling case for automated acceptance testing against regulatory business rules. However, the inherent challenges of comprehending unstructured natural language descriptions of these rules and crafting comprehensive test cases demand human intelligence. The emergence of Large Language Models (LLMs) holds promise for automated test case generation, leveraging their natural language processing capabilities. Yet, their dependence on human intervention for effective prompting hampers efficiency. In response, we introduce a groundbreaking, fully automated approach for generating high-coverage test cases from natural language business rules. Our methodology seamlessly integrates the versatility of LLMs with the predictability of algorithmic methods. We fine-tune pre-trained LLMs for improved information extraction accuracy and algorithmically generate comprehensive testable scenarios for the extracted business rules.Our prototype, LLM4Fin, is designed for testing real-world stock-trading software. Experimental results demonstrate LLM4Fin's superiority over both state-of-the-art LLM, such as ChatGPT, and skilled testing engineers. We achieve remarkable performance, with up to 98.18% and an average of 20%-110% improvement on business scenario coverage, and up to 93.72% on code coverage, while reducing the time cost from 20 minutes to a mere 7 seconds. These results provide robust evidence of the framework's practical applicability and efficiency, marking a significant advancement in FinTech software testing. © 2024 Elsevier B.V., All rights reserved.","Fintech Software; Large Language Model; Software Acceptance Testing; Test Case Generation; Algorithmic Languages; Automatic Test Pattern Generation; Enterprise Software; Financial Markets; Fintech; Model Checking; Software Prototyping; Software Testing; Acceptance Testing; Automated Acceptance Testing; Business Rules; Fintech Software; Language Model; Large Language Model; Natural Languages; Software Acceptance Testing; Test Case; Test Case Generation; Acceptance Tests","Algorithmic languages; Automatic test pattern generation; Enterprise software; Financial markets; Fintech; Model checking; Software prototyping; Software testing; Acceptance testing; Automated acceptance testing; Business rules; Fintech software; Language model; Large language model; Natural languages; Software acceptance testing; Test case; Test case generation; Acceptance tests","","","This work is supported by NSFC Programs (62161146001, 62372176, 62272166), Shanghai Trusted Software Innovation Center, Huawei, and Shanghai International Joint Lab (22510750100).","Iso Iec IEEE 24765, (2010); Nlpcda, (2020); Claude A Next Generation AI Assistant for Your Tasks no Matter the Scale, (2023); Computer Processing of Oriental Languages Special Issue on Information Retrieval on Oriental Languages, (1998); Chittimalli, Pavan Kumar, BuRRiTo: A framework to extract, specify, verify and analyze business rules, pp. 1190-1193, (2019); Corriveau, Jean Pierre, Requirements verification: Legal challenges in compliance testing, pp. 451-454, (2014); de Moura, Leonardo, Z3: An efficient SMT Solver, Lecture Notes in Computer Science, 4963 LNCS, pp. 337-340, (2008); Derczynski, Leon R.A., Analysis of named entity recognition and linking for tweets, Information Processing and Management, 51, 2, pp. 32-49, (2015); Du, Zhengxiao, GLM: General Language Model Pretraining with Autoregressive Blank Infilling, Proceedings of the Annual Meeting of the Association for Computational Linguistics, 1, pp. 320-335, (2022); Feng, Shuo, Testing Scenario Library Generation for Connected and Automated Vehicles, Part I: Methodology, IEEE Transactions on Intelligent Transportation Systems, 22, 3, pp. 1573-1582, (2021)","Christakis, M.; Pradel, M.","Association for Computing Machinery, Inc","ACM SIGSOFT; AITO","33rd ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2024","","Vienna","202635","","9798400706127","","","English","Conference paper","Final","","Scopus","2-s2.0-85205529439"
"K., Bönisch, Kevin; M., Stoeckel, Manuel; A., Mehler, Alexander","Bönisch, Kevin (58651075500); Stoeckel, Manuel (57216703262); Mehler, Alexander (13907942400)","58651075500; 57216703262; 13907942400","HyperCausal: Visualizing Causal Inference in 3D Hypertext","2024","","","","","330","336","0","1","10.1145/3648188.3677049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204922413&doi=10.1145%2F3648188.3677049&partnerID=40&md5=4340aec49899e9d0401b8b3d4c55a1a0","Goethe-Universität Frankfurt am Main, Frankfurt am Main, Germany","Bönisch, Kevin, Goethe-Universität Frankfurt am Main, Frankfurt am Main, Germany; Stoeckel, Manuel, Goethe-Universität Frankfurt am Main, Frankfurt am Main, Germany; Mehler, Alexander, Goethe-Universität Frankfurt am Main, Frankfurt am Main, Germany","We present HyperCausal, a 3D hypertext visualization framework for exploring causal inference in generative Large Language Models (LLMs). HyperCausal maps the generative processes of LLMs into spatial hypertexts, where tokens are represented as nodes connected by probability-weighted edges. The edges are weighted by the prediction scores of next tokens, depending on the underlying language model. HyperCausal facilitates navigation through the causal space of the underlying LLM, allowing users to explore predicted word sequences and their branching. Through comparative analysis of LLM parameters such as token probabilities and search algorithms, HyperCausal provides insight into model behavior and performance. Implemented using the Hugging Face transformers library and Three.js, HyperCausal ensures cross-platform accessibility to advance research in natural language processing using concepts from hypertext research. We demonstrate several use cases of HyperCausal and highlight the potential for detecting hallucinations generated by LLMs using this framework. The connection with hypertext research arises from the fact that HyperCausal relies on user interaction to unfold graphs with hierarchically appearing branching alternatives in 3D space. This approach refers to spatial hypertexts and early concepts of hierarchical hypertext structures. A third connection concerns hypertext fiction, since the branching alternatives mediated by HyperCausal manifest non-linearly organized reading threads along artificially generated texts that the user decides to follow optionally depending on the reading context. © 2024 Elsevier B.V., All rights reserved.","3d Hypertext; Large Language Models; Visualization; 3d Modeling; Generative Adversarial Networks; Hypertext Systems; Natural Language Processing Systems; Risk Assessment; 3d Hypertext; Causal Inferences; Comparative Analyzes; Generative Process; Language Model; Large Language Model; Modeling Parameters; Spatial Hypertext; Underlying Language; Visualization Framework; Visualization","3D modeling; Generative adversarial networks; Hypertext systems; Natural language processing systems; Risk assessment; 3d hypertext; Causal inferences; Comparative analyzes; Generative process; Language model; Large language model; Modeling parameters; Spatial hypertext; Underlying language; Visualization framework; Visualization","","","This work was supported by the project CORE (Critical Online Reasoning in Higher Education; FOR 5404, project number 462702138), subprojects B05 and C08, and the BIOfid project (grant number ME 2746/5-1), both funded by the German Research Foundation (DFG).","Saranya, A., A systematic review of Explainable Artificial Intelligence models and applications: Recent developments and future trends, Decision Analytics Journal, 7, (2023); Cybertext Perspectives on Ergodic Literature, (1997); Bernstein, Mark, Storyspace 1, Proceedings of the ACM Conference on Hypertext, pp. 172-181, (2002); Language Models are Few Shot Learners, (2020); Llm Visualization, (2023); Distill, (2019); Chen, Chaomei, From latent semantics to spatial hypertext - an integrated approach, Proceedings of the ACM Conference on Hypertext, pp. 77-86, (1998); Large Legal Fictions Profiling Legal Hallucinations in Large Language Models, (2024); Derose, Joseph F., Attention flows: Analyzing and comparing attention mechanisms in language models, IEEE Transactions on Visualization and Computer Graphics, 27, 2, pp. 1160-1170, (2021); Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019)","","Association for Computing Machinery, Inc","Association for Computing Machinery; sigweb","35th ACM Conference on Hypertext and Social Media, HT 2024","","Poznan","202566","","9798400705953","","","English","Conference paper","Final","","Scopus","2-s2.0-85204922413"
"J.K., Nguyen, Jeremy K.","Nguyen, Jeremy K. (55336899200)","55336899200","Human bias in AI models? Anchoring effects and mitigation strategies in large language models","2024","Journal of Behavioral and Experimental Finance","43","","100971","","","0","6","10.1016/j.jbef.2024.100971","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202886942&doi=10.1016%2Fj.jbef.2024.100971&partnerID=40&md5=6db5298e5336ecbd75452d851bbbbdcf","Swinburne University of Technology, Hawthorn, Australia","Nguyen, Jeremy K., Department of Accounting, Swinburne University of Technology, Hawthorn, Australia","This study builds on the seminal work of Tversky and Kahneman (1974), exploring the presence and extent of anchoring bias in forecasts generated by four Large Language Models (LLMs): GPT-4, Claude 2, Gemini Pro and GPT-3.5. In contrast to recent findings of advanced reasoning capabilities in LLMs, our randomised controlled trials reveal the presence of anchoring bias across all models: forecasts are significantly influenced by prior mention of high or low values. We examine two mitigation prompting strategies, ‘Chain of Thought’ and ‘ignore previous’, finding limited and varying degrees of effectiveness. Our results extend the anchoring bias research in finance beyond human decision-making to encompass LLMs, highlighting the importance of deliberate and informed prompting in AI forecasting in both ad hoc LLM use and in crafting few-shot examples. © 2024 Elsevier B.V., All rights reserved.","Anchoring Bias; Artificial Intelligence","","","","","Akter, Shahriar, Algorithmic bias in data-driven innovation in the age of AI, International Journal of Information Management, 60, (2021); undefined, (2024); A Cognitive Revolution Generative Artificial Intelligence in Higher Education, (2024); Guardian, (2023); Bender, Emily M., On the dangers of stochastic parrots: Can language models be too big?, pp. 610-623, (2021); Reversal Curse Llms Trained on A is B Fail to Learn B is A, (2023); Binz, Marcel, Using cognitive psychology to understand GPT-3, Proceedings of the National Academy of Sciences of the United States of America, 120, 6, (2023); Cen, Ling, The role of anchoring bias in the equity market: Evidence from analysts' earnings forecasts and stock returns, Journal of Financial and Quantitative Analysis, 48, 1, pp. 47-76, (2013); A Manager and an AI Walk into A Bar does Chatgpt Make Biased Decisions Like We do, (2023); Chen, Yiting, The emergence of economic rationality of GPT, Proceedings of the National Academy of Sciences of the United States of America, 120, 51, (2023)","","Elsevier B.V.","","","","","","22146350; 22146369","","","","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85202886942"
"I., Alonso, Iñigo; M., Oronoz, Maite; R., Agerri, Rodrigo","Alonso, Iñigo (58358273400); Oronoz, Maite (59330935900); Agerri, Rodrigo (6508050065)","58358273400; 59330935900; 6508050065","MedExpQA: Multilingual benchmarking of Large Language Models for Medical Question Answering","2024","Artificial Intelligence in Medicine","155","","102938","","","0","11","10.1016/j.artmed.2024.102938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200647612&doi=10.1016%2Fj.artmed.2024.102938&partnerID=40&md5=bfe302a8cdf52c3422260f8454686471","Universidad del Pais Vasco, Leioa, Spain","Alonso, Iñigo, Universidad del Pais Vasco, Leioa, Spain; Oronoz, Maite, Universidad del Pais Vasco, Leioa, Spain; Agerri, Rodrigo, Universidad del Pais Vasco, Leioa, Spain","Large Language Models (LLMs) have the potential of facilitating the development of Artificial Intelligence technology to assist medical experts for interactive decision support. This potential has been illustrated by the state-of-the-art performance obtained by LLMs in Medical Question Answering, with striking results such as passing marks in licensing medical exams. However, while impressive, the required quality bar for medical applications remains far from being achieved. Currently, LLMs remain challenged by outdated knowledge and by their tendency to generate hallucinated content. Furthermore, most benchmarks to assess medical knowledge lack reference gold explanations which means that it is not possible to evaluate the reasoning of LLMs predictions. Finally, the situation is particularly grim if we consider benchmarking LLMs for languages other than English which remains, as far as we know, a totally neglected topic. In order to address these shortcomings, in this paper we present MedExpQA, the first multilingual benchmark based on medical exams to evaluate LLMs in Medical Question Answering. To the best of our knowledge, MedExpQA includes for the first time reference gold explanations, written by medical doctors, of the correct and incorrect options in the exams. Comprehensive multilingual experimentation using both the gold reference explanations and Retrieval Augmented Generation (RAG) approaches show that performance of LLMs, with best results around 75 accuracy for English, still has large room for improvement, especially for languages other than English, for which accuracy drops 10 points. Therefore, despite using state-of-the-art RAG methods, our results also demonstrate the difficulty of obtaining and integrating readily available medical knowledge that may positively impact results on downstream evaluations for Medical Question Answering. Data, code, and fine-tuned models will be made publicly available.1 © 2024 Elsevier B.V., All rights reserved.","Large Language Models; Medical Question Answering; Multilinguality; Natural Language Processing; Retrieval Augmented Generation; Computational Linguistics; Decision Support Systems; Gold; Medical Applications; Natural Language Processing Systems; Artificial Intelligence Technologies; Language Model; Language Processing; Large Language Model; Medical Knowledge; Medical Question Answering; Multilinguality; Natural Language Processing; Natural Languages; Retrieval Augmented Generation; Benchmarking; Article; Benchmarking; Controlled Study; Data Accuracy; English (language); French (language); Information Retrieval; Italian (language); Knowledge; Large Language Model; Medical Examination; Multilingualism; Physician; Spanish (language); Artificial Intelligence; Human; Natural Language Processing; Artificial Intelligence; Humans; Multilingualism; Natural Language Processing","Computational linguistics; Decision support systems; Gold; Medical applications; Natural language processing systems; Artificial intelligence technologies; Language model; Language processing; Large language model; Medical knowledge; Medical question answering; Multilinguality; Natural language processing; Natural languages; Retrieval augmented generation; Benchmarking; Article; benchmarking; controlled study; data accuracy; English (language); French (language); information retrieval; Italian (language); knowledge; large language model; medical examination; multilingualism; physician; Spanish (language); artificial intelligence; human; natural language processing; Artificial Intelligence; Humans; Multilingualism; Natural Language Processing","","","Funding text 1: We thank the CasiMedicos Proyecto MIR 2.0 for their permission to share their data for research purposes. This work has been partially supported by the HiTZ Center and the Basque Government, Spain (Research group funding IT1570-22). We are also thankful to several MCIN/AEI/10.13039/501100011033 projects: (i) Antidote (PCI2020-120717-2), and by European Union NextGenerationEU/PRTR; (ii) DeepKnowledge (PID2021-127777OB-C21) and ERDF A way of making Europe; (iii) Lotu (TED2021-130398B-C22) and European Union NextGenerationEU/PRTR; (iv) EDHIA (PID2022-136522OB-C22); (v) DeepMinor (CNS2023-144375) and European Union NextGenerationEU/PRTR. We also thank the European High Performance Computing Joint Undertaking (EuroHPC Joint Undertaking, EXT-2023E01-013) for the GPU hours.; Funding text 2: We thank the CasiMedicos Proyecto MIR 2.0 for their permission to share their data for research purposes. This work has been partially supported by the HiTZ Center and the Basque Government (Research group funding IT1570-22 ). We are also thankful to several MCIN/AEI/ 10.13039/501100011033 projects: (i) Antidote ( PCI2020-120717-2 ), and by European Union NextGenerationEU/PRTR ; (ii) DeepKnowledge ( PID2021-127777OB-C21 ) and ERDF A way of making Europe ; (iii) Lotu ( TED2021-130398B-C22 ) and European Union NextGenerationEU/PRTR ; (iv) EDHIA ( PID2022-136522OB-C22 ); (v) DeepMinor ( CNS2023-144375 ) and European Union NextGenerationEU/PRTR . We also thank the European High Performance Computing Joint Undertaking (EuroHPC Joint Undertaking, EXT-2023E01-013 ) for the GPU hours.","Singhal, Karan, Large language models encode clinical knowledge, Nature, 620, 7972, pp. 172-180, (2023); Capabilities of Gpt 4 on Medical Challenge Problems, (2023); Safranek, Conrad W., The Role of Large Language Models in Medical Education: Applications and Implications, JMIR Medical Education, 9, (2023); Explanatory Argument Extraction of Correct Answers in Resident Medical Exams, (2023); Llama 2 Open Foundation and Fine Tuned Chat Models, (2023); Pmc Llama Further Finetuning Llama on Medical Papers, (2023); Mistral 7b, (2023); Biomistral A Collection of Open Source Pretrained Large Language Models for Medical Domains, (2024); Towards Expert Level Medical Question Answering with Large Language Models, (2023); Medrxiv, (2023)","","Elsevier B.V.","","","","","","18732860; 09333657","9789051991413; 905199141X","AIMEE","39121544","English","Article","Final","All Open Access; Green Accepted Open Access; Green Final Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85200647612"
"D., Bouneffouf, Djallel; R., Féraud, Raphaël","Bouneffouf, Djallel (55210872800); Féraud, Raphaël (6602456621)","55210872800; 6602456621","A Tutorial on Multi-Armed Bandit Applications for Large Language Models","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","6412","6413","0","1","10.1145/3637528.3671440","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203710177&doi=10.1145%2F3637528.3671440&partnerID=40&md5=80552c570db45e2621adca308590859c","IBM Research, Yorktown Heights, United States; Orange Innovation, Lannion, France","Bouneffouf, Djallel, IBM Research, Yorktown Heights, United States; Féraud, Raphaël, Orange Innovation, Lannion, France","This tutorial offers a comprehensive guide on using multi-armed bandit (MAB) algorithms to improve Large Language Models (LLMs). As Natural Language Processing (NLP) tasks grow, efficient and adaptive language generation systems are increasingly needed. MAB algorithms, which balance exploration and exploitation under uncertainty, are promising for enhancing LLMs. The tutorial covers foundational MAB concepts, including the exploration-exploitation trade-off and strategies like epsilon-greedy, UCB (Upper Confidence Bound), and Thompson Sampling. It then explores integrating MAB with LLMs, focusing on designing architectures that treat text generation options as arms in a bandit problem. Practical aspects like reward design, exploration policies, and scalability are discussed. Real-world case studies demonstrate the benefits of MAB-augmented LLMs in content recommendation, dialogue generation, and personalized content creation, showing how these techniques improve relevance, diversity, and user engagement. © 2025 Elsevier B.V., All rights reserved.","Large Language Models; Multi-armed Bandit; Contrastive Learning; Speech Enhancement; Adaptive Language Generation System; Balance Exploration; Exploration And Exploitation; Exploration/exploitation; Language Model; Language Processing; Large Language Model; Multiarmed Bandits (mabs); Natural Languages; Uncertainty; Natural Language Processing Systems","Contrastive Learning; Speech enhancement; Adaptive language generation system; Balance exploration; Exploration and exploitation; Exploration/exploitation; Language model; Language processing; Large language model; Multiarmed bandits (MABs); Natural languages; Uncertainty; Natural language processing systems","","","","Bandit Algorithms, (2018); Bouneffouf, Djallel, Survey on Applications of Multi-Armed and Contextual Bandits, (2020); Vaswani, Ashish, Attention is all you need, Advances in Neural Information Processing Systems, 2017-December, pp. 5999-6009, (2017); Lora Low Rank Adaptation of Large Language Models, (2021); Chu, Wei, Contextual bandits with linear Payoff functions, Journal of Machine Learning Research, 15, pp. 208-214, (2011); Context Attentive Bandits Contextual Bandit with Restricted Context, (2017); Bouneffouf, Djallel, Toward Optimal Solution for the Context-Attentive Bandit Problem, IJCAI International Joint Conference on Artificial Intelligence, pp. 3493-3500, (2021); Auer, Péter, The nonstochastic multiarmed bandit problem, SIAM Journal on Computing, 32, 1, pp. 48-77, (2003); Allesiardo, Robin, The non-stationary stochastic multi-armed bandit problem, International Journal of Data Science and Analytics, 3, 4, pp. 267-283, (2017); Urvoy, Tanguy, Generic exploration and K-armed voting bandits, PART 1, pp. 750-758, (2013)","","Association for Computing Machinery","ACM SIGKDD; ACM SIGMOD","30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2024","","Barcelona","202030","2154817X","9798400714542; 9798400712456; 9781450308373; 9781450315500; 1595936092; 9781450315609; 9781450315548; 9781450315562; 9781450315425; 9781450308137","","","English","Conference paper","Final","","Scopus","2-s2.0-85203710177"
"T., Goričan, Tomaž; M., Terčelj, Milan; I., Peruš, Iztok","Goričan, Tomaž (59302947900); Terčelj, Milan (55928343900); Peruš, Iztok (6507487112)","59302947900; 55928343900; 6507487112","New Approach for Automated Explanation of Material Phenomena (AA6082) Using Artificial Neural Networks and ChatGPT","2024","Applied Sciences (Switzerland)","14","16","7015","","","0","1","10.3390/app14167015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202438549&doi=10.3390%2Fapp14167015&partnerID=40&md5=3f6a5caab5e639bf795ffc527985dca0","Univerza v Mariboru, Maribor, Slovenia; Univerza v Ljubljani, Ljubljana, Slovenia","Goričan, Tomaž, Transportation Engineering and Architecture, Univerza v Mariboru, Maribor, Slovenia; Terčelj, Milan, Department for Materials and Metallurgy, Univerza v Ljubljani, Ljubljana, Slovenia; Peruš, Iztok, Transportation Engineering and Architecture, Univerza v Mariboru, Maribor, Slovenia, Department for Materials and Metallurgy, Univerza v Ljubljani, Ljubljana, Slovenia","Artificial intelligence methods, especially artificial neural networks (ANNs), have increasingly been utilized for the mathematical description of physical phenomena in (metallic) material processing. Traditional methods often fall short in explaining the complex, real-world data observed in production. While ANN models, typically functioning as “black boxes”, improve production efficiency, a deeper understanding of the phenomena, akin to that provided by explicit mathematical formulas, could enhance this efficiency further. This article proposes a general framework that leverages ANNs (i.e., Conditional Average Estimator—CAE) to explain predicted results alongside their graphical presentation, marking a significant improvement over previous approaches and those relying on expert assessments. Unlike existing Explainable AI (XAI) methods, the proposed framework mimics the standard scientific methodology, utilizing minimal parameters for the mathematical representation of physical phenomena and their derivatives. Additionally, it analyzes the reliability and accuracy of the predictions using well-known statistical metrics, transitioning from deterministic to probabilistic descriptions for better handling of real-world phenomena. The proposed approach addresses both aleatory and epistemic uncertainties inherent in the data. The concept is demonstrated through the hot extrusion of aluminum alloy 6082, where CAE ANN models and predicts key parameters, and ChatGPT explains the results, enabling researchers and/or engineers to better understand the phenomena and outcomes obtained by ANNs. © 2024 Elsevier B.V., All rights reserved.","Aluminum Alloy; Artificial Neural Networks; Automatic Explanation; Chatgpt; Hot Extrusion; Large Language Models; Gluing; Artificial Neural Network Modeling; Automatic Explanation; Chatgpt; Hot Extrusion; Language Model; Large Language Model; Neural-networks; New Approaches; Physical Phenomena; Real-world; Metal Extrusion","Gluing; Artificial neural network modeling; Automatic explanation; ChatGPT; Hot extrusion; Language model; Large language model; Neural-networks; New approaches; Physical phenomena; Real-world; Metal extrusion","","","This research was funded by the Republic of Slovenia, the Ministry of Education, Science and Sport. M.T. and I.P. acknowledge funding by the Slovenian Research Agency (ARRS), grant number P2-0268.","Kekez, Sofija, Application of artificial neural networks for prediction of mechanical properties of cnt/cnf reinforced concrete, Materials, 14, 19, (2021); Guo, Zhanli, Modelling the correlation between processing parameters and properties of maraging steels using artificial neural network, Computational Materials Science, 29, 1, pp. 12-28, (2004); Capdevila, C. C., Neural network analysis of the influence of processing on strength and ductility of automotive low carbon sheet steels, Computational Materials Science, 38, 1, pp. 192-201, (2006); Večko-Pirtovšek, Tatjana, Towards improved reliability of the analysis of factors influencing the properties on steel in industrial practice, ISIJ International, 49, 3, pp. 395-401, (2009); Peruš, Iztok, Contour Maps for Simultaneous Increase in Yield Strength and Elongation of Hot Extruded Aluminum Alloy 6082, Metals, 12, 3, (2022); Terčelj, Milan, Influence of the chemical composition and process parameters on the mechanical properties of an extruded aluminium alloy for highly loaded structural parts, Construction and Building Materials, 44, pp. 781-791, (2013); Li, Jingxiao, Determining Homogenization Parameters and Predicting 5182-Sc-Zr Alloy Properties by Artificial Neural Networks, Materials, 16, 15, (2023); Wu, Xiaoyan, Quantitative relationship analysis of mechanical properties with Mg content and heat treatment parameters in Al-7Si alloys using artificial neural network, Materials, 12, 5, (2019); Mosleh, Ahmed O., Bearing Aluminum-Based Alloys: Microstructure, Mechanical Characterizations, and Experiment-Based Modeling Approach, Materials, 15, 23, (2022); Wiciak-Pikuła, Martyna, Tool wear prediction based on artificial neural network during aluminum matrix composite milling, Sensors, 20, 20, pp. 1-18, (2020)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","20763417","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85202438549"
"D.M., Levine, David Michael; R., Tuwani, Rudraksh; B., Kompa, Benjamin; A., Varma, Amita; S.G., Finlayson, Samuel G.; A., Mehrotra, Ateev; A.L., Beam, Andrew L.","Levine, David Michael (57197749920); Tuwani, Rudraksh (57200332195); Kompa, Benjamin (57195729564); Varma, Amita (58146826600); Finlayson, Samuel G. (56329287300); Mehrotra, Ateev (23498035400); Beam, Andrew L. (36452687100)","57197749920; 57200332195; 57195729564; 58146826600; 56329287300; 23498035400; 36452687100","The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study","2024","The Lancet Digital Health","6","8","","e555","e561","0","27","10.1016/S2589-7500(24)00097-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199255672&doi=10.1016%2FS2589-7500%2824%2900097-9&partnerID=40&md5=dc5ca46333601f1e4f85a8eb8379352e","Brigham and Women's Hospital, Boston, United States; Harvard Medical School, Boston, United States; Harvard T.H. Chan School of Public Health, Boston, United States; Harvard T.H. Chan School of Public Health, Boston, United States; Harvard Medical School, Boston, United States; Harvard Medical School, Boston, United States; Harvard Medical School, Boston, United States","Levine, David Michael, Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, United States, Harvard Medical School, Boston, United States; Tuwani, Rudraksh, Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, United States, Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, United States; Kompa, Benjamin, Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, United States, Department of Biomedical Informatics, Harvard Medical School, Boston, United States; Varma, Amita, Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, United States, Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, United States; Finlayson, Samuel G., Harvard Medical School, Boston, United States; Mehrotra, Ateev, Department of Health Care Policy, Harvard Medical School, Boston, United States; Beam, Andrew L., Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, United States, Department of Biomedical Informatics, Harvard Medical School, Boston, United States","Background: Artificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood. Methods: We compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents’ and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately. Findings: Among all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances. Interpretation: A general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine. Funding: The National Heart, Lung, and Blood Institute. © 2024 Elsevier B.V., All rights reserved.","Artificial Intelligence; Diseases; Ground Truth; Harvard Medical School; Intelligence Models; Labeled Data; Language Model; Observational Study; Performance; Predictive Accuracy; Reading Level; Self-care; Diagnosis; Analytical Error; Article; Bootstrapping; Calibration; Confidence Interval; Controlled Study; Diagnostic Accuracy; Diagnostic Test Accuracy Study; Diagnostic Value; General Practitioner; Generative Pretrained Transformer; Heart Infarction; Human; Internet; Internist; Layperson; Major Clinical Study; Medical School; Observational Study; Patient Triage; Prediction; Reading; Search Engine; Self Care; Trend Study; United States; Validation Process; Vignette; Virus Infection; Adult; Artificial Intelligence; Female; Male; Middle Aged; Procedures; Adult; Artificial Intelligence; Female; Humans; Male; Middle Aged; Triage","Artificial intelligence; Diseases; Ground truth; Harvard Medical School; Intelligence models; Labeled data; Language model; Observational study; Performance; Predictive accuracy; Reading level; Self-care; Diagnosis; analytical error; Article; bootstrapping; calibration; confidence interval; controlled study; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; general practitioner; generative pretrained transformer; heart infarction; human; Internet; internist; layperson; major clinical study; medical school; observational study; patient triage; prediction; reading; search engine; self care; trend study; United States; validation process; vignette; virus infection; adult; artificial intelligence; female; male; middle aged; procedures; Adult; Artificial Intelligence; Female; Humans; Male; Middle Aged; Triage","","","The authors would like to thank the members of the OpenAI technical staff for their assistance with questions relating to GPT-3's training data. AB's work on this project was partially supported by funding from the National Heart, Lung, and Blood Institute (K01 HL141771).","Bates, David D.B., The potential of artificial intelligence to improve patient safety: a scoping review, npj Digital Medicine, 4, 1, (2021); Matheny, Michael Edwin, Artificial Intelligence in Health Care: A Report from the National Academy of Medicine, JAMA, 323, 6, pp. 509-510, (2020); Ces Medicina, (2022); Beam, Andrew L., Big data and machine learning in health care, JAMA, 319, 13, pp. 1317-1318, (2018); Yu, Kun Hsing, Artificial intelligence in healthcare, Nature Biomedical Engineering, 2, 10, pp. 719-731, (2018); Gulshan, Varun, Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs, JAMA, 316, 22, pp. 2402-2410, (2016); Beam, Andrew L., Challenges to the Reproducibility of Machine Learning Models in Health Care, JAMA, 323, 4, pp. 305-306, (2020); McDermott, Matthew B.A., Reproducibility in machine learning for health research: Still a ways to go, Science Translational Medicine, 13, 586, (2021); Futoma, Joseph D., The myth of generalisability in clinical research and machine learning in health care, The Lancet Digital Health, 2, 9, pp. e489-e492, (2020); Arxiv, (2020)","","Elsevier Ltd","","","","","","25897500","","","39059888","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85199255672"
"Y., Chen, Yanbo; Z., Fang, Zhe; N., Zhang, Ning; T., Qiang, Tuben; Z., Zhang, Zhi; T., Huang, Tao; Z., Xu, Zitao","Chen, Yanbo (55165518700); Fang, Zhe (58910646100); Zhang, Ning (57226601554); Qiang, Tuben (59235866800); Zhang, Zhi (59658667100); Huang, Tao (59854609100); Xu, Zitao (59205662700)","55165518700; 58910646100; 57226601554; 59235866800; 59658667100; 59854609100; 59205662700","Multi-objective Collaborative Operation Method for Park-level Integrated Energy System Cluster Based on Large Language Model for Green Electricity Prediction and Trading; 基于大语言模型绿电预测和绿电交易的园区综合能源系统集群多目标协同运行方法","2024","Gaodianya Jishu/High Voltage Engineering","50","7","","2849","2863","0","5","10.13336/j.1003-6520.hve.20241015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199678370&doi=10.13336%2Fj.1003-6520.hve.20241015&partnerID=40&md5=7b33b7a6412ffe84ee6fa925d5336e8f","North China Electric Power University, Beijing, China; Qinghai Institute of Technology, Xining, China; Qinghai University, Xining, China","Chen, Yanbo, North China Electric Power University, Beijing, China, Qinghai Institute of Technology, Xining, China, Key Laboratory of Intelligent Operation of New Energy Power System, Qinghai University, Xining, China; Fang, Zhe, North China Electric Power University, Beijing, China; Zhang, Ning, North China Electric Power University, Beijing, China; Qiang, Tuben, North China Electric Power University, Beijing, China; Zhang, Zhi, North China Electric Power University, Beijing, China; Huang, Tao, North China Electric Power University, Beijing, China; Xu, Zitao, North China Electric Power University, Beijing, China","In order to achieve digital and intelligent upgrading of traditional industrial parks, and to support high-quality regional development, there is an urgent need for intelligent dispatch models in parks. Therefore, this paper combines the smart park management system and the physical model of the park-level integrated energy system (PIES) to establish a cluster architecture of the PIES. A three-stage collaborative operation method for green electricity trading in the PIES cluster is proposed to solve the problem of green electricity trading in multiple PIES, and to achieve accurate prediction of distributed renewable energy and on-site consumption. Firstly, based on the large language model LLAMA-7B, green electricity prediction is achieved, and further green electricity power is divided into purchasing and selling electricity PIES. Secondly, based on the green electricity price quota curve prediction model and dynamic green electricity pricing strategy, the differential prices for green electricity trading between parks is established. On this basis, a multi-objective low-carbon economic optimization operation model is established to solve the contradiction between economic and environmental factors brought about by the green electricity exchange. The example analysis shows that the proposed model can comprehensively schedule the economic cost, actual carbon emissions, and renewable energy utilization rate of the PIES cluster, which has a positive promoting effect on the intelligent dispatch of multiple PIES. © 2024 Elsevier B.V., All rights reserved.","Green Electricity Trading; Large Language Model; Low-carbon Economic Dispatch; Multi-object Optimization; Park-level Integrated Energy System; Time Series Data Prediction; Carbon; Cluster Computing; Commerce; Cost Benefit Analysis; Economic Analysis; Electric Load Dispatching; Energy Utilization; Forecasting; Data Prediction; Economic Dispatch; Electricity Trading; Green Electricity; Green Electricity Trading; Integrated Energy Systems; Language Model; Large Language Model; Low-carbon Economic; Low-carbon Economic Dispatch; Multi-object Optimization; Park-level Integrated Energy System; Time Series Data Prediction; Time-series Data; Parks","Carbon; Cluster computing; Commerce; Cost benefit analysis; Economic analysis; Electric load dispatching; Energy utilization; Forecasting; Data prediction; Economic Dispatch; Electricity trading; Green electricity; Green electricity trading; Integrated energy systems; Language model; Large language model; Low-carbon economic; Low-carbon economic dispatch; Multi-object optimization; Park-level integrated energy system; Time series data prediction; Time-series data; Parks","","","Funding text 1: (2024MS009)\u3002 Project supported by Qinghai Province \""Senior Scientist Responsibility System\"" Project (Basic Theory, Key Technology and Demonstration for the Construction of a Zero-carbon Ecological Energy System in the Plateau), Fundamental Research Funds for the Central Universities (2024MS009).; Funding text 2: Qinghai Province \""Senior Scientist Responsibility System\"" Project (Basic Theory, Key Technology and Demonstration for the Construction of a Zero-carbon Ecological Energy System in the Plateau), Fundamental Research Funds for the Central Universities (2024MS009).","Zhu, Jianquan, Review on Optimal Operation of Park-level Integrated Energy System, Gaodianya Jishu/High Voltage Engineering, 48, 7, pp. 2469-2482, (2022); Yu, Xiaodan, A brief review to integrated energy system and energy internet, Diangong Jishu Xuebao/Transactions of China Electrotechnical Society, 31, 1, pp. 1-13, (2016); Chen, Yanbo, Review and Prospect of Zero Carbon Park Research, Zhongguo Dianji Gongcheng Xuebao/Proceedings of the Chinese Society of Electrical Engineering, 44, 14, pp. 5496-5516, (2024); Journal of World Economy, (2023); Ge, Leijiao, Overview of Integrated Energy System Optimal Operation Technology for Zero-carbon Parks, Dianwang Jishu/Power System Technology, 48, 5, pp. 1821-1835, (2024); New Type Power Systems, (2025); Zhang, Xiaohui, Integrated Energy System Planning Considering a Reward and Punishment Ladder-type Carbon Trading and Electric-thermal Transfer Load Uncertainty, Zhongguo Dianji Gongcheng Xuebao/Proceedings of the Chinese Society of Electrical Engineering, 40, 19, pp. 6132-6141, (2020); undefined, (2022); Chen, Jinpeng, Thermoelectric optimization of integrated energy system considering ladder-type carbon trading mechanism and electric hydrogen production, Dianli Zidonghua Shebei/Electric Power Automation Equipment, 41, 9, pp. 48-55, (2021); High Voltage Engineering, (2023)","","Science Press","","","","","","10036520","","GAJIE","","Chinese","Article","Final","","Scopus","2-s2.0-85199678370"
"S., Roy, Soumyadeep; A., Khatua, Aparup; F., Ghoochani, Fatemeh; U., Hadler, Uwe; W., Nejdl, Wolfgang; N., Ganguly, Niloy","Roy, Soumyadeep (57709170800); Khatua, Aparup (55480153300); Ghoochani, Fatemeh (59092168200); Hadler, Uwe (59093298100); Nejdl, Wolfgang (57204338128); Ganguly, Niloy (56081670000)","57709170800; 55480153300; 59092168200; 59093298100; 57204338128; 56081670000","Beyond Accuracy: Investigating Error Types in GPT-4 Responses to USMLE Questions","2024","","","","","1073","1082","0","8","10.1145/3626772.3657882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199188807&doi=10.1145%2F3626772.3657882&partnerID=40&md5=a789f44dbf5f2d9b1f0af3365cb934eb","Indian Institute of Technology Kharagpur, Kharagpur, India; University of Michigan, Ann Arbor, Ann Arbor, United States; Forschungszentrum L3S, Hannover, Germany","Roy, Soumyadeep, Indian Institute of Technology Kharagpur, Kharagpur, India; Khatua, Aparup, University of Michigan, Ann Arbor, Ann Arbor, United States; Ghoochani, Fatemeh, Forschungszentrum L3S, Hannover, Germany; Hadler, Uwe, Forschungszentrum L3S, Hannover, Germany; Nejdl, Wolfgang, Forschungszentrum L3S, Hannover, Germany; Ganguly, Niloy, Indian Institute of Technology Kharagpur, Kharagpur, India","GPT-4 demonstrates high accuracy in medical QA tasks, leading with an accuracy of 86.70%, followed by Med-PaLM 2 at 86.50%. However, around 14% of errors remain. Additionally, current works use GPT-4 to only predict the correct option without providing any explanation and thus do not provide any insight into the thinking process and reasoning used by GPT-4 or other LLMs. Therefore, we introduce a new domain-specific error taxonomy derived from collaboration with medical students. Our GPT-4 USMLE Error (G4UE) dataset comprises 4153 GPT-4 correct responses and 919 incorrect responses to the United States Medical Licensing Examination (USMLE) respectively. These responses are quite long (258 words on average), containing detailed explanations from GPT-4 justifying the selected option. We then launch a large-scale annotation study using the Potato annotation platform and recruit 44 medical experts through Prolific, a well-known crowdsourcing platform. We annotated 300 out of these 919 incorrect data points at a granular level for different classes and created a multi-label span to identify the reasons behind the error. In our annotated dataset, a substantial portion of GPT-4's incorrect responses is categorized as a ""Reasonable response by GPT-4,""by annotators. This sheds light on the challenge of discerning explanations that may lead to incorrect options, even among trained medical professionals. We also provide medical concepts and medical semantic predications extracted using the SemRep tool for every data point. We believe that it will aid in evaluating the ability of LLMs to answer complex medical questions. We make the resources available at https://github.com/roysoumya/usmle-gpt4-error-taxonomy. © 2025 Elsevier B.V., All rights reserved.","Gpt-4; Medical Qa; Multi-label Dataset; Usmle Error Taxonomy; Http; Semantics; Taxonomies; 'current; Datapoints; Error Taxonomy; Error Types; Gpt-4; High-accuracy; Medical Qa; Multi-label Dataset; Multi-labels; Usmle Error Taxonomy; Errors","HTTP; Semantics; Taxonomies; 'current; Datapoints; Error taxonomy; Error types; Gpt-4; High-accuracy; Medical qa; Multi-label dataset; Multi-labels; Usmle error taxonomy; Errors","","","Soumyadeep Roy is supported by the Institute Ph.D. Fellowship at the Indian Institute of Technology Kharagpur. This research was partially funded by the Federal Ministry of Education and Research (BMBF), Germany under the project LeibnizKILabor with grant No. 01DD20003.","Adams, Griffin, A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course Summarization, Proceedings of Machine Learning Research, 219, pp. 2-30, (2023); Besta, MacIej, Graph of Thoughts: Solving Elaborate Problems with Large Language Models, Proceedings of the AAAI Conference on Artificial Intelligence, 38, 16, pp. 17682-17690, (2024); Chen, Anjun, Benchmarking the symptom-checking capabilities of ChatGPT for a broad range of diseases, Journal of the American Medical Informatics Association, 31, 9, pp. 2084-2088, (2024); How is Chatgpts Behavior Changing Over Time, (2023); Evaluating Large Language Models Trained on Code, (2021); Corr, (2023); Evaluation of Gpt 3 5 and Gpt 4 for Supporting Real World Information Needs in Healthcare Delivery, (2023); Fleisig, Eve, When the Majority is Wrong: Modeling Annotator Disagreement for Subjective Tasks, pp. 6715-6726, (2023); Medalpacaan Open Source Collection of Medical Conversational Ai Models and Training Data, (2023); Harrigian, Keith, Characterization of Stigmatizing Language in Medical Records, Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2, pp. 312-329, (2023)","","Association for Computing Machinery, Inc","ACM SIGIR; Special Interest Group on Computer-Human Interaction (SIGCHI)","47th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2024","","Washington; DC","201170","","9798400704314","","","English","Conference paper","Final","All Open Access; Green Accepted Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85199188807"
"F., Ma, Feng; Z., Lyu, Zhichong; H., Li, Haibo","Ma, Feng (55549235800); Lyu, Zhichong (58321884000); Li, Haibo (59889584500)","55549235800; 58321884000; 59889584500","Can ChatGPT predict Chinese equity premiums?","2024","Finance Research Letters","65","","105631","","","0","12","10.1016/j.frl.2024.105631","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194968033&doi=10.1016%2Fj.frl.2024.105631&partnerID=40&md5=f1358e07936f76b315ba3f6d03b8bf38","Southwest Jiaotong University, Chengdu, China","Ma, Feng, School of Economics and Management, Southwest Jiaotong University, Chengdu, China; Lyu, Zhichong, School of Economics and Management, Southwest Jiaotong University, Chengdu, China; Li, Haibo, School of Economics and Management, Southwest Jiaotong University, Chengdu, China","Leveraging over 1.86 million news headlines, we examine the capability of ChatGPT-3.5, a large language model (LLM), to predict equity risk premiums in the Chinese market. The predictive scores from ChatGPT not only positively and significantly forecast equity premiums but also markedly outperform the bag-of-words (BoW) method, demonstrating its superior capability to discern intricate market sentiments from extensive datasets. The consistent and reliable performance in both in-sample and out-of-sample tests underscores the effectiveness of ChatGPT and its potential to revolutionize financial forecasting. This study highlights the substantial value and innovative contribution of LLMs, such as ChatGPT, in enriching the precision and depth of financial market analysis. © 2024 Elsevier B.V., All rights reserved.","Bag-of-words; Chatgpt; Chinese Equity Premium; Large Language Model","","","","This work is supported by the Natural Science Foundation of China [ 72071162 ].","Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Beckmann, Lars, ChatGPT and the banking business: Insights from the US stock market on potential implications for banks, Finance Research Letters, 63, (2024); undefined, (2024); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Calomiris, Charles W., How news and its context drive risk and returns around the world, Journal of Financial Economics, 133, 2, pp. 299-336, (2019); Campbell, John Y., Predicting excess stock returns out of sample: Can anything beat the historical average?, Review of Financial Studies, 21, 4, pp. 1509-1531, (2008); Cao, Jiawei, Institutional investors’ site visits and firms’ financial distress, Research in International Business and Finance, 67, (2024); Carpenter, Jennifer N., The real value of China's stock market, Journal of Financial Economics, 139, 3, pp. 679-696, (2021); undefined, (2023); undefined, (2022)","","Elsevier Ltd","","","","","","15446123","","","","English","Article","Final","","Scopus","2-s2.0-85194968033"
"F., Voigt, Frederic; K., von Luck, Kai; P., Stelldinger, Peer","Voigt, Frederic (57993064500); von Luck, Kai (55637029000); Stelldinger, Peer (59873053200)","57993064500; 55637029000; 59873053200","Assessment of the Applicability of Large Language Models for Quantitative Stock Price Prediction","2024","","","","","293","302","0","8","10.1145/3652037.3652047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198104824&doi=10.1145%2F3652037.3652047&partnerID=40&md5=1926b07a9821780d490f450d20a493ea","Hochschule für Angewandte Wissenschaften Hamburg, Hamburg, Germany","Voigt, Frederic, Faculty of Engineering and Computer Science, Hochschule für Angewandte Wissenschaften Hamburg, Hamburg, Germany; von Luck, Kai, Faculty of Engineering and Computer Science, Hochschule für Angewandte Wissenschaften Hamburg, Hamburg, Germany; Stelldinger, Peer, Faculty of Engineering and Computer Science, Hochschule für Angewandte Wissenschaften Hamburg, Hamburg, Germany","In accordance with the findings presented in [34], this study examines the applicability of Machine Learning (ML) models and training strategies from the Natural Language Processing (NLP) domain in addressing time series problems, emphasizing the structural and operational aspects of these models and strategies. Recognizing the structural congruence within the data, we opt for Stock Price Prediction (SPP) as the designated domain to assess the transferability of NLP models and strategies. Building upon initial positive outcomes derived from quantitative SPP models in our ongoing research endeavors, we provide a rationale for exploring a range of additional methods and conducting subsequent research experiments. The outlined research aims to elucidate the efficacy of leveraging NLP models and techniques for addressing time series problems exemplified as SPP. © 2024 Elsevier B.V., All rights reserved.","Big Data; Large Language Models; Natural Language Processing; Quantitative Analysis; Stock Embeddings; Stock Price Prediction; Big Data; Computational Linguistics; Financial Markets; Forecasting; Natural Language Processing Systems; Embeddings; Language Model; Language Processing; Large Language Model; Natural Language Processing; Natural Languages; Processing Model; Stock Embedding; Stock Price Prediction; Times Series; Time Series","Big data; Computational linguistics; Financial markets; Forecasting; Natural language processing systems; Embeddings; Language model; Language processing; Large language model; Natural language processing; Natural languages; Processing model; Stock embedding; Stock price prediction; Times series; Time series","","","","Corr, (2020); Scaling Transformer to 1m Tokens and Beyond with Rmt, (2023); Incorporating Fine Grained Events in Stock Movement Prediction, (2019); Corr, (2019); Corr, (2025); Dai, Zihang, Transformer-XL: Attentive language models beyond a fixed-length context, pp. 2978-2988, (2020); Daiya, DIvyanshu, Stock movement prediction and portfolio management via multimodal learning with transformer, Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing, 2021-June, pp. 3305-3309, (2021); Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019); Stock Embeddings Learning Distributed Representations for Financial Assets, (2022); Industry Classification Using A Novel Financial Time Series Case Representation, (2023)","Karim, E.; Nikanfar, S.; Pavel, H.R.","Association for Computing Machinery","Association for Computing Machinery (ACM-ICPS Digital Libraries); College of Engineering, University of Texas at Arlington (UTA); Department of Computer Science and Engineering at UTA; Human Centered Computing Laboratory (Heracleia) at UTA; National Science Foundation (NSF); Technologies Journal","17th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA 2024","","Crete","200616","","9798400717604; 9798400717888; 9798400709012; 9798400716607","","","English","Conference paper","Final","","Scopus","2-s2.0-85198104824"
"T., Eloundou, Tyna; S., Manning, Sam; P., Mishkin, Pamela; D., Rock, Daniel","Eloundou, Tyna (57386309300); Manning, Sam (57653556600); Mishkin, Pamela (57222478212); Rock, Daniel (57225962751)","57386309300; 57653556600; 57222478212; 57225962751","GPTs are GPTs: Labor market impact potential of LLMs. Research is needed to estimate how jobs may be affected","2024","Science","384","6702","","1306","1308","0","74","10.1126/science.adj0998","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196882726&doi=10.1126%2Fscience.adj0998&partnerID=40&md5=a44d322a9d7a9a7f9319c8d772244dcc","OpenAI, Inc., San Francisco, United States; Centre for the Governance of AI, Oxford, United Kingdom; Wharton School of the University of Pennsylvania, Philadelphia, United States","Eloundou, Tyna, OpenAI, Inc., San Francisco, United States; Manning, Sam, Centre for the Governance of AI, Oxford, United Kingdom; Mishkin, Pamela, OpenAI, Inc., San Francisco, United States; Rock, Daniel, Wharton School of the University of Pennsylvania, Philadelphia, United States","We propose a framework for evaluating the potential impacts of large-language models (LLMs) and associated technologies on work by considering their relevance to the tasks workers perform in their jobs. By applying this framework (with both humans and using an LLM), we estimate that roughly 1.8% of jobs could have over half their tasks affected by LLMs with simple interfaces and general training. When accounting for current and likely future software developments that complement LLM capabilities, this share jumps to just over 46% of jobs. The collective attributes of LLMs such as generative pretrained transformers (GPTs) strongly suggest that they possess key characteristics of other “GPTs,” general-purpose technologies (1, 2). Our research highlights the need for robust societal evaluations and policy measures to address potential effects of LLMs and complementary technologies on labor markets. We consider the progress of LLMs’ capabilities and the potential breadth of the complementary technologies that they spawn, underscoring that maximizing the impact of LLMs requires their integration within broader systems (3–5). The rubric that we develop [see supplementary materials (SM) section 3.1.2] defines task exposure to LLMs, in the spirit of prior work on quantifying exposure to machine learning (6–8). Following prior literature, we use the concept of exposure as a proxy for potential economic impact, irrespective of labor-augmentation or displacement effects (see section 2 of the SM for further discussion of the literature). Our approach differs from the broader scope of complementary innovations in general-purpose technology discussions, focusing more narrowly on advanced software capabilities than on the potential for business process reengineering, new intangible assets creation, or workforce retraining. General-purpose technologies such as electricity or computing historically have had far-reaching effects that took decades to fully materialize. With evidence of the general-purpose technology potential of LLMs, we urge caution in making long-term predictions while offering an outline of where work might change. © 2025 Elsevier B.V., All rights reserved.","Business; Displacement; Electricity Generation; Electricity Industry; Machine Learning; Market Conditions; Software; Article; Economic Inequality; Exploratory Research; Finance; Generative Pretrained Transformer; Human; Labor; Large Language Model; Leadership; Long Term Exposure; Occupational Exposure; Pharmacist; Stakeholder Engagement; Training; Unemployment Insurance; Workflow; Article; Controlled Study; Job Market","business; displacement; electricity generation; electricity industry; machine learning; market conditions; software; Article; economic inequality; exploratory research; finance; generative pretrained transformer; human; labor; large language model; leadership; long term exposure; occupational exposure; pharmacist; stakeholder engagement; training; unemployment insurance; workflow; article; controlled study; job market","","","","Bresnahan, Timothy F., General purpose technologies 'Engines of growth'?, Journal of Econometrics, 65, 1, pp. 83-108, (1995); Economic Transformations General Purpose Technologies and Long Term Economic Growth, (2005); Prospects for Economic Growth in the United States, (2019); AI Adoption and System Wide Change, (2021); Goldfarb, Avi, Could machine learning be a general purpose technology? A comparison of emerging technologies using data from online job postings, Research Policy, 52, 1, (2023); Aea Papers and Proceedings, (2018); Aea Papers and Proceedings, (2018); Impact of Artificial Intelligence on the Labor Market, (2019); O Net O Net 27 2 Database, (2023); Beyond AI Exposure Which Tasks are Cost Effective to Automate with Computer Vision, (2024)","","American Association for the Advancement of Science","","","","","","10959203; 00368075","9781844654512; 9781844652044","SCIEA","38900883","English","Article","Final","","Scopus","2-s2.0-85196882726"
"T., Liu, Taotao; Y., Duan, Yaocong; Y., Li, Yanchun; Y., Hu, Yingying; L., Su, Lingling; A., Zhang, Aiping","Liu, Taotao (57211043547); Duan, Yaocong (57210364772); Li, Yanchun (58705403800); Hu, Yingying (58705346800); Su, Lingling (57234339500); Zhang, Aiping (57262294600)","57211043547; 57210364772; 58705403800; 58705346800; 57234339500; 57262294600","ChatGPT achieves comparable accuracy to specialist physicians in predicting the efficacy of high-flow oxygen therapy","2024","Heliyon","10","11","e31750","","","0","3","10.1016/j.heliyon.2024.e31750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193797064&doi=10.1016%2Fj.heliyon.2024.e31750&partnerID=40&md5=e5a3e81fe41e6ecf5e4c11ad3b1604a3","Chinese Academy of Medical Sciences & Peking Union Medical College, Beijing, China; University of Glasgow, Glasgow, United Kingdom; Henan University of Science and Technology, Luoyang, China; Nanjing University of Chinese Medicine, Nanjing, China","Liu, Taotao, Department of Surgical Intensive Care Unit, Chinese Academy of Medical Sciences & Peking Union Medical College, Beijing, China; Duan, Yaocong, School of Psychology and Neuroscience, University of Glasgow, Glasgow, United Kingdom; Li, Yanchun, The First Affiliated Hospital, Henan University of Science and Technology, Luoyang, China; Hu, Yingying, The First Affiliated Hospital, Henan University of Science and Technology, Luoyang, China; Su, Lingling, Department of Critical Care Medicine, Nanjing University of Chinese Medicine, Nanjing, China; Zhang, Aiping, Department of Critical Care Medicine, Nanjing University of Chinese Medicine, Nanjing, China","Background: The failure of high-flow nasal cannula (HFNC) oxygen therapy can necessitate endotracheal intubation in patients, making timely prediction of the intubation risk following HFNC therapy crucial for reducing mortality due to delays in intubation. Objectives: To investigate the accuracy of ChatGPT in predicting the endotracheal intubation risk within 48 h following HFNC therapy and compare it with the predictive accuracy of specialist and non-specialist physicians. Methods: We conducted a prospective multicenter cohort study based on the data of 71 adult patients who received HFNC therapy. For each patient, their baseline data and physiological parameters after 6-h HFNC therapy were recorded to create a 6-alternative-forced-choice questionnaire that asked participants to predict the 48-h endotracheal intubation risk using scale options ranging from 1 to 6, with higher scores indicating a greater risk. GPT-3.5, GPT-4.0, respiratory and critical care specialist physicians and non-specialist physicians completed the same questionnaires (N = 71) respectively. We then determined the optimal diagnostic cutoff point, using the Youden index, for each predictor and 6-h ROX index, and compared their predictive performance using receiver operating characteristic (ROC) analysis. Results: The optimal diagnostic cutoff points were determined to be ≥ 4 for both GPT-4.0 and specialist physicians. GPT-4.0 demonstrated a precision of 76.1 %, with a specificity of 78.6 % (95%CI = 52.4–92.4 %) and sensitivity of 75.4 % (95%CI = 62.9–84.8 %). In comparison, the precision of specialist physicians was 80.3 %, with a specificity of 71.4 % (95%CI = 45.4–88.3 %) and sensitivity of 82.5 % (95%CI = 70.6–90.2 %). For GPT-3.5 and non-specialist physicians, the optimal diagnostic cutoff points were ≥5, with precisions of 73.2 % and 64.8 %, respectively. The area under the curve (AUC) in ROC analysis for GPT-4.0 was 0.821 (95%CI = 0.698–0.943), which was the highest among the predictors and significantly higher than that of non-specialist physicians [0.662 (95%CI = 0.518–0.805), P = 0.011]. Conclusion: GPT-4.0 achieves an accuracy level comparable to specialist physicians in predicting the 48-h endotracheal intubation risk following HFNC therapy, based on patient baseline data and physiological parameters after 6-h HFNC therapy. © 2024 Elsevier B.V., All rights reserved.","Artificial Intelligence; Chatgpt; High-flow Nasal Cannula Oxygen; Rox Index","","","","T.L. was supported by National High Level Hospital Clinical Research Funding [BJ-2023-173]. T.L. and L.S. were supported by Shenyang RMS Medical Tech Company [20210901].","Frat, Jean Pierre, High-flow oxygen through nasal cannula in acute hypoxemic respiratory failure, New England Journal of Medicine, 372, 23, pp. 2185-2196, (2015); Spoletini, Giulia, Heated humidified high-flow nasal oxygen in adults: Mechanisms of action and clinical implications, Chest, 148, 1, pp. 253-261, (2015); Hernández, Gonzalo, Effect of postextubation high-flownasal cannula vs noninvasive ventilation on reintubation and postextubation respiratory failure in high-risk patients a randomized clinical trial, JAMA, 316, 15, pp. 1565-1574, (2016); Nagata, Kazuma, Home High-Flow Nasal Cannula Oxygen Therapy for Stable Hypercapnic COPD : A Randomized Clinical Trial, American Journal of Respiratory and Critical Care Medicine, 206, 11, pp. 1326-1335, (2022); Li, Jie, Awake prone positioning for non-intubated patients with COVID-19-related acute hypoxaemic respiratory failure: a systematic review and meta-analysis, The Lancet Respiratory Medicine, 10, 6, pp. 573-583, (2022); Kang, Byungju, Failure of high-flow nasal cannula therapy may delay intubation and increase mortality, Intensive Care Medicine, 41, 4, pp. 623-632, (2015); Roca, O., Predicting success of high-flow nasal cannula in pneumonia patients with hypoxemic respiratory failure: The utility of the ROX index, Journal of Critical Care, 35, pp. 200-205, (2016); Prakash, Jay, ROX index as a good predictor of high flow nasal cannula failure in COVID-19 patients with acute hypoxemic respiratory failure: A systematic review and meta-analysis, Journal of Critical Care, 66, pp. 102-108, (2021); Vega Pittao, Maria Laura, COVID-19 Pneumonia and ROX index: Time to set a new threshold for patients admitted outside the ICU, Pulmonology, 28, 1, pp. 13-17, (2022); Chandel, Abhimanyu, High-Flow Nasal Cannula Therapy in COVID-19: Using the ROX Index to Predict Success, Respiratory Care, 66, 6, pp. 909-919, (2021)","","Elsevier Ltd","","","","","","24058440","","","","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85193797064"
"J., Shi, Ji; M., Lee, Minwoo; V.G., Girish, V. G.; G., Xiao, Guangyu; C., Lee, Choong-ki","Shi, Ji (58976170800); Lee, Minwoo (55716908000); Girish, V. G. (57193526330); Xiao, Guangyu (58976170900); Lee, Choong-ki (27169369700)","58976170800; 55716908000; 57193526330; 58976170900; 27169369700","Embracing the ChatGPT revolution: unlocking new horizons for tourism","2024","Journal of Hospitality and Tourism Technology","15","3","","433","448","0","39","10.1108/JHTT-07-2023-0203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189778117&doi=10.1108%2FJHTT-07-2023-0203&partnerID=40&md5=9369e2fbbab070215d41d3762b7ef59e","Kyung Hee University, Seoul, South Korea; University of Houston, Houston, United States; The Catholic University of Korea, Bucheon-si, South Korea","Shi, Ji, College of Hotel and Tourism Management, Kyung Hee University, Seoul, South Korea; Lee, Minwoo, University of Houston, Houston, United States; Girish, V. G., Department of Business Administration, The Catholic University of Korea, Bucheon-si, South Korea; Xiao, Guangyu, College of Hotel and Tourism Management, Kyung Hee University, Seoul, South Korea; Lee, Choong-ki, College of Hotel and Tourism Management, Kyung Hee University, Seoul, South Korea","Purpose: This study aims to investigate tourists’ attitudes and intentions regarding the usage of Chat Generative Pre-trained Transformer (ChatGPT) for accessing tourism information. Furthermore, by integrating the perceived risks associated with ChatGPT and the theory of planned behavior (TPB), this research examines the impact of three types of perceived risks, such as privacy risk, accuracy risk and overreliance risk, on tourists’ behavioral intention. Design/methodology/approach: Data were gathered for this study by using two online survey platforms, thus resulting in a sample of 536 respondents. The online survey questionnaire assessed tourists’ perceived risks, attitude, subjective norm, perceived behavioral control, behavioral intention and demographic information related to their usage of ChatGPT. Findings: The structural equation modeling analysis revealed that tourists express concerns about the associated risks of using ChatGPT to search for tourism information, specifically privacy risk, accuracy risk and overreliance risk. It was found that perceived risks significantly influence tourists’ attitude and intention toward the usage of ChatGPT, which is consistent with the hypotheses proposed in previous literature regarding tourists’ perceived risks of ChatGPT. Research limitations/implications: This work is a preliminary empirical study that assesses tourists’ behavioral intention toward the use of ChatGPT in the field of tourism. Previous research has remained at the hypothetical level, speculating about the impact of ChatGPT on the tourism industry. This study investigates the behavioral intention of tourists who have used ChatGPT to search for travel information. Furthermore, this study provides evidence based on the outcome of this research and offers theoretical foundations for the sustainable development of generative AI in the tourism domain. This study has limitations in that it primarily focused on exploring the risks associated with ChatGPT and did not extensively investigate its range of benefits. Practical implications: First, to address privacy concerns that pose significant challenges for chatbots various measures, such as data encryption, secure storage and obtaining user consent, are crucial. Second, despite concerns and uncertainties, the introduction of ChatGPT holds promising prospects for the tourism industry. By offering personalized recommendations and enhancing operational efficiency, ChatGPT has the potential to revolutionize travel experiences. Finally, recognizing the potential of ChatGPT in enhancing customer service and operational efficiency is crucial for tourism enterprises. Social implications: Recognizing the potential of ChatGPT in enhancing customer service and operational efficiency is crucial for tourism enterprises. As their interest in adopting ChatGPT grows, increased investments and resources will be dedicated to developing and implementing ChatGPT solutions. This enhancement may involve creating customized ChatGPT solutions and actively engaging in training and development programs to empower employees in effectively using ChatGPT’s capabilities. Such initiatives can contribute to improved customer service and overall operations within the tourism industry. Originality/value: This study integrates TPB with perceived risks in ChatGPT, thus providing empirical evidence. It highlights the importance of considering perceived risks in tourists’ intentions and contributes to the sustainable development of generative AI in tourism. As such, it provides valuable insights for practitioners and policymakers. © 2024 Elsevier B.V., All rights reserved.","Chatgpt; Generative Ai; Information; Perceived Risk; Theory Of Planned Behavior (tpb)","","","","","Action Control from Cognition to Behavior, (1985); Ajzen, Icek, The theory of planned behavior, Organizational Behavior and Human Decision Processes, 50, 2, pp. 179-211, (1991); Ajzen, Icek, Attitude-behavior relations: A theoretical analysis and review of empirical research, Psychological Bulletin, 84, 5, pp. 888-918, (1977); Ali, Faizan, The Intersection of Technology, Accessible Tourism and Tourists With Intellectual Disabilities: Proposing a Novel Conceptual Framework, Journal of Hospitality and Tourism Research, 47, 4, pp. NP76-NP90, (2023); Ali, Faizan, Antecedents and consequences of travelers' trust towards personalized travel recommendations offered by ChatGPT, International Journal of Hospitality Management, 114, (2023); Journal of AI, (2023); Carvalho, Inês, ChatGPT for tourism: applications, benefits and risks, Tourism Review, 79, 2, pp. 290-303, (2024); Cho, Sun-ae, The decision-making process regarding the continuance intention of using branded apps: an integrated approach to the PAM and the TPB, International Journal of Contemporary Hospitality Management, 35, 12, pp. 4158-4176, (2023); Tourism Economics, (2023); Journal of Hospitality Tourism Research, (2023)","","Emerald Publishing","","","","","","17579899; 17579880","","","","English","Article","Final","","Scopus","2-s2.0-85189778117"
"K.J.L., Koa, Kelvin J.L.; Y., Ma, Yunshan; R., Ng, Ritchie; T.S., Chua, Tat Seng","Koa, Kelvin J.L. (58617942700); Ma, Yunshan (57204979967); Ng, Ritchie (57226469533); Chua, Tat Seng (7101702977)","58617942700; 57204979967; 57226469533; 7101702977","Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models","2024","","","","","4304","4315","0","16","10.1145/3589334.3645611","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194111135&doi=10.1145%2F3589334.3645611&partnerID=40&md5=6bd2fa159477fc7f907df8df70bd2f10","National University of Singapore, Singapore City, Singapore; Eastspring Investments, Singapore City, Singapore","Koa, Kelvin J.L., National University of Singapore, Singapore City, Singapore; Ma, Yunshan, National University of Singapore, Singapore City, Singapore; Ng, Ritchie, Eastspring Investments, Singapore City, Singapore; Chua, Tat Seng, National University of Singapore, Singapore City, Singapore","Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale. To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a verbal self-reflective agent and Proximal Policy Optimization (PPO) that allow a LLM teach itself how to generate explainable stock predictions, in a fully autonomous manner. The reflective agent learns how to explain past stock movements through a self-reasoning process, while the PPO trainer trains the model to generate the most likely explanations given the input texts at test-time. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a specialized LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient, for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics. Our code can be accessed through https://github.com/koa-fin/sep. © 2024 Elsevier B.V., All rights reserved.","Explainable Ai; Large Language Models; Stock Prediction; Autonomous Agents; Computational Linguistics; Deep Learning; Electronic Trading; Financial Markets; Forecasting; Learning Systems; Chaotics; Decision-making Process; Explainable Ai; Human-readable; Language Model; Large Language Model; Learning Models; Policy Optimization; Stock Movement; Stock Predictions; Decision Making","Autonomous agents; Computational linguistics; Deep learning; Electronic trading; Financial markets; Forecasting; Learning systems; Chaotics; Decision-making process; Explainable ai; Human-readable; Language model; Large language model; Learning models; Policy optimization; Stock movement; Stock predictions; Decision making","","","This research is supported by the National Research Foundation, Singapore under its Industry Alignment Fund - Pre-Positioning (IAF-PP) Funding Initiative, by the National Research Foundation, Singapore through the National Cybersecurity R&D Lab at the National University of Singapore under its National Cybersecurity R&D Programme (Award No. NCR25-NCL P3-0001). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore.","International Journal of Business and Management, (2009); Bahdanau, Dzmitry, Neural machine translation by jointly learning to align and translate, (2015); A Multitask Multilingual Multimodal Evaluation of Chatgpt on Reasoning Hallucination and Interactivity, (2023); Biran, Or, Human-centric justification of machine learning predictions, IJCAI International Joint Conference on Artificial Intelligence, 0, pp. 1461-1467, (2017); Campello, Ricardo José Gabrielli Barreto, Density-based clustering based on hierarchical density estimates, Lecture Notes in Computer Science, 7819 LNAI, PART 2, pp. 160-172, (2013); Carta, Salvatore Mario, Explainable Machine Learning Exploiting News and Domain-Specific Lexicon for Stock Market Forecasting, IEEE Access, 9, pp. 30193-30205, (2021); Explore Establish Exploit Red Teaming Language Models from Scratch, (2023); Universal Sentence Encoder, (2018); Combating Misinformation in the Age of Llms Opportunities and Challenges, (2023); Chatgpt Informed Graph Neural Network for Stock Movement Prediction, (2023)","","Association for Computing Machinery, Inc","ACM SIGWEB","33rd ACM Web Conference, WWW 2024","","Singapore","199460","","9798400701719","","","English","Conference paper","Final","All Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85194111135"
"K., Chow, Kingsum; Y., Tang, Yu; Z., Lyu, Zhiheng; A., Rajput, Anil; K., Ban, Khun","Chow, Kingsum (7202178192); Tang, Yu (59139732700); Lyu, Zhiheng (57542333700); Rajput, Anil (59139732800); Ban, Khun (57193625744)","7202178192; 59139732700; 57542333700; 59139732800; 57193625744","Performance Optimization in the LLM World 2024","2024","","","","","156","157","0","4","10.1145/3629527.3651436","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193973028&doi=10.1145%2F3629527.3651436&partnerID=40&md5=fb5239c540607a9915a5643791b86ff3","School of Software Technology, Zhejiang University, Ningbo, China; The University of Hong Kong, Hong Kong, Hong Kong; AMD Corporation, Portland, United States; Intel Corporation, Santa Clara, United States","Chow, Kingsum, School of Software Technology, Zhejiang University, Ningbo, China; Tang, Yu, School of Software Technology, Zhejiang University, Ningbo, China; Lyu, Zhiheng, Department of Computer Science, The University of Hong Kong, Hong Kong, Hong Kong; Rajput, Anil, Datacenter Ecosystem, AMD Corporation, Portland, United States; Ban, Khun, Data Center and AI, Intel Corporation, Santa Clara, United States","The popularity and adoption of large language models (LLM) like ChatGPT has evolved rapidly. LLM pre-training is expensive. ChatGPT is estimated to cost over 700,000 per day to operate, and using GPT-4 to support customer service can cost a small business over 21,000 a month. The high infrastructure and financial costs, coupled with the specialized talent required, make LLM technology inaccessible to most organizations. For instance, the up-front costs include the emissions generated to manufacture the relevant hardware and the cost to run that hardware during the training procedure, both while the machines are operating at full capacity and while they are not. The best estimate of the dynamic computing cost in the case of GPT-3, the model behind the original ChatGPT, is approximately 1,287,000 kWh, or 552 tons of carbon dioxide. The goal of this workshop is to address the urgency of reducing energy consumption of LLM applications, by bringing together researchers from the academia and industry to share their experience and insights in performance engineering in the LLM world. © 2024 Elsevier B.V., All rights reserved.","Cost Benefit Analysis; Cost Estimating; Energy Utilization; Best Estimates; Customer-service; Financial Costs; Infrastructure Costs; Language Model; Modeling Technology; Performance Optimizations; Pre-training; Small Business; Training Procedures; Carbon Dioxide","Cost benefit analysis; Cost estimating; Energy utilization; Best estimates; Customer-service; Financial costs; Infrastructure costs; Language model; Modeling technology; Performance optimizations; Pre-training; Small business; Training procedures; Carbon dioxide","","","","","","Association for Computing Machinery, Inc","ACM SIGMETRICS; ACM SIGSOFT; SPEC Reaserch","15th ACM/SPEC International Conference on Performance Engineering, ICPE 2024","","London","199384","","9798400704451","","","English","Conference paper","Final","","Scopus","2-s2.0-85193973028"
"K., Kirtac, Kemal; G., Germano, Guido","Kirtac, Kemal (58858934500); Germano, Guido (7102798637)","58858934500; 7102798637","Sentiment trading with large language models","2024","Finance Research Letters","62","","105227","","","0","29","10.1016/j.frl.2024.105227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188957331&doi=10.1016%2Fj.frl.2024.105227&partnerID=40&md5=c2a4b1392694a6d849ea6a7955dd4f7b","UCL Engineering, London, United Kingdom; Systemic Risk Centre, London, United Kingdom","Kirtac, Kemal, UCL Engineering, London, United Kingdom; Germano, Guido, UCL Engineering, London, United Kingdom, Systemic Risk Centre, London, United Kingdom","We analyse the performance of the large language models (LLMs) OPT, BERT, and FinBERT, alongside the traditional Loughran-McDonald dictionary, in the sentiment analysis of 965,375 U.S. financial news articles from 2010 to 2023. Our findings reveal that the GPT-3-based OPT model significantly outperforms the others, predicting stock market returns with an accuracy of 74.4%. A long-short strategy based on OPT, accounting for 10 basis points (bps) in transaction costs, yields an exceptional Sharpe ratio of 3.05. From August 2021 to July 2023, this strategy produces an impressive 355% gain, outperforming other strategies and traditional market portfolios. This underscores the transformative potential of LLMs in financial market prediction and portfolio management and the necessity of employing sophisticated language models to develop effective investment strategies based on news sentiment. © 2024 Elsevier B.V., All rights reserved.","Artificial Intelligence Investment Strategies; Generative Pre-trained Transformer (gpt); Large Language Models; Machine Learning In Stock Return Prediction; Natural Language Processing (nlp)","","","","","Acemoglu, Daron, Artificial Intelligence and Jobs: Evidence from Online Vacancies, Journal of Labor Economics, 40, S1, pp. S293-S340, (2022); Understanding Intermediate Layers Using Linear Classifier Probes, (2016); Baker, Scott R., Measuring economic policy uncertainty, Quarterly Journal of Economics, 131, 4, pp. 1593-1636, (2016); Baker, Malcolm P., Investor sentiment and the cross-section of stock returns, Journal of Finance, 61, 4, pp. 1645-1680, (2006); Structure of Economic News, (2025); Calomiris, Charles W., How news and its context drive risk and returns around the world, Journal of Financial Economics, 133, 2, pp. 299-336, (2019); Campbell, John L., The information content of mandatory risk factor disclosures in corporate filings, Review of Accounting Studies, 19, 1, pp. 396-455, (2014); Carhart, Mark M., On persistence in mutual fund performance, Journal of Finance, 52, 1, pp. 57-82, (1997); Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019); Fama, Eugene F., Common risk factors in the returns on stocks and bonds, Journal of Financial Economics, 33, 1, pp. 3-56, (1993)","","Elsevier Ltd","","","","","","15446123","","","","English","Article","Final","All Open Access; Green Accepted Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85188957331"
"C., Peng, Chen; H., He, Hailing; Z., Liu, Zhengping; L., Zhang, Lieping; X., Cao, Xinwei; A.T., Khan, Ameer Tamoor; V.N., Katsikis, Vasilios N.; S., Li, Shuai","Peng, Chen (55605931300); He, Hailing (59380278900); Liu, Zhengping (59380734900); Zhang, Lieping (59380434400); Cao, Xinwei (57215652987); Khan, Ameer Tamoor (57218327607); Katsikis, Vasilios N. (14622656900); Li, Shuai (58667863100)","55605931300; 59380278900; 59380734900; 59380434400; 57215652987; 57218327607; 14622656900; 58667863100","Empowering financial futures: Large language models in the modern financial landscape","2024","EAI Endorsed Transactions on AI and Robotics","3","","","","","0","11","10.4108/airo.6117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207310449&doi=10.4108%2Fairo.6117&partnerID=40&md5=e5e3efa7474061119f88a1f205131b36","Jishou University, Jishou, China; Jishou University, Jishou, China; Jiangnan University, Wuxi, China; Københavns Universitet, Copenhagen, Denmark; National and Kapodistrian University of Athens, Athens, Greece; Oulun Yliopisto, Oulu, Finland","Peng, Chen, Department of Computer Science and Engineering, Jishou University, Jishou, China; He, Hailing, School of Communication and Electronic Engineering, Jishou University, Jishou, China; Liu, Zhengping, School of Communication and Electronic Engineering, Jishou University, Jishou, China; Zhang, Lieping, School of Communication and Electronic Engineering, Jishou University, Jishou, China; Cao, Xinwei, School of Business, Jiangnan University, Wuxi, China; Khan, Ameer Tamoor, Department of Plant and Environmental Sciences, Københavns Universitet, Copenhagen, Denmark; Katsikis, Vasilios N., Department of Economics, National and Kapodistrian University of Athens, Athens, Greece; Li, Shuai, Faculty of Information Technology and Electrical Engineering, Oulun Yliopisto, Oulu, Finland","In this paper, we delve into the transformative influence of Large Language Models (LLMs) in the financial sector. Through meticulous exploration, we uncover the multifaceted applications of LLMs, ranging from elevating customer support and fortifying fraud detection to reshaping market analysis and prediction. LLMs, with their unparalleled ability to process extensive textual data, bring forth innovative solutions and insights. However, we also address critical challenges such as user trust and ethical considerations, emphasizing the need for responsible integration. Collaborative efforts between industry stakeholders and researchers are essential prerequisites for making a pivotal stride towards a future where LLMs redefine financial practices, with efficiency, accuracy, and ethical precision shaping the industry’s evolution. © 2024 Elsevier B.V., All rights reserved.","Customer Support; Financial Sector; Fraud Detection; Large Language Models","","","","","Li, Zhibin, A Novel Calibration System for Robot Arm via an Open Dataset and a Learning Perspective, IEEE Transactions on Circuits and Systems II: Express Briefs, 69, 12, pp. 5169-5173, (2022); Li, Zhibin, An overview of calibration technology of industrial robots, IEEE/CAA Journal of Automatica Sinica, 8, 1, pp. 23-36, (2021); IEEE Transactions on Neural Networks and Learning Systems, (2022); Jin, Long, Different-level simultaneous minimization scheme for fault tolerance of redundant manipulator aided with discrete-time recurrent neural network, Frontiers in Neurorobotics, 11, SEP, (2017); Zhang, Zhijun, A new varying-parameter recurrent neural-network for online solution of time-varying sylvester equation, IEEE Transactions on Cybernetics, 48, 11, pp. 3135-3148, (2018); Xiao, Lin, Nonlinear recurrent neural networks for finite-time solution of general time-varying linear matrix equations, Neural Networks, 98, pp. 102-113, (2018); Liao, Bolin, Inter-robot management via neighboring robot sensing and measurement using a zeroing neural dynamics approach, Expert Systems with Applications, 244, (2024); Min, Bonan, Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey, ACM Computing Surveys, 56, 2, (2024); Haque, Md Asraful, A Brief Analysis of “ChatGPT” – A Revolutionary Tool Designed by OpenAI, EAI Endorsed Transactions on AI and Robotics, 1, (2022); Tank, Umesh, A Study Towards Building Content Aware Models in NLP using Genetic Algorithms, EAI Endorsed Transactions on AI and Robotics, 2, (2023)","","European Alliance for Innovation","","","","","","27907511","","","","English","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85207310449"
"H., Almalki, Hassan; A.O., Khadidos, Alaa Omar; N., Alhebaishi, Nawaf","Almalki, Hassan (59682804600); Khadidos, Alaa Omar (57213160277); Alhebaishi, Nawaf (57192958341)","59682804600; 57213160277; 57192958341","Enhancing Alzheimer’s Detection: Leveraging ADNI Data and Large Language Models for High-Accuracy Diagnosis","2024","International Journal of Advanced Computer Science and Applications","15","11","","1363","1375","0","1","10.14569/IJACSA.2024.01511134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000671835&doi=10.14569%2FIJACSA.2024.01511134&partnerID=40&md5=1d0ffdecb5528eab00a8c2cd754cbc70","College of Engineering and Information Technology, Jeddah, Saudi Arabia; Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; King Abdulaziz University, Jeddah, Saudi Arabia","Almalki, Hassan, Department of Information Technology, College of Engineering and Information Technology, Jeddah, Saudi Arabia; Khadidos, Alaa Omar, Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia, Center of Research Excellence in Artificial Intelligence and Data Science, King Abdulaziz University, Jeddah, Saudi Arabia; Alhebaishi, Nawaf, Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia","Alzheimer’s disease (AD), the most common type of dementia, is expected to affect 152 million people by 2050, emphasizing the importance of early diagnosis. This study uses the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset, combining cognitive tests, biomarkers, demographic details, and genetic data to build predictive models. Using large language models (LLMs), specifically ChatGPT 3.5, we achieved high classification accuracy, with ROC AUC values of 0.98 for cognitively normal (CN) individuals, 0.99 for dementia, and 0.98 for mild cognitive impairment (MCI). These findings show that LLMs can handle complex data quickly and accurately. By focusing on numerical and text-based data instead of just imaging, this method provides a cost-effective and accessible option for diagnosing AD. Adding genetic information improves the predictions, reflecting the important role of genetics in AD risk. This study highlights the potential of combining different types of data with advanced machine learning and LSTM to improve early AD diagnosis. Future research should explore more ways to combine data and test different machine learning models to further enhance diagnostic tools. © 2025 Elsevier B.V., All rights reserved.","Alzheimer; Chatgpt; Dementia; Llms; Lstm; Diagnosis; Neuroimaging; Alzheimer; Chatgpt; Cognitive Tests; Dementia; Early Diagnosis; Genetic Data; High-accuracy; Language Model; Large Language Model; Lstm; Neurodegenerative Diseases","Diagnosis; Neuroimaging; Alzheimer; ChatGPT; Cognitive tests; Dementia; Early diagnosis; Genetic data; High-accuracy; Language model; Large language model; LSTM; Neurodegenerative diseases","","","","Raj, Sushrutha, Classify Alzheimer genes association using Naïve Bayes algorithm, Human Gene, 41, (2024); Transfer Learning and Class Decomposition for Detecting the Cognitive Decline of Alzheimer Disease, (2023); Techrxiv, (2023); Aviles-Rivero, Angelica I., Multi-modal Hypergraph Diffusion Network with Dual Prior for Alzheimer Classification, Lecture Notes in Computer Science, 13433 LNCS, pp. 717-727, (2022); Memon, Muhammad Hammad, Early Stage Alzheimer's Disease Diagnosis Method, pp. 222-225, (2019); Lee, Garam, Predicting Alzheimer’s disease progression using multi-modal deep learning approach, Scientific Reports, 9, 1, (2019); Aderghal, Karim, Classification of Alzheimer Disease on Imaging Modalities with Deep CNNs Using Cross-Modal Transfer Learning, Proceedings of the IEEE Symposium on Computer-Based Medical Systems, 2018-June, pp. 345-350, (2018); 3D Cnn Based Classification Using Smri and MD Dti Images for Alzheimer Disease Studies, (2018); undefined, (2019); Predicting Alzheimer S Disease Using 3dmgnet, (2022)","","Science and Information Organization","","","","","","21565570; 2158107X","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-86000671835"
"M., Abdelsamie, Mohamed; H., Wang, Hua","Abdelsamie, Mohamed (58874193300); Wang, Hua (57223638931)","58874193300; 57223638931","Comparative Analysis of LLM-based Market Prediction and Human Expertise with Sentiment Analysis and Machine Learning Integration","2024","","","","","","","0","2","10.1109/DSIT61374.2024.10881868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000192406&doi=10.1109%2FDSIT61374.2024.10881868&partnerID=40&md5=6c16a90738fee44c7e10547f41b267a1","Zhejiang University International Business School, Haining, China","Abdelsamie, Mohamed, Zhejiang University International Business School, Haining, China; Wang, Hua, Zhejiang University International Business School, Haining, China","This study conducts a comparative analysis of market prediction accuracy between Large Language Model (LLM)-based systems and human expertise within the financial analysis domain. Leveraging Quantum, an advanced LLM specialized for financial forecasting, we evaluate its predictive performance against human analysts and general-purpose LLMs, including GPT-3, GPT-4, FinGPT, and FinBERT. Employing a dataset of historical financial data, news headlines, and social media sentiment, we systematically assess predictive accuracy, response efficiency, and interpretability across models. The integration of sentiment analysis and machine learning further strengthens prediction reliability. Results reveal that Quantum's specialized model demonstrates superior accuracy and speed in financial forecasting compared to human predictions and generalized LLMs, particularly in fast-moving, data-rich contexts. Nevertheless, limitations in nuanced contextual understanding and adaptability persist, highlighting the enduring value of human expertise. This research reinforces the potential of LLMs as robust tools for financial decision-making while identifying key areas for refinement to enhance synergy with human analytical insights. https://chatgpt.com/g/g-bS4Q76v0I-quantum © 2025 Elsevier B.V., All rights reserved.","Financial Prediction; Large Language Models; Machine Learning; Market Forecasting; Quantum Ai; Sentiment Analysis; Adversarial Machine Learning; Contrastive Learning; Machine Learning; Predictive Analytics; Sentiment Analysis; Comparative Analyzes; Financial Prediction; Human Expertise; Language Model; Large Language Model; Machine-learning; Market Forecasting; Market Prediction; Quantum Ai; Prediction Models","Adversarial machine learning; Contrastive Learning; Machine learning; Predictive analytics; Sentiment analysis; Comparative analyzes; Financial prediction; Human expertise; Language model; Large language model; Machine-learning; Market forecasting; Market prediction; Quantum AI; Prediction models","","","","Liu, Chenghao, Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study, IEEE Access, 12, pp. 134041-134061, (2024); Revolutionizing Finance with Llms an Overview of Applications and Insights, (2024); Journal of Financial Analytics; IEEE Transactions on Finance, (2024); Journal of Nlp Research, (2023); Kirtac, Kemal, Sentiment trading with large language models, Finance Research Letters, 62, (2024); Chinese Financial Analysis Journal, (2024); Bert Pre Training of Deep Bidirectional Transformers for Language Understanding, (2018); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); International Journal of Financial Data Science, (2024)","","Institute of Electrical and Electronics Engineers Inc.","IEEE; IEEE Communications Society (ComSoc); International Society for Applied Computing (ISAC)","7th International Conference on Data Science and Information Technology, DSIT 2024","","Nanjing","207065","","9798350384093","","","English","Conference paper","Final","","Scopus","2-s2.0-86000192406"
"Q., Chen, Qizhao; H., Kawashima, Hiroaki","Chen, Qizhao (59560720800); Kawashima, Hiroaki (8870589800)","59560720800; 8870589800","Stock Price Prediction Using LLM-Based Sentiment Analysis","2024","","","","","4846","4853","0","2","10.1109/BigData62323.2024.10825946","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218039365&doi=10.1109%2FBigData62323.2024.10825946&partnerID=40&md5=54fd983a216a01dd1a3be924f96635ac","University of Hyogo, Kobe, Japan","Chen, Qizhao, Graduate School of Information Science, University of Hyogo, Kobe, Japan; Kawashima, Hiroaki, Graduate School of Information Science, University of Hyogo, Kobe, Japan","This paper examines the effectiveness of recent large language model-based news sentiment estimation for stock price forecasting with the combination of latest transformer-based prediction models. To achieve a better accuracy in sentiment classification, experiments are designed to compare six different models (GPT 4, Llama 3, Gemma 2, Mistral 7b, FinBERT, VADER) in financial news sentiment classification, and it was found that recent large language models can outperform FinBERT and VADER, which are the most commonly used models in financial sentiment analysis. Based on the experiment results, Llama 3, with relatively stable performance, is chosen to classify the news sentiments of the selected companies. Informer, Transformer, TCN, LSTM, SVR, Random Forest and Naive Forecast are used to predict the stock prices with different sliding window sizes. Experiments with different scenarios are designed to evaluate the prediction ability of news sentiment. Results show that adding news sentiment data can indeed improve the stock price prediction. Informer, one of the state-of-the-art transformer models for long-term prediction tasks, yields the best performances in most cases. Ablation study of Informer suggests that the generative style decoder plays an important role in performance improvement. © 2025 Elsevier B.V., All rights reserved.","Informer; Llm; Sentiment Analysis; Time Series Forecasting; Transformer; Costs; Informer; Language Model; Llm; Model-based Opc; Performance; Sentiment Analysis; Sentiment Classification; Stock Price Prediction; Time Series Forecasting; Transformer; Prediction Models","Costs; Informer; Language model; LLM; Model-based OPC; Performance; Sentiment analysis; Sentiment classification; Stock price prediction; Time series forecasting; Transformer; Prediction models","","","","Wu, Jimmy Ming Tai, A graph-based CNN-LSTM stock price prediction algorithm with leading indicators, Multimedia Systems, 29, 3, pp. 1751-1770, (2023); Journal of Modeling and Optimization, (2020); Proceedings of the 2nd International Academic Conference on Blockchain Information Technology and Smart Finance Icbis 2023, (2023); Malibari, Nadeem, Predicting Stock Closing Prices in Emerging Markets with Transformer Neural Networks: The Saudi Stock Exchange Case, International Journal of Advanced Computer Science and Applications, 12, 12, pp. 876-886, (2021); Abdelfattah, Bassant A., Enhancing the Prediction of Stock Market Movement Using Neutrosophic-Logic-Based Sentiment Analysis, Journal of Theoretical and Applied Electronic Commerce Research, 19, 1, pp. 116-134, (2024); Xiao, Qianyi, Stock trend prediction using sentiment analysis, PeerJ Computer Science, 9, (2023); Maqbool, Junaid, Stock Prediction by Integrating Sentiment Scores of Financial News and MLP-Regressor: A Machine Learning Approach, Procedia Computer Science, 218, pp. 1067-1078, (2022); Koukaras, Paraskevas, Stock Market Prediction Using Microblogging Sentiment Analysis and Machine Learning, Telecom, 3, 2, pp. 358-378, (2022); Mohan, Saloni, Stock price prediction using news sentiment analysis, pp. 205-208, (2019); Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019)","Ding, W.; Lu, C.-T.; Wang, F.; Di, L.; Wu, K.; Huan, J.; Nambiar, R.; Li, J.; Ilievski, F.; Baeza-Yates, R.; Hu, X.","Institute of Electrical and Electronics Engineers Inc.","Ankura; IEEE Computer Society; IEEE Dataport; U.S. National Science Foundation (NSF); Virginia Tech","2024 IEEE International Conference on Big Data, BigData 2024","","Washington; DC","206131","","9798350362480","","","English","Conference paper","Final","","Scopus","2-s2.0-85218039365"
"A., Elahi, Ali; F., Taghvaei, Fatemeh","Elahi, Ali (57202994446); Taghvaei, Fatemeh (59462463000)","57202994446; 59462463000","Combining Financial Data and News Articles for Stock Price Movement Prediction Using Large Language Models","2024","","","","","4875","4883","0","2","10.1109/BigData62323.2024.10825449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218029065&doi=10.1109%2FBigData62323.2024.10825449&partnerID=40&md5=790912932a746f9111e10d052957e832","College of Engineering, Chicago, United States; College of Engineering, Chicago, United States","Elahi, Ali, College of Engineering, Chicago, United States; Taghvaei, Fatemeh, College of Engineering, Chicago, United States","Predicting financial markets and stock price movements requires analyzing a company's performance, historic price movements, industry-specific events alongside the influence of human factors such as social media and press coverage. We assume that financial reports (such as income statements, balance sheets, and cash flow statements), historical price data, and recent news articles can collectively represent aforementioned factors.We combine financial data in tabular format with textual news articles and employ pre-trained Large Language Models (LLMs) to predict market movements. Recent research in LLMs has demonstrated that they are able to perform both tabular and text classification tasks, making them our primary model to classify the multi-modal data. We utilize retrieval augmentation techniques to retrieve and attach relevant chunks of news articles to financial metrics related to a company and prompt the LLMs in zero, two, and four-shot settings. Our dataset contains news articles collected from different sources, historic stock price, and financial report data for 20 companies with the highest trading volume across different industries in the stock market. We utilized recently released language models for our LLM-based classifier, including GPT- 3 and 4, and LLaMA- 2 and 3 models.We introduce an LLM-based classifier capable of performing classification tasks using combination of tabular (structured) and textual (unstructured) data. By using this model, we predicted the movement of a given stock's price in our dataset with a weighted F1-score of 58.5% and 59.1% and Matthews Correlation Coefficient of 0.175 for both 3-month and 6-month periods.The dataset and codes for this paper can be found on Github. https://github.com/aliielahi/FinedFMP 1 © 2025 Elsevier B.V., All rights reserved.","Financial Stock Price Movement Prediction; Information Retrieval; Large Language Models; Retrieval Augmented Generation; Commerce; Financial Data Processing; Financial Markets; Network Security; Prediction Models; Classification Tasks; Financial Data; Financial Reports; Financial Stock Price Movement Prediction; Language Model; Large Language Model; News Articles; Retrieval Augmented Generation; Stock Price; Stock Price Movement Predictions; Costs","Commerce; Financial data processing; Financial markets; Network security; Prediction models; Classification tasks; Financial data; Financial reports; Financial stock price movement prediction; Language model; Large language model; News articles; Retrieval augmented generation; Stock price; Stock price movement predictions; Costs","","","","Li, Yinheng, Large Language Models in Finance: A Survey, pp. 374-382, (2023); Loukas, Lefteris, Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking, pp. 392-400, (2023); Vamvourellis, Dimitrios, Learning Mutual Fund Categorization using Natural Language Processing, pp. 87-95, (2022); Zhang, Boyu, Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models, pp. 349-356, (2023); Query2doc Query Expansion with Large Language Models, (2023); Lakkaraju, Kausik, LLMs for Financial Advisement: A Fairness and Efficacy Study in Personal Decision Making, pp. 100-107, (2023); Llmfactor Extracting Profitable Factors Through Prompts for Explainable Stock Movement Prediction, (2024); Corr, (2024); Weng, Bin, Stock market one-day ahead movement prediction using disparate data sources, Expert Systems with Applications, 79, pp. 153-163, (2017); Journal of Finance, (1970)","Ding, W.; Lu, C.-T.; Wang, F.; Di, L.; Wu, K.; Huan, J.; Nambiar, R.; Li, J.; Ilievski, F.; Baeza-Yates, R.; Hu, X.","Institute of Electrical and Electronics Engineers Inc.","Ankura; IEEE Computer Society; IEEE Dataport; U.S. National Science Foundation (NSF); Virginia Tech","2024 IEEE International Conference on Big Data, BigData 2024","","Washington; DC","206131","","9798350362480","","","English","Conference paper","Final","","Scopus","2-s2.0-85218029065"
"Y., Abe, Yoshia; S., Matsuo, Shuhei; R., Kondo, Ryoma; R., Hisano, Ryohei","Abe, Yoshia (58833651000); Matsuo, Shuhei (59484456900); Kondo, Ryoma (57215313136); Hisano, Ryohei (36571975300)","58833651000; 59484456900; 57215313136; 36571975300","Leveraging Large Language Models for Institutional Portfolio Management: Persona-Based Ensembles","2024","","","","","4799","4808","0","0","10.1109/BigData62323.2024.10825362","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217991165&doi=10.1109%2FBigData62323.2024.10825362&partnerID=40&md5=19bea37491118f60610147e5ea8937aa","University of Tokyo, Graduate School of Information Science and Technology, Tokyo, Japan; University of Tokyo, Graduate School of Information Science and Technology, Tokyo, Japan","Abe, Yoshia, University of Tokyo, Graduate School of Information Science and Technology, Tokyo, Japan; Matsuo, Shuhei, University of Tokyo, Graduate School of Information Science and Technology, Tokyo, Japan; Kondo, Ryoma, University of Tokyo, Graduate School of Information Science and Technology, Tokyo, Japan; Hisano, Ryohei, University of Tokyo, Graduate School of Information Science and Technology, Tokyo, Japan","Large language models (LLMs) have demonstrated promising performance in various financial applications, though their potential in complex investment strategies remains underexplored. To address this gap, we investigate how LLMs can predict price movements in stock and bond portfolios using economic indicators, enabling portfolio adjustments akin to those employed by institutional investors. Additionally, we explore the impact of incorporating different personas within LLMs, using an ensemble approach to leverage their diverse predictions. Our findings show that LLM-based strategies, especially when combined with the mode ensemble, outperform the buy-and-hold strategy in terms of Sharpe ratio during periods of rising consumer price index (CPI). However, traditional strategies are more effective during declining CPI trends or sharp market downturns. These results suggest that while LLMs can enhance portfolio management, they may require complementary strategies to optimize performance across varying market conditions. © 2025 Elsevier B.V., All rights reserved.","Ensemble Method; Finance; Large Language Models; Persona; Portfolio Management; Prompt Engineering; Asset Management; Commerce; Decentralized Finance; Financial Markets; Investments; Consumer Price Index; Ensemble Methods; Financial Applications; Investment Strategy; Language Model; Large Language Model; Performance; Persona; Portfolio Managements; Prompt Engineering","Asset management; Commerce; Decentralized finance; Financial markets; Investments; Consumer price index; Ensemble methods; Financial applications; Investment strategy; Language model; Large language model; Performance; Persona; Portfolio managements; Prompt engineering","","","This research was supported by JST SPRING GX project (Grant Number JPMJSP2108), the JST FOREST Program (Grant Number JPMJFR216Q) and The University of Tokyo Data Science School. We thank Kimberly Moravec, PhD, from Edanz for editing a draft of this manuscript.","Company Similarity Using Large Language Models, (2023); Enhancing Knowledge Graph Construction Using Large Language Models, (2023); Bhattacharya, Indranil, Accounting fraud detection using contextual language learning, International Journal of Accounting Information Systems, 53, (2024); A Survey of Large Language Models for Financial Applications Progress Prospects and Challenges, (2024); Ko, Hyungjin, Can ChatGPT improve investment decisions? From a portfolio management perspective, Finance Research Letters, 64, (2024); Romanko, Oleksandr, ChatGPT-Based Investment Portfolio Selection, Operations Research Forum, 4, 4, (2023); Cheng, Yuhan, GPT's idea of stock factors, Quantitative Finance, 24, 9, pp. 1301-1326, (2024); Barber, Brad M., Trading is hazardous to your wealth: The common stock investment performance of individual investors, Journal of Finance, 55, 2, pp. 773-806, (2000); Financial Behavior Players Services Products and Markets, (2017); Journal of Psychology and Financial Markets, (2001)","Ding, W.; Lu, C.-T.; Wang, F.; Di, L.; Wu, K.; Huan, J.; Nambiar, R.; Li, J.; Ilievski, F.; Baeza-Yates, R.; Hu, X.","Institute of Electrical and Electronics Engineers Inc.","Ankura; IEEE Computer Society; IEEE Dataport; U.S. National Science Foundation (NSF); Virginia Tech","2024 IEEE International Conference on Big Data, BigData 2024","","Washington; DC","206131","","9798350362480","","","English","Conference paper","Final","","Scopus","2-s2.0-85217991165"
"H., Razavi, Hooman; M.R., Jamali, Mohammad Reza","Razavi, Hooman (56684729200); Jamali, Mohammad Reza (7006385326)","56684729200; 7006385326","Large Language Models (LLM) for Estimating the Cost of Cyber-attacks","2024","","","","","403","409","0","9","10.1109/IST64061.2024.10843617","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217619024&doi=10.1109%2FIST64061.2024.10843617&partnerID=40&md5=b8a58d17ff2241bd20fede87dac8370c","Tecnológico de Monterrey, Monterrey, Mexico; Pulseware Co., Tehran, Iran","Razavi, Hooman, School of Science and Engineering, Tecnológico de Monterrey, Monterrey, Mexico; Jamali, Mohammad Reza, Pulseware Co., Tehran, Iran","With the expansion of digital services and intelligent agents, cyber-attacks are increasingly frequent and impactful. Estimating the financial consequences of these attacks has become crucial in guiding investments in mitigation and defense strategies. This paper presents a framework leveraging Large Language Models (LLMs) and big data analytics to estimate the financial impact of cyber threats, specifically focusing on lost business opportunities in the banking sector. As a frequent target of cyberattacks, the banking industry suffers significant financial losses and a decline in customer trust. By analyzing over 23 billion transactions, the LLM algorithm identifies business activity patterns and calculates losses during operational downtimes. The study compares the performance of LLMs with alternative models, including Deep Learning, Support Vector Machines (SVM), and Random Walk, highlighting the superior accuracy of LLMs in estimating business activity disruptions. The findings provide a scalable methodology for calculating the financial cost of cyber-attacks in the banking sector, with potential applications in other industries. The study underscores the critical need for robust cybersecurity measures and effective risk mitigation strategies, given the high costs incurred during cyber-attack downtimes. © 2025 Elsevier B.V., All rights reserved.","Big Data Analytics; Cyber Risk Assessment; Cyber-attack; Deep Learning; Large Language Models; Qos; Statistical Analysis; Computer Viruses; Costs; Decentralized Finance; Deep Learning; Network Security; Phishing; Risk Assessment; Banking Sectors; Big Data Analytic; Business Activities; Cybe Risk Assessment; Cyber-attacks; Data Analytics; Language Model; Large Language Model; Risks Assessments; Cyber Attacks","Computer viruses; Costs; Decentralized finance; Deep learning; Network security; Phishing; Risk assessment; Banking sectors; Big data analytic; Business activities; Cybe risk assessment; Cyber-attacks; Data analytics; Language model; Large language model; Risks assessments; Cyber attacks","","","","Zhang, Xinrong, A game-theoretic approach of cyberattack resilient constraint-following control for cyber–physical systems, Ad Hoc Networks, 153, (2024); Facchinetti, Silvia, A statistical approach for assessing cyber risk via ordered response models, Risk Analysis, 44, 2, pp. 425-438, (2024); Razavi, Hooman, The rise of AI in middle eastern FinTech with the case studies from the UAE and Turkey, pp. 259-297, (2024); T N, Nisha N., Zero click attacks – a new cyber threat for the e-banking sector, Journal of Financial Crime, 30, 5, pp. 1150-1161, (2023); Kuzior, Aleksandra, Countering Cybercrime Risks in Financial Institutions: Forecasting Information Trends, Journal of Risk and Financial Management, 15, 12, (2022); Stationx; Behfar, Arezou, Can Password Meter be More Effective Towards User Attention, Engagement, and Attachment?: A Study of Metaphor-based Designs, pp. 164-171, (2023); He, Zhijian Chris, The Impact of Customer-Reported Cybersecurity Breaches on Key Supplier Innovations and Relationship Disruption, Journal of Information Systems, 37, 2, pp. 21-49, (2023); Razavi, Hooman, Quantifying the Financial Impact of Cyber Security Attacks on Banks: A Big Data Analytics Approach, Canadian Conference on Electrical and Computer Engineering, 2023-September, pp. 533-538, (2023); International Journal of Advanced Research in Humanities and Law, (2024)","","Institute of Electrical and Electronics Engineers Inc.","","11th International Symposium on Telecommunication, IST 2024","","Hybrid, Tehran","206253","","9798350356250","","","English","Conference paper","Final","","Scopus","2-s2.0-85217619024"
"","","","2024 6th International Conference on Machine Learning, Big Data and Business Intelligence, MLBDBI 2024","2024","","","","","","","301","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216976361&partnerID=40&md5=cb1fb94b2db4afe0b619cb030162e75d","","","The proceedings contain 57 papers. The topics discussed include: research on aspect-level emotion categorization based on hybrid attention mechanism; research on financial transaction data protection and intelligent risk assessment based on differential privacy; fine-tuned large language model for autonomous vehicles accident report; research on optimization strategy of production line in aviation manufacturing enterprises based on machine learning; research on factor interaction effects and nonlinear relationships in quantitative models; exploring emotion recognition in children with autism spectrum disorder using ChatGPT; and predicting user purchase behavior on JD.com: a sequential interaction and engagement depth model. © 2025 Elsevier B.V., All rights reserved.","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","IEEE","6th International Conference on Machine Learning, Big Data and Business Intelligence, MLBDBI 2024","","Hangzhou","205892","","9798331541798","","","English","Conference review","Final","","Scopus","2-s2.0-85216976361"
"L., Majer, Laura; J., Snajder, Jan","Majer, Laura (58672597800); Snajder, Jan (14020411700)","58672597800; 14020411700","Claim Check-Worthiness Detection: How Well do LLMs Grasp Annotation Guidelines?","2024","","","","","245","263","0","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216933378&partnerID=40&md5=eecd77a970190f5911650473c640d05d","University of Zagreb, Faculty of Electrical Engineering and Computing, Zagreb, Croatia","Majer, Laura, Text Analysis and Knowledge Engineering Lab, University of Zagreb, Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Snajder, Jan, Text Analysis and Knowledge Engineering Lab, University of Zagreb, Faculty of Electrical Engineering and Computing, Zagreb, Croatia","The rising threat of disinformation underscores the need to fully or partially automate the fact-checking process. Identifying text segments requiring fact-checking is known as claim detection (CD) and claim check-worthiness detection (CW), the latter incorporating complex domain-specific criteria of worthiness and often framed as a ranking task. Zero- and few-shot LLM prompting is an attractive option for both tasks, as it bypasses the need for labeled datasets and allows verbalized claim and worthiness criteria to be directly used for prompting. We evaluate the LLMs’ predictive accuracy on five CD/CW datasets from diverse domains, using corresponding annotation guidelines in prompts. We examine two key aspects: (1) how to best distill factuality and worthiness criteria into a prompt, and (2) how much context to provide for each claim. To this end, we experiment with different levels of prompt verbosity and varying amounts of contextual information given to the model. We additionally evaluate the top-performing models with ranking metrics, resembling prioritization done by fact-checkers. Our results show that optimal prompt verbosity varies, meta-data alone adds more performance boost than co-text, and confidence scores can be directly used to produce reliable check-worthiness rankings. © 2025 Elsevier B.V., All rights reserved.","Labeled Data; Complex Domains; Contextual Information; Diverse Domains; Domain Specific; Labeled Dataset; Meta-data; Performance; Predictive Accuracy; Prioritization; Text Segments; Computational Linguistics","Labeled data; Complex domains; Contextual information; Diverse domains; Domain specific; Labeled dataset; Meta-data; Performance; Predictive accuracy; Prioritization; Text segments; Computational linguistics","","","This research was supported by the Adria Digital Media Observatory (ADMO) project, which is part of EDMO, EU\u2019s largest interdisciplinary network for countering disinformation.","Can Chatgpt Fact Check Politifact Tested, (2023); Alam, Firoj, Fighting the COVID-19 Infodemic: Modeling the Perspective of Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the Society, pp. 611-649, (2021); Balloccu, Simone, Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs, 1, pp. 67-93, (2024); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019); Challenges of Online Fact Checking, (2020); Reddy, Revanth Gangi, NEWSCLAIMS: A New Benchmark for Claim Detection from News with Attribute Knowledge, pp. 6002-6018, (2022); Gencheva, Pepa, A context-aware approach for detecting worth-checking claims in political debates, International Conference Recent Advances in Natural Language Processing, RANLP, 2017-September, pp. 267-276, (2017); Glockner, Max, Missing Counter-Evidence Renders NLP Fact-Checking Unrealistic for Misinformation, pp. 5916-5936, (2022); Hassan, Naeemul, Toward automated fact-checking: Detecting check-worthy factual claims by claimbuster, Part F129685, pp. 1803-1812, (2017)","Schlichtkrull, M.; Chen, Y.; Whitehouse, C.; Deng, Z.; Akhtar, M.; Aly, R.; Guo, Z.; Christodoulopoulos, C.; Cocarascu, O.; Mittal, A.; Thorne, J.; Vlachos, A.","Association for Computational Linguistics (ACL)","Google","7th Fact Extraction and VERification Workshop, FEVER 2024","","Miami; FL","205926","","9798891761728","","","English","Conference paper","Final","","Scopus","2-s2.0-85216933378"
"T., Guo, Tian; E., Hauptmann, Emmanuel","Guo, Tian (59801309200); Hauptmann, Emmanuel (57219759904)","59801309200; 57219759904","Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow","2024","","","","","1028","1045","0","1","10.18653/v1/2024.emnlp-industry.77","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216806545&doi=10.18653%2Fv1%2F2024.emnlp-industry.77&partnerID=40&md5=2ccbe33a5d5919c4678d9110014341cc","Systematic Equities Team, Geneva, Switzerland","Guo, Tian, Systematic Equities Team, Geneva, Switzerland; Hauptmann, Emmanuel, Systematic Equities Team, Geneva, Switzerland","Large language models (LLMs) and their fine-tuning techniques have demonstrated superior performance in various language understanding and generation tasks. This paper explores fine-tuning LLMs for predicting stock returns with financial newsflow. Return prediction is fundamental for quantitative investing tasks like portfolio construction and optimization. We formulate the model to include a text representation and forecasting modules. We propose to compare the encoder-only and decoder-only LLMs, considering they generate text representations in distinct ways. The impact of these different representations on return forecasting remains an open question. Meanwhile, we compare two simple methods of integrating LLMs’ token-level representations into the forecasting module. The experiments on real investment universes reveal that: (1) aggregated representations from LLMs’ token-level embeddings generally produce return predictions that enhance the performance of long-only and long-short portfolios; (2) in the relatively large investment universe, the decoder LLMs-based prediction model leads to stronger portfolios, whereas in the small universes, there are no consistent winners; (3) return predictions derived from LLMs’ text representations are a strong signal for portfolio construction, outperforming conventional sentiment scores. These findings suggest the potential of LLM fine-tuning for enhancing return prediction-based portfolio construction. © 2025 Elsevier B.V., All rights reserved.","Financial Markets; Investments; Sales; Fine Tuning; Language Generation; Language Model; Language Understanding; Optimisations; Performance; Simple Method; Stock Return Predictions; Stock Returns; Text Representation; Prediction Models","Financial markets; Investments; Sales; Fine tuning; Language generation; Language model; Language understanding; Optimisations; Performance; SIMPLE method; Stock return predictions; Stock returns; Text representation; Prediction models","","","","Allen, David Edmund Edmund, Daily market news sentiment and stock prices, Applied Economics, 51, 30, pp. 3212-3235, (2019); Asset Management A Systematic Approach to Factor Investing, (2014); Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Transformers Need Glasses Information Over Squashing in Language Tasks, (2024); Llm2vec Large Language Models are Secretly Powerful Text Encoders, (2024); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Journal of Machine Learning Research, (2024); Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019); Ding, Ning, Parameter-efficient fine-tuning of large-scale pre-trained language models, Nature Machine Intelligence, 5, 3, pp. 220-235, (2023); Llama 3 Herd of Models, (2024)","Dernoncourt, F.; Preotiuc-Pietro, D.; Shimorina, A.","Association for Computational Linguistics (ACL)","","2024 Conference on Empirical Methods in Natural Language Processing: Industry Track, EMNLP 2024","","Miami; FL","205881","","9798891761667","","","English","Conference paper","Final","","Scopus","2-s2.0-85216806545"
"K., Peng, Kexin; H., Iima, Hitoshi; Y., Kitamura, Yoshihiro","Peng, Kexin (59459380400); Iima, Hitoshi (6602606103); Kitamura, Yoshihiro (35401039300)","59459380400; 6602606103; 35401039300","Prediction of Foreign Exchange Rates by a Large Language Model","2024","","","","","1062","1066","0","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216409938&partnerID=40&md5=b4a8742064951f26658782f51f01afff","Kyoto Institute of Technology, Kyoto, Japan; Waseda University, Tokyo, Japan","Peng, Kexin, Kyoto Institute of Technology, Kyoto, Japan; Iima, Hitoshi, Kyoto Institute of Technology, Kyoto, Japan; Kitamura, Yoshihiro, Waseda University, Tokyo, Japan","This paper proposes a prompt-based method utilizing a large language model (LLM) to predict changes in foreign exchange rates based on limit order information. While traditional deep learning models for prediction utilize numerical values as input and output, LLMs use sentences and prompts. To address this, we design prompts that incorporate the numerical values. GPT-2, a widely adopted LLM, is employed and fine-tuned using a training dataset. The effectiveness of our proposed method is demonstrated through empirical analysis using actual time series data. © 2025 Elsevier B.V., All rights reserved.","Finance; Foreign Exchange Rate; Large Language Model; Machine Learning; Time Series; Adversarial Machine Learning; Contrastive Learning; Decentralized Finance; Deep Learning; Foreign Exchange Rates; Input And Outputs; Language Model; Large Language Model; Learning Models; Limit Orders; Machine-learning; Numerical Values; Times Series; Training Dataset; Prediction Models","Adversarial machine learning; Contrastive Learning; Decentralized finance; Deep learning; Foreign exchange rates; Input and outputs; Language model; Large language model; Learning models; Limit orders; Machine-learning; Numerical values; Times series; Training dataset; Prediction models","","","","Hoffmann, Peter, A dynamic limit order market with fast and slow traders, Journal of Financial Economics, 113, 1, pp. 156-169, (2014); Time Series Analysis Forecasting and Control, (1976); Hochreiter, Sepp, Long Short-Term Memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Cho, Kyunghyun, Learning phrase representations using RNN encoder-decoder for statistical machine translation, pp. 1724-1734, (2014); Ito, Katsuki, LSTM forecasting foreign exchange rates using limit order book, Finance Research Letters, 47, (2022); A Survey of Large Language Models, (2023); Language Models are Unsupervised Multitask Learners, (2019); Xue, Hao, PromptCast: A New Prompt-Based Learning Paradigm for Time Series Forecasting, IEEE Transactions on Knowledge and Data Engineering, 36, 11, pp. 6851-6864, (2024); Loshchilov, Ilya G., SGDR: Stochastic gradient descent with warm restarts, (2017); Econometrica, (1980)","","Institute of Electrical and Electronics Engineers Inc.","","2024 SICE Festival with Annual Conference, SICE FES 2024","","Kochi City","205495","","9784907764838","","","English","Conference paper","Final","","Scopus","2-s2.0-85216409938"
"F., Hamann, Felix; M., Falk, Maurice; L., Walker, Lukas","Hamann, Felix (57219687766); Falk, Maurice (58066761400); Walker, Lukas (58659997600)","57219687766; 58066761400; 58659997600","Expanding Knowledge Graphs Through Text: Leveraging Large Language Models for Inductive Link Prediction","2024","Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)","352","","","1407","1417","0","1","10.18420/inf2024_123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216084920&doi=10.18420%2Finf2024_123&partnerID=40&md5=8b865c667b6e0b62f7819b071890f4c2","Fachhochschule Wiesbaden, Wiesbaden, Germany","Hamann, Felix, Fachhochschule Wiesbaden, Wiesbaden, Germany; Falk, Maurice, Fachhochschule Wiesbaden, Wiesbaden, Germany; Walker, Lukas, Fachhochschule Wiesbaden, Wiesbaden, Germany","Knowledge graphs (KG) play a crucial role for knowledge modelling in various domains such as web search, medical applications, or technical support, yet they are often incomplete. To mitigate this problem, knowledge graph completion (KGC) may be used to infer missing links of the graph. Taking it a step further, in an automated knowledge acquisition process, links for entirely new, unseen entities may be incorporated. This process is known as inductive link prediction (I-LP). Optionally, text as an external source of information is leveraged to infer the correct linkage of such entities. Depending on the context, this text either provides a comprehensive singular description of the entity or includes numerous incidental references to it. This paper presents a study that explores the application of LLAMA3 as a representative of the current generation of large language models (LLM) to I-LP. Through experimentation on popular benchmark datasets such as Wikidata5m, FB15k-237, WN18-RR, and IRT2, we evaluate the performance of LLMs for inserting new facts into a knowledge base, given textual references to the target object. These benchmarks, by design, exhibit significant variations in the quality of the associated text, as well as in the number of entities and links included. This paper explores several prompt formulations and studies whether pre-emptive retrieval of text helps. For automated link prediction, we implement the full cycle of prompt generation, answer processing, entity candidate lookup and finally link prediction. Our results show that LLM-based inductive link-prediction is outperformed by previously suggested models which fine-tune task-specific LM encoders. © 2025 Elsevier B.V., All rights reserved.","Inductive Link Prediction; Knowledge Graph Completion; Large Language Models; Prompting; Economic And Social Effects; Knowledge Acquisition; Modeling Languages; Prediction Models; Inductive Link; Inductive Link Prediction; Knowledge Graph Completion; Knowledge Graphs; Knowledge Model; Language Model; Large Language Model; Link Prediction; Prompting; Web Searches; Knowledge Graph","Economic and social effects; Knowledge acquisition; Modeling languages; Prediction models; Inductive link; Inductive link prediction; Knowledge graph completion; Knowledge graphs; Knowledge model; Language model; Large language model; Link prediction; Prompting; Web searches; Knowledge graph","","","This work was supported by the BMBF program FH-Kooperativ, project SCENT (13FH003KX0)","Gpt 4 Technical Report, (2023); Enriching Word Vectors with Subword Information, (2016); Daza, Daniel, Inductive entity representations from text via link prediction, pp. 798-808, (2021); Dettmers, Tim, Convolutional 2D knowledge graph embeddings, pp. 1811-1818, (2018); Bert Pre Training of Deep Bidirectional Transformers for Language Understanding, (2018); Proc Iea Aie 2021; Synthesis Lectures on Data Semantics and Knowledge, (2021); Lora Low Rank Adaptation of Large Language Models, (2021); Beyond Transduction A Survey on Inductive Few Shot and Zero Shot Link Prediction in Knowledge Graphs, (2023); Irt2 Inductive Linking and Ranking in Knowledge Graphs of Varying Scale, (2023)","Klein, M.; Krupka, D.; Winter, C.; Gergeleit, M.; Martin, L.","Gesellschaft fur Informatik (GI)","De Gruyter; Digitale Infrastrukturen; Eco; Huawei; KI-Campus","2024 Lock-in or log out? Wie digitale Souveranitat gelingt, INFORMATIK 2024","","Wiesbaden","205930","29447682; 16175468","9783885797432; 9783885792956; 3885793458; 9783885797098; 9783885792543; 3885793644; 9783885792222; 9783885796053; 9783885792574; 9783885796985","","","English","Conference paper","Final","","Scopus","2-s2.0-85216084920"
"Y., Liu, Yueyue; H., Zhang, Hongyu; Z., Li, Zhiqiang; Y., Miao, Yuantian","Liu, Yueyue (58871828800); Zhang, Hongyu (55685668500); Li, Zhiqiang (57098408500); Miao, Yuantian (57193890592)","58871828800; 55685668500; 57098408500; 57193890592","CPLS: Optimizing the Assignment of LLM Queries","2024","","","","","151","162","0","0","10.1109/ICSME58944.2024.00024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215523686&doi=10.1109%2FICSME58944.2024.00024&partnerID=40&md5=798a05e86f454cccc01e78192ca44a35","The University of Newcastle, Australia, Callaghan, Australia; Chongqing University, Chongqing, China; Shaanxi Normal University, Xi'an, China","Liu, Yueyue, School of Information and Physical Sciences, The University of Newcastle, Australia, Callaghan, Australia; Zhang, Hongyu, School of Big Data and Software Engineering, Chongqing University, Chongqing, China; Li, Zhiqiang, School of Computer Science, Shaanxi Normal University, Xi'an, China; Miao, Yuantian, School of Information and Physical Sciences, The University of Newcastle, Australia, Callaghan, Australia","Large Language Models (LLMs) like ChatGPT have gained significant attention because of their impressive capabilities, leading to a dramatic increase in their integration into intelligent software engineering. However, their usage as a service with varying performance and price options presents a challenging trade-off between desired performance and the associated cost. To address this challenge, we propose CPLS, a framework that utilizes transfer learning and local search techniques for assigning intelligent software engineering jobs to LLM-based services. CPLS aims to minimize the total cost of LLM invocations while maximizing the overall accuracy. The framework first leverages knowledge from historical data across different projects to predict the probability of an LLM processing a query correctly. Then, CPLS incorporates problem-specific rules into a local search algorithm to effectively generate Pareto optimal solutions based on the predicted accuracy and cost. To evaluate the proposed approach, we conduct extensive experiments on LLM-based log parsing, a typical software maintenance task. Our experimental results demonstrate that CPLS outperforms the baseline methods, providing solutions with the highest accuracy in 14 out of 16 instances. Compared to the baselines, CPLS achieves an accuracy improvement ranging from 1.24% to 485.54%, or reduces costs by 15.21% to 89.09% while maintaining the highest accuracy achieved by the baselines. © 2025 Elsevier B.V., All rights reserved.","Cross-project Prediction; Large Language Models; Local Search; Log Parsing; Query Assignment; Computer Software Maintenance; Computer Software Selection And Evaluation; Cost Engineering; Cost Reduction; Data Accuracy; Query Languages; Query Processing; Search Engines; Transfer Learning; Cross-project Prediction; High-accuracy; Intelligent Software; Language Model; Large Language Model; Local Search; Log Parsing; Model-based Opc; Performance; Query Assignment; Structured Query Language","Computer software maintenance; Computer software selection and evaluation; Cost engineering; Cost reduction; Data accuracy; Query languages; Query processing; Search engines; Transfer learning; Cross-project prediction; High-accuracy; Intelligent software; Language model; Large language model; Local search; Log parsing; Model-based OPC; Performance; Query assignment; Structured Query Language","","","","Large Language Models for Software Engineering A Systematic Literature Review, (2023); Wang, Simin, Machine/Deep Learning for Software Engineering: A Systematic Literature Review, IEEE Transactions on Software Engineering, 49, 3, pp. 1188-1231, (2023); Gpt 4 Technical Report, (2023); undefined, (2023); Frugalgpt how to Use Large Language Models While Reducing Cost and Improving Performance, (2023); undefined, (2024); Zhu, Jieming, Tools and Benchmarks for Automated Log Parsing, pp. 121-130, (2019); He, Shilin, A Survey on Automated Log Analysis for Reliability Engineering, ACM Computing Surveys, 54, 6, (2022); Llmparser A Llm Based Log Parsing Framework, (2023); Le, Van Hoang, Log Parsing: How Far Can ChatGPT Go?, pp. 1699-1704, (2023)","","Institute of Electrical and Electronics Engineers Inc.","IEEE Computer Society; IEEE Computer Society Technical Community on Software Engineering (TCSE)","40th IEEE International Conference on Software Maintenance and Evolution, ICSME 2024","","Flagstaff; AZ","205391","","9798350395686","","","English","Conference paper","Final","","Scopus","2-s2.0-85215523686"
"B., Xia, Bolun; A., Gupta, Aparna; M.J.J., Zaki, Mohammed Javeed J.","Xia, Bolun (59123998700); Gupta, Aparna (55371796000); Zaki, Mohammed Javeed J. (7202243707)","59123998700; 55371796000; 7202243707","Semantic Graph Learning for Trend Prediction from Long Financial Documents","2024","","","","","","","0","1","10.1109/CIFER62890.2024.10772910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214991295&doi=10.1109%2FCIFER62890.2024.10772910&partnerID=40&md5=c535bc8b702bcb8434a1255dede53d13","Rensselaer Polytechnic Institute, Troy, United States","Xia, Bolun, Rensselaer Polytechnic Institute, Troy, United States; Gupta, Aparna, Rensselaer Polytechnic Institute, Troy, United States; Zaki, Mohammed Javeed J., Rensselaer Polytechnic Institute, Troy, United States","The advent of large language models (LLMs) has initiated much research into their various financial applications. However, in applying LLMs on long documents, semantic relations are not explicitly incorporated, and a full or arbitrarily sparse attention operation is employed. In recent years, progress has been made in Abstract Meaning Representation (AMR), which is a graph-based representation of text to preserve its semantic relations. Since AMR can represent semantic relationships at a deeper level, it can be beneficially utilized by graph neural networks (GNNs) for constructing effective document-level graph representations built upon LLM embeddings to predict target metrics in the financial domain. We propose FLAG: Financial Long document classification via AMR-based GNN, an AMR graph based framework to generate document-level embeddings for long financial document classification. We construct document-level graphs from sentence-level AMR graphs, endow them with specialized LLM word embeddings in the financial domain, apply a deep learning mechanism that utilizes a GNN, and examine the efficacy of our AMR-based approach in predicting labeled target data from long financial documents. Extensive experiments are conducted on a dataset of quarterly earnings calls transcripts of companies in various sectors of the economy, as well as on a corpus of more recent earnings calls of companies in the S&P 1500 Composite Index. We find that our AMR-based approach outperforms fine-tuning LLMs directly on text in predicting stock price movement trends at different time horizons in both datasets. Our work also outperforms previous work utilizing document graphs and GNNs for text classification. © 2025 Elsevier B.V., All rights reserved.","Deep Learning; Earnings; Graph Neural Networks; Labeled Data; Network Embeddings; Semantics; Document Classification; Embeddings; Financial Applications; Financial Domains; Language Model; Level Graphs; Semantic Graphs; Semantic Relations; Trend Prediction; Graph Embeddings","Deep learning; Earnings; Graph neural networks; Labeled data; Network embeddings; Semantics; Document Classification; Embeddings; Financial applications; Financial domains; Language model; Level graphs; Semantic graphs; Semantic relations; Trend prediction; Graph embeddings","","","This work was supported by an industry funded award from the RPI-Stevens NSF IUCRC Center for Research toward Advancing Financial Technologies (NSF Award #: 2113850).","View in Article, (2023); Financebench A New Benchmark for Financial Question Answering, (2023); Banarescu, Laura, Abstract meaning representation for sembanking, pp. 178-186, (2013); Naseem, Tahira, Rewarding smatch: Transition-based AMR parsing with reinforcement learning, pp. 4586-4592, (2020); Finbert A Pretrained Language Model for Financial Communications, (2020); Brody, Shaked, HOW ATTENTIVE ARE GRAPH ATTENTION NETWORKS?, (2022); Bloomberggpt A Large Language Model for Finance, (2023); Fingpt Open Source Financial Large Language Models, (2023); Speech and Language Processing, (2000); Mikolov, Tomáš, Efficient estimation of word representations in vector space, (2013)","","Institute of Electrical and Electronics Engineers Inc.","","2024 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics, CIFEr 2024","","Hoboken; NJ","204911","","9798350354836","","","English","Conference paper","Final","","Scopus","2-s2.0-85214991295"
"G., Fatouros, Georgios; K., Metaxas, Kostas; J.K., Soldatos, John K.; D.P., Kyriazis, Dimosthenis P.","Fatouros, Georgios (57914788800); Metaxas, Kostas (58822556400); Soldatos, John K. (8662280800); Kyriazis, Dimosthenis P. (16301182100)","57914788800; 58822556400; 8662280800; 16301182100","Can Large Language Models beat wall street? Evaluating GPT-4’s impact on financial decision-making with MarketSenseAI","2024","Neural Computing and Applications","","","","","","0","7","10.1007/s00521-024-10613-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211795026&doi=10.1007%2Fs00521-024-10613-4&partnerID=40&md5=a2ffd42ec4af954b9cb2414e9e1f2fd7","University of Piraeus, Piraeus, Greece; Alpha Tensor Technologies Ltd., London, United Kingdom; INNOV-ACTS LIMITED, Nicosia, Cyprus","Fatouros, Georgios, Department of Digital Systems, University of Piraeus, Piraeus, Greece, Alpha Tensor Technologies Ltd., London, United Kingdom; Metaxas, Kostas, Alpha Tensor Technologies Ltd., London, United Kingdom; Soldatos, John K., INNOV-ACTS LIMITED, Nicosia, Cyprus; Kyriazis, Dimosthenis P., Department of Digital Systems, University of Piraeus, Piraeus, Greece","This paper introduces MarketSenseAI, an innovative framework leveraging GPT-4’s advanced reasoning for selecting stocks in financial markets. By integrating Chain of Thought and In-Context Learning, MarketSenseAI analyzes diverse data sources, including market trends, news, fundamentals, and macroeconomic factors, to emulate expert investment decision-making. The development, implementation, and validation of the framework are elaborately discussed, underscoring its capability to generate actionable and interpretable investment signals. A notable feature of this work is employing GPT-4 both as a predictive mechanism and signal evaluator, revealing the significant impact of the AI-generated explanations on signal accuracy, reliability, and acceptance. Through empirical testing on the competitive S&P 100 stocks over a 15-month period, MarketSenseAI demonstrated exceptional performance, delivering excess alpha of 10–30% and achieving a cumulative return of up to 72% over the period, while maintaining a risk profile comparable to the broader market. Our findings highlight the transformative potential of Large Language Models in financial decision-making, marking a significant leap in integrating generative AI into financial analytics and investment strategies. © 2024 Elsevier B.V., All rights reserved.","Artificial Intelligence; Financial Markets; Gpt-4; Large Language Models; Marketsenseai; Stock Selection; Decentralized Finance; Decision Making; Financial Markets; Investments; Context Learning; Decisions Makings; Financial Decisions; Gpt-4; In Contexts; Language Model; Large Language Model; Marketsenseai; Stock Selections; Wall Streets; Acceptance Tests","Decentralized finance; Decision making; Financial markets; Investments; Context learning; Decisions makings; Financial decisions; GPT-4; In contexts; Language model; Large language model; Marketsenseai; Stock selections; Wall streets; Acceptance tests","","","Open access funding was provided by European Union\u2019s funded Research and Innovation Project HUMAINE [grant number 101120218].","Financial Institutions Markets and Money, (1993); Lewellen, Jonathan, Momentum and Autocorrelation in Stock Returns, Review of Financial Studies, 15, 2 SPEC., pp. 533-563, (2002); Malkiel, Burton Gordon, The efficient market hypothesis and its, Journal of Economic Perspectives, 17, 1, pp. 59-82, (2003); Value Investing from Graham to Buffett and Beyond, (2001); Bouchaud, Jean Philippe, Fluctuations and response in financial markets: The subtle nature of ‘random’ price changes, Quantitative Finance, 4, 2, pp. 176-190, (2004); Weiss-Cohen, Leonardo, Behavioral biases in pension fund trustees’ decision making, Review of Behavioral Finance, 11, 2, pp. 128-143, (2019); Market Dysfunction and Central Bank Tools; Rev Financ Stud, (2015); Does 0dte Options Trading Increase Volatility, (2023); Anand, Abhinav, The role of Reddit in the GameStop short squeeze, Economics Letters, 211, (2022)","","Springer Science and Business Media Deutschland GmbH","","","","","","14333058; 09410643","","","","English","Article","aip","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85211795026"
"Y., Liu, Yueyue; H., Zhang, Hongyu; Y., Miao, Yuantian; V.H., Le, Van Hoang; Z., Li, Zhiqiang","Liu, Yueyue (58871828800); Zhang, Hongyu (55685668500); Miao, Yuantian (57193890592); Le, Van Hoang (57232672500); Li, Zhiqiang (57098408500)","58871828800; 55685668500; 57193890592; 57232672500; 57098408500","OptLLM: Optimal Assignment of Queries to Large Language Models","2024","Proceedings of the IEEE International Conference on Web Services, ICWS","","","","788","798","0","0","10.1109/ICWS62655.2024.00098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210260381&doi=10.1109%2FICWS62655.2024.00098&partnerID=40&md5=ae831351c80009288d40eb3641488ae0","The University of Newcastle, Australia, Callaghan, Australia; Chongqing University, Chongqing, China; Shaanxi Normal University, Xi'an, China","Liu, Yueyue, School of Information and Physical Sciences, The University of Newcastle, Australia, Callaghan, Australia; Zhang, Hongyu, School of Big Data and Software Engineering, Chongqing University, Chongqing, China; Miao, Yuantian, School of Information and Physical Sciences, The University of Newcastle, Australia, Callaghan, Australia; Le, Van Hoang, School of Information and Physical Sciences, The University of Newcastle, Australia, Callaghan, Australia; Li, Zhiqiang, School of Computer Science, Shaanxi Normal University, Xi'an, China","Large Language Models (LLMs) have garnered considerable attention owing to their remarkable capabilities, leading to an increasing number of companies offering LLMs as services. Different LLMs achieve different performance at different costs. A challenge for users lies in choosing the LLMs that best fit their needs, balancing cost and performance. In this paper, we propose a framework for addressing the cost-effective query allocation problem for LLMs. Given a set of input queries and candidate LLMs, our framework, named OptLLM, provides users with a range of optimal solutions to choose from, aligning with their budget constraints and performance preferences, including options for maximizing accuracy and minimizing cost. OptLLM predicts the performance of candidate LLMs on each query using a multi-label classification model with uncertainty estimation and then iteratively generates a set of non-dominated solutions by destructing and reconstructing the current solution. To evaluate the effectiveness of OptLLM, we conduct extensive experiments on various types of tasks, including text classification, question answering, sentiment analysis, reasoning, and log parsing. Our experimental results demonstrate that OptLLM substantially reduces costs by 2.40% to 49.18% while achieving the same accuracy as the best LLM. Compared to other multi-objective optimization algorithms, OptLLM improves accuracy by 2.94% to 69.05% at the same cost or saves costs by 8.79% and 95.87% while maintaining the highest attainable accuracy. © 2025 Elsevier B.V., All rights reserved.","Cost-performance Tradeoff; Large Language Models; Multi-objective Optimization; Performance Prediction; Query Assignment; Cost Benefit Analysis; Query Languages; Query Processing; Structured Query Language; Cost Performance; Cost-performance Tradeoff; Language Model; Large Language Model; Multi-objectives Optimization; Optimal Assignment; Performance; Performance Prediction; Performance Tradeoff; Query Assignment; Budget Control","Cost benefit analysis; Query languages; Query processing; Structured Query Language; Cost performance; Cost-performance tradeoff; Language model; Large language model; Multi-objectives optimization; Optimal assignment; Performance; Performance prediction; Performance tradeoff; Query assignment; Budget control","","","","Kasneci, Enkelejda, ChatGPT for good? On opportunities and challenges of large language models for education, Learning and Individual Differences, 103, (2023); Ouyang, Long, Training language models to follow instructions with human feedback, Advances in Neural Information Processing Systems, 35, (2022); An Explanation of in Context Learning as Implicit Bayesian Inference, (2021); Min, Sewon, Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?, pp. 11048-11064, (2022); Is Your Code Generated by Chatgpt Really Correct Rigorous Evaluation of Large Language Models for Code Generation, (2023); Xia, Chunqiu Steven, Automated Program Repair in the Era of Large Pre-trained Language Models, Proceedings - International Conference on Software Engineering, pp. 1482-1494, (2023); Keep the Conversation Going Fixing 162 Out of 337 Bugs for 0 42 Each Using Chatgpt, (2023); Fly Swat or Cannon Cost Effective Language Model Choice Via Meta Modeling, (2023); How Much does It Cost to Use Gpt Models Gpt 3 Pricing Explained, (2023); Frugalgpt how to Use Large Language Models While Reducing Cost and Improving Performance, (2023)","Chang, R.N.; Chang, C.K.; Jiang, Z.; Yang, J.; Jin, Z.; Sheng, M.; Fan, J.; Fletcher, K.K.; He, Q.; He, Q.; Ardagna, C.; Yang, J.; Yin, J.; Wang, Z.; Beheshti, A.; Russo, S.; Atukorala, N.; Wu, J.; Yu, P.S.; Ludwig, H.; Reiff-Marganiec, S.; Zhang, E.; Sailer, A.; Bena, N.; Li, K.; Watanabe, Y.; Zhao, T.; Wang, S.; Tu, Z.; Wang, Y.; Wei, K.","Institute of Electrical and Electronics Engineers Inc.","","2024 IEEE International Conference on Web Services, ICWS 2024","","Hybrid, Shenzhen","203400","28363876; 28363868","9798350368550","","","English","Conference paper","Final","","Scopus","2-s2.0-85210260381"
"H., Ni, Haowei; S., Meng, Shuchen; X., Chen, Xupeng; Z., Zhao, Ziqing; A., Chen, Andi; P., Li, Panfeng; S., Zhang, Shiyao; Q., Yin, Qifu; Y., Wang, Yuanqing; Y., Chan, Yuxi","Ni, Haowei (59214958700); Meng, Shuchen (59215393900); Chen, Xupeng (59781938000); Zhao, Ziqing (59614760900); Chen, Andi (59314882600); Li, Panfeng (58754136000); Zhang, Shiyao (59214520300); Yin, Qifu (59314484600); Wang, Yuanqing (57219529012); Chan, Yuxi (59314094500)","59214958700; 59215393900; 59781938000; 59614760900; 59314882600; 58754136000; 59214520300; 59314484600; 57219529012; 59314094500","Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach","2024","","","","","909","915","0","1","10.1109/DOCS63458.2024.10704454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207841260&doi=10.1109%2FDOCS63458.2024.10704454&partnerID=40&md5=29484688902c8c4234c89733392a63f1","Columbia University, New York, United States; Central University of Finance and Economics, Beijing, China; New York University, New York, United States; Cornell University, Ithaca, United States; University of Michigan, Ann Arbor, Ann Arbor, United States; Rutgers University, New Jersey, United States","Ni, Haowei, Columbia University, New York, United States; Meng, Shuchen, Central University of Finance and Economics, Beijing, China; Chen, Xupeng, New York University, New York, United States; Zhao, Ziqing, Cornell University, Ithaca, United States; Chen, Andi, ; Li, Panfeng, University of Michigan, Ann Arbor, Ann Arbor, United States; Zhang, Shiyao, Cornell University, Ithaca, United States; Yin, Qifu, Columbia University, New York, United States; Wang, Yuanqing, New York University, New York, United States; Chan, Yuxi, Rutgers University, New Jersey, United States","Accurate stock market predictions following earnings reports are crucial for investors. Traditional methods, particularly classical machine learning models, struggle with these predictions because they cannot effectively process and interpret extensive textual data contained in earnings reports and often overlook nuances that influence market movements. This paper introduces an advanced approach by employing Large Language Models (LLMs) instruction fine-tuned with a novel combination of instruction-based techniques and quantized low-rank adaptation (QLoRA) compression. Our methodology integrates 'base factors', such as financial metric growth and earnings transcripts, with 'external factors', including recent market indices performances and analyst grades, to create a rich, supervised dataset. This comprehensive dataset enables our models to achieve superior predictive performance in terms of accuracy, weighted Fl, and Matthews correlation coefficient (M CC), especially evident in the comparison with benchmarks such as GPT-4. We specifically highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases significant improvements over baseline models. The paper also discusses the potential of expanding the output capabilities to include a 'Hold''''' option and extending the prediction horizon, aiming to accommodate various investment styles and time frames. This study not only demonstrates the power of integrating cutting-edge AI with fine-tuned financial data but also paves the way for future research in enhancing AI -driven financial analysis tools. © 2024 Elsevier B.V., All rights reserved.","Instruction Fine Tuning; Large Language Model; Quantized Low-rank Adaptation; Adversarial Machine Learning; Benchmarking; Contrastive Learning; Decentralized Finance; Financial Markets; Investments; Prediction Models; Supervised Learning; Fine Tuning; Instruction Fine Tuning; Language Model; Large Language Model; Machine Learning Models; Modeling Approach; Quantized Low-rank Adaptation; Stock Market Prediction; Stock Predictions; Textual Data; Earnings","Adversarial machine learning; Benchmarking; Contrastive Learning; Decentralized finance; Financial markets; Investments; Prediction models; Supervised learning; Fine tuning; Instruction fine tuning; Language model; Large language model; Machine learning models; Modeling approach; Quantized low-rank adaptation; Stock market prediction; Stock predictions; Textual data; Earnings","","","","Language Models are Free Boosters for Biomedical Imaging Tasks, (2024); Survival Prediction Across Diverse Cancer Types Using Neural Networks, (2024); Adaptive Ensembles of Fine Tuned Transformers for Llm Generated Text Detection, (2024); Large Language Models for Forecasting and Anomaly Detection A Systematic Literature Review, (2024); News Recommendation with Attention Mechanism, (2024); Tuning Free Accountable Intervention for Llm Deploymenta Metacognitive Approach, (2024); Large Language Models for Data Annotation A Survey, (2024); Convolutional Neural Network Classification of Cancer Cytopathology Images Taking Breast Cancer as an Example, (2024); Ruan, Kangrui, From Twitter to Reasoner: Understand Mobility Travel Modes and Sentiment Using Large Language Models, pp. 454-459, (2024); Graphcnnpred A Stock Market Indices Prediction Using A Graph Based Deep Learning System, (2024)","","Institute of Electrical and Electronics Engineers Inc.","IEEE","6th International Conference on Data-Driven Optimization of Complex Systems, DOCS 2024","","Hangzhou","203284","","9798350377842","","","English","Conference paper","Final","","Scopus","2-s2.0-85207841260"
"Y., Cheng, Yuhan; Y., Zeng, Yuming; J., Zou, Jie","Cheng, Yuhan (58388773000); Zeng, Yuming (59389266300); Zou, Jie (59389623800)","58388773000; 59389266300; 59389623800","Harnessing ChatGPT for predictive financial factor generation: A new frontier in financial analysis and forecasting","2024","British Accounting Review","","","101507","","","0","3","10.1016/j.bar.2024.101507","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207791229&doi=10.1016%2Fj.bar.2024.101507&partnerID=40&md5=d98bfe30b7e19c6c116d94655a515774","Shandong University, Jinan, China; University of Oxford, Oxford, United Kingdom; Shandong University, Jinan, China","Cheng, Yuhan, School of Management, Shandong University, Jinan, China, Institute of Mathematics, University of Oxford, Oxford, United Kingdom, School of Economics, Shandong University, Jinan, China; Zeng, Yuming, School of Management, Shandong University, Jinan, China, Institute of Mathematics, University of Oxford, Oxford, United Kingdom, School of Economics, Shandong University, Jinan, China; Zou, Jie, School of Management, Shandong University, Jinan, China, Institute of Mathematics, University of Oxford, Oxford, United Kingdom, School of Economics, Shandong University, Jinan, China","The search for predictive financial factors in stock pricing of companies has long been a key focus in accounting and finance, but traditional methods often require complex, subjective inputs. This paper introduces a method using ChatGPT-4 to generate financial factors based on the structure of financial statements and key variables, eliminating the need for numerical data. Leveraging GPT's natural language processing capabilities and extensive knowledge base, our approach efficiently generates factors that are highly predictive of future returns and exhibit robustness over time, unaffected by variations in different conversational windows. Regression analysis demonstrates that these factors cannot be linearly explained by traditional financial factors. This paper highlights AI's potential in revolutionizing financial analysis and decision-making. © 2024 Elsevier B.V., All rights reserved.","Chatgpt; Company Performance Forecasting; Financial Data Analysis; Financial Factor Generation; Large Language Model","","","","This research was supported by the National Natural Science Foundation of China (No. 72403143 and No. 72403146) and the Shandong Provincial Natural Science Foundation (No. ZR2024QG188 and No. ZR2024QG172). We also thank the Shandong Province Philosophy and Social Science Young Talent Team Project (2024-QNRC-11) for its funding.","International Review of Management and Marketing, (2019); International Journal of Academic Research in Accounting Finance and Management Sciences, (2014); Alwathainani, Abdulaziz M., Consistency of firms' past financial performance measures and future returns, British Accounting Review, 41, 3, pp. 184-196, (2009); Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Artikis, Panagiotis G., Implications of the cash component of earnings for earnings persistence and stock returns, British Accounting Review, 48, 2, pp. 117-133, (2016); Bali, Turan G., Option Return Predictability with Machine Learning and Big Data, Review of Financial Studies, 36, 9, pp. 3548-3602, (2023); Bao, Yang, Detecting Accounting Fraud in Publicly Traded U.S. Firms Using a Machine Learning Approach, Journal of Accounting Research, 58, 1, pp. 199-235, (2020); Bertomeu, Jeremy, Machine learning improves accounting: discussion, implementation and research opportunities, Review of Accounting Studies, 25, 3, pp. 1135-1155, (2020); Bertomeu, Jeremy, Using machine learning to detect misstatements, Review of Accounting Studies, 26, 2, pp. 468-519, (2021); Bianchi, Daniele, Bond Risk Premiums with Machine Learning, Review of Financial Studies, 34, 2, pp. 1046-1089, (2021)","","Academic Press","","","","","","10958347; 08908389","","","","English","Article","aip","","Scopus","2-s2.0-85207791229"
"A., Lopez-Lira, Alejandro","Lopez-Lira, Alejandro (57223403009)","57223403009","The Predictive Edge: Outsmart the Market using Generative AI and ChatGPT in Financial Forecasting","2024","","","","","1","252","0","3","10.1002/9781394308286","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207167586&doi=10.1002%2F9781394308286&partnerID=40&md5=bb3ae67b18439a29af405d285e09ec46","","Lopez-Lira, Alejandro, ","Use ChatGPT to improve your analysis of stock markets and securities In The Predictive Edge: Outsmart the Market Using Generative AI and ChatGPT in Financial Forecasting, renowned AI and finance researcher Dr. Alejandro Lopez-Lira delivers an engaging and insightful new take on how to use large language models (LLMs) like ChatGPT to find new investment opportunities and make better trading decisions. In the book, you’ll learn how to interpret the outputs of LLMs to craft sounder trading strategies and incorporate market sentiment into your analyses of individual securities. In addition to a complete and accessible explanation of how ChatGPT and other LLMs work, you’ll find: Discussions of future trends in artificial intelligence and finance Strategies for implementing new and soon-to-come AI tools into your investing strategies and processes Techniques for analyzing market sentiment using ChatGPT and other AI tools A can’t-miss playbook for taking advantage of the full potential of the latest AI advancements, The Predictive Edge is a fully to-date and exciting exploration of the intersection of tech and finance. It will earn a place on the bookshelves of individual and professional investors everywhere. © 2024 Elsevier B.V., All rights reserved.","","","","","","Introducing Claude, (2023); Orca 2 Teaching Small Language Models how to Reason, (2023); Introducing the Worlds Largest Open Multilingual Language Model Bloom, (2023); Development of Intelligence in Children the Binet Simon Scale, (2017); Verywell Mind, (2023); Cohere the Leading AI Platform for Enterprise, (2023); Llm Parameters Demystified Getting the Best Outputs from Language AI, (2022); Lamda Our Breakthrough Conversation Technology, (2021); Google Research, (2025); Frames of Mind the Theory of Multiple Intelligences, (1983)","","wiley","","","","","","","9781394242719; 9781394308286","","","English","Book","Final","","Scopus","2-s2.0-85207167586"
"A.M., Saghiri, Ali Mohammad; N., Wang, Nan","Saghiri, Ali Mohammad (24598183400); Wang, Nan (59321485600)","24598183400; 59321485600","Self-Evolving Programs: A Novel Approach Leveraging LLMs and Quine Programs","2024","","","","","","","0","0","10.1109/ICCIMS61672.2024.10690672","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206616081&doi=10.1109%2FICCIMS61672.2024.10690672&partnerID=40&md5=0a7630825b68d12cd51a425be952e401","William Paterson College, Wayne, United States","Saghiri, Ali Mohammad, Department of Computer Science, William Paterson College, Wayne, United States; Wang, Nan, Department of Computer Science, William Paterson College, Wayne, United States","In an era where software systems undergo rapid evolution, the demand for self-evolving programs has received much attention. This paper introduces a groundbreaking methodology that amalgamates the predictive power of Large Language Model-Based Methods with the self-replicating nature of Quine Programs to organize self-evolving software. This innovative integration not only facilitates dynamic code adaptation to fluctuating runtime conditions but also pioneers a shift from traditional static coding paradigms. Through this approach, we aim to revolutionize software development, particularly enhancing security and performance with a focus on countering selfish mining attacks in Bitcoin. It should be noted that the suggested approach has not yet been considered in the field of software engineering, and its applications are not limited to software security. It has high potential to be used in every domain that requires adaptive programs. Since the suggested approach is novel, the proposed solution in Bitcoin is also novel. The results of simulation show the efficiency of the proposed solution. © 2024 Elsevier B.V., All rights reserved.","Dynamic Code Optimization; Language Model-based Methods; Quine Programs; Self-evolving Programs; Selfish Mining Defense; Application Programs; Dynamic Programming; Software Design; Code Adaptation; Dynamic Code Optimizations; Language Model; Language Model-based Method; Model-based Method; Predictive Power; Quine Program; Self-evolving Program; Selfish Mining Defense; Software-systems; Bitcoin","Application programs; Dynamic programming; Software design; Code adaptation; Dynamic code optimizations; Language model; Language model-based method; Model-based method; Predictive power; Quine program; Self-evolving program; Selfish mining defense; Software-systems; Bitcoin","","","The authors gratefully acknowledge the support of the National Science Foundation under NSF Grant #2028011 for funding this research.","Manzalini, Antonio, Self-optimized cognitive network of networks, Computer Journal, 54, 2, pp. 189-196, (2011); Bildverarbeitung, (2014); Yamamoto, Lidia, Self-replicating and self-modifying programs in fraglets, pp. 159-167, (2007); Randazzo, Ettore, Recursively Fertile Self-replicating Neural Agents, Artificial Life Conference Proceedings, 33, pp. 529-537, (2021); 16th International Conference on Agents and Artificial Intelligence Spain; Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, (2022); Quine Computing; Springer Science Business Media, (2013); An Llm Compiler for Parallel Function Calling; Large Language Models for Compiler Optimization, (2023)","","Institute of Electrical and Electronics Engineers Inc.","","1st International Conference on Computing, Internet of Things and Microwave Systems, ICCIMS 2024","","Gatineau; QC","203023","","9798350351736","","","English","Conference paper","Final","","Scopus","2-s2.0-85206616081"
"A., Arun, Abhinand; K.V., Aswin Babu, K. V.; G., Rajesh, Goutham; H., Parthasaradhi, H.; B., Bhadran, Bindhya","Arun, Abhinand (58706728500); Aswin Babu, K. V. (58637264700); Rajesh, Goutham (57265439900); Parthasaradhi, H. (58616890700); Bhadran, Bindhya (56441748700)","58706728500; 58637264700; 57265439900; 58616890700; 56441748700","Transforming Healthcare: Unified Medical Identification and AI-Enabled Treatment Advancements","2024","","","","","378","382","0","1","10.1109/ICICI62254.2024.00068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205969532&doi=10.1109%2FICICI62254.2024.00068&partnerID=40&md5=3c96c6ddd664f8903b6466367542a659","Amrita University, Amritapuri Campus, Kollam, India","Arun, Abhinand, Department of Computer Science and Engineering, Amrita University, Amritapuri Campus, Kollam, India; Aswin Babu, K. V., Department of Computer Science and Engineering, Amrita University, Amritapuri Campus, Kollam, India; Rajesh, Goutham, Department of Computer Science and Engineering, Amrita University, Amritapuri Campus, Kollam, India; Parthasaradhi, H., Department of Computer Science and Engineering, Amrita University, Amritapuri Campus, Kollam, India; Bhadran, Bindhya, Department of Computer Science and Engineering, Amrita University, Amritapuri Campus, Kollam, India","In the dynamic realm of healthcare, accurate disease prediction stands as a cornerstone for proactive management and personalized care. Through the introduction of Unified Medical Identification (UMI), users can easily connect to their medical records anywhere at any time. With advanced features like rural language support via video-based disease prediction integrated with the Large Language Model, the system generates a broader bracket of users. An ensembled machine learning model is used for general disease prediction. Integrating the CatBoost Classifier with the LangChain framework, the model accurately detects chronic diseases keeping UMI as the central source of the user's medical data. Furthermore, an AI chatbot aids in the enhancement of user engagement offering targeted treatment options and suitable lifestyle recommendations resulting in better health outcomes. With a remarkable 92.8% accuracy in general disease prediction and a whopping 95.8% accuracy in chronic disease prediction, this revolutionary tool not only reforms the healthcare delivery mode but also guarantees that it is well accepted and widely available across dissimilar communities. © 2024 Elsevier B.V., All rights reserved.","Ensembled Machine Learning Model; Langchain; Large Language Model; Unified Medical Identification; Adversarial Machine Learning; Federated Learning; Prediction Models; Unified Modeling Language; Central Source; Chronic Disease; Ensembled Machine Learning Model; Langchain; Language Model; Large Language Model; Machine Learning Models; Medical Record; Proactive Management; Unified Medical Identification; Electronic Health Record","Adversarial machine learning; Federated learning; Prediction models; Unified Modeling Language; Central source; Chronic disease; Ensembled machine learning model; Langchain; Language model; Large language model; Machine learning models; Medical record; Proactive management; Unified medical identification; Electronic health record","","","","Aswath, G. I., A frugal and innovative telemedicine approach for rural India - Automated doctor machine, International Journal of Medical Engineering and Informatics, 12, 3, pp. 278-290, (2020); Sai, A. M.Abhishek, A Web-Based Chatbot for Indian Cities: A Comparison of CNN, ANN, and LSTM Models, (2023); Bharath Suhas, K. B., Generative AI for Community Empowerment: Transforming Livelihood Opportunities in a Rural Indian Village, (2024); Ani, R., IoT based patient monitoring and diagnostic prediction tool using ensemble classifier, 2017-January, pp. 1588-1593, (2017); Reddy, Thirupati Sai Eswar, Cardiovascular Disease Prediction using Machine Learning and Deep Learning, (2022); Inventive Computation and Information Technologies Proceedings of Icicit, (2022); Disease Prediction from Various Symptoms Using Machine Learning, (2020); Holderried, Friederike, A Generative Pretrained Transformer (GPT)-Powered Chatbot as a Simulated Patient to Practice History Taking: Prospective, Mixed Methods Study, JMIR Medical Education, 10, 1, (2024); Bharathi Mohan, G., Disease Prediction Based on Symptoms Using Ensemble and Hybrid Machine Learning Models, pp. 799-804, (2024); Geluvaraj, B., A Hybrid Approach for Predicting Diseases using Clustering and Classification Techniques, (2022)","","Institute of Electrical and Electronics Engineers Inc.","","2nd International Conference on Inventive Computing and Informatics, ICICI 2024","","Bangalore","202740","","9798350373295","","","English","Conference paper","Final","","Scopus","2-s2.0-85205969532"
"H., Jiang, Haiqi; Y., Ding, Ying; R., Chen, Rui; C., Fan, Chenyou","Jiang, Haiqi (58546641500); Ding, Ying (59348474600); Chen, Rui (59348976100); Fan, Chenyou (57191411277)","58546641500; 59348474600; 59348976100; 57191411277","Carbon Price Forecasting with LLM-Based Refinement and Transfer-Learning","2024","Lecture Notes in Computer Science","15024 LNCS","","","139","154","0","2","10.1007/978-3-031-72356-8_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205299267&doi=10.1007%2F978-3-031-72356-8_10&partnerID=40&md5=4fe5c8b927997a44e4d9844c747d4fd5","South China Normal University, Guangzhou, China","Jiang, Haiqi, South China Normal University, Guangzhou, China; Ding, Ying, South China Normal University, Guangzhou, China; Chen, Rui, South China Normal University, Guangzhou, China; Fan, Chenyou, South China Normal University, Guangzhou, China","We propose a unified forecasting framework for accurately predicting carbon markets of EU Emission Trading Scheme (EU ETS) and Chinese Emission Allowance (CEA). Our framework utilizes a Time-Series Model (TSM) for initial prediction followed by applying a Large Language Model (LLM) to refine the forecasts. We prompt the LLM to refine the TSM forecasts by demonstrating an example pair of past TSM predictions and their corresponding true future prices to the LLM as a chain-of-thought. The in-context learning capacity of the LLM allows the LLM to rectify inaccurate predictions to reflect on TSM predictions and refine the forecasts. To further reduce the prompting delays and expenses involving LLMs, we innovate a post-finetuning approach to train a Gated Linear Unit (GLU) model to condense the LLM’s in-context learning capability. This enables direct fine-tuning of TSM outputs without the need for explicit prompting LLM during inference. Experimental results show that our method can refine the TSM prediction by 10% to 40% in various zones, as well as enhance transfer learning by 10% to 21% through the inclusion of market context of the source zone when predicting the target zone. Remarkably, our GLU model achieves comparable, and in some cases superior, performance compared to LLM prompting. It effectively combines the short-term forecasting capability of classical Time Series Models with the long-term trend prediction ability typically associated with the LLMs. © 2024 Elsevier B.V., All rights reserved.","Carbon Future Market; Gated Linear Unit; Large Language Models; Post-finetuning; Price Forecasts; Time-series Prediction; Transfer Learning; Low Emission; Time Series; Transfer Learning; Carbon Future Market; Gated Linear Unit; Language Model; Large Language Model; Linear Units; Post-finetuning; Price Forecasts; Time Series Prediction; Times Series Models; Prediction Models","Low emission; Time series; Transfer learning; Carbon future market; Gated linear unit; Language model; Large language model; Linear units; Post-finetuning; Price forecasts; Time series prediction; Times series models; Prediction models","","","This work is supported by the National Natural Science Foundation of China (Project 62106156), and the South China Normal University, China. We also thank Tianqi Pang for providing the implementations of Lasso methods on EU ETS forecasting.","Graph of Thoughts Solving Elaborate Problems with Large Language Models Arxiv Preprint Arxiv, (2023); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Chen, Rui, Do AI-powered mutual funds perform better?, Finance Research Letters, 47, (2022); Fan, Chenyou, Pre-trained Financial Model for Price Movement Forecasting, Communications in Computer and Information Science, 1969 CCIS, pp. 216-229, (2024); Lora Low Rank Adaptation of Large Language Models Arxiv Preprint Arxiv, (2021); Chatgpt and Corporate Policies, (2024); Li, Yinheng, Large Language Models in Finance: A Survey, pp. 374-382, (2023); P Tuning V2 Prompt Tuning can Be Comparable to Fine Tuning Universally Across Scales and Tasks Arxiv Preprint Arxiv, (2021); Self Refine Iterative Refinement with Self Feedback Arxiv Preprint Arxiv, (2023); Corr, (2022)","Wand, M.; Schmidhuber, J.; Wand, M.; Malinovská, K.; Schmidhuber, J.; Tetko, I.V.; Tetko, I.V.","Springer Science and Business Media Deutschland GmbH","","33rd International Conference on Artificial Neural Networks, ICANN 2024","","Lugano","319199","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference paper","Final","","Scopus","2-s2.0-85205299267"
"Z., Lu, Zhaoyuan; T., Li, Taijun; J., Zhang, Jingzhen; M., Liu, Moyang; X., Li, Xiang; L., Cui, Linyi; J., Chen, Junqi; Z., Niu, Zhibin","Lu, Zhaoyuan (58852138400); Li, Taijun (59332800800); Zhang, Jingzhen (59332876800); Liu, Moyang (59332951100); Li, Xiang (57214906388); Cui, Linyi (59332951200); Chen, Junqi (57217523754); Niu, Zhibin (57202424167)","58852138400; 59332800800; 59332876800; 59332951100; 57214906388; 59332951200; 57217523754; 57202424167","RisQNet: Rescuing SMEs from Financial Shocks with a Novel Networked-Loan Risk Assessment","2024","IJCAI International Joint Conference on Artificial Intelligence","","","","7385","7393","0","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204303359&partnerID=40&md5=ada8c99a0e5793f84aa88bb4d72c68e8","Tianjin University, Tianjin, China; Tianjin University, Tianjin, China; Office of Information Center; China Iron and Steel Research Institute Group, Beijing, China; University of California, Berkeley, Berkeley, United States; Bank Of China, Beijing, China","Lu, Zhaoyuan, School of New Media and Communication, Tianjin University, Tianjin, China; Li, Taijun, College of Intelligence and Computing, Tianjin University, Tianjin, China; Zhang, Jingzhen, College of Intelligence and Computing, Tianjin University, Tianjin, China; Liu, Moyang, College of Intelligence and Computing, Tianjin University, Tianjin, China; Li, Xiang, China Iron and Steel Research Institute Group, Beijing, China, University of California, Berkeley, Berkeley, United States; Cui, Linyi, Bank Of China, Beijing, China; Chen, Junqi, College of Intelligence and Computing, Tianjin University, Tianjin, China, Office of Information Center; Niu, Zhibin, School of New Media and Communication, Tianjin University, Tianjin, China, College of Intelligence and Computing, Tianjin University, Tianjin, China","In the face of economic downturns, Small and Medium-sized Enterprises (SMEs) within interconnected networked-loans are vulnerable to cascading debt crises, exacerbated by factors like social media-induced financial shocks. Traditional risk assessment models, which mainly rely on financial data, inadequately predict such crises, as evidenced by the collapse of Silicon Valley Bank in 2023. To address this issue, we developed RisQNet, a model that uses temporal graph networks to incorporate diverse risks, including real-time media influences. This approach not only advances risk prediction through news feature extraction and large language models but also enhances risk management strategies with intuitive visualization tools. Validated on a dataset with a total loan volume of USD 3 trillion, RisQNet outperforms the state-of-the-art baseline and achieves 87.1% of AUC. Our collaborative effort with financial regulators and the SME community underpins the model's development, aligning with the UN SDG 8. RisQNet represents a significant step forward in leveraging AI for financial stability, offering a promising approach to combat the propagation of debt crises in financial networks. © 2024 Elsevier B.V., All rights reserved.","Artificial Intelligence; Economic And Social Effects; Risk Assessment; Risk Management; Risk Perception; Debt Crisis; Economic Downturn; Financial Data; Graph Networks; Risk Assessment - Modelling; Risks Assessments; Silicon Valley; Small And Medium-sized Enterprise; Social Media; Temporal Graphs; Decentralized Finance","Artificial intelligence; Economic and social effects; Risk assessment; Risk management; Risk perception; Debt crisis; Economic downturn; Financial data; Graph networks; Risk assessment - modelling; Risks assessments; Silicon valley; Small and medium-sized enterprise; Social media; Temporal graphs; Decentralized finance","","","","Achakzai, Muhammad Atif Khan, Using machine learning Meta-Classifiers to detect financial frauds, Finance Research Letters, 48, (2022); On the Bottleneck of Graph Neural Networks and Its Practical Implications, (2020); Baesens, Bart M.M., Benchmarking state-of-the-art classification algorithms for credit scoring, Journal of the Operational Research Society, 54, 6, pp. 627-635, (2003); Balashankar, Ananth, Predicting food crises using news streams, Science Advances, 9, 9, (2023); Complexity and Geographical Economics, (2015); Bruna, Joan, Spectral networks and deep locally connected networks on graphs, (2014); Chen, Tianqi, XGBoost: A scalable tree boosting system, 13-17-August-2016, pp. 785-794, (2016); Cheng, Dawei, Risk assessment for networked-guarantee loans using high-order graph attention representation, IJCAI International Joint Conference on Artificial Intelligence, 2019-August, pp. 5822-5828, (2019); Cheng, Dawei, Contagious Chain Risk Rating for Networked-guarantee Loans, pp. 2715-2723, (2020); Cheng, Dawei, Critical Firms Prediction for Stemming Contagion Risk in Networked-Loans through Graph-Based Deep Reinforcement Learning, 37, pp. 14205-14213, (2023)","Larson, K.","International Joint Conferences on Artificial Intelligence","International Joint Conferences on Artifical Intelligence (IJCAI)","33rd International Joint Conference on Artificial Intelligence, IJCAI 2024","","Jeju","202043","10450823","9780999241196; 9781577357384; 9781956792003; 9780999241165; 9780999241141; 9781577355120; 9781577354260; 9780769536156; 0934613346; 9780999241127","","","English","Conference paper","Final","","Scopus","2-s2.0-85204303359"
"X., Li, Xuhong; J., Chen, Jiamin; Y., Chai, Yekun; H., Xiong, Haoyi","Li, Xuhong (57204712975); Chen, Jiamin (57226466021); Chai, Yekun (57219634121); Xiong, Haoyi (55362625600)","57204712975; 57226466021; 57219634121; 55362625600","GILOT: Interpreting Generative Language Models via Optimal Transport","2024","Proceedings of Machine Learning Research","235","","","27515","27530","0","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203805495&partnerID=40&md5=3fe23ab0e53af517ad25784e475ff35b","Baidu, Inc., Beijing, China","Li, Xuhong, Baidu, Inc., Beijing, China; Chen, Jiamin, Baidu, Inc., Beijing, China; Chai, Yekun, Baidu, Inc., Beijing, China; Xiong, Haoyi, Baidu, Inc., Beijing, China","While large language models (LLMs) surge with the rise of generative AI, algorithms to explain LLMs highly desire. Existing feature attribution methods adequate for discriminative language models like BERT often fail to deliver faithful explanations for LLMs, primarily due to two issues: (1) For every specific prediction, the LLM outputs a probability distribution over the vocabulary-a large number of tokens with unequal semantic distance; (2) As an autoregressive language model, the LLM handles input tokens while generating a sequence of probability distributions of various tokens. To address above two challenges, this work proposes GILOT that leverages Optimal Transport approach to measure the distributional change of all possible generated sequences upon the absence of every input token, while taking into account the tokens' similarity, so as to faithfully estimate feature attribution for LLMs. We have carried out extensive experiments on top of Llama families and their fine-tuned derivatives across various scales to validate the effectiveness of GILOT for estimating the input attributions. The results show that GILOT outperforms existing solutions on a number of faithfulness metrics under fair comparison settings. Source code is publicly available at https://github.com/holyseven/GiLOT. © 2024 Elsevier B.V., All rights reserved.","Generative Adversarial Networks; Ai Algorithms; Auto-regressive; Discriminative Language Models; Language Model; Model Outputs; Optimal Transport; Probability: Distributions; Semantic Distance; Source Codes; Semantics","Generative adversarial networks; AI algorithms; Auto-regressive; Discriminative language models; Language model; Model outputs; Optimal transport; Probability: distributions; Semantic distance; Source codes; Semantics","","","We acknowledge the anonymous reviewers for their constructive suggestions and insightful discussions to this work. Xuhong Li and Haoyi Xiong were supported in part by the National Key R&D Program of China under the grant No. 2021ZD0110303.","Abnar, Samira, Quantifying attention flow in transformers, Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 4190-4197, (2020); Gpt 4 Technical Report, (2023); Normlime A New Feature Importance Metric for Explaining Deep Neural Networks, (2019); Language Models can Explain Neurons in Language Models, (2023); Bolukbasi, Tolga, Man is to computer programmer as woman is to homemaker? Debiasing word embeddings, Advances in Neural Information Processing Systems, pp. 4356-4364, (2016); Sparks of Artificial General Intelligence Early Experiments with Gpt 4, (2023); Chai, Yekun, ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages, Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 10628-10650, (2023); Chefer, Hila, Transformer Interpretability Beyond Attention Visualization, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 782-791, (2021); Transactions on Machine Learning Research, (2022); Cuturi, Marco, Sinkhorn distances: Lightspeed computation of optimal transport, Advances in Neural Information Processing Systems, (2013)","Salakhutdinov, R.; Kolter, Z.; Heller, K.; Weller, A.; Oliver, N.; Scarlett, J.; Berkenkamp, F.","ML Research Press","","41st International Conference on Machine Learning, ICML 2024","","Vienna","201670","26403498","9781713845065","","","English","Conference paper","Final","","Scopus","2-s2.0-85203805495"
"W., Kang, Wentian; X., Yuan, Xuan; X., Zhang, Xiaohan; Y., Chen, Yishan; J., Li, Jingyu","Kang, Wentian (59317628100); Yuan, Xuan (59317451700); Zhang, Xiaohan (58889390800); Chen, Yishan (59318476500); Li, Jingyu (57204428831)","59317628100; 59317451700; 58889390800; 59318476500; 57204428831","ChatGPT-based Sentiment Analysis and Risk Prediction in the Bitcoin Market","2024","Procedia Computer Science","242","","","211","218","0","2","10.1016/j.procs.2024.08.258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203321031&doi=10.1016%2Fj.procs.2024.08.258&partnerID=40&md5=43e5db029c1f6ccfdff02b327646491c","Beijing University of Technology, Beijing, China; Beijing University of Technology, Beijing, China","Kang, Wentian, Statistics and Mechanics, Beijing University of Technology, Beijing, China; Yuan, Xuan, Statistics and Mechanics, Beijing University of Technology, Beijing, China; Zhang, Xiaohan, School of Economics and Management, Beijing University of Technology, Beijing, China; Chen, Yishan, School of Economics and Management, Beijing University of Technology, Beijing, China; Li, Jingyu, School of Economics and Management, Beijing University of Technology, Beijing, China","The risk prediction of financial markets is of paramount importance, with investor sentiment playing a critical role. However, current research appears to be lacking in-depth exploration of this particular aspect within the Bitcoin market. This study aims to explore the impact of market participants' sentiment on risk prediction in the bitcoin market. We first applied ChatGPT to analyze the sentiment of crawled Bitcoin-related news headlines. Meanwhile, Monte Carlo simulation was employed to calculate value at risk (VaR). And we selected five conventional factors, including Bitcoin price, transaction volume, market share, hash rate, and average difficulty of mining. Finally, K-Nearest Neighbors (KNN) regression model was used to construct the model for predicting the risk of bitcoin market. We made a comparison between the accuracy outcomes when considering and not considering sentiment as factors. The results show that market participant's sentiment is significantly associated with market risk, and the inclusion of sentiment can significantly improve the accuracy of the risk prediction model. © 2024 Elsevier B.V., All rights reserved.","Bitcoin Market; Chatgpt; Investor Sentiment; Risk Prediction; Text Mining; 'current; Bitcoin Market; Chatgpt; Investor's Sentiments; Market Participants; Monte Carlo's Simulation; Risk Predictions; Sentiment Analysis; Text-mining; Value At Risk; Prediction Models","'current; Bitcoin market; ChatGPT; Investor's sentiments; Market participants; Monte Carlo's simulation; Risk predictions; Sentiment analysis; Text-mining; Value at Risk; Prediction models","","","This work was supported by the National Natural Science Foundation of China (grant number 72201012).","Gao, Zhenbin, The fluctuation correlation between investor sentiment and stock index using VMD-LSTM: Evidence from China stock market, North American Journal of Economics and Finance, 66, (2023); Zhang, Boyu, Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models, pp. 349-356, (2023); Kybernetes, (2021); Almansour, Bashar Yaser, Behavioral finance factors and investment decisions: A mediating role of risk perception, Cogent Economics and Finance, 11, 2, (2023); Li, Zewei, Effects of Investment Experience on the Stock Investment Task: The Mediating Role of Risk Perception, Behavioral Sciences, 13, 2, (2023); He, Zhifang, Asymmetric impacts of individual investor sentiment on the time-varying risk-return relation in stock market, International Review of Economics and Finance, 78, pp. 177-194, (2022); Lin, Xudong, How connected is the crypto market risk to investor sentiment?, Finance Research Letters, 56, (2023); Nguyen, Bac, Large-scale distance metric learning for k-nearest neighbors regression, Neurocomputing, 214, pp. 805-814, (2016); Bouzebda, Salim M., The k-nearest neighbors method in single index regression model for functional quasi-associated time series data, Revista Matematica Complutense, 36, 2, pp. 361-391, (2023); Yang, Xiaoyue, A New Algorithm for Large-Scale Geographically Weighted Regression with K-Nearest Neighbors, ISPRS International Journal of Geo-Information, 12, 7, (2023)","Shi, Y.; Shi, Y.","Elsevier B.V.","Bucharest University of Economic Studies; et al.; Key Lab of Big Data Mining and Knowledge Management, Chinese Academy of Sciences; Research Centre on Fictitious Economy and Data Science, Chinese Academy of Sciences; Romanian Academy; School of Economics and Management, University of Chinese Academy of Sciences","11th International Conference on Information Technology and Quantitative Management, ITQM 2024","","Bucharest","202180","18770509","9781510849914","","","English","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85203321031"
"M.N.R., Khan, Md Nabil Rahman; M.S., Salsabil, Most Sadia; K.M., Hasib, Khan Md; M.R., Islam, Md Rafiqul; M.S., Alam, Mohammad Shafiul; C.M., Sanin, Cesar Maldonado; E., Szczerbicki, Edward","Khan, Md Nabil Rahman (57997956100); Salsabil, Most Sadia (57997822000); Hasib, Khan Md (57207760588); Islam, Md Rafiqul (57713922300); Alam, Mohammad Shafiul (57213805418); Sanin, Cesar Maldonado (11639622700); Szczerbicki, Edward (7004603162)","57997956100; 57997822000; 57207760588; 57713922300; 57213805418; 11639622700; 7004603162","News that Moves the Market: DSEX-News Dataset for Forecasting DSE Using BERT","2024","Communications in Computer and Information Science","2145 CCIS","","","219","235","0","1","10.1007/978-981-97-5934-7_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202205881&doi=10.1007%2F978-981-97-5934-7_19&partnerID=40&md5=cd4faef83b41d3740460c8ad83c219bf","Ahsanullah University of Science and Technology, Dhaka, Bangladesh; Bangladesh University of Business and Technology, Dhaka, Bangladesh; Australian Institute of Higher Education, Sydney, Australia; Gdańsk University of Technology, Gdansk, Poland","Khan, Md Nabil Rahman, Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh; Salsabil, Most Sadia, Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh; Hasib, Khan Md, Department of Computer Science and Engineering, Bangladesh University of Business and Technology, Dhaka, Bangladesh; Islam, Md Rafiqul, Business Information Systems, Australian Institute of Higher Education, Sydney, Australia; Alam, Mohammad Shafiul, Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh; Sanin, Cesar Maldonado, Business Information Systems, Australian Institute of Higher Education, Sydney, Australia; Szczerbicki, Edward, Faculty of Management and Economics, Gdańsk University of Technology, Gdansk, Poland","Stock market is a complex and dynamic industry that has always presented challenges for stakeholders and investors due to its unpredictable nature. This unpredictability motivates the need for more accurate prediction models. Traditional prediction models have limitations in handling the dynamic nature of the stock market. Additionally, previous methods have used less relevant data, leading to suboptimal performance. This study proposes the use of Bidirectional Encoder Representations from Transformers (BERT), a pre-trained Large Language Model (LLM), to predict Dhaka Stock Exchange (DSE) market movements. We also introduce a new dataset designed specifically for this problem, capturing important characteristics and patterns that were missing in other datasets. We test our new dataset of headlines and stock market indexes on various machine learning techniques, including Decision Tree (DT), Logistic Regression (LR), K-Nearest Neighbors (KNN), Random Forest (RF), Linear Support Vector Machine (LSVM), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs), Bidirectional Long Short-Term Memory (Bi-LSTM), BERT, Financial Bidirectional Encoder Representations from Transformers (FinBERT), and RoBERTa, which are compared to assess their predictive capabilities. Our proposed model achieves 99.83% accuracy on the training set and 99.78% accuracy on the test set, outperforming previous methods. © 2024 Elsevier B.V., All rights reserved.","Deep Learning; Large Language Model; Machine Learning; Natural Language Processing; Sentiment Analysis; Stock Exchange; Commerce; Financial Markets; Investments; K-nearest Neighbors; Logistic Regression; Marketplaces; Prediction Models; Support Vector Machines; Deep Learning; Language Model; Language Processing; Large Language Model; Machine-learning; Natural Language Processing; Natural Languages; Prediction Modelling; Sentiment Analysis; Stock Exchange; Long Short-term Memory","Commerce; Financial markets; Investments; k-nearest neighbors; Logistic regression; Marketplaces; Prediction models; Support vector machines; Deep learning; Language model; Language processing; Large language model; Machine-learning; Natural language processing; Natural languages; Prediction modelling; Sentiment analysis; Stock exchange; Long short-term memory","","","","Li, Bing, Public sentiment analysis in twitter data for prediction of a company's stock price movements, pp. 232-239, (2014); Cakra, Yahya Eru, Stock price prediction using linear regression based on sentiment analysis, pp. 147-154, (2016); Int J Soc Sci Humanity Stud, (2013); Int J Advance Soft Comput Appl, (2014); Abdullah, Sheikh Shaugat, Analysis of stock market using text mining and natural language processing, (2013); Khan, Md Nabil Rahman, A Multi-modal Deep Learning Approach for Predicting Dhaka Stock Exchange, pp. 879-885, (2023); Khan, Md Nabil Rahman, A Hybrid Method based on Machine Learning to Predict the Stock Prices in Bangladesh, pp. 67-73, (2022); Xl Sum Large Scale Multilingual Abstractive Summarization for 44 Languages Arxiv Preprint Arxiv, (2021); Corr, (2017); Cohen, Jacob, A Coefficient of Agreement for Nominal Scales, Educational and Psychological Measurement, 20, 1, pp. 37-46, (1960)","Nguyen, N.T.; Wojtkiewicz, K.; Chbeir, R.; Manolopoulos, Y.; Fujita, H.; Hong, T.-P.; Nguyen, L.M.","Springer Science and Business Media Deutschland GmbH","","16th Asian Conference on Intelligent Information and Database Systems , ACIIDS 2024","","Ras Al Khaimah","317049","18650937; 18650929","9789819671748; 9789819664610; 9783032026743; 9783032008831; 9783032026712; 9789819671779; 9783031949425; 9789819666874; 9783031936968; 9783031941207","","","English","Conference paper","Final","","Scopus","2-s2.0-85202205881"
"C., Liu, Chenghao; A., Arulappan, Arunkumar; R.K., Naha, Ranesh Kumar; A., Mahanti, Aniket; J., Kamruzzaman, Joarder; I., Ra, Inho","Liu, Chenghao (59160936800); Arulappan, Arunkumar (57539746200); Naha, Ranesh Kumar (56841650300); Mahanti, Aniket (19640237200); Kamruzzaman, Joarder (6602151152); Ra, Inho (8895759300)","59160936800; 57539746200; 56841650300; 19640237200; 6602151152; 8895759300","Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study","2024","IEEE Access","12","","","134041","134061","0","13","10.1109/ACCESS.2024.3445413","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201784614&doi=10.1109%2FACCESS.2024.3445413&partnerID=40&md5=08b2ac75d992a83864fe484888c9d3fc","Vellore Institute of Technology, Vellore, India; Queensland University of Technology, Brisbane, Australia; The University of Auckland, Auckland, New Zealand; University of New Brunswick, Fredericton, Canada; Federation University Australia, Ballarat, Australia; Kunsan National University, Gunsan, South Korea","Liu, Chenghao, School of Computer Science, The University of Auckland, Auckland, New Zealand; Arulappan, Arunkumar, School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, India; Naha, Ranesh Kumar, School of Information Systems, Queensland University of Technology, Brisbane, Australia; Mahanti, Aniket, School of Computer Science, The University of Auckland, Auckland, New Zealand, Department of Computer Science, University of New Brunswick, Fredericton, Canada; Kamruzzaman, Joarder, Centre for Smart Analytics, Federation University Australia, Ballarat, Australia; Ra, Inho, School of Software, Kunsan National University, Gunsan, South Korea","This paper comprehensively examines Large Language Models (LLMs) in sentiment analysis, specifically focusing on financial markets and exploring the correlation between news sentiment and Bitcoin prices. We systematically categorize various LLMs used in financial sentiment analysis, highlighting their unique applications and features. We also investigate the methodologies for effective data collection and categorization, underscoring the need for diverse and comprehensive datasets. Our research features a case study investigating the correlation between news sentiment and Bitcoin prices, utilizing advanced sentiment analysis and financial analysis methods to demonstrate the practical application of LLMs. The findings reveal a modest but discernible correlation between news sentiment and Bitcoin price fluctuations, with historical news patterns showing a more substantial impact on Bitcoin's longer-term price than immediate news events. This highlights LLMs' potential in market trend prediction and informed investment decision-making. © 2024 Elsevier B.V., All rights reserved.","Bitcoin Price; Large Language Model; Machine Learning; Market Dynamics; Sentiment Analysis; Bitcoin Price; Correlation; Language Model; Large Language Model; Machine-learning; Market Dynamics; Predictive Models; Quality Assessment; Sentiment Analysis; Bitcoin","Bitcoin price; Correlation; Language model; Large language model; Machine-learning; Market dynamics; Predictive models; Quality assessment; Sentiment analysis; Bitcoin","","","This work was supported by the School of Computer Science Engineering and Information Systems, Vellore Institute of Technology.","Baker, Malcolm P., Investor sentiment in the stock market, Journal of Economic Perspectives, 21, 2, pp. 129-151, (2007); Tetlock, Paul C., Giving content to investor sentiment: The role of media in the stock market, Journal of Finance, 62, 3, pp. 1139-1168, (2007); Smales, Lee A., The importance of fear: investor sentiment and stock market returns, Applied Economics, 49, 34, pp. 3395-3421, (2017); Proceedings of the 2012 International Conference on Advances in Social Networks Analysis and Mining Asonam 2012, (2012); Cambria, Erik, Jumping NLP curves: A review of natural language processing research, IEEE Computational Intelligence Magazine, 9, 2, pp. 48-57, (2014); Ramiah, Vikash B., Neoclassical finance, behavioral finance and noise traders: A review and assessment of the literature, International Review of Financial Analysis, 41, pp. 89-100, (2015); Wu, Fangzhao, Structured microblog sentiment classification via social context regularization, Neurocomputing, 175, PartA, pp. 599-609, (2016); Feature Selection Methods Effects on Machine Learning Approaches in Malay Sentiment Analysis, (2015); Moore, Robert C., Intelligent selection of language model training data, pp. 220-224, (2010); Bloomberggpt A Large Language Model for Finance, (2023)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-85201784614"
"G., Arnone, Gioia","Arnone, Gioia (58010551800)","58010551800","AI and Chatbots in FinTech: Revolutionizing Digital Experiences and Predictive Analytics","2024","Contributions to Finance and Accounting","Part F2871","","","1","125","0","3","10.1007/978-3-031-55536-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201386286&doi=10.1007%2F978-3-031-55536-7&partnerID=40&md5=9fbacd65d1cd476f36bbb7201ec42c63","Parthenope University of Naples, Naples, Italy; Vrije Universiteit Brussel, Brussels, Belgium","Arnone, Gioia, Parthenope University of Naples, Naples, Italy, Vrije Universiteit Brussel, Brussels, Belgium","This book is a comprehensive guide to the use of Artificial Intelligence (AI) in the Financial Technology (FinTech) industry. It is comprised of ten chapters, each addressing a specific aspect of AI in FinTech. The reader is introduced to AI in FinTech, including its history and current state and the role of chatbots in FinTech and how they are used to improve customer service. Furthermore, the book explores the business framework of AI-based ChatGPT in FinTech, including the technology behind ChatGPT and how it can be applied to various financial sectors. The book examines the use of predictive analytics and machine learning in FinTech, highlighting how these tools are used to predict customer behavior and improve decision-making. The author delves into how ChatGPT is used to determine buying behavior and discusses the use of machine learning to reshape the digital experience in FinTech. Additionally, the book provides best practices for retaining customers in FinTech, including how to use AI to create personalized experiences that keep customers coming back, and explores the different applications of predictive models in FinTech, including how they are used to improve risk management and fraud detection. Lastly, the book discusses the use of ChatGPT for stock price prediction and the detection of financial fraud and examines the role of ChatGPT in the world of cryptocurrency, including how it can be used to make informed investment decisions. Overall, this book provides a comprehensive overview of the different ways AI is being used in FinTech and the potential it holds for improving customer experiences and driving innovation in the financial industry. © 2024 Elsevier B.V., All rights reserved.","Ai; Blockchain; Business Framework; Capital Markets; Chatgpt; Cryptocurrencies; Financial Services; Fintech; Machine Learning; Predictive Models; Stock Price","","","","","Abdullah, Malak A., ChatGPT: Fundamentals, Applications and Social Impacts, (2022); Analytics Vidhya, (2023); Responsible Finance Forum Bbva, (2020); Alessio, Helaine Mary, Interaction of proctoring and student major on online test performance, International Review of Research in Open and Distributed Learning, 19, 5, pp. 166-185, (2018); Dark Side of Chatgpt, (2023); Openai Chatgpt Generated Literature Review Digital Twin in Healthcare, (2022); A Multitask Multilingual Multimodal Evaluation of Chatgpt on Reasoning Hallucination and Interactivity, (2023); Beck, Thorsten, Payment instruments, finance and development, Journal of Development Economics, 133, pp. 162-186, (2018); Transactions of the Association for Computational Linguistics, (2018); Bender, Emily M., Climbing towards NLU: On meaning, form, and understanding in the age of data, Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 5185-5198, (2020)","","Springer Nature","","","","","","27306038; 27306046","","","","English","Book chapter","Final","","Scopus","2-s2.0-85201386286"
"","","","2024 7th International Conference on Artificial Intelligence and Big Data, ICAIBD 2024","2024","","","","","","","621","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201236297&partnerID=40&md5=c1500cd6b2b3bc87477d9c6e21fca1ce","","","The proceedings contain 98 papers. The topics discussed include: patient clustering to improve process mining for disease trajectory analysis using Indonesia health insurance dataset; a comprehensive review of transformer-based models: ChatGPT and bard in focus; pneumonia image classification: deep learning and machine learning fusion; exploring the pathways to optimize immersive imaging experiences using AIGC technology; sentiment analysis of song dynasty classical poetry using fine-tuned large language models: a study with LLMs; a random forest stock prediction model based on Bayesian optimization; multi-level generative pretrained transformer for improving malware detection performance; and research on building a competency model for managers in private express enterprises based on recruitment big data. © 2024 Elsevier B.V., All rights reserved.","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","Sichuan Province Computer Federation","7th International Conference on Artificial Intelligence and Big Data, ICAIBD 2024","","Chengdu","201445","","9798350385106","","","English","Conference review","Final","","Scopus","2-s2.0-85201236297"
"P., Pezeshkpour, Pouya; E.R., Hruschka, Estevam Rafael","Pezeshkpour, Pouya (56685603000); Hruschka, Estevam Rafael (57194234770)","56685603000; 57194234770","Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions","2024","","","","","2006","2017","0","23","10.18653/v1/2024.findings-naacl.130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197931784&doi=10.18653%2Fv1%2F2024.findings-naacl.130&partnerID=40&md5=c68d23e3448c38214da8d38d77e8b5a0","Megagon Labs, Mountain View, United States","Pezeshkpour, Pouya, Megagon Labs, Mountain View, United States; Hruschka, Estevam Rafael, Megagon Labs, Mountain View, United States","Large Language Models (LLMs) have demonstrated remarkable capabilities in various NLP tasks. However, previous works have shown these models are sensitive towards prompt wording, and few-shot demonstrations and their order, posing challenges to fair assessment of these models. As these models become more powerful, it becomes imperative to understand and address these limitations. In this paper, we focus on LLMs robustness on the task of multiple-choice questions-commonly adopted task to study reasoning and fact-retrieving capability of LLMs. Investigating the sensitivity of LLMs towards the order of options in multiple-choice questions, we demonstrate a considerable performance gap of approximately 13% to 85% in LLMs on different benchmarks, when answer options are reordered, even when using demonstrations in a few-shot setting. Through a detailed analysis, we conjecture that this sensitivity arises when LLMs are uncertain about the prediction between the top-2/3 choices, and specific options placements may favor certain prediction between those top choices depending on the question caused by positional bias. We also identify patterns in top-2 choices that amplify or mitigate the model's bias toward option placement. We found that for amplifying bias, the optimal strategy involves positioning the top two choices as the first and last options. Conversely, to mitigate bias, we recommend placing these choices among the adjacent options. To validate our conjecture, we conduct various experiments and adopt two approaches to calibrate LLMs' predictions, leading to up to 8 percentage points improvement across different models and benchmarks. © 2024 Elsevier B.V., All rights reserved.","Benchmarking; Computational Linguistics; Language Model; Model Bias; Model Prediction; Model Robustness; Model Sensitivity; Multiple-choice Questions; Optimal Strategies; Percentage Points; Performance Gaps; Forecasting","Benchmarking; Computational linguistics; Language model; Model bias; Model prediction; Model robustness; Model sensitivity; Multiple-choice questions; Optimal strategies; Percentage points; Performance gaps; Forecasting","","","","Palm 2 Technical Report, (2023); Palm Scaling Language Modeling with Pathways, (2022); Clark, Peter E., From F to A on the New York regents science exams - an overview of the aristo project, AI Magazine, 41, 4, pp. 39-53, (2020); Measuring Massive Multitask Language Understanding, (2020); Large Language Models are Zero Shot Rankers for Recommender Systems, (2023); Language Models Mostly Know What They Know, (2022); Can Large Language Models Reason about Medical Questions, (2022); Teaching Models to Express their Uncertainty in Words, (2022); Gpt 4 Technical Report, (2023); Ouyang, Long, Training language models to follow instructions with human feedback, Advances in Neural Information Processing Systems, 35, (2022)","Duh, K.; Gomez, H.; Bethard, S.","Association for Computational Linguistics (ACL)","Baidu; CapitalOne; et al.; Grammarly; Megagon Labs; Otter.ai","2024 Findings of the Association for Computational Linguistics: NAACL 2024","","Mexico City","200405","","9798891761193","","","English","Conference paper","Final","","Scopus","2-s2.0-85197931784"
"B., Shi, Bao; H., Cai, Haiyang; H., Gao, Hui; Y., Ou, Yongsheng; D., Wang, Degang","Shi, Bao (57693253800); Cai, Haiyang (59197965700); Gao, Hui (57190883134); Ou, Yongsheng (55618994600); Wang, Degang (56102987100)","57693253800; 59197965700; 57190883134; 55618994600; 56102987100","The Robot's Understanding of Classification Concepts Based on Large Language Model","2024","Proceedings of IEEE Workshop on Advanced Robotics and its Social Impacts, ARSO","","","","122","127","0","1","10.1109/ARSO60199.2024.10557816","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197253499&doi=10.1109%2FARSO60199.2024.10557816&partnerID=40&md5=fce0496ff97451f48a89e18161d4a948","Dalian University of Technology, Dalian, China","Shi, Bao, School of Control Science and Engineering, Dalian University of Technology, Dalian, China; Cai, Haiyang, School of Control Science and Engineering, Dalian University of Technology, Dalian, China; Gao, Hui, School of Control Science and Engineering, Dalian University of Technology, Dalian, China; Ou, Yongsheng, School of Control Science and Engineering, Dalian University of Technology, Dalian, China; Wang, Degang, School of Control Science and Engineering, Dalian University of Technology, Dalian, China","Cognition of classification concepts empowers robots to enhance their planning and task execution capabilities. By incorporating classification cognition of the environment and tasks, robots can make more informed decisions and improve their autonomy. In various domains, specific concept classification is crucial, such as disease categorization in medical diagnosis, transaction classification in the financial field, etc. Therefore, this article conducts an in-depth exploration of the cognition and understanding of abstract classification concepts (object color, object type, object size, etc.), and builds a programmed classification structure based on a large language model (PCS-LLM) to improve the robot's ability to classify the different categories. First, through the programmed definition of interactive objects and executable action libraries in the scene, constraints are added to the prediction of general LLM, thereby improving the executability of predicted actions. Secondly, for abstract classification concepts, typical tasks and decomposed actions performed by robots are programmatically defined as an example of LLM generating new task decomposed actions. Finally, in mixed scenarios, the robot's understanding and decomposition of any concept combination task is verified based on the UR5 robotic arm. Experimental results show that the robot can achieve corresponding classification operations when faced with tasks involving any combination of concepts. © 2024 Elsevier B.V., All rights reserved.","Classification Concept Cognition; Large Language Model (llm); Mixed Scene; Programmatic Defined Structure; Robot Skill Generalization; Abstracting; Computational Linguistics; Computer Aided Diagnosis; Classification Concept Cognition; Concept-based; Generalisation; Language Model; Large Language Model; Mixed Scene; Programmatic Defined Structure; Programmatics; Robot Skill Generalization; Robot Skills; Robot Programming","Abstracting; Computational linguistics; Computer aided diagnosis; Classification concept cognition; Concept-based; Generalisation; Language model; Large language model; Mixed scene; Programmatic defined structure; Programmatics; Robot skill generalization; Robot skills; Robot programming","","","This work was partially supported by Natural Science Foundation of China (Grants No. 62173319, 62063006).","Akbari, Aliakbar, Knowledge-oriented task and motion planning for multiple mobile robots, Journal of Experimental and Theoretical Artificial Intelligence, 31, 1, pp. 137-162, (2019); Latifinavid, Masoud, Kinematic Modelling and Position Control of A 3-DOF Parallel Stabilizing Robot Manipulator, Journal of Intelligent and Robotic Systems: Theory and Applications, 107, 2, (2023); Garrett, Caelan Reed, FFRob: An efficient heuristic for task and motion planning, Springer Tracts in Advanced Robotics, 107, pp. 179-195, (2015); Do as I can Not as I Say Grounding Language in Robotic Affordances, (2022); Socratic Models Composing Zero Shot Multimodal Reasoning with Language, (2022); Chen, Yiye, A Joint Network for Grasp Detection Conditioned on Natural Language Commands, Proceedings - IEEE International Conference on Robotics and Automation, 2021-May, pp. 4576-4582, (2021); Blukis, Valts, Few-shot Object Grounding and Mapping for Natural Language Robot Instruction Following, Proceedings of Machine Learning Research, 155, pp. 1829-1854, (2020); Stepputtis, Simon, Language-conditioned imitation learning for robot manipulation tasks, Advances in Neural Information Processing Systems, 2020-December, (2020); Conference on Robot Learning, (2021); Shao, Lin, Concept2Robot: Learning manipulation concepts from instructions and human demonstrations, International Journal of Robotics Research, 40, 12-14, pp. 1419-1434, (2021)","","IEEE Computer Society","Beijing Nokov Science and Technology Co., Ltd.; et al.; IEEE; IEEE Robotics and Automation Society (RA); The Chinese University of Hong Kong; The Hong Kong University of Science and Technology","20th IEEE International Conference on Advanced Robotics and Its Social Impacts, ARSO 2024","","Hong Kong; Hong Kong Science and Technology Park","200352","21627576; 21627568","9781424419531; 9781665479660; 9781479923694; 9781665464246; 9781728131764; 9781467304825; 9781538680377; 9781467380294; 9781479969685; 9781467307963","","","English","Conference paper","Final","","Scopus","2-s2.0-85197253499"
"I., Kar, Indrajit; Z., Ralte, Zonunfeli; M., Shivakumara, Maheshakumara; R., Roy, Rana; A., Kumari, Arti","Kar, Indrajit (58220466400); Ralte, Zonunfeli (58264272100); Shivakumara, Maheshakumara (59187370400); Roy, Rana (59187782700); Kumari, Arti (58560056400)","58220466400; 58264272100; 59187370400; 59187782700; 58560056400","Agents are All you need: Elevating Trading Dynamics with Advanced Generative AI-Driven Conversational LLM Agents and Tools","2024","","","","","","","0","3","10.1109/I2CT61223.2024.10543356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196820617&doi=10.1109%2FI2CT61223.2024.10543356&partnerID=40&md5=49f31a7a28d41e266b4b789181a6d00c","Zensar Technologies, Hyderabad, India; RastrAI","Kar, Indrajit, Zensar Technologies, Hyderabad, India; Ralte, Zonunfeli, RastrAI; Shivakumara, Maheshakumara, Zensar Technologies, Hyderabad, India; Roy, Rana, Zensar Technologies, Hyderabad, India; Kumari, Arti, Zensar Technologies, Hyderabad, India","This paper presents the development of a groundbreaking LLM multi-agent system designed to optimize the Energy Exchange (EX)'s electricity trading. The system integrates cutting-edge, Generative AI, embedding-based deep learning models and LLM Agents to forecast electricity prices with heightened accuracy and facilitate interactive reporting. Our first agent performs advanced deep learning , tapping into IEX's rich databases for day-ahead and intraday market prices, alongside additional data streams such as weather and economic indicators. We eschew traditional predictive models in favor of sophisticated embedding-based models adept at discerning complex temporal patterns, enabling precise forecasts up to seven days ahead. Rigorous validation methods, including k-fold cross-validation, are applied, with accuracy gauged by metrics like Root Mean Squared Error (RMSE). The second agent is founded on a robust GenAI tools framework, translating intricate model predictions into intelligible reports and extract insights through another LLM based Agents. This interface adeptly handles energy market specifics, ensuring contextually relevant interactions. This tool's integration aims to enhance decision-making for market participants and to inject unprecedented predictive transparency into market dynamics. Our initiative heralds a transformative step toward realizing a data-centric, efficient, and customer-focused energy market in India, with potential expansion throughout the South Asian region powered by LLM and generative AI. © 2024 Elsevier B.V., All rights reserved.","Agents Tools; Energy Price Prediction; Forecasting; Generative Ai; Gpt; Large Language Model; Costs; Decision Making; Embeddings; Long Short-term Memory; Mean Square Error; Multi Agent Systems; Power Markets; Agent Tool; Day-ahead; Energy Price Prediction; Energy Prices; Generative Ai; Gpt; Language Model; Large Language Model; Price Prediction; Forecasting","Costs; Decision making; Embeddings; Long short-term memory; Mean square error; Multi agent systems; Power markets; Agent tool; Day-ahead; Energy price prediction; Energy prices; Generative AI; GPT; Language model; Large language model; Price prediction; Forecasting","","","","undefined; Szkuta, B. R., Electricity price short-term forecasting using artificial neural networks, IEEE Transactions on Power Systems, 14, 3, pp. 851-857, (1999); Title of Paper if Known; Crespo Cuaresma, Jesús, Forecasting electricity spot-prices using linear univariate time-series models, Applied Energy, 77, 1, pp. 87-106, (2004); Plakas, Konstantinos A., A Predictive Fuzzy Logic Model for Forecasting Electricity Day-Ahead Market Prices for Scheduling Industrial Applications †, Energies, 16, 10, (2023); Lago, Jesus, Forecasting day-ahead electricity prices: A review of state-of-the-art algorithms, best practices and an open-access benchmark, Applied Energy, 293, (2021); Nogales, Francisco Javier, Forecasting next-day electricity prices by time series models, IEEE Transactions on Power Systems, 17, 2, pp. 342-348, (2002); Olivares, Kin G., Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx, International Journal of Forecasting, 39, 2, pp. 884-900, (2023); Maciejowska, Katarzyna, Enhancing load, wind and solar generation for day-ahead forecasting of electricity prices, Energy Economics, 99, (2021); Gao, Feng, Forecasting power market clearing price and quantity using a neural network method, Proceedings of the IEEE Power Engineering Society Transmission and Distribution Conference, 4, pp. 2183-2188, (2000)","","Institute of Electrical and Electronics Engineers Inc.","Siddhant College of Engineering (SCE)","9th IEEE International Conference for Convergence in Technology, I2CT 2024","","Pune","200137","","9798350394474","","","English","Conference paper","Final","","Scopus","2-s2.0-85196820617"
"","","","Proceedings of the 6th International Conference on Finance, Economics, Management and IT Business, FEMIB 2024","2024","","","","","","","134","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196751232&partnerID=40&md5=24880e4515677452d691f73e6ec538fd","","","The proceedings contain 14 papers. The topics discussed include: what do customers demand? inclusive and sustainable entrepreneurial marketing; applications of artificial intelligence in sustainability assessment and risk management in European banking; safeguarding downside risk in portfolio insurance: navigating Swiss stock market regimes with options, trading signals, and financial products; internal audit: friend or foe of innovation in an organization: case of Czech banking sector; the recruiting process as an attractiveness factor: how do companies manage to position themselves competitively as employers?; developing a framework for city brand-image promotion via social media communication; leveraging multimodal large language models and natural language processing techniques for comprehensive ESG risk score prediction; ChatGPT in higher education: a risk management approach to academic integrity, critical thinking, and workforce readiness; applying text analytics methodology to analyze project reports; and stock market forecasting using machine learning models through volatility-driven trading strategies. © 2024 Elsevier B.V., All rights reserved.","","","","","","","Arami, M.; Baudier, P.; Chang, V.","SciTePress","Institute for Systems and Technologies of Information, Control and Communication (INSTICC)","6th International Conference on Finance, Economics, Management and IT Business, FEMIB 2024","","Angers","200171","","9789897586958","","","English","Conference review","Final","","Scopus","2-s2.0-85196751232"
"O.H., Hamid, Oussama H.","Hamid, Oussama H. (36109874600)","36109874600","Beyond Probabilities: Unveiling the Delicate Dance of Large Language Models (LLMs) and AI-Hallucination","2024","","","","","85","90","0","7","10.1109/CogSIMA61085.2024.10553755","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196715899&doi=10.1109%2FCogSIMA61085.2024.10553755&partnerID=40&md5=01f48c418790e05ca09908e5680ed42a","HCT-Abu Dhabi Baniyas Campus, Abu Dhabi, United Arab Emirates","Hamid, Oussama H., Computer Information Systems Department, HCT-Abu Dhabi Baniyas Campus, Abu Dhabi, United Arab Emirates","Large language models (LLMs), like OpenAI’s ChatGPT and Google’s Gemini, operate as probabilistic models, leveraging their ability to generalise and discern intricate patterns within data. By assigning probabilities to different tokens based on patterns learned during extensive training on large datasets, these models can generate a wide range of contextually appropriate responses, spanning from textual scripts to auditory and visual outputs (both static and moving images). However, the inherent probabilistic nature of LLMs introduces a notable challenge, leading to the phenomenon known in the field of artificial intelligence as ‘AI-hallucination, ’ where the model may produce responses that sound plausible but are factually incorrect or nonsensical. Despite being perceived as a drawback, we posit in this paper that AI-hallucinations can be reframed as a distinctive feature of LLMs rather than a mere limitation. Our argument stems from the understanding that attempts to mitigate the harms caused by AI-hallucinations might inadvertently lead to increased model rigidity. This delicate balance between minimising harm and preserving the model’s flexibility is a central theme in our discussion. Furthermore, we revisit the concept of ‘context, ’ contending that a complete definition goes beyond the mere description of circumstances, environment, or surrounding facts. We assert that context is enriched by a conscious embodiment, involving the choice or refusal of action (considering all associate ethical implications) among a set of available options. © 2024 Elsevier B.V., All rights reserved.","Ai-hallucination; Artificial Intelligence (ai); Consciousness; Context; Gemini; Generalisation-hallucination Dilemma; Gpt; Large Language Models (llms); Artificial Intelligence; Computational Linguistics; Artificial Intelligence-hallucination; Consciousness; Context; Geminus; Generalisation; Generalization-hallucination Dilemma; Gpt; Language Model; Large Language Model; Large Datasets","Artificial intelligence; Computational linguistics; Artificial intelligence-hallucination; Consciousness; Context; Geminus; Generalisation; Generalization-hallucination dilemma; GPT; Language model; Large language model; Large datasets","","","This work has been supported by the Office of Chief Academic Officer at HCT under Grant Number PD4445. Many thanks for the generous support. I would also like to extend my appreciation to the anonymous reviewers for their thoughtful comments on the manuscript.","Google to Pause Gemini AI Models Image Generation of People Due to Inaccuracies, (2024); Gemini 1 5 Our Next Generation Model Now Available for Private Preview in Google Ai Studio, (2024); A Multitask Multilingual Multimodal Evaluation of Chatgpt on Reasoning Hallucination and Interactivity, (2023); Sovrano, Francesco, Toward Eliminating Hallucinations: GPT-based Explanatory AI for Intelligent Textbooks and Documentation, CEUR Workshop Proceedings, 3444, pp. 54-65, (2023); Guardian, (2024); Google Pauses Geminis Ability to Generate Ai Images of People After Diversity Errors, (2024); Hamid, Oussama H., ChatGPT and the Chinese Room Argument: An Eloquent AI Conversationalist Lacking True Understanding and Consciousness, pp. 238-241, (2023); Vaswani, Ashish, Attention is all you need, Advances in Neural Information Processing Systems, 2017-December, pp. 5999-6009, (2017); Improving Language Understanding by Generative Pre Training, (2018); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020)","","Institute of Electrical and Electronics Engineers Inc.","","2024 IEEE Conference on Cognitive and Computational Aspects of Situation Management, CogSIMA 2024","","Montreal; QC","200167","","9798350362817","","","English","Conference paper","Final","","Scopus","2-s2.0-85196715899"
"S.A., Alryalat, Saif Aldeen; A.M., Musleh, Ayman Mohammed; M.Y., Kahook, Malik Yaser","Alryalat, Saif Aldeen (57191917985); Musleh, Ayman Mohammed (58753114900); Kahook, Malik Yaser (8709820700)","57191917985; 58753114900; 8709820700","Evaluating the strengths and limitations of multimodal ChatGPT-4 in detecting glaucoma using fundus images","2024","Frontiers in Ophthalmology","4","","1387190","","","0","7","10.3389/fopht.2024.1387190","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196533283&doi=10.3389%2Ffopht.2024.1387190&partnerID=40&md5=53855e91838a3ae45d7a1c79c165ff80","The University of Jordan, Amman, Jordan; Houston Methodist Hospital, Houston, United States; Jordan University Hospital, Amman, Jordan; University of Colorado School of Medicine, Aurora, United States","Alryalat, Saif Aldeen, Department of Ophthalmology, The University of Jordan, Amman, Jordan, Department of Ophthalmology, Houston Methodist Hospital, Houston, United States; Musleh, Ayman Mohammed, Jordan University Hospital, Amman, Jordan; Kahook, Malik Yaser, Department of Ophthalmology, University of Colorado School of Medicine, Aurora, United States","Overview: This study evaluates the diagnostic accuracy of a multimodal large language model (LLM), ChatGPT-4, in recognizing glaucoma using color fundus photographs (CFPs) with a benchmark dataset and without prior training or fine tuning. Methods: The publicly accessible Retinal Fundus Glaucoma Challenge “REFUGE” dataset was utilized for analyses. The input data consisted of the entire 400 image testing set. The task involved classifying fundus images into either ‘Likely Glaucomatous’ or ‘Likely Non-Glaucomatous’. We constructed a confusion matrix to visualize the results of predictions from ChatGPT-4, focusing on accuracy of binary classifications (glaucoma vs non-glaucoma). Results: ChatGPT-4 demonstrated an accuracy of 90% with a 95% confidence interval (CI) of 87.06%-92.94%. The sensitivity was found to be 50% (95% CI: 34.51%-65.49%), while the specificity was 94.44% (95% CI: 92.08%-96.81%). The precision was recorded at 50% (95% CI: 34.51%-65.49%), and the F1 Score was 0.50. Conclusion: ChatGPT-4 achieved relatively high diagnostic accuracy without prior fine tuning on CFPs. Considering the scarcity of data in specialized medical fields, including ophthalmology, the use of advanced AI techniques, such as LLMs, might require less data for training compared to other forms of AI with potential savings in time and financial resources. It may also pave the way for the development of innovative tools to support specialized medical care, particularly those dependent on multimodal data for diagnosis and follow-up, irrespective of resource constraints. © 2024 Elsevier B.V., All rights reserved.","Artificial Intelligence; Chatgpt; Glaucoma; Gpt; Large Language Models","","","","","Kaul, Vivek, History of artificial intelligence in medicine, Gastrointestinal Endoscopy, 92, 4, pp. 807-812, (2020); Weiss, Sholom M., Glaucoma consultation by computer, Computers in Biology and Medicine, 8, 1, pp. 25-40, (1978); Alryalat, Saif Aldeen, Machine learning in glaucoma: a bibliometric analysis comparing computer science and medical fields’ research, Expert Review of Ophthalmology, 16, 6, pp. 511-515, (2021); Chaurasia, Abadh Kishore, Diagnostic Accuracy of Artificial Intelligence in Glaucoma Screening and Clinical Practice, Journal of Glaucoma, 31, 5, pp. 285-299, (2022); Nath, Siddharth, New meaning for NLP: the trials and tribulations of natural language processing with GPT-3 in ophthalmology, British Journal of Ophthalmology, 106, 7, pp. 889-892, (2022); Orlando, José Ignacio, REFUGE Challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs, Medical Image Analysis, 59, (2020); Lyu, Qing, Translating radiology reports into plain language using ChatGPT and GPT-4 with prompt learning: results, limitations, and potential, Visual Computing for Industry, Biomedicine, and Art, 6, 1, (2023); Elmoufidi, Abdelali, CNN with Multiple Inputs for Automatic Glaucoma Assessment Using Fundus Images, International Journal of Image and Graphics, 23, 1, (2023); Singh, Law Kumar, Collaboration of features optimization techniques for the effective diagnosis of glaucoma in retinal fundus images, Advances in Engineering Software, 173, (2022); Sankar Ganesh, S., A Novel Context Aware Joint Segmentation and Classification Framework for Glaucoma Detection, Computational and Mathematical Methods in Medicine, 2021, (2021)","","Frontiers Media SA","","","","","","26740826","","","","English","Article","Final","All Open Access; Gold Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85196533283"
"V., Vishnu Vandana, V.; A.M., Rao, A. M.","Vishnu Vandana, V. (59144041800); Rao, A. M. (59144205500)","59144041800; 59144205500","Retrieval method as a learning intervention for long term retention and creative thinking skills","2024","Journal of Engineering Education Transformations","37","Special Issue 2","","663","665","0","2","10.16920/jeet/2024/v37is2/24102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194194063&doi=10.16920%2Fjeet%2F2024%2Fv37is2%2F24102&partnerID=40&md5=f9c0eb116e34163baff5606bdfda4297","Anurag University, Hyderabad, India","Vishnu Vandana, V., School of Management, Anurag University, Hyderabad, India; Rao, A. M., School of Management, Anurag University, Hyderabad, India","Few key skills among many that are needed in the 21st century are critical thinking, creativity, collaboration, meta cognitive skills, technology literacy and decision making under uncertainty. With the emergence of ChatGPT and other Generative AI tools, there is a dire need for a distinctive way of learning and application of learning to ensure learning effectiveness. Mere content is no longer the most important factor to learn these skills but. what is needed is the ability to retrieve material learnt, in the context of application. For the learner to be able to apply the critical thinking levels and higher learning levels of Blooms taxonomy, the basic first level of remembering forms the basic foundation, particularly when the students are from first generation educated families or with disadvantaged socioeconomic backgrounds. However, when students cram for the exams, they generally get an ‘illusion of learning’, where they think they know, but in reality often they may not be able to recall what they crammed when they need it later. This is a case of inefficient investment of time and effort in learning for the student. For the teacher, it slows down the teaching process and opportunity to engage in higher order thinking level applications. Addressing the frustrations of both teacher and students, the authors applied the concept of Retrieval method for MBA I year for Marketing Management course during a semester and a survey was conducted at the end of the semester to understand the perception of students on effectiveness of Retrieval techniques. The results supported that retrieval techniques were effective in supporting the student learning. © 2024 Elsevier B.V., All rights reserved.","Blooms Taxonomy; Learning Intervention; Retention Technique; Retrieval Technique","","","","","Powerful Teaching Unleash the Science of Learning, (2019); undefined, (1981); Teachers Tackle Thinking, (1990); Karpicke, Jeffrey D., Retrieval practice produces more learning than elaborative studying with concept mapping, Science, 331, 6018, pp. 772-775, (2011); Science and Children, (2017); A Taxonomy for Learning Teaching and Assessing A Revision of Bloom S Taxonomy of Educational Objectives, (2001); McDermott, Kathleen B., Practicing Retrieval Facilitates Learning, Annual Review of Psychology, 72, pp. 609-633, (2021); Make It Stick the Science of Successful Learning, (2014); Clearing House, (1998)","","Rajarambapu Institute Of Technology","","","","","","23941707; 23492473","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85194194063"
"P., Sarzaeim, Paria; Q.H., Mahmoud, Qusay H.; A., Azim, Akramul","Sarzaeim, Paria (58782086300); Mahmoud, Qusay H. (6701548037); Azim, Akramul (36023296200)","58782086300; 6701548037; 36023296200","A Framework for LLM-Assisted Smart Policing System","2024","IEEE Access","12","","","74915","74929","0","13","10.1109/ACCESS.2024.3404862","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194096093&doi=10.1109%2FACCESS.2024.3404862&partnerID=40&md5=95c7a99df5857ef1d0e1669ee92230bd","Ontario Tech University, Oshawa, Canada","Sarzaeim, Paria, Computer and Software Engineering, Ontario Tech University, Oshawa, Canada; Mahmoud, Qusay H., Computer and Software Engineering, Ontario Tech University, Oshawa, Canada; Azim, Akramul, Computer and Software Engineering, Ontario Tech University, Oshawa, Canada","In the face of rapidly increasing crime rates, the evolving complexity of crime data processing, and public safety challenges, the need for more advanced policing solutions has increased leading to the emergence of smart policing systems and predictive policing techniques. This urgency and shift toward smart policing incorporates artificial intelligence (AI), with a specific focus on machine learning (ML) as an essential tool for data analysis, pattern recognition, and proactive crime forecasting. Among these, the flexibility and power of AI techniques including large language models (LLMs), as a subset of generative AI, have increased the interest in applying them in real-world applications, such as financial, medical, legal, and agricultural applications. However, the abilities and possibilities of adopting LLMs in applications including crime prediction remain unexplored. This paper focuses on bridging this gap by developing a framework based on the transformative potential of BART, GPT-3, and GPT-4, three state-of-the-art LLMs, in the domain of smart policing, specifically, crime prediction. As a prototype, diverse methods such as zero-shot prompting, few-shot prompting, and fine-tuning are used to comprehensively assess the performance of these models in crime prediction based on state-of-the-art datasets from two major cities: San Francisco and Los Angeles. The main objective is to illuminate the adaptability of LLMs and their capacity to revolutionize crime analysis practices. Additionally, a comparative analysis of the aforementioned methods on the GPT series model and BART with ML techniques is provided which shows that the GPT models are more suitable than the traditional ML models for crime classification in most experimental scenarios. © 2024 Elsevier B.V., All rights reserved.","Crime Prediction; Few-shot Prompting; Fine-tuning; Large Language Models; Llm; Zero-shot Prompting; Computational Linguistics; Crime; Data Handling; Job Analysis; Learning Systems; Pattern Recognition; Recurrent Neural Networks; Adaptation Models; Crime Prediction; Few-shot Prompting; Fine Tuning; Language Model; Large Language Model; Predictive Models; Task Analysis; Zero-shot Prompting; Forecasting","Computational linguistics; Crime; Data handling; Job analysis; Learning systems; Pattern recognition; Recurrent neural networks; Adaptation models; Crime prediction; Few-shot prompting; Fine tuning; Language model; Large language model; Predictive models; Task analysis; Zero-shot prompting; Forecasting","","","","Haghshenas, Sami Shaffiee, The Role of Artificial Intelligence in Managing Emergencies and Crises within Smart Cities, (2023); Wang, Hongning, Preventing crimes against public health with artificial intelligence and machine learning capabilities, Socio-Economic Planning Sciences, 80, (2022); Maliphol, Sira, Smart Policing: Ethical Issues & Technology Management of Robocops, (2022); Afzal, Muhammad, Smart Policing: A Critical Review of the Literature, Lecture Notes in Computer Science, 12219 LNCS, pp. 59-70, (2020); Elluri, Lavanya, Developing machine learning based predictive models for smart policing, pp. 198-204, (2019); Baek, Myungsun, Smart Policing Technique with Crime Type and Risk Score Prediction Based on Machine Learning for Early Awareness of Risk Situation, IEEE Access, 9, pp. 131906-131915, (2021); Mu, Xiaoyang, The Platform Construction of the Traffic Management Smart Police Center under the Background of ""internet+, pp. 929-932, (2021); Jayakody, Anuradha J.A., I-Police-An Intelligent Policing System Through Public Area Surveillance, pp. 148-154, (2021); Predictive Policing, (2019); Emory Law Journal, (2012)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85194096093"
"H., Rouzegar, Hamidreza; M., Makrehchi, Masoud","Rouzegar, Hamidreza (58833232800); Makrehchi, Masoud (6506351437)","58833232800; 6506351437","Enhancing Text Classification through LLM-Driven Active Learning and Human Annotation","2024","","","","","98","111","0","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188699932&partnerID=40&md5=33efaf4a28b8aa753600ca545cdfdbdc","Ontario Tech University, Oshawa, Canada","Rouzegar, Hamidreza, Department of Electrical, Ontario Tech University, Oshawa, Canada; Makrehchi, Masoud, Department of Electrical, Ontario Tech University, Oshawa, Canada","In the context of text classification, the financial burden of annotation exercises for creating training data is a critical issue. Active learning techniques, particularly those rooted in uncertainty sampling, offer a cost-effective solution by pinpointing the most instructive samples for manual annotation. Similarly, Large Language Models (LLMs) such as GPT-3.5 provide an alternative for automated annotation but come with concerns regarding their reliability. This study introduces a novel methodology that integrates human annotators and LLMs within an Active Learning framework. We conducted evaluations on three public datasets. IMDB for sentiment analysis, a Fake News dataset for authenticity discernment, and a Movie Genres dataset for multi-label classification. The proposed framework integrates human annotation with the output of LLMs, depending on the model uncertainty levels. This strategy achieves an optimal balance between cost efficiency and classification performance. The empirical results show a substantial decrease in the costs associated with data annotation while either maintaining or improving model accuracy. © 2024 Elsevier B.V., All rights reserved.","Classification (of Information); Computational Linguistics; Cost Effectiveness; Fake Detection; Learning Systems; Uncertainty Analysis; Active Learning; Cost-effective Solutions; Critical Issues; Human Annotations; Language Model; Learning Techniques; Model-driven; Text Classification; Training Data; Uncertainty Samplings; Sentiment Analysis","Classification (of information); Computational linguistics; Cost effectiveness; Fake detection; Learning systems; Uncertainty analysis; Active Learning; Cost-effective solutions; Critical issues; Human annotations; Language model; Learning techniques; Model-driven; Text classification; Training data; Uncertainty samplings; Sentiment analysis","","","","Andersen, Jakob Smedegaard, Towards More Reliable Text Classification on Edge Devices via a Human-in-the-Loop, International Conference on Agents and Artificial Intelligence, 2, pp. 636-646, (2022); Chatgpt Outperforms Crowd Workers for Text Annotation Tasks, (2023); Goudjil, Mohamed, A Novel Active Learning Method Using SVM for Text Classification, International Journal of Automation and Computing, 15, 3, pp. 290-298, (2018); Hachey, Benjamin, Investigating the effects of selective sampling on the annotation task, pp. 144-151, (2005); Haque, Md Rakibul, Performance Analysis of Different Neural Networks for Sentiment Analysis on IMDb Movie Reviews, pp. 161-164, (2019); Is Chatgpt Better than Human Annotators Potential and Limitations of Chatgpt in Explaining Implicit Hate Speech, (2023); Lewis, David D., A sequential algorithm for training text classifiers, pp. 3-12, (1994); Human Still Wins Over Llm an Empirical Study of Active Learning on Domain Specific Annotation Tasks, (2023); On the Limitations of Simulating Active Learning, (2023); Active Learning Principles for in Context Learning with Large Language Models, (2023)","Henning, S.; Stede, M.","Association for Computational Linguistics (ACL)","European Language Association Resources (ELRA)","18th Linguistic Annotation Workshop, LAW 2024","","St. Julian's","198143","","9798891760738","","","English","Conference paper","Final","","Scopus","2-s2.0-85188699932"
"H., Wang, Haiping; X., Zhou, Xin","Wang, Haiping (58045082200); Zhou, Xin (57918566400)","58045082200; 57918566400","Forecasting Chinese Overnight Stock Index Movement Using Large Language Models with Market Summary","2024","Communications in Computer and Information Science","2017 CCIS","","","48","62","0","0","10.1007/978-981-97-0837-6_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187651529&doi=10.1007%2F978-981-97-0837-6_4&partnerID=40&md5=34be8c92a940ac7f7944af01adcbf164","NYU Shanghai, Shanghai, China","Wang, Haiping, Volatility Institute, NYU Shanghai, Shanghai, China; Zhou, Xin, Volatility Institute, NYU Shanghai, Shanghai, China","Forecasting financial market movement constitutes a complex and pivotal research area within the realm of Financial Technology (Fintech). In this work, we investigate the ability of large language models to predict Chinese overnight stock index movement, utilizing market summary gleaned from news media sources. We fine-tune various pre-trained models to compare the performance with that of Generative Pre-training Transformer (GPT) models, specifically GPT-3.5 and GPT-4, as provided by OpenAI. The empirical findings underscore that the fine-tuned pre-trained models, characterized by fewer parameters and more straightforward architectures, surpass the esteemed GPT-3.5 and GPT-4 models in predictive metrics of accuracy and f1. All fine-tuned models are publicly available on the huggingface platform (https://huggingface.co/hw2942). © 2024 Elsevier B.V., All rights reserved.","Bert; Forecasting Overnight Stock Index Movement; Gpt; Large Language Models; Commerce; Computational Linguistics; Financial Markets; Bert; Forecasting Overnight Stock Index Movement; Generative Pre-training Transformer; Language Model; Large Language Model; News Media; Performance; Pre-training; Research Areas; Stock Indices; Forecasting","Commerce; Computational linguistics; Financial markets; BERT; Forecasting overnight stock index movement; Generative pre-training transformer; Language model; Large language model; News media; Performance; Pre-training; Research areas; Stock indices; Forecasting","","","","Longformer the Long Document Transformer, (2020); Revisiting Pre Trained Models for Chinese Natural Language Processing, (2020); Lert A Linguistically Motivated Pre Trained Language Model, (2022); Pert Pre Training Bert with Permuted Language Model, (2022); Gao, Ruize, Forecasting the overnight return direction of stock market index combining global market indices: A multiple-branch deep learning approach, Expert Systems with Applications, 194, (2022); Huang, Allen H., FinBERT: A Large Language Model for Extracting Information from Financial Text*, Contemporary Accounting Research, 40, 2, pp. 806-841, (2023); Proceedings of Naacl Hlt, (2019); Bart Denoising Sequence to Sequence Pre Training for Natural Language Generation Translation and Comprehension, (2019); Li, Wei, Modeling the stock relation with graph network for overnight stock movement prediction, IJCAI International Joint Conference on Artificial Intelligence, 2021-January, pp. 4541-4547, (2020); Roberta A Robustly Optimized Bert Pretraining Approach","Tan, Y.; Shi, Y.","Springer Science and Business Media Deutschland GmbH","","8th International Conference on Data Mining and Big Data, DMBD 2023","","Sanya","308589","18650937; 18650929","9789819671748; 9789819664610; 9783032026743; 9783032008831; 9783032026712; 9789819671779; 9783031949425; 9789819666874; 9783031936968; 9783031941207","","","English","Conference paper","Final","","Scopus","2-s2.0-85187651529"
"S., Xu, Sascha; F.K., Wilhelm-Mauch, Frank K.; W., Maass, Wolfgang","Xu, Sascha (58730186900); Wilhelm-Mauch, Frank K. (57203986439); Maass, Wolfgang (7005129380)","58730186900; 57203986439; 7005129380","Quantum Feature Embeddings for Graph Neural Networks","2024","Proceedings of the Annual Hawaii International Conference on System Sciences","","","","7633","7642","0","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184348532&partnerID=40&md5=b4953617307e2700c462b613d3145d94","German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Forschungszentrum Jülich GmbH, Julich, Germany","Xu, Sascha, German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Wilhelm-Mauch, Frank K., Forschungszentrum Jülich GmbH, Julich, Germany; Maass, Wolfgang, German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany","Quantum computing offers a promising avenue to reduce growing machine learning model complexity as required in large language models and simulation models for weather forecasts, financial forecasts, or engineering. Graph neural networks are a particular class of machine learning models that have garnered much attention for their ability to deal well with structured data. We investigate how to enhance existing GNNs and find through the inductive bias that quantum circuits are used best to encode node features. The proposed Quantum Feature Embeddings (QFEs) turn raw input features into quantum states, enabling non-linear and entangled representations. In particular, QFEs provide normalized, non-redundant weight matrices in an exponentially larger feature space and require much fewer qubits than fully quantum graph neural networks. On standard graph benchmark datasets, we showcase that for the same parameter count QFEs perform better than their classical counterpart, and are able to match the performance of an exponentially larger model. Finally, we study the potential benefit of using a hybrid quantum graph neural network over a classic alternative on a concrete use case, laser cutting. We find that the proposed model has the performance and thus the near-term potential to uplift these business applications. © 2024 Elsevier B.V., All rights reserved.","Gnns; Quantum Machine Learning; Benchmarking; Computational Linguistics; Embeddings; Graph Neural Networks; Quantum Entanglement; Quantum Optics; Qubits; Weather Forecasting; Feature Embedding; Gnn; Machine Learning Models; Machine-learning; Performance; Quantum Features; Quantum Graph; Quantum Machine Learning; Quantum Machines; Machine Learning","Benchmarking; Computational linguistics; Embeddings; Graph neural networks; Quantum entanglement; Quantum optics; Qubits; Weather forecasting; Feature embedding; GNN; Machine learning models; Machine-learning; Performance; Quantum features; Quantum graph; Quantum machine learning; Quantum machines; Machine learning","","","This work is part of the research project QUASIM (grant number: 01MQ22001A, www.quasim-project.de), funded by the German Federal Ministry for Economic Affairs and Climate Action (BMWK).","Sohail Akhtar, Syed Sohail, Laser cutting of rectangular geometry into aluminum alloy: Effect of cut sizes on thermal stress field, Optics and Lasers in Engineering, 61, pp. 57-66, (2014); Relational Inductive Biases Deep Learning and Graph Networks, (2018); Baxter, Jonathan, A Model of Inductive Bias Learning, Journal of Artificial Intelligence Research, 12, (2000); Beer, Kerstin, Training deep quantum neural networks, Nature Communications, 11, 1, (2020); Benedetti, Marcello, Parameterized quantum circuits as machine learning models, Quantum Science and Technology, 4, 4, (2019); Pennylane Automatic Differentiation of Hybrid Quantum Classical Computations, (2018); Bottou, Léon, Large-scale machine learning with stochastic gradient descent, pp. 177-186, (2010); Caro, Matthias C., Generalization in quantum machine learning from few training data, Nature Communications, 13, 1, (2022); Hybrid Quantum Classical Graph Convolutional Network, (2021); Gradients of Parameterized Quantum Gates Using the Parameter Shift Rule and Gate Decomposition, (2019)","Bui, T.X.","IEEE Computer Society","AIS; Learning Health Community (LHC); National Security Agency; Promoting Awareness Victim Empowerment (PAVE); University of Arkansas, Sam M. Walton College of Business Information Systems; University of Hawai'i at Manoa, College of Business","57th Annual Hawaii International Conference on System Sciences, HICSS 2024","","Honolulu; HI; Hilton Hawaiian Village Waikiki Beach Resort","201047","15301605","9780769530758; 0818673249; 0769514359; 0818632305; 9780998133119; 0769530753; 0769525075; 9780998133140; 9780998133126; 9780769525075","","","English","Conference paper","Final","","Scopus","2-s2.0-85184348532"
"B., Cao, Bochun","Cao, Bochun (58867509400)","58867509400","Improving Strategies for Educational Imbalance Based on Large Language Model","2024","Proceedings of SPIE - The International Society for Optical Engineering","12983","","1298321","","","0","1","10.1117/12.3017920","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184283057&doi=10.1117%2F12.3017920&partnerID=40&md5=b2d9dce4f04afca92dc4fd138ee87760","Yali High School, Changsha, China","Cao, Bochun, Yali High School, Changsha, China","It can be observed on a global scale that the quality of education between different regions (such as between urban and rural areas) is usually affected by the local economic structure and development stage. For example, many well-known metropolises have high education levels and famous colleges and universities, and the proportion of students admitted to prestigious universities is also high. Rural areas often lack famous schools and corresponding resources, resulting in lower overall student performance and a lower proportion of students admitted to prestigious universities. This article uses statistical methods to study this issue. Further use data including infrastructure investment, hiring more high-quality teachers, providing more diverse and inclusive courses, providing more learning materials and resources, and using a variety of machine learning and deep learning and large language model techniques to predict the growth of educational resources in underdeveloped areas. Evaluation of these predictive models reveals the strength of large language models in predicting the growth of educational resources in underdeveloped regions. The findings provide strategic insights for education policy makers and stakeholders to close pervasive education disparities. © 2024 Elsevier B.V., All rights reserved.","Deep Learning; Education Policy; Large Language Model; Machine Learning; Quality Of Education In Different Cities; Computational Linguistics; Deep Learning; Economics; Education Computing; Investments; Learning Systems; Rural Areas; Education Policies; Educational Resource; Global Scale; Language Model; Large Language Model; Machine-learning; Quality Of Education; Quality Of Education In Different City; Urban And Rural Areas; Students","Computational linguistics; Deep learning; Economics; Education computing; Investments; Learning systems; Rural areas; Education policies; Educational resource; Global scale; Language model; Large language model; Machine-learning; Quality of education; Quality of education in different city; Urban and rural areas; Students","","","","2016 6th International Conference on Management Education Information and Control Meici 2016, (2016); Boeren, Ellen, Understanding Sustainable Development Goal (SDG) 4 on “quality education” from micro, meso and macro perspectives, International Review of Education, 65, 2, pp. 277-294, (2019); Woronov, Terry E., Raising quality, fostering ""creativity"": Ideologies and practices of education reform in Beijing, Anthropology and Education Quarterly, 39, 4, pp. 401-422, (2008); 2016 International Conference on Advances in Management Arts and Humanities Science Amahs 2016, (2016); Chinese Education Society, (1997); Bishop, Russell, Te Kotahitanga: Addressing educational disparities facing Māori students in New Zealand, Teaching and Teacher Education, 25, 5, pp. 734-742, (2009); Daniele, Vittorio, Socioeconomic inequality and regional disparities in educational achievement: The role of relative poverty, Intelligence, 84, (2021); Ma, Yuna, Educational inequality and achievement disparity: An empirical study of migrant children in China, Children and Youth Services Review, 87, pp. 145-153, (2018); Mukhopadhaya, Pundarik, Trends in income disparity and equality enhancing (?) education policies in the development stages of Singapore, International Journal of Educational Development, 23, 1, pp. 37-56, (2003); Kasneci, Enkelejda, ChatGPT for good? On opportunities and challenges of large language models for education, Learning and Individual Differences, 103, (2023)","Limongi, T.; Lin, H.","SPIE","American Society for Science and Technology","2nd International Conference on Electrical, Electronics, and Information Engineering, EEIE 2023","","Wuhan","196461","0277786X; 1996756X","9781510692657; 9781510690561; 9781510693302; 9781510692251; 9781510692275; 9781510693081; 9781510688728; 9781510688629; 9781510692671; 9781510693326","PSISD","","English","Conference paper","Final","","Scopus","2-s2.0-85184283057"
"","","","IFIP WG 8.6 International Working Conference on Transfer and Diffusion of IT, TDIT 2023","2024","IFIP Advances in Information and Communication Technology","699 AICT","","","","","1342","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180631189&partnerID=40&md5=5df14da1d0658757964e23a5c3182006","","","The proceedings contain 112 papers. The special focus in this conference is on Transfer and Diffusion of IT. The topics include: Assessing the Factors Influencing the Adoption of Generative Artificial Intelligence (GenAI) in the Manufacturing Sector; sentence Generator for Hindi Language Using Formal Semantics; human Resource Analytics: Leveraging Machine Learning for Employee Attrition Prediction; Continuance Intention of ChatGPT Use by Students; amazon Alexa and I: Exploring Factors Affecting Usage Behaviours and Patterns Over Time; analysing Platform Design Consideration to Ensure Digital Inclusion Among Indigenous People; understanding the Usage and Opinion Formation on LinkedIn: Uses and Gratifications Theory; blockchain-Based Application Security Versus Centralized and Distributed Data Management Systems – A Comparative Study; struggle for Visibility: Mobilizing Dormant Logic on Social Media Platforms; The European Union’s Artificial Intelligence Act: An Analysis of Preliminary Perceptions and Responses of Irish SMEs; does Women Mobile Technology Inclusion Shape Their Attitude Towards Intimate Partner Violence? An Empirical Evidence from Sub-Saharan African Communities; blockchain: A Structural Topic Modelling Approach; portfolio Selection Using Network Filtering Methods: A Graph Theoretic Approach; exploring the Fusion of Metaverse and Sports: Current Trends and Future Directions; Understanding the Role of Time in Content Selection Decisions on OTT Platforms; how Successful Online Platforms Create Value?; institutional Voids and Digital Ecosystems of India’s Public Sector; how Social Media Marketing Enhances Brand Communities Engagement: Developing an Integrated Model Using S-O-R Paradigm; e-Government and Well-Being: A Cross-Country Study; information Security Awareness Safety Governance Model for Senior Citizens in Indian Banking Sector for Mobile and Internet Banking. © 2023 Elsevier B.V., All rights reserved.","","","","","","","Sharma, S.K.; Metri, B.; Dwivedi, Y.K.; Lal, B.; Elbanna, A.","Springer Science and Business Media Deutschland GmbH","","IFIP WG 8.6 International Working Conference on Transfer and Diffusion of IT, TDIT 2023","","Nagpur","305469","1868422X; 18684238","9783032007766; 9783031962301; 9783031949234; 9783031971143; 9783031962387; 9783031965210; 9780387291215; 9783319900223; 9783319162737; 1402080697","","","English","Conference review","Final","","Scopus","2-s2.0-85180631189"
"","","","IFIP WG 8.6 International Working Conference on Transfer and Diffusion of IT, TDIT 2023","2024","IFIP Advances in Information and Communication Technology","698 AICT","","","","","1342","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180626542&partnerID=40&md5=23fcdf4413945c707c5ca42c4ff2f13d","","","The proceedings contain 112 papers. The special focus in this conference is on Transfer and Diffusion of IT. The topics include: Assessing the Factors Influencing the Adoption of Generative Artificial Intelligence (GenAI) in the Manufacturing Sector; sentence Generator for Hindi Language Using Formal Semantics; human Resource Analytics: Leveraging Machine Learning for Employee Attrition Prediction; Continuance Intention of ChatGPT Use by Students; amazon Alexa and I: Exploring Factors Affecting Usage Behaviours and Patterns Over Time; analysing Platform Design Consideration to Ensure Digital Inclusion Among Indigenous People; understanding the Usage and Opinion Formation on LinkedIn: Uses and Gratifications Theory; blockchain-Based Application Security Versus Centralized and Distributed Data Management Systems – A Comparative Study; struggle for Visibility: Mobilizing Dormant Logic on Social Media Platforms; The European Union’s Artificial Intelligence Act: An Analysis of Preliminary Perceptions and Responses of Irish SMEs; does Women Mobile Technology Inclusion Shape Their Attitude Towards Intimate Partner Violence? An Empirical Evidence from Sub-Saharan African Communities; blockchain: A Structural Topic Modelling Approach; portfolio Selection Using Network Filtering Methods: A Graph Theoretic Approach; exploring the Fusion of Metaverse and Sports: Current Trends and Future Directions; Understanding the Role of Time in Content Selection Decisions on OTT Platforms; how Successful Online Platforms Create Value?; institutional Voids and Digital Ecosystems of India’s Public Sector; how Social Media Marketing Enhances Brand Communities Engagement: Developing an Integrated Model Using S-O-R Paradigm; e-Government and Well-Being: A Cross-Country Study; information Security Awareness Safety Governance Model for Senior Citizens in Indian Banking Sector for Mobile and Internet Banking. © 2023 Elsevier B.V., All rights reserved.","","","","","","","Sharma, S.K.; Metri, B.; Dwivedi, Y.K.; Lal, B.; Elbanna, A.","Springer Science and Business Media Deutschland GmbH","","IFIP WG 8.6 International Working Conference on Transfer and Diffusion of IT, TDIT 2023","","Nagpur","305469","1868422X; 18684238","9783032007766; 9783031962301; 9783031949234; 9783031971143; 9783031962387; 9783031965210; 9780387291215; 9783319900223; 9783319162737; 1402080697","","","English","Conference review","Final","","Scopus","2-s2.0-85180626542"
"","","","IFIP WG 8.6 International Working Conference on Transfer and Diffusion of IT, TDIT 2023","2024","IFIP Advances in Information and Communication Technology","697 AICT","","","","","1342","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180625398&partnerID=40&md5=e7e70dcfb23afdf34ce139281ec8e4ed","","","The proceedings contain 112 papers. The special focus in this conference is on Transfer and Diffusion of IT. The topics include: Assessing the Factors Influencing the Adoption of Generative Artificial Intelligence (GenAI) in the Manufacturing Sector; sentence Generator for Hindi Language Using Formal Semantics; human Resource Analytics: Leveraging Machine Learning for Employee Attrition Prediction; Continuance Intention of ChatGPT Use by Students; amazon Alexa and I: Exploring Factors Affecting Usage Behaviours and Patterns Over Time; analysing Platform Design Consideration to Ensure Digital Inclusion Among Indigenous People; understanding the Usage and Opinion Formation on LinkedIn: Uses and Gratifications Theory; blockchain-Based Application Security Versus Centralized and Distributed Data Management Systems – A Comparative Study; struggle for Visibility: Mobilizing Dormant Logic on Social Media Platforms; The European Union’s Artificial Intelligence Act: An Analysis of Preliminary Perceptions and Responses of Irish SMEs; does Women Mobile Technology Inclusion Shape Their Attitude Towards Intimate Partner Violence? An Empirical Evidence from Sub-Saharan African Communities; blockchain: A Structural Topic Modelling Approach; portfolio Selection Using Network Filtering Methods: A Graph Theoretic Approach; exploring the Fusion of Metaverse and Sports: Current Trends and Future Directions; Understanding the Role of Time in Content Selection Decisions on OTT Platforms; how Successful Online Platforms Create Value?; institutional Voids and Digital Ecosystems of India’s Public Sector; how Social Media Marketing Enhances Brand Communities Engagement: Developing an Integrated Model Using S-O-R Paradigm; e-Government and Well-Being: A Cross-Country Study; information Security Awareness Safety Governance Model for Senior Citizens in Indian Banking Sector for Mobile and Internet Banking. © 2023 Elsevier B.V., All rights reserved.","","","","","","","Sharma, S.K.; Metri, B.; Dwivedi, Y.K.; Lal, B.; Elbanna, A.","Springer Science and Business Media Deutschland GmbH","","IFIP WG 8.6 International Working Conference on Transfer and Diffusion of IT, TDIT 2023","","Nagpur","305469","1868422X; 18684238","9783032007766; 9783031962301; 9783031949234; 9783031971143; 9783031962387; 9783031965210; 9780387291215; 9783319900223; 9783319162737; 1402080697","","","English","Conference review","Final","","Scopus","2-s2.0-85180625398"
"F., Hadzic, Fedja; M., Krayneva, Maya","Hadzic, Fedja (14034146500); Krayneva, Maya (58745128600)","14034146500; 58745128600","Lateral AI: Simulating Diversity in Virtual Communities","2024","Lecture Notes in Computer Science","14472 LNAI","","","41","53","0","1","10.1007/978-981-99-8391-9_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178591574&doi=10.1007%2F978-981-99-8391-9_4&partnerID=40&md5=2f0b7832e65168c270d0cf8c6e482f4c","September AI Labs, Perth, Australia; Sheridan Institute of Higher Education, Perth, Australia","Hadzic, Fedja, September AI Labs, Perth, Australia; Krayneva, Maya, Sheridan Institute of Higher Education, Perth, Australia","In this paper, we present Lateral AI that offers a diverse and multi-dimensional world experience. It makes use of semi-automated prompt engineering on top of GPT3.5. The coupling with named entity recognition and text summarization enables creation of a diversity of AI personas and a multiplicity of requests. The features of Lateral AI, such as creation of custom AI personas, prioritisation of user-embedded knowledge in those personas and follow-up requests, enable users to co-create with AI. Users can contribute certain information and perspectives to the application if a Large Language Model does not have access to it. Lateral AI makes the user an active component of the integrated system rather than a mere AI consumer. We demonstrate use of Lateral AI to generate a range of diverse responses and illustrate the ability of AI to predict beyond its factual knowledge. Lateral AI is a unique and alternative option to other AI models, contributing to the diverse and creative pool of emerging AI technologies and applications. The principles behind Lateral AI can be used to simulate diverse communities in a variety of settings such as online virtual communities and human robotics. © 2023 Elsevier B.V., All rights reserved.","Knowledge Prioritization In Llms; Lateral Ai; Lateral Thinking; Llm Predictions; Virtual Communities; Character Recognition; Social Networking (online); Knowledge Prioritization In Llm; Lateral Ai; Lateral Thinking; Llm Prediction; Multi Dimensional; Named Entity Recognition; Prioritization; Text Summarisation; Virtual Community; World Experience; Virtual Reality","Character recognition; Social networking (online); Knowledge prioritization in LLM; Lateral AI; Lateral thinking; LLM prediction; Multi dimensional; Named entity recognition; Prioritization; Text Summarisation; Virtual community; World experience; Virtual reality","","","","Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019); Language Models are Unsupervised Multitask Learners, (2019); Corr, (2020); Corr, (2022); Training Compute Optimal Large Language Models, (2022); Palm Scaling Language Modeling with Pathways Arxiv Preprint Arxiv, (2022); Arxiv, (2022); Opt Open Pre Trained Transformer Language Models, (2022); Llama Open and Efficient Foundation Language Models Arxiv Preprint Arxiv, (2023); undefined","Liu, T.; Webb, G.; Yue, L.; Wang, D.","Springer Science and Business Media Deutschland GmbH","","36th Australasian Joint Conference on Artificial Intelligence, AJCAI 2023","","Brisbane; QLD","304859","16113349; 03029743","9789819698936; 9789819698042; 9789819698110; 9789819698905; 9789819512324; 9783032026019; 9783032008909; 9783031915802; 9789819698141; 9783031984136","","","English","Conference paper","Final","","Scopus","2-s2.0-85178591574"
"X., Li, Xiaoyang; H., Feng, Haoming; H., Yang, Hailong; J., Huang, Jiyuan","Li, Xiaoyang (57205354545); Feng, Haoming (58361455000); Yang, Hailong (58131483200); Huang, Jiyuan (58408964500)","57205354545; 58361455000; 58131483200; 58408964500","Can ChatGPT reduce human financial analysts’ optimistic biases?","2024","Economic and Political Studies","12","1","","20","33","0","14","10.1080/20954816.2023.2276965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177589202&doi=10.1080%2F20954816.2023.2276965&partnerID=40&md5=e282669e8ce0d6ef3280d5a77b94a204","The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Renmin University of China, Beijing, China; Universität Zürich, Zurich, Switzerland; Swiss Finance Institute, Zurich, Switzerland","Li, Xiaoyang, School of Accounting and Finance, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Feng, Haoming, School of Finance, Renmin University of China, Beijing, China; Yang, Hailong, School of Finance, Renmin University of China, Beijing, China; Huang, Jiyuan, Department of Banking and Finance, Universität Zürich, Zurich, Switzerland, Swiss Finance Institute, Zurich, Switzerland","This paper examines the potential of ChatGPT, a large language model, as a financial advisor for listed firm performance forecasts. We focus on the constituent stocks of the China Securities Index 300 and compare ChatGPT’s forecasts for major financial performance measures with human analysts’ forecasts and the realised values. Our findings suggest that ChatGPT can correct the optimistic biases of human analysts. This study contributes to the literature by exploring the potential of ChatGPT as a financial advisor and demonstrating its role in reducing human biases in financial decision-making. © 2024 Elsevier B.V., All rights reserved.","Analyst Forecast; Chatgpt; Human–machine Interaction; Large Language Models; Optimistic Biases","","","","Haoming Feng thanks the National Social Science Foundation of China for financial support [Grant No. 20ZDA053]. Xiaoyang Li thanks the National Natural Science Foundation of China for financial support [Grant No. 72303197]. Jiyuan Huang thanks the Swiss National Science Foundation (SNSF) for financial support through the project \u2018Trading and Financing during Market Stress\u2019 [Grant No. 100018_172679].","Abarbanell, Jeffery S., Do analysts' earnings forecasts incorporate information in prior stock price changes?, Journal of Accounting and Economics, 14, 2, pp. 147-165, (1991); Ackert, Lucy F., A simultaneous equations analysis of analysts' forecast bias, analyst following, and institutional ownership, Journal of Business Finance and Accounting, 30, 7-8, pp. 1017-1042, (2003); undefined, (2020); Accounting Review, (1992); Exploring the Role of Artificial Intelligence in Enhancing Academic Performance A Case Study of Chatgpt, (2022); Amir, Eli, Do financial analysts get intangibles?, European Accounting Review, 12, 4, pp. 635-659, (2003); Aubry, Mathieu, Biased Auctioneers, Journal of Finance, 78, 2, pp. 795-833, (2023); Bolliger, Guido, The characteristics of individual analysts' forecasts in Europe, Journal of Banking and Finance, 28, 9, pp. 2283-2309, (2004); Boyaci, Tamer, Human and Machine: The Impact of Machine Input on Decision Making Under Cognitive Limitations, Management Science, 70, 2, pp. 1258-1275, (2024); Cao, Sean Shun, How to Talk When a Machine Is Listening: Corporate Disclosure in the Age of AI, Review of Financial Studies, 36, 9, pp. 3603-3642, (2023)","","Routledge","","","","","","20954816; 24704024","","","","English","Article","Final","All Open Access; Green Accepted Open Access; Green Final Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85177589202"
"C., Zhang, Chenxi; Y., Yang, Yi; J., Qiu, Jing; J., Ruan, Jiaqi; G., Liang, Gaoqi; L., Yang, Lixin","Zhang, Chenxi (57209499852); Yang, Yi (57213786370); Qiu, Jing (55846308000); Ruan, Jiaqi (57200604635); Liang, Gaoqi (57189219788); Yang, Lixin (59936493400)","57209499852; 57213786370; 55846308000; 57200604635; 57189219788; 59936493400","Comprehensive Approaches to a Low-Carbon Transition of the Power Grid","2024","","","","","4027","4032","0","0","10.1109/EI264398.2024.10990385","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007624913&doi=10.1109%2FEI264398.2024.10990385&partnerID=40&md5=a6aa1555aa44d086ff1619355f9f2424","The University of Sydney, Sydney, Australia; The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Harbin Institute of Technology, Harbin, China; Ltd., Sanming, China","Zhang, Chenxi, School of Electrical and Computer Engineering, The University of Sydney, Sydney, Australia; Yang, Yi, School of Electrical and Computer Engineering, The University of Sydney, Sydney, Australia; Qiu, Jing, School of Electrical and Computer Engineering, The University of Sydney, Sydney, Australia; Ruan, Jiaqi, Department of Electrical and Electronic Engineering, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Liang, Gaoqi, School of Mechanical Engineering and Automation, Harbin Institute of Technology, Harbin, China; Yang, Lixin, Ltd., Sanming, China","As the largest source of carbon emissions, the power grid has garnered significant attention for its decarbonization from academia, government, and industry. This transition is complex due to the involvement of various stakeholders, including power generation, transmission networks, and active customers. The purpose of this paper is to present a framework aimed at facilitating the low-carbon transition, focusing on emission reduction strategies across four components of the power system. On the generation side, retiring coal-fired generators and deploying renewable energy sources coupled with energy storage systems can significantly lower overall system emissions. Correspondingly, on the consumer side, the electrification of transportation offers a viable alternative to internal combustion engine vehicles, thereby reducing societal emissions. Furthermore, in terms of system control, planning methodologies such as gas-electric coupling optimization can expedite emission reduction efforts. For market design, effective policies like carbon taxes and carbon emission allowance trading incentivize power companies to actively lower emissions. Besides the above, advanced AI-based prediction methods, such as generative adversarial networks (GANs) and large language models (LLMs), enhance the accuracy of forecasting uncertainty including electricity prices and loads, improving the efficiency of transition. These evolving policies and grid technologies will enable us to decarbonize the grid and better mitigate the impacts of climate change driven by electricity consumption. © 2025 Elsevier B.V., All rights reserved.","Decarbonization; Gas-electric Coupling Optimization; Generative Adversarial Networks (gans); Large Language Models (llms); Transportation Electrification; Electric Power Plant Loads; Electric Vehicles; Electrification; Emission Control; Global Warming; Smart Power Grids; Solar Fuels; Adversarial Networks; Coupling Optimization; Decarbonisation; Electric Coupling; Gas-electric Coupling Optimization; Generative Adversarial Network; Language Model; Large Language Model; Low-carbon Transitions; Transportation Electrifications; Electric Power Transmission Networks","Electric power plant loads; Electric vehicles; Electrification; Emission control; Global warming; Smart power grids; Solar fuels; Adversarial networks; Coupling optimization; Decarbonisation; Electric coupling; Gas-electric coupling optimization; Generative adversarial network; Language model; Large language model; Low-carbon transitions; Transportation electrifications; Electric power transmission networks","","","","State and Trends of Carbon Pricing 2021, (2021); Carbon Neutrality by 2050 the World S Most Urgent Mission United Nations Secretary General, (2022); How Much of U S Carbon Dioxide Emissions are Associated with Electricity Generation, (2022); O'Malley, Mark J., Multicarrier Energy Systems: Shaping Our Energy Future, Proceedings of the IEEE, 108, 9, pp. 1437-1456, (2020); Farhoumandi, Matin, Generation Expansion Planning Considering the Rehabilitation of Aging Generating Units, IEEE Transactions on Smart Grid, 11, 4, pp. 3384-3393, (2020); Tao, Yuechuan, Carbon-Oriented Electricity Network Planning and Transformation, IEEE Transactions on Power Systems, 36, 2, pp. 1034-1048, (2021); Shen, Wei, Low-Carbon Electricity Network Transition Considering Retirement of Aging Coal Generators, IEEE Transactions on Power Systems, 35, 6, pp. 4193-4205, (2020); Yang, Yi, Integrated grid, coal-fired power generation retirement and GESS planning towards a low-carbon economy, International Journal of Electrical Power and Energy Systems, 124, (2021); Chen, Yize, Model-Free Renewable Scenario Generation Using Generative Adversarial Networks, IEEE Transactions on Power Systems, 33, 3, pp. 3265-3275, (2018); Zhang, Chenxi, Trading-oriented battery energy storage planning for distribution market, International Journal of Electrical Power and Energy Systems, 129, (2021)","","Institute of Electrical and Electronics Engineers Inc.","","8th IEEE Conference on Energy Internet and Energy System Integration, EI2 2024","","Shenyang","208917","","9798331523527","","","English","Conference paper","Final","","Scopus","2-s2.0-105007624913"
"Z., Guo, Zikun; W., Guo, Wei; Q., Li, Qixian; Y., Zou, Yuchang; J., Cai, Jingyao","Guo, Zikun (59172473100); Guo, Wei (59279900700); Li, Qixian (59810202600); Zou, Yuchang (59809082400); Cai, Jingyao (59809082500)","59172473100; 59279900700; 59810202600; 59809082400; 59809082500","FN-Agents: Analysis of Exchange Rate Volatility Prediction Based on Multi-Agent Systems","2024","","","","","350","355","0","0","10.1109/CAIT64506.2024.10963060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004642669&doi=10.1109%2FCAIT64506.2024.10963060&partnerID=40&md5=69b5885e0871b2e0c5120e80f2d932a8","Guangdong University of Finance, Guangzhou, China; Guangdong University of Finance, Guangzhou, China","Guo, Zikun, School of National Finance, Guangdong University of Finance, Guangzhou, China; Guo, Wei, School of Credit Management, Guangdong University of Finance, Guangzhou, China; Li, Qixian, School of National Finance, Guangdong University of Finance, Guangzhou, China; Zou, Yuchang, School of National Finance, Guangdong University of Finance, Guangzhou, China; Cai, Jingyao, School of Credit Management, Guangdong University of Finance, Guangzhou, China","Exchange rate prediction is challenging. While large language models (LLMs) offer new approaches, their lack of domain-specific fine-tuning hinders effective assessment of factors influencing exchange rates. To address this, we propose FN-Agents - a framework integrating technologies such as vector databases, Retrieval-Augmented Generation(RAG), and self-reflection - to enable LLMs to better utilize external resources for exchange rate tasks. FN-Agents assists LLMs in acquiring expert knowledge, learning through self-reflection, building fine-tuned datasets, and ultimately generating interpretable core feature sets autonomously. Experiments demonstrate that FN-Agents excels in feature selection and enhances the predictive accuracy of mainstream models. © 2025 Elsevier B.V., All rights reserved.","Agents; Exchange Rate Forecasting; Experiential Learning; Privatized Knowledge; Exchange Rate Forecasting; Exchange Rate Volatilities; Exchange Rates; Exchange Rates Prediction; Experiential Learning; Language Model; Multiagent Systems (mass); Prediction-based; Privatized Knowledge; Self Reflection","Exchange rate forecasting; Exchange rate volatilities; Exchange rates; Exchange rates prediction; Experiential learning; Language model; Multiagent systems (MASs); Prediction-based; Privatized knowledge; Self reflection","","","This work was supported by the Educational Commission Key Program of GuangDong Province of China under Grants 2024ZDZX1036.","View in Article, (2023); Chowdhery, Aakanksha, PaLM: Scaling Language Modeling with Pathways, Journal of Machine Learning Research, 24, (2023); Open and Efficient Foundation Language Models, (2023); Liu, Pengfei, Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing, ACM Computing Surveys, 55, 9, (2023); Chen, Jiawei, Benchmarking Large Language Models in Retrieval-Augmented Generation, Proceedings of the AAAI Conference on Artificial Intelligence, 38, 16, pp. 17754-17762, (2024); Finverse an Autonomous Agent System for Versatile Financial Analysis, (2024); Finagent A Multimodal Foundation Agent for Financial Trading Tool Augmented Diversified and Generalist, (2024); Yu, Yangyang, FINMEM: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design, 3, 1, pp. 595-597, (2024); React Synergizing Reasoning and Acting in Language Models, (2024); Proximal Policy Optimization Algorithms, (2017)","","Institute of Electrical and Electronics Engineers Inc.","IEEE; Zhejiang A and F University","5th International Conference on Computers and Artificial Intelligence Technology, CAIT 2024","","Hangzhou","208372","","9798331530891","","","English","Conference paper","Final","","Scopus","2-s2.0-105004642669"
"M.E., Ahmed, Mohamed Erfan; G.A., Ebrahim, Gamal A.; M.A., Abdelaal, Marwa A.","Ahmed, Mohamed Erfan (59730115100); Ebrahim, Gamal A. (8564437600); Abdelaal, Marwa A. (57193403994)","59730115100; 8564437600; 57193403994","Enhancing Stock Price Prediction: A Hybrid Approach Leveraging Large Language Models and Deep Learning","2024","","","","","","","0","0","10.1109/ICCA62237.2024.10927923","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002256773&doi=10.1109%2FICCA62237.2024.10927923&partnerID=40&md5=1ce9521e206b8c3b370915d9ab3395a8","Faculty of Engineering Ain Shams University, Cairo, Egypt; Faculty of Computers and Information, Cairo, Egypt","Ahmed, Mohamed Erfan, Faculty of Engineering Ain Shams University, Cairo, Egypt; Ebrahim, Gamal A., Faculty of Engineering Ain Shams University, Cairo, Egypt; Abdelaal, Marwa A., Department of Computer Science, Faculty of Computers and Information, Cairo, Egypt","Accurate stock price prediction is a challenging yet crucial goal in finance, with significant implications for investment decisions and risk management. This paper presents a comprehensive review of machine learning techniques for stock price prediction, examining traditional methods such as regression and ensemble models, as well as advanced approaches that integrate sentiment analysis and textual data sources. With the emergence of powerful Large Language Models (LLMs) such as ChatGPT, Llama and Gemini, we explore their potential for enhancing predictive accuracy using historical stock data. Key challenges are discussed, including data quality, model interpretability, and adapting to dynamic market conditions. Additionally, this paper proposes a trustworthy stock price prediction model based on LLMs enabling informed investment decision-making. Experimental results demonstrate that ChatGPT-4o model achieved a prediction accuracy of approximately 97%, which can be improved by tuning model parameters. Consequently, the paper highlights the potential of LLMs in improving stock price forecasting. © 2025 Elsevier B.V., All rights reserved.","Large Language Models (llms); Machine Learning; Stock Price Prediction; Adversarial Machine Learning; Decision Management; Hybrid Approach; Investment Decisions; Investment Risks; Language Model; Large Language Model; Machine Learning Techniques; Machine-learning; Risks Management; Stock Price Prediction; Prediction Models","Adversarial machine learning; Decision management; Hybrid approach; Investment decisions; Investment risks; Language model; Large language model; Machine learning techniques; Machine-learning; Risks management; Stock price prediction; Prediction models","","","","Sharma, Ashish, Survey of stock market prediction using machine learning approach, 2017-January, pp. 506-509, (2017); Rakhra, Manik, Face Recognition with Smart Security System, (2022); Tiwari, Vidushi, Stock Market Prediction using different Machine Learning Algorithms, pp. 147-151, (2023); Singh, Gurinder, Artificial Intelligence led Industry 4.0 Application for Sustainable Development, pp. 339-343, (2022); Malik, Varun, EPR-ML: E-Commerce Product Recommendation Using NLP and Machine Learning Algorithm, pp. 1778-1783, (2022); Shukla, Ritesh Kumar, Prediction of Stock Price Market Using News Sentiments By Machine Learning, pp. 6-10, (2023); Rakhra, Manik, An Analysis of the Impact of Business Analytics on Progress, (2022); Fattah, Doaa A., AutoKeras and particle swarm optimization to predict the price trend of stock exchange, Bulletin of Electrical Engineering and Informatics, 11, 2, pp. 1100-1109, (2022); Schmidhuber, Jürgen U., Deep Learning in neural networks: An overview, Neural Networks, 61, pp. 85-117, (2015); Mary Auxilia, P. A., The Dynamic Role of Big Data Analytics in Learning and Development and Its Impact on Risk Analysis in Stock Market, Smart Innovation, Systems and Technologies, 290, pp. 157-164, (2023)","","Institute of Electrical and Electronics Engineers Inc.","","2024 International Conference on Computer and Applications, ICCA 2024","","Cairo","207834","","9798350367560","","","English","Conference paper","Final","","Scopus","2-s2.0-105002256773"
"K., Peng, Kexin; H., Iima, Hitoshi","Peng, Kexin (59459380400); Iima, Hitoshi (6602606103)","59459380400; 6602606103","Foreign Exchange Rate Forecast by a Large Language Model Integrated with Trend Description","2024","Proceedings of the International Conference on Soft Computing and Machine Intelligence, ISCMI","","2024","","173","176","0","0","10.1109/ISCMI63661.2024.10851549","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001571804&doi=10.1109%2FISCMI63661.2024.10851549&partnerID=40&md5=856d42e1fc81d6fc4291b4dded92ede1","Kyoto Institute of Technology, Kyoto, Japan; Kyoto Institute of Technology, Kyoto, Japan","Peng, Kexin, Kyoto Institute of Technology, Kyoto, Japan; Iima, Hitoshi, Kyoto Institute of Technology, Kyoto, Japan","In this paper, we propose a large language model to forecast the direction of change in a foreign exchange rate. The input of the proposed model is textual information as a prompt, whereas that of conventional forecast models is numerical information. A recent trend in the exchange rate is added to input textual information to enhance forecast accuracy. GPT-2 is adopted as our large language model and is fine-tuned using training data. The effectiveness of the proposed model is empirically examined using actual data. © 2025 Elsevier B.V., All rights reserved.","Deep Learning; Finance; Large Language Model; Machine Learning; Time Series; Adversarial Machine Learning; Contrastive Learning; Deep Learning; Forecast Models; Foreign Exchange Rates; Language Model; Large Language Model; Machine-learning; Numerical Information; Recent Trends; Textual Information; Times Series; Prediction Models","Adversarial machine learning; Contrastive Learning; Deep learning; Forecast models; Foreign exchange rates; Language model; Large language model; Machine-learning; Numerical information; Recent trends; Textual information; Times series; Prediction models","","","This work was partly supported by JSPS KAKENHI JP23K11263.","Ayitey Junior, Michael, Forex market forecasting using machine learning: Systematic Literature Review and meta-analysis, Journal of Big Data, 10, 1, (2023); Hochreiter, Sepp, Long Short-Term Memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Cho, Kyunghyun, Learning phrase representations using RNN encoder-decoder for statistical machine translation, pp. 1724-1734, (2014); Recurrent Neural Networks and Long Short Term Memory Networks Tutorial and Survey, (2023); Ito, Katsuki, LSTM forecasting foreign exchange rates using limit order book, Finance Research Letters, 47, (2022); Krichen, Moez, Convolutional Neural Networks: A Survey, Computers, 12, 8, (2023); Zhao, Bendong, Convolutional neural networks for time series classification, Journal of Systems Engineering and Electronics, 28, 1, pp. 162-169, (2017); A Survey of Large Language Models, (2023); Xue, Hao, PromptCast: A New Prompt-Based Learning Paradigm for Time Series Forecasting, IEEE Transactions on Knowledge and Data Engineering, 36, 11, pp. 6851-6864, (2024); Peng, Kexin, Prediction of Foreign Exchange Rates by a Large Language Model, pp. 1062-1066, (2024)","","Institute of Electrical and Electronics Engineers Inc.","","11th International Conference on Soft Computing and Machine Intelligence, ISCMI 2024","","Melbourne; VIC","206431","26400154; 26400146","","","","English","Conference paper","Final","","Scopus","2-s2.0-105001571804"
"J., Fang, Jingxing; Z., Xiao, Zhaomin; Y., Wu, Yingyi; J., Zhang, Jinran; Z., Xu, Zhuoer; Z., Mai, Zhelu","Fang, Jingxing (59718213100); Xiao, Zhaomin (58506245500); Wu, Yingyi (59718431000); Zhang, Jinran (57554420800); Xu, Zhuoer (58951485600); Mai, Zhelu (58951156300)","59718213100; 58506245500; 59718431000; 57554420800; 58951485600; 58951156300","A Comparative Study of Sequential Deep Learning Models in Financial Time Series Forecasting","2024","Proceedings of the International Conference on Soft Computing and Machine Intelligence, ISCMI","","2024","","22","26","0","1","10.1109/ISCMI63661.2024.10851487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001566756&doi=10.1109%2FISCMI63661.2024.10851487&partnerID=40&md5=01b3354bb386d4b067780ca4842621ba","I-66 Express Mobility Partners, Manassas, United States; University of North Texas, Denton, United States; Meta, Meta, United States; Taylor University, Upland, United States; Hewlett Packard Enterprise, Palo Alto, United States","Fang, Jingxing, ; Xiao, Zhaomin, University of North Texas, Denton, United States; Wu, Yingyi, Meta, Meta, United States; Zhang, Jinran, Taylor University, Upland, United States; Xu, Zhuoer, Hewlett Packard Enterprise, Palo Alto, United States; Mai, Zhelu, I-66 Express Mobility Partners, Manassas, United States","Time series analysis of daily stock prices is challenging due to the inherent complexity, nonlinearity, and nonstationarity of financial data. In this paper, we compare three sequential deep learning models - LSTM, Transformer, and Large Language Models (LLMs) - for stock price prediction. By transforming the regression problem of predicting daily log returns into a classification task, we evaluate the models' classification accuracies, with the Transformer achieving the highest accuracy of 22%, followed by LSTM (15.6%) and LLM (15.3%). Regression metrics showed LSTM initially performing better, with a lower RMSE (180.92) than LLM (1739.61). However, outlier predictions in the LLM, caused by incomplete number outputs, inflated its error. After removing these outliers, LLM's RMSE improved significantly to 33.85, surpassing LSTM. These results demonstrate the potential of Transformer and LLM models for financial time series prediction. Future work will explore incorporating self-reflection mechanisms in LLM predictions and extending the comparison to multivariate financial time series incorporating textual data and other features. © 2025 Elsevier B.V., All rights reserved.","Deep Learning; Finance; Large Language Model; Survey; Time Series Forecasting; Decentralized Finance; Deep Learning; Prediction Models; Time Series; Comparatives Studies; Financial Time Series Forecasting; Inherent Complexity; Language Model; Large Language Model; Learning Models; Stock Price; Time Series Forecasting; Time-series Analysis; Contrastive Learning","Decentralized finance; Deep learning; Prediction models; Time series; Comparatives studies; Financial time series forecasting; Inherent complexity; Language model; Large language model; Learning models; Stock price; Time series forecasting; Time-series analysis; Contrastive Learning","","","","Adebiyi, Ayodele Ariyo, Stock price prediction using the ARIMA model, pp. 106-112, (2014); Nh Ttc A Gradient Based Framework for Generalized Anticipatory Collision Avoidance, (2019); Lin, Yuling, An SVM-based approach for stock market trend prediction, Proceedings of the International Joint Conference on Neural Networks, (2013); Predicting the Direction of Stock Market Prices Using Random Forest, (2016); Selvin, Sreelekshmy, Stock price prediction using LSTM, RNN and CNN-sliding window model, 2017-January, pp. 1643-1647, (2017); Shuzhen, Wang, A Stock Price Prediction Method Based on BiLSTM and Improved Transformer, IEEE Access, 11, pp. 104211-104223, (2023); Transformer for Times Series an Application to the S P500, (2024); Swathi, T., An optimal deep learning-based LSTM for stock price prediction using twitter sentiment analysis, Applied Intelligence, 52, 12, pp. 13675-13688, (2022); A Comprehensive Capability Analysis of Gpt 3 and Gpt 3 5 Series Models, (2023); Koa, Kelvin J.L., Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models, pp. 4304-4315, (2024)","","Institute of Electrical and Electronics Engineers Inc.","","11th International Conference on Soft Computing and Machine Intelligence, ISCMI 2024","","Melbourne; VIC","206431","26400154; 26400146","","","","English","Conference paper","Final","","Scopus","2-s2.0-105001566756"
"L.D., Dsouza, Lester David; J.A., Nasir, Jamal Abdul; M.M., Kamal, Muhammad Mohsin; L.Y., Connolly, Lena Yuryna","Dsouza, Lester David (59714733000); Nasir, Jamal Abdul (56419640500); Kamal, Muhammad Mohsin (59715906100); Connolly, Lena Yuryna (55651304500)","59714733000; 56419640500; 59715906100; 55651304500","Leveraging Large Language Models for Predicting Stock Option Valuation and Financial Risk Mitigation","2024","IEEE International Conference on Data Mining Workshops, ICDMW","","","","97","105","0","2","10.1109/ICDMW65004.2024.00019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001400452&doi=10.1109%2FICDMW65004.2024.00019&partnerID=40&md5=038e43528c32259a548be5db32272de1","University of Galway, Galway, Ireland; Knowledge Platform (Private) Limited, Islamabad, Pakistan; Zayed University, Dubai, United Arab Emirates","Dsouza, Lester David, School of Computer Science, University of Galway, Galway, Ireland; Nasir, Jamal Abdul, School of Computer Science, University of Galway, Galway, Ireland; Kamal, Muhammad Mohsin, NLP Research Centre, Knowledge Platform (Private) Limited, Islamabad, Pakistan; Connolly, Lena Yuryna, College of Technological Innovation, Zayed University, Dubai, United Arab Emirates","The prediction of short-term stock options with near-future expiration dates is a challenging task due to high volatility, limited information, market noise and the risk of time decay. This work focuses on the new approach to the stock options valuation by leveraging Large Language Models (LLMs) through the integration of quantitative (i.e. financial features-lagged prices, moving averages, and volatility indicators) and qualitative data (i.e. news data, including article titles, full textual content, and publication dates). More specifically, our approach fuses sentiment analysis from LLMs applied to financial news from two reputable outlets (i.e. Economic Times and Yahoo Finance India) with quantitative data on stock options, which includes stock option closing price. By conducting experiments on companies from the NIFTY 50 index using ChatGPT-3.5, ChatGPT-4, and LLaMA 3.1, we show that our method achieves superior prediction accuracy compared to other similar approaches. The paper develops a new framework to improve the valuation of short-term stock options using advanced natural language processing behaviors afforded by LLMs to achieve a more holistic capture of market dynamics and sentiment in option pricing. © 2025 Elsevier B.V., All rights reserved.","Bearish Prediction; Bullish Prediction; Chatgpt-3.5; Chatgpt-4; Financial Markets; Large Language Models; Llama 3.1; Nifty50; Option Valuation; Risk Management; Sentiment Analysis; Short-term Options; Decentralized Finance; Financial Markets; Modeling Languages; Natural Language Processing Systems; Prediction Models; Risk Analysis; Risk Assessment; Risk Management; Bearish Prediction; Bullish Prediction; Chatgpt-3.5; Chatgpt-4; Language Model; Large Language Model; Llama 3.1; Nifty50; Option Valuation; Risks Management; Sentiment Analysis; Short-term Option; Costs","Decentralized finance; Financial markets; Modeling languages; Natural language processing systems; Prediction models; Risk analysis; Risk assessment; Risk management; Bearish prediction; Bullish prediction; ChatGPT-3.5; ChatGPT-4; Language model; Large language model; LLaMA 3.1; NIFTY50; Option valuation; Risks management; Sentiment analysis; Short-term option; Costs","","","This publication has emanated from research supported in part by a grant from Science Foundation Ireland under Grant number 21/IRDIF/9847.","Diebold, Francis X., On the network topology of variance decompositions: Measuring the connectedness of financial firms, Journal of Econometrics, 182, 1, pp. 119-134, (2014); Options Futures and Other Derivatives, (2018); Investment Under Uncertainty, (1994); Pricing Options Under Jump Diffusion Processes; White Center for Financial Research, (2025); Time Series Analysisforecasting and Control, (1976); Otexts, (2018); Atsalakis, George S., Surveying stock market forecasting techniques - Part II: Soft computing methods, Expert Systems with Applications, 36, 3 PART 2, pp. 5932-5941, (2009); Zhang, Peter G., Time series forecasting using a hybrid ARIMA and neural network model, Neurocomputing, 50, pp. 159-175, (2003); Xing, Frank Z., Natural language based financial forecasting: a survey, Artificial Intelligence Review, 50, 1, pp. 49-73, (2018)","He, Y.; Hamidouche, W.; Razzak, I.; Hacid, H.; Panov, M.","IEEE Computer Society","","24th IEEE International Conference on Data Mining Workshops, ICDMW 2024","","Abu Dhabi","207707","23759259; 23759232","9781728146034; 9798350346091; 9781509054725; 9798350381641; 9781665424271; 9781538692882; 9798331530631; 9781538614808; 9781479942749; 9781728190129","","","English","Conference paper","Final","","Scopus","2-s2.0-105001400452"
"B., Lefort, Baptiste; E., Benhamou, Eric; J.J., Ohana, Jean Jacques; B., Guez, Beatrice; D., Saltiel, David","Lefort, Baptiste (58827579100); Benhamou, Eric (57219457827); Ohana, Jean Jacques (57221150081); Guez, Beatrice (57219460079); Saltiel, David (57219624094)","58827579100; 57219457827; 57221150081; 57219460079; 57219624094","Sentiment Score of Bloomberg Market Wraps with ChatGPT","2024","IEEE International Conference on Data Mining Workshops, ICDMW","","","","111","116","0","0","10.1109/ICDMW65004.2024.00021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001364338&doi=10.1109%2FICDMW65004.2024.00021&partnerID=40&md5=d5029c435e4113bdc295f2f5ff8ea4b9","Ai for Alpha, Alpha, France; Ai For Alpha, Paris, France","Lefort, Baptiste, Ai for Alpha, Alpha, France; Benhamou, Eric, Ai For Alpha, Paris, France; Ohana, Jean Jacques, Ai For Alpha, Paris, France; Guez, Beatrice, Ai For Alpha, Paris, France; Saltiel, David, Ai For Alpha, Paris, France","In this paper, we used a large dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines affect stock market movements. To make this analysis more effective, we employed ChatGPT. First, from the summary of daily financial updates, we identify top global news headlines that could have a significant influence on stock markets. Second, for each headline, we questioned ChatGPT to answer whether the news might lead to a rise, a fall in stock prices or an indecisive future. This two-stage method proves more effective than a direct question on the entire text. By gathering ChatGPT's predictions day by day, we formed an overall market sentiment score and transform this score into a practical investment strategy in the NASDAQ index, demonstrating the significance of minimizing noise in sentiment scores by initially accumulating and then detrending them. This approach showcases that ChatGPT's analysis of news headlines can provide valuable insights into future stock market behaviours and be a valuable tool to develop intuitive NLP-driven investment strategies leveraging news predictive power. © 2025 Elsevier B.V., All rights reserved.","Bloomberg News; Chatgpt; Nlp; Sentimentscore; Commerce; Financial Markets; Bloomberg; Bloomberg News; Chatgpt; Detrending; Investment Strategy; Large Datasets; Sentiment Scores; Sentimentscore; Stock Price; Two-stage Methods; Marketplaces","Commerce; Financial markets; Bloomberg; Bloomberg news; ChatGPT; Detrending; Investment strategy; Large datasets; Sentiment scores; Sentimentscore; Stock price; Two-stage methods; Marketplaces","","","","Tetlock, Paul C., Giving content to investor sentiment: The role of media in the stock market, Journal of Finance, 62, 3, pp. 1139-1168, (2007); Schumaker, Robert P., Textual analysis of stock market prediction using breaking financial news: The AZFin text system, ACM Transactions on Information Systems, 27, 2, (2009); Georgetown Journal of International Law, (2015); Fatouros, Georgios, DeepVaR: a framework for portfolio risk assessment leveraging probabilistic deep neural networks, Digital Finance, 5, 1, pp. 29-56, (2023); Poria, Soujanya, Aspect extraction for opinion mining with a deep convolutional neural network, Knowledge-Based Systems, 108, pp. 42-49, (2016); Bert Pre Training of Deep Bidirectional Transformers for Language Understanding, (2018); Liu, Zhuang, FinBERT: A pre-trained financial language representation model for financial text mining, IJCAI International Joint Conference on Artificial Intelligence, 2021-January, pp. 4513-4519, (2020); Loughran, Tim, When Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ks, Journal of Finance, 66, 1, pp. 35-65, (2011); Poria, Soujanya, A review of affective computing: From unimodal analysis to multimodal fusion, Information Fusion, 37, pp. 98-125, (2017); Li, Chenying, FinMath: Injecting a Tree-structured Solver for Question Answering over Financial Reports, pp. 6147-6152, (2022)","He, Y.; Hamidouche, W.; Razzak, I.; Hacid, H.; Panov, M.","IEEE Computer Society","","24th IEEE International Conference on Data Mining Workshops, ICDMW 2024","","Abu Dhabi","207707","23759259; 23759232","9781728146034; 9798350346091; 9781509054725; 9798350381641; 9781665424271; 9781538692882; 9798331530631; 9781538614808; 9781479942749; 9781728190129","","","English","Conference paper","Final","","Scopus","2-s2.0-105001364338"
"C., Liu, Chen; L., Cai, Linzhe; G., Dalzell, Geordie; N., Mills, Nishan","Liu, Chen (57215725555); Cai, Linzhe (58031880100); Dalzell, Geordie (57191247969); Mills, Nishan (57204273605)","57215725555; 58031880100; 57191247969; 57204273605","Large Language Model for Extreme Electricity Price Forecasting in the Australia Electricity Market","2024","IECON Proceedings (Industrial Electronics Conference)","","","","","","0","1","10.1109/IECON55916.2024.10906045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000964471&doi=10.1109%2FIECON55916.2024.10906045&partnerID=40&md5=2669e03ba4a5ee019195718d721e79f8","RMIT University, Melbourne, Australia; La Trobe University, Melbourne, Australia","Liu, Chen, School of Engineering, RMIT University, Melbourne, Australia; Cai, Linzhe, School of Engineering, RMIT University, Melbourne, Australia; Dalzell, Geordie, School of Engineering, RMIT University, Melbourne, Australia; Mills, Nishan, La Trobe University, Melbourne, Australia","This work addresses the challenge of accurately forecasting electricity prices within the volatile Australian market, especially during extreme conditions. It leverages advanced generative pre-trained Large Language Models (LLMs) to analyze the content of electricity market notices with the goal of identifying the drivers behind extreme price fluctuations. Additionally, this approach employs LLMs for an in-depth time-series analysis of electricity prices, providing Australian electricity company traders with insights to refine their trading strategies. To enhance forecasting accuracy this study adopts the QLoRA method for fine-tuning open access LLMs, enabling the analysis of market notices to generate a time series event dataset. A CNN-LSTM network architecture is designed to process both electricity price data and market notice information, thereby improving forecast precision in periods of extreme price volatility. The proposed decision support framework undergoes simulation and evaluation using data from the Australian electricity market, demonstrating its potential to significantly benefit traders in navigating the complexities of the energy sector. © 2025 Elsevier B.V., All rights reserved.","Australia; Australian Electricities; Depth-time; Electricity Prices; Electricity Prices Forecasting; Extreme Conditions; Forecasting Electricity; Language Model; Price Fluctuation; Time-series Analysis; Power Markets","Australia; Australian electricities; Depth-time; Electricity prices; Electricity prices forecasting; Extreme conditions; Forecasting electricity; Language model; Price fluctuation; Time-series analysis; Power markets","","","This research was undertaken with the assistance of computing resources from RACE (RMIT AWS Cloud Supercomputing). We extend our heartfelt gratitude to our supervisor, Prof Xinghuo Yu for his invaluable guidance, support, and critical insights that significantly contributed to refining the topic of our work. The authorship team would like to acknowledge the vision, support and guidance of the IEEE Industrial Electronics Society in conducting the Generative AI Hackathon under the leadership of Daswin De Silva and Lakshitha Gunasekara.","National Electricity Market; Chinnathambi, Radhakrishnan Angamuthu, Deep Neural Networks (DNN) for Day-Ahead Electricity Price Markets, (2018); Ugurlu, Umut, Electricity price forecasting using recurrent neural networks, Energies, 11, 5, (2018); Zhu, Yongli, Power market price forecasting via deep learning, pp. 4935-4939, (2018); Kuo, Ping Huan, An electricity price forecasting model by hybrid structured deep neural networks, Sustainability (Switzerland), 10, 4, (2018); Xie, Xiaolong, The day-ahead electricity price forecasting based on stacked CNN and LSTM, Lecture Notes in Computer Science, 11266 LNCS, pp. 216-230, (2018); Ugurlu, Umut, The financial effect of the electricity price forecasts' inaccuracy on a hydro-based generation company, Energies, 11, 8, (2018); Chang, Zihan, Electricity price prediction based on hybrid model of adam optimized LSTM neural network and wavelet transform, Energy, 187, (2019); Yang, Wendong, A novel machine learning-based electricity price forecasting model based on optimal model selection strategy, Energy, 238, (2022); Neupane, Bijay, Ensemble prediction model with expert selection for electricity price forecasting, Energies, 10, 1, (2017)","","IEEE Computer Society","IEEE Industrial Electronics Society (IES)","50th Annual Conference of the IEEE Industrial Electronics Society, IECON 2024","","Chicago; IL","207560","21624704; 25771647","9781665435543; 9781424417667; 9781665480253; 9798350331820; 9781665464543; 9780780392526; 9781424452262; 0879426888; 9781424407835; 9781479902248","IEPRE","","English","Conference paper","Final","","Scopus","2-s2.0-105000964471"
"J., Li, Jiatong; R., Hu, Renjun; K., Huang, Kunzhe; Y., Zhuang, Yan; Q., Liu, Qi; M., Zhu, Mengxiao; X., Shi, Xing; W., Lin, Wei","Li, Jiatong (57871688700); Hu, Renjun (57188965440); Huang, Kunzhe (57260667800); Zhuang, Yan (57822391000); Liu, Qi (56382635200); Zhu, Mengxiao (57077443400); Shi, Xing (58436237100); Lin, Wei (57203497158)","57871688700; 57188965440; 57260667800; 57822391000; 56382635200; 57077443400; 58436237100; 57203497158","PertEval: Unveiling Real Knowledge Capacity of LLMs with Knowledge-Invariant Perturbations","2024","Advances in Neural Information Processing Systems","37","","","","","0","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000551550&partnerID=40&md5=a424128da278de6f213b6fcb1753ac2a","University of Science and Technology of China, Hefei, China; Alibaba Group Holding Limited, Hangzhou, China","Li, Jiatong, University of Science and Technology of China, Hefei, China; Hu, Renjun, Alibaba Group Holding Limited, Hangzhou, China; Huang, Kunzhe, Alibaba Group Holding Limited, Hangzhou, China; Zhuang, Yan, University of Science and Technology of China, Hefei, China; Liu, Qi, University of Science and Technology of China, Hefei, China; Zhu, Mengxiao, University of Science and Technology of China, Hefei, China; Shi, Xing, Alibaba Group Holding Limited, Hangzhou, China; Lin, Wei, Alibaba Group Holding Limited, Hangzhou, China","Expert-designed close-ended benchmarks are indispensable in assessing the knowledge capacity of large language models (LLMs). Despite their widespread use, concerns have mounted regarding their reliability due to limited test scenarios and an unavoidable risk of data contamination. To rectify this, we present PertEval, a toolkit devised for in-depth probing of LLMs' knowledge capacity through knowledge-invariant perturbations. These perturbations employ human-like restatement techniques to generate on-the-fly test samples from static benchmarks, meticulously retaining knowledge-critical content while altering irrelevant details. Our toolkit further includes a suite of response consistency analyses that compare performance on raw vs. perturbed test sets to precisely assess LLMs' genuine knowledge capacity. Six representative LLMs are re-evaluated using PertEval. Results reveal significantly inflated performance of the LLMs on raw benchmarks, including an absolute 25.8% overestimation for GPT-4. Additionally, through a nuanced response pattern analysis, we discover that PertEval retains LLMs' uncertainty to specious knowledge, and reveals their potential rote memorization to correct options which leads to overestimated performance. We also find that the detailed response consistency analyses by PertEval could illuminate various weaknesses in existing LLMs' knowledge mastery and guide the development of refinement. Our findings provide insights for advancing more robust and genuinely knowledgeable LLMs. Our code is available at https://github.com/aigc-apps/PertEval. © 2025 Elsevier B.V., All rights reserved.","","","","","This research was supported by grants from the Joint Research Project of the Science and Technology Innovation Community in Yangtze River Delta (No. 2023CSJZN0200), the National Natural Science Foundation of China (No. 62337001), the Fundamental Research Funds for the Central Universities, and the Alibaba Research Intern Program. We thank all the volunteers for their massive efforts in supporting our experiments, including Yi Cheng, Xiaowen Zhang, and Anyu Chen at Alibaba Cloud Computing, Dingchu Zhang at Nanjing University, Yuyang Xu at Zhejiang University, and Yangyang Wang at Shandong University.","Wei, Jason, Chain-of-Thought Prompting Elicits Reasoning in Large Language Models, Advances in Neural Information Processing Systems, 35, (2022); Webb, Taylor W., Emergent analogical reasoning in large language models, Nature Human Behaviour, 7, 9, pp. 1526-1541, (2023); Valmeekam, Karthik, On the Planning Abilities of Large Language Models: A Critical Investigation, Advances in Neural Information Processing Systems, 36, (2023); Yu, Jifan, KOLA: CAREFULLY BENCHMARKING WORLD KNOWLEDGE OF LARGE LANGUAGE MODELS, (2024); Bengio, Yoshua, Managing extreme AI risks amid rapid progress: Preparation requires technical research and development, as well as adaptive, proactive governance, Science, 384, 6698, pp. 842-845, (2024); Hendrycks, Dan, MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING, (2021); Zhong, Wanjun, AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models, pp. 2299-2314, (2024); Think You have Solved Question Answering Try Arc the Ai2 Reasoning Challenge, (2018); Pal, Ankit, MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering, Proceedings of Machine Learning Research, 174, pp. 248-260, (2022); Large Language Models as Tax Attorneys A Case Study in Legal Capabilities Emergence, (2023)","Globerson, A.; Mackey, L.; Belgrave, D.; Fan, A.; Paquet, U.; Tomczak, J.; Zhang, C.","Neural information processing systems foundation","","38th Conference on Neural Information Processing Systems, NeurIPS 2024","","Vancouver; BC","207061","10495258","0262100762; 0262122413; 0262025507; 9780262232531; 0262042088; 9780262025508; 0262100657; 9781627480031; 0262194503; 9780262100656","","","English","Conference paper","Final","","Scopus","2-s2.0-105000551550"
"Y., Liu, Yiran; K., Yang, Ke; Z., Qi, Zehan; X., Liu, Xiao; Y., Yu, Yang; C., Zhai, Chengxiang","Liu, Yiran (57986312400); Yang, Ke (58823045300); Qi, Zehan (58806186800); Liu, Xiao (57195957831); Yu, Yang (56019147800); Zhai, Chengxiang (35232046000)","57986312400; 58823045300; 58806186800; 57195957831; 56019147800; 35232046000","Bias and Volatility: A Statistical Framework for Evaluating Large Language Model's Stereotypes and the Associated Generation Inconsistency","2024","Advances in Neural Information Processing Systems","37","","","","","0","2","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000518469&partnerID=40&md5=a236898d5c6879a2f7b9e36821069048","Tsinghua University, Beijing, China; University of Illinois Urbana-Champaign, Urbana, United States; China University of Petroleum-Beijing, Beijing, China","Liu, Yiran, Tsinghua University, Beijing, China; Yang, Ke, University of Illinois Urbana-Champaign, Urbana, United States; Qi, Zehan, Tsinghua University, Beijing, China; Liu, Xiao, Tsinghua University, Beijing, China; Yu, Yang, China University of Petroleum-Beijing, Beijing, China; Zhai, Chengxiang, University of Illinois Urbana-Champaign, Urbana, United States","We present a novel statistical framework for analyzing stereotypes in large language models (LLMs) by systematically estimating the bias and variation in their generation. Current evaluation metrics in the alignment literature often overlook the randomness of stereotypes caused by the inconsistent generative behavior of LLMs. For example, this inconsistency can result in LLMs displaying contradictory stereotypes, including those related to gender or race, for identical professions across varied contexts. Neglecting such inconsistency could lead to misleading conclusions in alignment evaluations and hinder the accurate assessment of the risk of LLM applications perpetuating or amplifying social stereotypes and unfairness. This work proposes a Bias-Volatility Framework (BVF) that estimates the probability distribution function of LLM stereotypes. Specifically, since the stereotype distribution fully captures an LLM's generation variation, BVF enables the assessment of both the likelihood and extent to which its outputs are against vulnerable groups, thereby allowing for the quantification of the LLM's aggregated discrimination risk. Furthermore, we introduce a mathematical framework to decompose an LLM's aggregated discrimination risk into two components: bias risk and volatility risk, originating from the mean and variation of LLM's stereotype distribution, respectively. We apply BVF to assess 12 commonly adopted LLMs and compare their risk levels. Our findings reveal that: i) Bias risk is the primary cause of discrimination risk in LLMs; ii) Most LLMs exhibit significant pro-male stereotypes for nearly all careers; iii) Alignment with reinforcement learning from human feedback lowers discrimination by reducing bias, but increases volatility; iv) Discrimination risk in LLMs correlates with key sociol-economic factors like professional salaries. Finally, we emphasize that BVF can also be used to assess other dimensions of generation inconsistency's impact on LLM behavior beyond stereotypes, such as knowledge mastery. © 2025 Elsevier B.V., All rights reserved.","","","","","","undefined, (2023); 9th Annual Conference of the Special Interest Group for Computing Information and Society, (2017); Bolukbasi, Tolga, Man is to computer programmer as woman is to homemaker? Debiasing word embeddings, Advances in Neural Information Processing Systems, pp. 4356-4364, (2016); Identifying and Reducing Gender Bias in Word Level Language Models, (2019); Brigham, John C., Ethnic stereotypes, Psychological Bulletin, 76, 1, pp. 15-38, (1971); Cabello, Laura, On the Independence of Association Bias and Empirical Fairness in Language Models, pp. 370-378, (2023); Caliskan, Aylin, Semantics derived automatically from language corpora contain human-like biases, Science, 356, 6334, pp. 183-186, (2017); Knowledge is Power Understanding Causality Makes Legal Judgment Prediction Models More Generalizable and Robust, (2025); Bias and Productivity in Humans and Algorithms Theory and Evidence from Resume Screening, (2018); Conference on Neural Information Processing Systems, (2017)","Globerson, A.; Mackey, L.; Belgrave, D.; Fan, A.; Paquet, U.; Tomczak, J.; Zhang, C.","Neural information processing systems foundation","","38th Conference on Neural Information Processing Systems, NeurIPS 2024","","Vancouver; BC","207061","10495258","0262100762; 0262122413; 0262025507; 9780262232531; 0262042088; 9780262025508; 0262100657; 9781627480031; 0262194503; 9780262100656","","","English","Conference paper","Final","","Scopus","2-s2.0-105000518469"
"Q., Xie, Qianqian; W., Han, Weiguang; Z., Chen, Zhengyu; R., Xiang, Ruoyu; X., Zhang, Xiao; Y., He, Yueru; M., Xiao, Mengxi; D., Li, Dong; Y., Dai, Yongfu; D., Feng, Duanyu","Xie, Qianqian (57190030285); Han, Weiguang (57212485862); Chen, Zhengyu (58916765000); Xiang, Ruoyu (58899534100); Zhang, Xiao (58484873100); He, Yueru (58915728800); Xiao, Mengxi (58915728900); Li, Dong (58916461900); Dai, Yongfu (58659716900); Feng, Duanyu (57217043323)","57190030285; 57212485862; 58916765000; 58899534100; 58484873100; 58915728800; 58915728900; 58916461900; 58659716900; 57217043323","FinBen: A Holistic Financial Benchmark for Large Language Models","2024","Advances in Neural Information Processing Systems","37","","","","","0","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000468879&partnerID=40&md5=5b736b8e939fa93003000302221c80ae","The Fin AI, Japan; Wuhan University, Wuhan, China; The University of Manchester, Manchester, United Kingdom; University of Florida, Gainesville, United States; Columbia University, New York, United States; The Chinese University of Hong Kong, Shenzhen, Shenzhen, China; Sichuan University, Chengdu, China; Yunnan University, Kunming, China; Stevens Institute of Technology, Hoboken, United States; Stony Brook University, Stony Brook, United States; Nanjing Audit University, Nanjing, China; Jiangxi Normal University, Nanchang, China; Southwest Jiaotong University, Chengdu, China","Xie, Qianqian, The Fin AI, Japan, Wuhan University, Wuhan, China; Han, Weiguang, Wuhan University, Wuhan, China; Chen, Zhengyu, Wuhan University, Wuhan, China; Xiang, Ruoyu, The Fin AI, Japan; Zhang, Xiao, The Fin AI, Japan; He, Yueru, The Fin AI, Japan; Xiao, Mengxi, Wuhan University, Wuhan, China; Li, Dong, Wuhan University, Wuhan, China; Dai, Yongfu, Sichuan University, Chengdu, China; Feng, Duanyu, Sichuan University, Chengdu, China","LLMs have transformed NLP and shown promise in various fields, yet their potential in finance is underexplored due to a lack of comprehensive benchmarks, the rapid development of LLMs, and the complexity of financial tasks. In this paper, we introduce FinBen, the first extensive open-source evaluation benchmark, including 42 datasets spanning 24 financial tasks, covering eight critical aspects: information extraction (IE), textual analysis, question answering (QA), text generation, risk management, forecasting, decision-making, and bilingual (English and Spanish). FinBen offers several key innovations: a broader range of tasks and datasets, the first evaluation of stock trading, novel agent and Retrieval-Augmented Generation (RAG) evaluation, and two novel datasets for regulations and stock trading. Our evaluation of 21 representative LLMs, including GPT-4, ChatGPT, and the latest Gemini, reveals several key findings: While LLMs excel in IE and textual analysis, they struggle with advanced reasoning and complex tasks like text generation and forecasting. GPT-4 excels in IE and stock trading, while Gemini is better at text generation and forecasting. Instruction-tuned LLMs improve textual analysis but offer limited benefits for complex tasks such as QA. FinBen has been used to host the first financial LLMs shared task at the FinNLP-AgentScen workshop during IJCAI-2024, attracting 12 teams. Their novel solutions outperformed GPT-4, showcasing FinBen's potential to drive innovations in financial LLMs. All datasets and code are publicly available for the research community2, with results shared and updated regularly on the Open Financial LLM Leaderboard. © 2025 Elsevier B.V., All rights reserved.","","","","","The authors acknowledge UFIT Research Computing, NVAITC, and HPG for providing computational resources and support that have contributed to the research results reported in this publication. URL: http://www.rc.ufl.edu. This work is supported by the project JPNP20006 from New Energy and Industrial Technology Development Organization (NEDO). This work has also been partially supported by project MIS 5154714 of the National Recovery and Resilience Plan Greece 2.0 funded by the European Union under the Next Generation EU Program. Additionally, we gratefully acknowledge FINOS (Fintech Open Source Foundation) for supporting the Open Financial LLM Leaderboard initiative. Xiao-Yang Liu acknowledges the support from NSF IUCRC CRAFT center research grant (CRAFT Grant 22017) for this research. The opinions expressed in this publication do not necessarily represent the views of NSF IUCRC CRAFT. Haoqiang Kang and Xiao-Yang Liu also acknowledge the support from Columbia's SIRS and STAR Program, The Tang Family Fund for Research Innovations in FinTech, Engineering, and Business Operations.","Qwen2 Technical Report, (2024); Abu-Mostafa, Yaser S., Introduction to financial forecasting, Applied Intelligence, 6, 3, pp. 205-213, (1996); Falcon Series of Open Language Models, (2023); Alvarado, Julio Cesar Salinas, Domain adaption of named entity recognition to support credit risk assessment, pp. 84-90, (2015); Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Ariel, Robert A., A monthly effect in stock returns, Journal of Financial Economics, 18, 1, pp. 161-174, (1987); Ssrn Electronic Journal, (2018); Baichuan 2 Open Large Scale Language Models, (2023); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Sparks of Artificial General Intelligence Early Experiments with Gpt 4, (2023)","Globerson, A.; Mackey, L.; Belgrave, D.; Fan, A.; Paquet, U.; Tomczak, J.; Zhang, C.","Neural information processing systems foundation","","38th Conference on Neural Information Processing Systems, NeurIPS 2024","","Vancouver; BC","207061","10495258","0262100762; 0262122413; 0262025507; 9780262232531; 0262042088; 9780262025508; 0262100657; 9781627480031; 0262194503; 9780262100656","","","English","Conference paper","Final","","Scopus","2-s2.0-105000468879"
"Z., Yang, Zhiju; G., Man, Gaoyuan; S., Yue, Songqing","Yang, Zhiju (57204016487); Man, Gaoyuan (58193703700); Yue, Songqing (57203001364)","57204016487; 58193703700; 57203001364","Automated Smart Contract Vulnerability Detection using Fine-Tuned Large Language Models","2023","","","","","19","23","0","2","10.1145/3651655.3651658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195795552&doi=10.1145%2F3651655.3651658&partnerID=40&md5=627e1e406719dfba4c51f00fab2297cb","Seattle University, Seattle, United States; Arizona State University, Tempe, United States; University of Wisconsin-Platteville, Platteville, United States","Yang, Zhiju, Seattle University, Seattle, United States; Man, Gaoyuan, Arizona State University, Tempe, United States; Yue, Songqing, University of Wisconsin-Platteville, Platteville, United States","As decentralized finance (DeFi) built on blockchain grows rapidly, the security of smart contracts underpinning DeFi has become a major concern due to exploits leading to billions in damages. Although tools exist for automated vulnerability detection in smart contracts, studies show that most vulnerabilities remain undetected. In this work, we propose using fine-Tuned large language models (LLMs) for enhanced automated detection of vulnerabilities in smart contracts. We collected over 26,727 labeled smart contract vulnerabilities and fine-Tuned the 13B parameter Llama-2 model. Evaluation of 1,000 unseen functions shows promising precision of 31-36% in predicting vulnerability categories. The fine-Tuned LLM demonstrates potential as an auxiliary tool to identify vulnerable code and assist auditors. Future work is outlined for improving performance via larger models, higher-quality data, and specialized binary detection models. We present promising preliminary results on integrating LLMs into smart contract analysis and motivate further research at the intersection of LLMs and blockchain security. © 2024 Elsevier B.V., All rights reserved.","Large Language Model; Security; Smart Contract; Vulnerability Detection; Automation; Blockchain; Computational Linguistics; Automated Detection; Block-chain; Decentralised; High Quality Data; Improving Performance; Language Model; Large Language Model; Large Models; Security; Vulnerability Detection; Smart Contract","Automation; Blockchain; Computational linguistics; Automated detection; Block-chain; Decentralised; High quality data; Improving performance; Language model; Large language model; Large models; Security; Vulnerability detection; Smart contract","","","","Zhou, Liyi, SoK: Decentralized Finance (DeFi) Attacks, Proceedings - IEEE Symposium on Security and Privacy, 2023-May, pp. 2444-2461, (2023); Qin, Kaihua, Attacking the DeFi Ecosystem with Flash Loans for Fun and Profit, Lecture Notes in Computer Science, 12674 LNCS, pp. 3-32, (2021); Ye, Jiaming, Clairvoyance: Cross-contract Static Analysis for Detecting Practical Reentrancy Vulnerabilities in Smart Contracts, pp. 274-275, (2020); Daian, Philip, Flash boys 2.0: Frontrunning in decentralized exchanges, miner extractable value, and consensus instability, Proceedings - IEEE Symposium on Security and Privacy, 2020-May, pp. 1106-1120, (2020); Zhang, Zhuo, Demystifying Exploitable Bugs in Smart Contracts, Proceedings - International Conference on Software Engineering, pp. 615-627, (2023); Feist, Josselin, Slither: A static analysis framework for smart contracts, pp. 8-15, (2019); Brent, Lexi, Ethainter: A smart contract security analyzer for composite vulnerabilities, Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), pp. 454-469, (2020); Vandal A Scalable Security Analysis Framework for Smart Contracts, (2018); Llama 2 Open Foundation and Fine Tuned Chat Models, (2023); Ali, Muhammad Ahsan, An accurate CT saturation classification using a deep learning approach based on unsupervised feature extraction and supervised fine-tuning strategy, Energies, 10, 11, (2017)","","Association for Computing Machinery","","6th International Conference on Blockchain Technology and Applications, ICBTA 2023","","Xi'an","199910","","9798400708671; 9798400716966","","","English","Conference paper","Final","All Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85195795552"
"F., Antaki, Fares; S., Touma, Samir; D., Milad, Daniel; J., El-Khoury, Jonathan; R., Duval, Renaud","Antaki, Fares (57201361149); Touma, Samir (57215845303); Milad, Daniel (57207936325); El-Khoury, Jonathan (57217018414); Duval, Renaud (35409099800)","57201361149; 57215845303; 57207936325; 57217018414; 35409099800","Evaluating the Performance of ChatGPT in Ophthalmology: An Analysis of Its Successes and Shortcomings","2023","Ophthalmology Science","3","4","100324","","","0","315","10.1016/j.xops.2023.100324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163557911&doi=10.1016%2Fj.xops.2023.100324&partnerID=40&md5=c4b6a15b8f18da1dac6b5d4093509cc0","University of Montreal, Montreal, Canada; Hôpital Maisonneuve-Rosemont, Montreal, Canada; Centre Hospitalier de L'Université de Montréal, Montreal, Canada; Centre Hospitalier de L'Université de Montréal, Montreal, Canada","Antaki, Fares, Department of Ophthalmology, University of Montreal, Montreal, Canada, Hôpital Maisonneuve-Rosemont, Montreal, Canada, Department of Ophthalmology, Centre Hospitalier de L'Université de Montréal, Montreal, Canada, Centre Hospitalier de L'Université de Montréal, Montreal, Canada; Touma, Samir, Department of Ophthalmology, University of Montreal, Montreal, Canada, Hôpital Maisonneuve-Rosemont, Montreal, Canada, Department of Ophthalmology, Centre Hospitalier de L'Université de Montréal, Montreal, Canada; Milad, Daniel, Department of Ophthalmology, University of Montreal, Montreal, Canada, Hôpital Maisonneuve-Rosemont, Montreal, Canada, Department of Ophthalmology, Centre Hospitalier de L'Université de Montréal, Montreal, Canada; El-Khoury, Jonathan, Department of Ophthalmology, University of Montreal, Montreal, Canada, Hôpital Maisonneuve-Rosemont, Montreal, Canada, Department of Ophthalmology, Centre Hospitalier de L'Université de Montréal, Montreal, Canada; Duval, Renaud, Department of Ophthalmology, University of Montreal, Montreal, Canada, Hôpital Maisonneuve-Rosemont, Montreal, Canada","Purpose: Foundation models are a novel type of artificial intelligence algorithms, in which models are pretrained at scale on unannotated data and fine-tuned for a myriad of downstream tasks, such as generating text. This study assessed the accuracy of ChatGPT, a large language model (LLM), in the ophthalmology question-answering space. Design: Evaluation of diagnostic test or technology. Participants: ChatGPT is a publicly available LLM. Methods: We tested 2 versions of ChatGPT (January 9 “legacy” and ChatGPT Plus) on 2 popular multiple choice question banks commonly used to prepare for the high-stakes Ophthalmic Knowledge Assessment Program (OKAP) examination. We generated two 260-question simulated exams from the Basic and Clinical Science Course (BCSC) Self-Assessment Program and the OphthoQuestions online question bank. We carried out logistic regression to determine the effect of the examination section, cognitive level, and difficulty index on answer accuracy. We also performed a post hoc analysis using Tukey's test to decide if there were meaningful differences between the tested subspecialties. Main Outcome Measures: We reported the accuracy of ChatGPT for each examination section in percentage correct by comparing ChatGPT's outputs with the answer key provided by the question banks. We presented logistic regression results with a likelihood ratio (LR) chi-square. We considered differences between examination sections statistically significant at a P value of < 0.05. Results: The legacy model achieved 55.8% accuracy on the BCSC set and 42.7% on the OphthoQuestions set. With ChatGPT Plus, accuracy increased to 59.4% ± 0.6% and 49.2% ± 1.0%, respectively. Accuracy improved with easier questions when controlling for the examination section and cognitive level. Logistic regression analysis of the legacy model showed that the examination section (LR, 27.57; P = 0.006) followed by question difficulty (LR, 24.05; P < 0.001) were most predictive of ChatGPT's answer accuracy. Although the legacy model performed best in general medicine and worst in neuro-ophthalmology (P < 0.001) and ocular pathology (P = 0.029), similar post hoc findings were not seen with ChatGPT Plus, suggesting more consistent results across examination sections. Conclusion: ChatGPT has encouraging performance on a simulated OKAP examination. Specializing LLMs through domain-specific pretraining may be necessary to improve their performance in ophthalmic subspecialties. Financial Disclosure(s): Proprietary or commercial disclosure may be found after the references. © 2023 Elsevier B.V., All rights reserved.","Artificial Intelligence; Chatgpt; Generative Pretrained Transformer; Medical Education; Ophthalmology; Accreditation; Article; Artificial Intelligence; Cognition; Eye Disease; General Practice; Logistic Regression Analysis; Measurement Accuracy; Measurement Repeatability; Neuroophthalmology; Ophthalmology; Post Hoc Analysis","accreditation; Article; artificial intelligence; cognition; eye disease; general practice; logistic regression analysis; measurement accuracy; measurement repeatability; neuroophthalmology; ophthalmology; post hoc analysis","","","The authors thank Mr. Charles-Édouard Giguère, statistician at the Institut Universitaire en Santé Mentale de Montréal, for his assistance in the statistical analysis. We thank the American Academy of Ophthalmology for generously granting us permission to use the underlying BCSC Self-Assessment Program materials. The authors have made the following disclosures: F.A.: Grants – Bayer. S.T.: Grants – Bayer. Obtained funding: N/A","Ting, Daniel Shu Wei, Artificial intelligence and deep learning in ophthalmology, British Journal of Ophthalmology, 103, 2, pp. 167-175, (2019); Schmidt-Erfurth, Ursula Margarethe, Artificial intelligence in retina, Progress in Retinal and Eye Research, 67, pp. 1-29, (2018); Antaki, Fares, Accuracy of automated machine learning in classifying retinal pathologies from ultra-widefield pseudocolour fundus images, British Journal of Ophthalmology, 107, 1, pp. 90-95, (2021); Nath, Siddharth, New meaning for NLP: the trials and tribulations of natural language processing with GPT-3 in ophthalmology, British Journal of Ophthalmology, 106, 7, pp. 889-892, (2022); undefined; Corr, (2021); Wiggins, Walter F., On the Opportunities and Risks of Foundation Models for Natural Language Processing in Radiology, Radiology: Artificial Intelligence, 4, 4, (2022); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Large Language Models Encode Clinical Knowledge, (2022); Can Large Language Models Reason about Medical Questions, (2022)","","Elsevier Inc.","","","","","","26669145","","","","English","Article","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85163557911"
"B., Zhang, Boyu; H., Yang, Hongyang; T., Zhou, Tianyu; M.A., Ali Babar, Muhammad Ali; X., Liu, Xiaoyang","Zhang, Boyu (59850446900); Yang, Hongyang (57204013580); Zhou, Tianyu (59849159500); Ali Babar, Muhammad Ali (6602842620); Liu, Xiaoyang (44361326100)","59850446900; 57204013580; 59849159500; 6602842620; 44361326100","Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models","2023","","","","","349","356","0","106","10.1145/3604237.3626866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179046770&doi=10.1145%2F3604237.3626866&partnerID=40&md5=a3b996a92966d52590ea2cce6f713c24","The University of Adelaide, Adelaide, Australia; Columbia University, New York, United States; Brown University, Providence, United States; Rensselaer Polytechnic Institute, Troy, United States","Zhang, Boyu, The University of Adelaide, Adelaide, Australia; Yang, Hongyang, Columbia University, New York, United States; Zhou, Tianyu, Brown University, Providence, United States; Ali Babar, Muhammad Ali, The University of Adelaide, Adelaide, Australia; Liu, Xiaoyang, Columbia University, New York, United States, Rensselaer Polytechnic Institute, Troy, United States","Financial sentiment analysis is critical for valuation and investment decision-making. Traditional NLP models, however, are limited by their parameter size and the scope of their training datasets, which hampers their generalization capabilities and effectiveness in this field. Recently, Large Language Models (LLMs) pre-trained on extensive corpora have demonstrated superior performance across various NLP tasks due to their commendable zero-shot abilities. Yet, directly applying LLMs to financial sentiment analysis presents challenges: The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs' sentiment analysis. To address these challenges, we introduce a retrieval-augmented LLMs framework for financial sentiment analysis. This framework includes an instruction-tuned LLMs module, which ensures LLMs behave as predictors of sentiment labels, and a retrieval-augmentation module which retrieves additional context from reliable external sources. Benchmarked against traditional models and LLMs like ChatGPT and LLaMA, our approach achieves 15% to 48% performance gain in accuracy and F1 score. © 2023 Elsevier B.V., All rights reserved.","Instruction Tuning; Large Language Models; Retrieval Augmented Generation; Sentiment Analysis; Computational Linguistics; Decision Making; Investments; Reliability Analysis; Generalization Capability; Instruction Tuning; Investment Decision Making; Language Model; Large Language Model; Performance; Pre-training; Retrieval Augmented Generation; Sentiment Analysis; Training Dataset","Computational linguistics; Decision making; Investments; Reliability analysis; Generalization capability; Instruction tuning; Investment decision making; Language model; Large language model; Performance; Pre-training; Retrieval augmented generation; Sentiment analysis; Training dataset","","","","Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Cai, Deng, Recent Advances in Retrieval-Augmented Text Generation, pp. 3417-3419, (2022); Vicuna an Open Source Chatbot Impressing Gpt 4 with 90 Chatgpt Quality, (2023); Day, Min Yuh, Deep learning for financial sentiment analysis on finance news providers, pp. 1127-1134, (2016); Definition of Sentiment Analysis Finance Glossary Gartner, (2023); Lewis, Patrick, Retrieval-augmented generation for knowledge-intensive NLP tasks, Advances in Neural Information Processing Systems, 2020-December, (2020); Retrieval Augmented Generation for Code Summarization Via Hybrid Gnn, (2020); Fixing Weight Decay Regularization in Adam, (2017); 2023 is Prompt all You Need no A Comprehensive and Broader View of Instruction Learning","","Association for Computing Machinery, Inc","J.P. Morgan Chase and Co.; U.S. Bank","4th ACM International Conference on AI in Finance, ICAIF 2023","","New York City; NY","194766","","9798400702402","","","English","Conference paper","Final","","Scopus","2-s2.0-85179046770"
"B.E., Hommel, Björn E.","Hommel, Björn E. (57347097000)","57347097000","Expanding the methodological toolbox: Machine-based item desirability ratings as an alternative to human-based ratings","2023","Personality and Individual Differences","213","","112307","","","0","4","10.1016/j.paid.2023.112307","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163160558&doi=10.1016%2Fj.paid.2023.112307&partnerID=40&md5=44477130d088c1d0cbcde37f583ba9c3","Universität Leipzig, Leipzig, Germany; magnolia psychometrics GmbH, Leipzig, Germany","Hommel, Björn E., Wilhelm Wundt Institute for Psychology, Universität Leipzig, Leipzig, Germany, magnolia psychometrics GmbH, Leipzig, Germany","The accuracy of self-reported data in the social and behavioral sciences may be compromised by response biases such as socially desirable responding. Researchers and scale developers therefore obtain item desirability ratings, in order to maintain item neutrality, and parity with alternative options when creating forced-choice items. Gathering item desirability ratings from human judges can be time-consuming and costly, with no consistent guidelines with regard to required sample size and composition. However, recent advancements in natural language processing have yielded large language models (LLMs) with exceptional abilities to identify abstract semantic attributes in text. The presented research highlights the potential application of LLMs to estimate the desirability of items, as evidenced by the re-analysis of data from 14 distinct studies. Findings indicate a significant and strong correlation between human- and machine-rated item desirability of .80, across 521 items. Results furthermore showed that the proposed fine-tuning approach of LLMs results in predictions that explained 19 % more variance beyond that of sentiment analysis. These results demonstrate the feasibility of relying on machine-based item desirability ratings as a viable alternative to human-based ratings and contribute to the field of personality psychology by expanding the methodological toolbox available to researchers, scale developers, and practitioners. © 2023 Elsevier B.V., All rights reserved.","Artificial Intelligence; Item Desirability; Large Language Models; Natural Language Processing; Sentiment Analysis; Social Desirability Bias; Article; Artificial Intelligence; Feasibility Study; Human; Human Experiment; Natural Language Processing; Personality Psychology; Physician; Prediction; Sentiment Analysis; Social Desirability Bias","article; artificial intelligence; feasibility study; human; human experiment; natural language processing; personality psychology; physician; prediction; sentiment analysis; social desirability bias","","","I want to thank Lucy Erber and Paulina Machado Costa for their support in reviewing the literature for this research.","Andersen, Henrik Kenneth, Responding to socially desirable and undesirable topics: Different types of response behaviour?, Methods, Data, Analyses, 13, 1, pp. 7-35, (2019); Anderson, Norman Henry, LIKABLENESS RATINGS OF 555 PERSONALITY-TRAIT WORDS, Journal of Personality and Social Psychology, 9, 3, pp. 272-279, (1968); Xlm T A Multilingual Language Model Toolkit for Twitter, (2021); Bochner, Stephen, Desirability ratings of 110 personality-trait words, Journal of Social Psychology, 125, 4, pp. 459-465, (1985); Britz, Sara, The Aachen List of Trait Words, Journal of Psycholinguistic Research, 48, 5, pp. 1111-1132, (2019); Behavior Research Methods, (2022); Chandler, Jesse J., Likeableness and meaningfulness ratings of 555 (+487) person-descriptive words, Journal of Research in Personality, 72, pp. 50-57, (2018); Converse, Patrick D., Statement desirability ratings in forced-choice personality measure development: Implications for reducing score inflation and providing trait-level information, Human Performance, 23, 4, pp. 323-342, (2010); Dumas, Jean E., Likableness, familiarity, and frequency of 844 person-descriptive words, Personality and Individual Differences, 32, 3, pp. 523-531, (2002); Social Desirability Variable in Personality Assessment and Research, (1957)","","Elsevier Ltd","","","","","","01918869","","PEIDD","","English","Article","Final","","Scopus","2-s2.0-85163160558"
"N., Fu, Na; L., Geng, Liyan; J., Ma, Junhai; X., Ding, Xue","Fu, Na (57205579416); Geng, Liyan (54408260000); Ma, Junhai (56770281700); Ding, Xue (58489747300)","57205579416; 54408260000; 56770281700; 58489747300","Price, Complexity, and Mathematical Model","2023","Mathematics","11","13","2883","","","0","1","10.3390/math11132883","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164935592&doi=10.3390%2Fmath11132883&partnerID=40&md5=bff75db5bc12fa8aa9e75c21be1e1ed5","Tianjin University, Tianjin, China; Tianjin Agricultural University, Tianjin, China; Shijiazhuang Tiedao University, Shijiazhuang, China","Fu, Na, Department of Management and Economics, Tianjin University, Tianjin, China, Tianjin Agricultural University, Tianjin, China; Geng, Liyan, School of Management, Shijiazhuang Tiedao University, Shijiazhuang, China; Ma, Junhai, Department of Management and Economics, Tianjin University, Tianjin, China; Ding, Xue, Department of Management and Economics, Tianjin University, Tianjin, China","The whole world has entered the era of the Vuca. Some traditional methods of problem analysis begin to fail. Complexity science is needed to study and solve problems from the perspective of complex systems. As a complex system full of volatility and uncertainty, price fluctuations have attracted wide attention from researchers. Therefore, through a literature review, this paper analyzes the research on complex theories on price prediction. The following conclusions are drawn: (1) The price forecast receives widespread attention year by year, and the number of published articles also shows a rapid rising trend. (2) The hybrid model can achieve higher prediction accuracy than the single model. (3) The complexity of models is increasing. In the future, the more complex methods will be applied to price forecast, including AI technologies such as LLM. (4) Crude-oil prices and stock prices will continue to be the focus of research, with carbon prices, gold prices, Bitcoin, and others becoming new research hotspots. The innovation of this research mainly includes the following three aspects: (1) The whole analysis of all the articles on price prediction using mathematical models in the past 10 years rather than the analysis of a single field such as oil price or stock price. (2) Classify the research methods of price forecasting in different fields, and found the common problems of price forecasting in different fields (including data processing methods and model selection, etc.), which provide references for different researchers to select price forecasting models. (3) Use VOSviewer to analyze the hot words appearing in recent years according to the timeline, find the research trend, and provide references for researchers to choose the future research direction. © 2023 Elsevier B.V., All rights reserved.","Algorithm; Chaos; Complexity; Fluctuate; Mathematic; Price; Volatility","","","","This research was funded by Tianjin Philosophy and Social Science Planning Project, fund number TJGL22-015.","Wu, Fang, The equilibrium, complexity analysis and control in epiphytic supply chain with product horizontal diversification, Nonlinear Dynamics, 93, 4, pp. 2145-2158, (2018); Ma, Junhai, A time-based pricing game in a competitive vehicle market regarding the intervention of carbon emission reduction, Energy Policy, 142, (2020); Wu, Fang, The complex evolution of information quality improvement in competitive market, RAIRO - Operations Research, 57, 2, pp. 351-369, (2023); Ma, Junhai, Complexity and Hopf bifurcation analysis on a kind of fractional-order IS-LM macroeconomic system, International Journal of Bifurcation and Chaos, 26, 11, (2016); Wu, Fang, Research Trend, Logical Structure and Outlook on Complex Economic Game, Mathematics, 11, 5, (2023); Ma, Junhai, Dynamic Pricing Game under Different Channel Power Structures in a Closed-Loop Supply Chain, International Journal of Bifurcation and Chaos, 30, 4, (2020); Ma, Junhai, Bullwhip effect and complexity analysis in a multi-channel supply chain considering price game with discount sensitivity, International Journal of Production Research, 57, 17, pp. 5432-5452, (2019); Ma, Junhai, Studying the Complexity of Multichannel Supply Chain with Different Power Structures under Carbon Subsidy Policy, International Journal of Bifurcation and Chaos, 31, 11, (2021); Ma, Junhai, Pricing strategy and coordination of automobile manufacturers based on government intervention and carbon emission reduction, Energy Policy, 148, (2021); Fan, Xinghua, Chaotic characteristic identification for carbon price and an multi-layer perceptron network prediction model, Expert Systems with Applications, 42, 8, pp. 3945-3952, (2015)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","22277390","","","","English","Review","Final","All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access","Scopus","2-s2.0-85164935592"
"M., Stanojević, Milǒs; J.R., Brennan, Jonathan R.; D.G., Dunagan, Donald G.; M.J., Steedman, Mark J.; J.T., Hale, John T.","Stanojević, Milǒs (56577734500); Brennan, Jonathan R. (55426863500); Dunagan, Donald G. (57223809178); Steedman, Mark J. (6602901918); Hale, John T. (14015526600)","56577734500; 55426863500; 57223809178; 6602901918; 14015526600","Modeling Structure-Building in the Brain With CCG Parsing and Large Language Models","2023","Cognitive Science","47","7","e13312","","","0","22","10.1111/cogs.13312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164272338&doi=10.1111%2Fcogs.13312&partnerID=40&md5=25337d6b7d27702b072033d63a92a8ae","DeepMind Technologies Limited, London, United Kingdom; University of Michigan, Ann Arbor, Ann Arbor, United States; University of Georgia, Athens, United States; The University of Edinburgh, Edinburgh, United Kingdom","Stanojević, Milǒs, DeepMind Technologies Limited, London, United Kingdom; Brennan, Jonathan R., Department of Linguistics, University of Michigan, Ann Arbor, Ann Arbor, United States; Dunagan, Donald G., Department of Linguistics, University of Georgia, Athens, United States; Steedman, Mark J., The University of Edinburgh, Edinburgh, United Kingdom; Hale, John T., DeepMind Technologies Limited, London, United Kingdom, Department of Linguistics, University of Georgia, Athens, United States","To model behavioral and neural correlates of language comprehension in naturalistic environments, researchers have turned to broad-coverage tools from natural-language processing and machine learning. Where syntactic structure is explicitly modeled, prior work has relied predominantly on context-free grammars (CFGs), yet such formalisms are not sufficiently expressive for human languages. Combinatory categorial grammars (CCGs) are sufficiently expressive directly compositional models of grammar with flexible constituency that affords incremental interpretation. In this work, we evaluate whether a more expressive CCG provides a better model than a CFG for human neural signals collected with functional magnetic resonance imaging (fMRI) while participants listen to an audiobook story. We further test between variants of CCG that differ in how they handle optional adjuncts. These evaluations are carried out against a baseline that includes estimates of next-word predictability from a transformer neural network language model. Such a comparison reveals unique contributions of CCG structure-building predominantly in the left posterior temporal lobe: CCG-derived measures offer a superior fit to neural signals compared to those derived from a CFG. These effects are spatially distinct from bilateral superior temporal effects that are unique to predictability. Neural effects for structure-building are thus separable from predictability during naturalistic listening, and those effects are best characterized by a grammar whose expressive power is motivated on independent linguistic grounds. © 2023 Elsevier B.V., All rights reserved.","Fmri; Grammar; Language Modeling; Neural Networks; Parsing; Surprisal; Syntax; Brain; Brain Mapping; Comprehension; Diagnostic Imaging; Hearing; Human; Language; Linguistics; Auditory Perception; Brain; Brain Mapping; Comprehension; Humans; Language; Linguistics","brain; brain mapping; comprehension; diagnostic imaging; hearing; human; language; linguistics; Auditory Perception; Brain; Brain Mapping; Comprehension; Humans; Language; Linguistics","","","This material is based upon work supported by the National Science Foundation under grant numbers 1903783 (JTH) and 1607251 (JRB). We are grateful to Laura Rimell and Chris Dyer for comments on an earlier version of this work. Thanks to Shohini Bhattasali, Jixing Li, Nathan Spreng, and Wen\u2010Ming Luh for supporting data collection and curation and also to Luca Campanelli for help with early analyses of these data.","Abney, Steven P., Memory requirements and local ambiguities of parsing strategies, Journal of Psycholinguistic Research, 20, 3, pp. 233-250, (1991); Abraham, Alexandre, Machine learning for neuroimaging with scikit-learn, Frontiers in Neuroinformatics, 8, FEB, (2014); Altmann, Gerry T.M., Interaction with context during human sentence processing, Cognition, 30, 3, pp. 191-238, (1988); Amici, Serena, Anatomical correlates of sentence comprehension and verbal working memory in neurodegenerative disease, Journal of Neuroscience, 27, 23, pp. 6282-6290, (2007); Barker, Chris, Direct Compositionality, pp. 1-439, (2023); Bemis, Douglas Knox, Simple composition: A magnetoencephalography investigation into the comprehension of minimal linguistic phrases, Journal of Neuroscience, 31, 8, pp. 2801-2814, (2011); Everyday Language Input and Production in 1001 Children from 6 Continents, (2022); Grammatical Basis of Linguistic Performance, (1984); Bhattasali, Shohini, Localising memory retrieval and syntactic composition: an fMRI study of naturalistic language comprehension, Language, Cognition and Neuroscience, 34, 4, pp. 491-510, (2019); Bracketing Guidelines for Treebank II Style Penn Treebank Project, (1995)","","John Wiley and Sons Inc","","","","","","15516709; 03640213","","COGSD","37417470","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85164272338"
"Y., Wang, Yiding; K., Chen, Kai; H., Tan, Haisheng; K., Guo, Kun","Wang, Yiding (57215122155); Chen, Kai (56275702700); Tan, Haisheng (22936378500); Guo, Kun (35793494900)","57215122155; 56275702700; 22936378500; 35793494900","Tabi: An Efficient Multi-Level Inference System for Large Language Models","2023","","","","","233","248","0","50","10.1145/3552326.3587438","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160213896&doi=10.1145%2F3552326.3587438&partnerID=40&md5=28864125238be20f4e44e3605ac74a82","Hong Kong University of Science and Technology, Hong Kong, Hong Kong; University of Science and Technology of China, Hefei, China; Fuzhou University, Fuzhou, China","Wang, Yiding, ISING Lab, Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Chen, Kai, ISING Lab, Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Tan, Haisheng, University of Science and Technology of China, Hefei, China; Guo, Kun, Fuzhou University, Fuzhou, China","Today’s trend of building ever larger language models (LLMs), while pushing the performance of natural language processing, adds significant latency to the inference stage. We observe that due to the diminishing returns of adding parameters to LLMs, a smaller model could make the same prediction as a costly LLM for a majority of queries. Based on this observation, we design Tabi, an inference system with a multi-level inference engine that serves queries using small models and optional LLMs for demanding applications. Tabi is optimized for discriminative models (i.e., not generative LLMs) in a serving framework. Tabi uses the calibrated confidence score to decide whether to return the accurate results of small models extremely fast or re-route them to LLMs. For re-routed queries, it uses attention-based word pruning and weighted ensemble techniques to offset the system overhead and accuracy loss. We implement and evaluate Tabi with multiple tasks and models. Our result shows that Tabi achieves 21%-40% average latency reduction (with comparable tail latency) over the state-of-the-art while meeting LLM-grade high accuracy targets. © 2023 Elsevier B.V., All rights reserved.","Attention-based Transformer; Machine Learning Inference; Computational Linguistics; Learning Algorithms; Natural Language Processing Systems; Attention-based Transformer; Inference Stages; Inference Systems; Language Model; Language Processing; Machine Learning Inference; Machine-learning; Multilevels; Natural Languages; Performance; Machine Learning","Computational linguistics; Learning algorithms; Natural language processing systems; Attention-based transformer; Inference stages; Inference systems; Language model; Language processing; Machine learning inference; Machine-learning; Multilevels; Natural languages; Performance; Machine learning","","","We thank the anonymous EuroSys reviewers and our shepherd Dr. Somali Chaterji for their constructive feedback and suggestions. This work is supported in part by the Key-Area R&D Program of Guangdong Province (2021B0101400001), the Hong Kong RGC TRS T41-603/20-R, GRF-16213621, ITF-ACCESS, the NSFC Grant 62062005, and the Turing AI Computing Cloud (TACC) [82]. Haisheng Tan is partly supported by the NSFC Grant 62132009, and Kun Guo is partly supported by the Natural Science Foundation of Fujian Province Grant No.2022J01118. We thank Yilun Jin and Han Tian for providing valuable feedback regarding the early idea. Kai Chen is the corresponding author.","undefined; Huggingface Models; Huggingface Tokenizers; Huggingface Transformers; undefined; undefined; undefined; Ali, Ahsan, Batch: Machine learning inference serving on serverless platforms with adaptive batching, International Conference for High Performance Computing, Networking, Storage and Analysis, SC, 2020-November, (2020); Bender, Emily M., On the dangers of stochastic parrots: Can language models be too big?, pp. 610-623, (2021); Proceedings of the 34th International Conference on Machine Learning, (2017)","","Association for Computing Machinery, Inc","Ant Group Research; et al.; Google; Huawei; KAUST; Meta","18th European Conference on Computer Systems, EuroSys 2023","","Rome","188495","","9781450394871","","","English","Conference paper","Final","All Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85160213896"
"J., Ren, Jie; Y., Zhao, Yao; T., Vu, Tu; P.J., Liu, Peter J.; B., Lakshminarayanan, Balaji","Ren, Jie (58728918100); Zhao, Yao (57219584382); Vu, Tu (57216431009); Liu, Peter J. (57200337917); Lakshminarayanan, Balaji (57213686205)","58728918100; 57219584382; 57216431009; 57200337917; 57213686205","Self-Evaluation Improves Selective Generation in Large Language Models","2023","Proceedings of Machine Learning Research","239","","","49","64","0","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196140051&partnerID=40&md5=9af95eacc8da244898e53d3c7a58d72f","DeepMind Technologies Limited, London, United Kingdom; Google LLC, Mountain View, United States","Ren, Jie, DeepMind Technologies Limited, London, United Kingdom; Zhao, Yao, DeepMind Technologies Limited, London, United Kingdom; Vu, Tu, Google LLC, Mountain View, United States; Liu, Peter J., DeepMind Technologies Limited, London, United Kingdom; Lakshminarayanan, Balaji, DeepMind Technologies Limited, London, United Kingdom","Safe deployment of large language models (LLMs) may benefit from a reliable method for assessing their generated content to determine when to abstain or to selectively generate. While likelihood-based metrics such as perplexity are widely employed, recent research has demonstrated the limitations of using sequence-level probability estimates given by LLMs as reliable indicators of generation quality. Conversely, LLMs have demonstrated strong calibration at the token level, particularly when it comes to choosing correct answers in multiple-choice questions or evaluating true/false statements. In this work, we reformulate open-ended generation tasks into token-level prediction tasks, and leverage LLMs’ superior calibration at the token level. We instruct an LLM to self-evaluate its answers, employing either a multi-way comparison or a point-wise evaluation approach, with the option to include a “None of the above” option to express the model’s uncertainty explicitly. We benchmark a range of scoring methods based on self-evaluation and evaluate their performance in selective generation using TRUTHFULQA and TL;DR. Through experiments with PALM-2 and GPT-3, we demonstrate that self-evaluation based scores not only improve accuracy, but also correlate better with the overall quality of generated content. © 2024 Elsevier B.V., All rights reserved.","Benchmarking; Computational Linguistics; Quality Control; Evaluation Approach; Language Model; Multiple-choice Questions; Point Wise; Prediction Tasks; Probability Estimate; Recent Researches; Reliable Methods; Selective Generation; Self Evaluation; Calibration","Benchmarking; Computational linguistics; Quality control; Evaluation approach; Language model; Multiple-choice questions; Point wise; Prediction tasks; Probability estimate; Recent researches; Reliable methods; Selective generation; Self evaluation; Calibration","","","","Towards A Human Like Open Domain Chatbot, (2020); Can Nlp Models Identify Distinguish and Justify Questions that Don T have A Definitive Answer, (2023); Constitutional Ai Harmlessness from Ai Feedback, (2022); Universal Self Consistency for Large Language Model Generation, (2023); Scaling Instruction Finetuned Language Models, (2022); Selectively Answering Ambiguous Questions, (2023); Bert Pre Training of Deep Bidirectional Transformers for Language Understanding, (2018); On Calibration of Modern Neural Networks, (2017); Scaling Out of Distribution Detection for Real World Settings, (2019); Language Models Mostly Know What They Know, (2022)","Antoran, J.; Blaas, A.; Buchanan, K.; Feng, F.; Fortuin, V.; Ghalebikesabi, S.; Kriegler, A.; Mason, I.; Rohde, D.; Ruiz, F.J.R.; Uelwer, T.; Xie, Y.; Yang, R.","ML Research Press","","4th ""I Can't Believe It's Not Better: Failure Modes in the Age of Foundation Models"" at NeurIPS Workshops","","New Orleans; LA","200095","26403498","9781713845065","","","English","Conference paper","Final","","Scopus","2-s2.0-85196140051"
"M., Murata, Masaki","Murata, Masaki (35734565400)","35734565400","Content Analysis of Items in Newspaper Data Using Table Arrangement Technology and ChatGPT for Stock Price Prediction","2023","","","","","1826","1833","0","1","10.1109/CSCE60160.2023.00302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191150999&doi=10.1109%2FCSCE60160.2023.00302&partnerID=40&md5=bcde55767d38f7deaffafae284c25556","Tottori University, Tottori, Japan","Murata, Masaki, Tottori University, Tottori, Japan","In this study, we employed table arrangement techniques and ChatGPT to analyze newspaper content relevant to stock prices. Using table arrangement techniques, we effectively organized sentences from articles into tables, extracting 22 key content elements. Additionally, we discovered that ChatGPT possesses the ability to extract and present newspaper data in tabular form. Factors were found to influence stock price movements. Drops in stock prices were impacted by factors such as crude oil prices, and the COVID-19 pandemic. Conversely, rising stock prices were supported by global trends, and vac-cine effectiveness. Furthermore, we propose a highly effective, large-scale method for constructing tables by combining table arrangement techniques and ChatGPT. The proposed method achieves an accuracy rate of 0.95 under a lenient criterion. © 2024 Elsevier B.V., All rights reserved.","Chatgpt; Content Analysis; Newspaper Data; Regular Research Paper; Stock Prices; Table Arrangement; Covid-19; Financial Markets; Newsprint; Chatgpt; Content Analysis; Crude Oil Prices; Newspaper Data; Regular Research Paper; Research Papers; Stock Price; Stock Price Movements; Stock Price Prediction; Table Arrangement; Costs","COVID-19; Financial markets; Newsprint; ChatGPT; Content analysis; Crude oil prices; Newspaper data; Regular research paper; Research papers; Stock price; Stock price movements; Stock price prediction; Table arrangement; Costs","","","This study was conducted with grant support from the Ishii Memorial Securities Research Promotion Foundation.","Bollen, Johan, Twitter mood predicts the stock market, Journal of Computational Science, 2, 1, pp. 1-8, (2011); Lee, Heeyoung, On the importance of text analysis for stock price prediction, pp. 1170-1175, (2014); Khadjeh Nassirtoussi, Arman K., Text mining for market prediction: A systematic review, Expert Systems with Applications, 41, 16, pp. 7653-7670, (2014); Akita, Ryo, Deep learning for stock prediction using numerical and textual information, (2016); 26th Annual Meeting of the Association for Natural Language Processing, (2020); Journal of Natural Language Processing, (2021); Wu, Xueqing, Text-to-Table: A New Way of Information Extraction, Proceedings of the Annual Meeting of the Association for Computational Linguistics, 1, pp. 2518-2533, (2022); Chatgpt, (2022); Training Language Models to Follow Instructions with Human Feedback, (2022); Workshop on Information Extraction for the 6th Annual Meeting of the Association for Natural Language Processing, (2000)","","Institute of Electrical and Electronics Engineers Inc.","American Council on Science and Education","2023 Congress in Computer Science, Computer Engineering, and Applied Computing, CSCE 2023","","Las Vegas; NV","198742","","9798350327595","","","English","Conference paper","Final","","Scopus","2-s2.0-85191150999"
"","","","2023 IEEE International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE 2023","2023","Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WET ICE","","","","","","235","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190369483&partnerID=40&md5=fab2f5138cd48350e29e111209e1300f","","","The proceedings contain 36 papers. The topics discussed include: an approach for software development effort estimation using ChatGPT; bitcoin transactions types and their impact on storage scalability; security-based multipath route switching protocol for quality-of-service enhancement in VANETs using Wiedemann car-following model; performance evaluation of container management tasks in OS-level Virtualization Platforms; Virtual Collaborative Assembly System Based on Unity; DeepChain: a deep learning and blockchain based framework for detecting risky transactions on hie system; a hybrid-DLT based trustworthy AI framework; a smart mining strategy for blockchain-enabled cyber-physical systems; and collisions-resistant hash function based on a logistics map. © 2024 Elsevier B.V., All rights reserved.","","","","","","","","IEEE Computer Society","","2023 IEEE International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE 2023","","Paris","198476","15244547","0769528791; 0769512690; 0769526233; 0769519636; 9798331505875; 9780769550022; 9780769526232; 9781479942497; 0769523625; 9780769547176","PETEF","","English","Conference review","Final","","Scopus","2-s2.0-85190369483"
"M., Turpin, Miles; J., Michael, Julian; E., Perez, Ethan; S.R., Bowman, Samuel R.","Turpin, Miles (58306438100); Michael, Julian (57191107268); Perez, Ethan (57204288235); Bowman, Samuel R. (57155948600)","58306438100; 57191107268; 57204288235; 57155948600","Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting","2023","Advances in Neural Information Processing Systems","36","","","","","0","110","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188265330&partnerID=40&md5=f84d06f55e768fe53e6850e298783fbd","NYU Alignment Research Group, United States; Cohere, Palo Alto, United States; Anthropic, San Francisco, United States","Turpin, Miles, NYU Alignment Research Group, United States, Cohere, Palo Alto, United States; Michael, Julian, NYU Alignment Research Group, United States; Perez, Ethan, NYU Alignment Research Group, United States, Anthropic, San Francisco, United States; Bowman, Samuel R., NYU Alignment Research Group, United States, Anthropic, San Francisco, United States","Large Language Models (LLMs) can achieve strong performance on many tasks by producing step-by-step reasoning before giving a final output, often referred to as chain-of-thought reasoning (CoT). It is tempting to interpret these CoT explanations as the LLM's process for solving a task. This level of transparency into LLMs' predictions would yield significant safety benefits. However, we find that CoT explanations can systematically misrepresent the true reason for a model's prediction. We demonstrate that CoT explanations can be heavily influenced by adding biasing features to model inputs-e.g., by reordering the multiple-choice options in a few-shot prompt to make the answer always “(A)”-which models systematically fail to mention in their explanations. When we bias models toward incorrect answers, they frequently generate CoT explanations rationalizing those answers. This causes accuracy to drop by as much as 36% on a suite of 13 tasks from BIG-Bench Hard, when testing with GPT-3.5 from OpenAI and Claude 1.0 from Anthropic. On a social-bias task, model explanations justify giving answers in line with stereotypes without mentioning the influence of these social biases. Our findings indicate that CoT explanations can be plausible yet misleading, which risks increasing our trust in LLMs without guaranteeing their safety. Building more transparent and explainable systems will require either improving CoT faithfulness through targeted efforts or abandoning CoT in favor of alternative methods. © 2025 Elsevier B.V., All rights reserved.","Bias Modeling; Language Model; Model Inputs; Model Prediction; Multiple Choice; Performance; Safety Benefits; Task Modelling; Computational Linguistics","Bias modeling; Language model; Model inputs; Model prediction; Multiple choice; Performance; Safety benefits; Task modelling; Computational linguistics","","","We thank Peter Hase, Tamera Lanham, David Rein, Leo Gao, and Jacob Pfau for helpful discussions and feedback. This project has benefited from financial support to SB by Eric and Wendy Schmidt (made by recommendation of the Schmidt Futures program) and Open Philanthropy, and from in-kind support by Anthropic. This material is based upon work supported by the National Science Foundation under Grant Nos. 1922658 and 2046556. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.","A Stripped Down Version of Bbq is Included in the Big Bench Benchmark; undefined; If Explanations in the Few Shot Prompt Reference Multiple Choice Labels We Switch these Appropriately; undefined; No Cot Setting the Accuracy Difference is Just A Measure of the Model S Susceptibility to the Bias Since there is no Generated Explanation; Despite Being Instructed to Output A Single Answer Occasionally the Model Predicts both Answer Choices; Andreas, Jacob, Language Models as Agent Models, pp. 5798-5808, (2022); Meet Claude, (2023); Constitutional Ai Harmlessness from Ai Feedback, (2022); Burns, Collin, DISCOVERING LATENT KNOWLEDGE IN LANGUAGE MODELS WITHOUT SUPERVISION, (2023)","Oh, A.; Neumann, T.; Globerson, A.; Saenko, K.; Hardt, M.; Levine, S.","Neural information processing systems foundation","","37th Conference on Neural Information Processing Systems, NeurIPS 2023","","New Orleans; LA; Ernest N. Morial Convention Center","198465","10495258","0262100762; 0262122413; 0262025507; 9780262232531; 0262042088; 9780262025508; 0262100657; 9781627480031; 0262194503; 9780262100656","","","English","Conference paper","Final","","Scopus","2-s2.0-85188265330"
"X., Yu, Xinli; Z., Chen, Zheng; Y., Lu, Yanbin","Yu, Xinli (58476742700); Chen, Zheng (59283740200); Lu, Yanbin (58315985200)","58476742700; 59283740200; 58315985200","Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting","2023","","","","","739","753","0","18","10.18653/v1/2023.emnlp-industry.69","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184667082&doi=10.18653%2Fv1%2F2023.emnlp-industry.69&partnerID=40&md5=a2096ecec89ed60cc40729ef88f593c7","","Yu, Xinli, ; Chen, Zheng, ; Lu, Yanbin, ","Applying machine learning to financial time series has been an active area of industrial research enabling innovation in market insights, risk management, strategic decision-making, and policy formation. This paper explores the novel use of Large Language Models (LLMs) for explainable financial time series forecasting, addressing challenges in cross-sequence reasoning, multi-modal data integration, and result interpretation that are inherent in traditional approaches. Focusing on NASDAQ-100 stocks, we utilize public historical stock data, company metadata, and economic/financial news. Our experiments employ GPT-4 for zero-shot/few-shot inference and Open LLaMA for instruction-based fine-tuning. The study demonstrates LLMs' ability to generate well-reasoned decisions by leveraging cross-sequence information and extracting insights from text and price time series. We show that our LLM-based approach outperforms classic ARMA-GARCH and gradient-boosting tree models. Furthermore, fine-tuned public LLMs, such as Open-LLaMA, can generate reasonable and explainable forecasts, although they underperform compared to GPT-4. © 2025 Elsevier B.V., All rights reserved.","Data Integration; Decision Making; Financial Data Processing; Financial Markets; Forecasting; Industrial Research; Time Series; Active Area; Decision Policy; Financial Time Series; Financial Time Series Forecasting; Language Model; Machine-learning; Policy Formation; Risks Management; Strategic Decision Making; Temporal Data; Risk Management","Data integration; Decision making; Financial data processing; Financial markets; Forecasting; Industrial research; Time series; Active area; Decision policy; Financial time series; Financial time series forecasting; Language model; Machine-learning; Policy formation; Risks management; Strategic decision making; Temporal Data; Risk management","","","","Aghabozorgi, Saeed Reza, Time-series clustering - A decade review, Information Systems, 53, pp. 16-38, (2015); Handbook of Financial Time Series, (2009); International Journal of Advanced Networking and Applications, (2012); Bahrammirzaee, Arash, A comparative survey of artificial intelligence applications in finance: Artificial neural networks, expert system and hybrid intelligent systems, Neural Computing and Applications, 19, 8, pp. 1165-1195, (2010); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Language Models are Few Shot Learners, (2020); Chen, Cathy W.S., A review of threshold time series models in finance, Statistics and its Interface, 4, 2, pp. 167-182, (2011); Chen, Zheng, Correlated Anomaly Detection from Large Streaming Data, pp. 982-992, (2018); Cheng, Dawei, Financial time series forecasting with multi-modality graph neural network, Pattern Recognition, 121, (2022); Vicuna an Open Source Chatbot Impressing Gpt 4 with 90 Chatgpt Quality, (2023)","Wang, M.; Zitouni, I.","Association for Computational Linguistics (ACL)","","2023 Conference on Empirical Methods in Natural Language Processing: Industry Track, EMNLP 2023","","Singapore","196541","","9788891760684","","","English","Conference paper","Final","All Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85184667082"
"J., Zhao, Jin; N., Xue, Nianwen; B., Min, Bonan","Zhao, Jin (57331632700); Xue, Nianwen (36777746400); Min, Bonan (23480129200)","57331632700; 36777746400; 23480129200","Cross-Document Event Coreference Resolution: Instruct Humans or Instruct GPT?","2023","","","","","561","574","0","3","10.18653/v1/2023.conll-1.38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184519713&doi=10.18653%2Fv1%2F2023.conll-1.38&partnerID=40&md5=30e15b2b77aa4b4c2d43628ff0c6315d","Brandeis University, Waltham, United States; Amazon AWS AI Labs","Zhao, Jin, Brandeis University, Waltham, United States; Xue, Nianwen, Brandeis University, Waltham, United States; Min, Bonan, Amazon AWS AI Labs","This paper explores utilizing Large Language Models (LLMs) to perform Cross-Document Event Coreference Resolution (CDEC) annotations and evaluates how they fare against human annotators with different levels of training. Specifically, we formulate CDEC as a multi-class classification problem on pairs of events that are represented as decontextualized sentences, and compare the predictions of GPT-4 with the judgment of fully trained annotators and crowdworkers on the same dataset. Our study indicates that GPT-4 with zero-shot learning outperformed crowd-workers by a large margin and exhibits a level of performance comparable to trained annotators. Upon closer analysis, GPT-4 also exhibits tendencies of being overly confident, and forcing annotation decisions even when such decisions are not warranted due to insufficient information. Our results have implications on how to perform complicated annotations such as CDEC in the age of LLMs, and show that the best way to acquire such annotations might be to combine the strengths of LLMs and trained human annotators in the annotation process, and using untrained or undertrained crowdworkers is no longer a viable option to acquire high-quality data to advance the state of the art for such problems. We make our source and data publicly available.1 © 2024 Elsevier B.V., All rights reserved.","Classification (of Information); Natural Language Processing Systems; Coreference Resolution; Cross Documents; Forcings; High Quality Data; Language Model; Large Margins; Multiclass Classification Problems; Performance; State Of The Art; Workers'; Zero-shot Learning","Classification (of information); Natural language processing systems; Coreference resolution; Cross documents; Forcings; High quality data; Language model; Large margins; Multiclass classification problems; Performance; State of the art; Workers'; Zero-shot learning","","","This research was supported by the CNS Division of the National Science Foundation (Awards No. 2213804, 2213805). We express our gratitude for their financial backing, which was pivotal in advancing our understanding of cross-document event coreference.","A Multitask Multilingual Multimodal Evaluation of Chatgpt on Reasoning Hallucination and Interactivity, (2023); Bugert, Michael, Event Coreference Data (Almost) for Free: Mining Hyperlinks from Online News, pp. 471-491, (2021); Caciularu, Avi, CDLM: Cross-Document Language Modeling, pp. 2648-2662, (2021); Choi, Eunsol, Decontextualization: Making sentences stand-alone, Transactions of the Association for Computational Linguistics, 9, pp. 447-461, (2021); Cybulska, Agata, Using a sledgehammer to crack a nut? Lexical diversity and event coreference resolution, pp. 4545-4552, (2014); Eirew, Alon, WEC: Deriving a Large-scale Cross-document Event Coreference dataset from Wikipedia, pp. 2498-2510, (2021); Fleiss, Joseph L., Measuring nominal scale agreement among many raters, Psychological Bulletin, 76, 5, pp. 378-382, (1971); Hong, Yu, Building a Cross-document Event-Event Relation Corpus, pp. 1-6, (2016); Huang, Fan, Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech, pp. 294-297, (2023); Lu, Chao Yi, A Survey of Approaches to Automatic Question Generation: from 2019 to Early 2021, pp. 151-162, (2021)","Jiang, J.; Reitter, D.; Deng, S.","Association for Computational Linguistics (ACL)","Google","27th Conference on Computational Natural Language Learning, CoNLL 2023","","Singapore","196534","","9798891760394","","","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85184519713"
"R., Shui, Ruihao; Y., Cao, Yixin; X., Wang, Xiang; T.S., Chua, Tat Seng","Shui, Ruihao (57219796517); Cao, Yixin (57015851100); Wang, Xiang (57191904438); Chua, Tat Seng (7101702977)","57219796517; 57015851100; 57191904438; 7101702977","A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction","2023","","","","","7337","7348","0","18","10.18653/v1/2023.findings-emnlp.490","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183296473&doi=10.18653%2Fv1%2F2023.findings-emnlp.490&partnerID=40&md5=b41748fdc69bac9c923ca5283d068409","National University of Singapore, Singapore City, Singapore; Singapore Management University, Singapore City, Singapore; University of Science and Technology, Hangzhou, China","Shui, Ruihao, National University of Singapore, Singapore City, Singapore; Cao, Yixin, Singapore Management University, Singapore City, Singapore; Wang, Xiang, University of Science and Technology, Hangzhou, China; Chua, Tat Seng, National University of Singapore, Singapore City, Singapore","Large language models (LLMs) have demonstrated great potential for domain-specific applications, such as the law domain. However, recent disputes over GPT-4's law evaluation raise questions concerning their performance in real-world legal tasks. To systematically investigate their competency in the law, we design practical baseline solutions based on LLMs and test on the task of legal judgment prediction. In our solutions, LLMs can work alone to answer open questions or coordinate with an information retrieval (IR) system to learn from similar cases or solve simplified multi-choice questions. We show that similar cases and multi-choice options, namely label candidates, included in prompts can help LLMs recall domain knowledge that is critical for expertise legal reasoning. We additionally present an intriguing paradox wherein an IR system surpasses the performance of LLM+IR due to limited gains acquired by weaker LLMs from powerful IR systems. In such cases, the role of LLMs becomes redundant. Our evaluation pipeline can be easily extended into other tasks to facilitate evaluations in other domains. Code is available at https://github.com/srhthu/LM-CompEval-Legal. © 2025 Elsevier B.V., All rights reserved.","Computational Linguistics; Domain Knowledge; Comprehensive Evaluation; Domain-specific Application; Information-retrieval Systems; Language Model; Law Evaluation; Legal Judgements; Multi Choices; Performance; Real-world; Similar Case; Search Engines","Computational linguistics; Domain Knowledge; Comprehensive evaluation; Domain-specific application; Information-retrieval systems; Language model; Law evaluation; Legal judgements; Multi choices; Performance; Real-world; Similar case; Search engines","","","We thank all reviewers for their constructive comments. This research is supported by NExT Research Center, the National Natural Science Foundation of China (9227010114) and the University Synergy Innovation Program of Anhui Province (GXXT-2022-040).","Borgeaud, Sebastian, Improving Language Models by Retrieving from Trillions of Tokens, Proceedings of Machine Learning Research, 162, pp. 2206-2240, (2022); Brown, Tom B., Language models are few-shot learners, Advances in Neural Information Processing Systems, 2020-December, (2020); Chalkidis, Ilias, Neural legal judgment prediction in English, pp. 4317-4323, (2020); Vicuna an Open Source Chatbot Impressing Gpt 4 with 90 Chatgpt Quality, (2023); Christiano, Paul F., Deep reinforcement learning from human preferences, Advances in Neural Information Processing Systems, 2017-December, pp. 4300-4308, (2017); Bert Pre Training of Deep Bidirectional Transformers for Language Understanding, (2018); Du, Zhengxiao, GLM: General Language Model Pretraining with Autoregressive Blank Infilling, Proceedings of the Annual Meeting of the Association for Computational Linguistics, 1, pp. 320-335, (2022); Measuring Massive Multitask Language Understanding, (2020); Distilling the Knowledge in A Neural Network, (2015); Jiang, Zhengbao, How can we know when language models know? On the calibration of language models for question answering, Transactions of the Association for Computational Linguistics, 9, pp. 962-977, (2021)","","Association for Computational Linguistics (ACL)","Apple; Colossal-AI; et al.; Google Research; GTCOM; King Salman Global Academy for Arabic Language","2023 Findings of the Association for Computational Linguistics: EMNLP 2023","","Hybrid","196127","","9798891760615","","","English","Conference paper","Final","All Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85183296473"
"S., Akhouri, Shivam; V., Ajbani, Vidhi; R., Lakshminarayanan, Ritika; T.N., Pandey, Trilok Nath; M.S., Nigam, Meher Shrishti; S.S., Shekhar Patra, Sudhansu Shekhar","Akhouri, Shivam (58045956200); Ajbani, Vidhi (58837864100); Lakshminarayanan, Ritika (58837365700); Pandey, Trilok Nath (57201073039); Nigam, Meher Shrishti (58514782400); Shekhar Patra, Sudhansu Shekhar (56926181800)","58045956200; 58837864100; 58837365700; 57201073039; 58514782400; 56926181800","An Imperial Analysis of Large Language Models for Automated Tweet Sentiment Prediction","2023","","","","","182","188","0","0","10.1109/ICSCNA58489.2023.10370253","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182994689&doi=10.1109%2FICSCNA58489.2023.10370253&partnerID=40&md5=d9b14b4cd833246e24486ac6a7b66a60","Vellore Institute of Technology, Chennai, Chennai, India; Kalinga Institute of Industrial Technology, Bhubaneswar, Bhubaneswar, India","Akhouri, Shivam, Vellore Institute of Technology, Chennai, Chennai, India; Ajbani, Vidhi, Vellore Institute of Technology, Chennai, Chennai, India; Lakshminarayanan, Ritika, Vellore Institute of Technology, Chennai, Chennai, India; Pandey, Trilok Nath, Vellore Institute of Technology, Chennai, Chennai, India; Nigam, Meher Shrishti, Vellore Institute of Technology, Chennai, Chennai, India; Shekhar Patra, Sudhansu Shekhar, School of Computer Applications, Kalinga Institute of Industrial Technology, Bhubaneswar, Bhubaneswar, India","Company' s brand perception majorly depends on customer experience and the reviews which follow that. A customer is capable of influencing many more people just on the basis of reviews given by him/her. Google released Pathways Language Model (PaLM) which is a major advancement in Artificial Intelligence (AI). It has been trained with the Pathways System, which allows it to generalize tasks in various domains. In this work, a trustworthy platform is provided for the examination of millions of people's continually moving and changing perspectives. Twitter data is captured, and effective sentiment and data analysis is used to generate trustworthy and helpful info graphics reflecting public opinion. Product sales, stock returns, election outcomes, and other commercial and social events may all be predicted and explained using the information found in tweets. Brands, product manufacturers, and other companies may utilise the information derived from data analysis to better understand their brand image, expand their market share by targeting the relevant demographics at the right moments, and enhance their offerings in terms of both quality and customer service. © 2024 Elsevier B.V., All rights reserved.","Attention Units; Data Visualization; Masks; Sentiment Analysis; Tokenization; Competition; Data Handling; Data Visualization; Image Enhancement; Investments; Quality Control; Sales; Social Aspects; Attention Unit; Customer Experience; Google+; Language Model; Product Sales; Public Opinions; Sentiment Analysis; Social Events; Stock Returns; Tokenization","Competition; Data handling; Data visualization; Image enhancement; Investments; Quality control; Sales; Social aspects; Attention unit; Customer experience; Google+; Language model; Product sales; Public opinions; Sentiment analysis; Social events; Stock returns; Tokenization","","","","Philander, Kahlil S., Twitter sentiment analysis: Capturing sentiment from integrated resort tweets, International Journal of Hospitality Management, 55, pp. 16-24, (2016); Chamlertwat, Wilas, Discovering consumer insight from twitter via sentiment analysis, Journal of Universal Computer Science, 18, 8, pp. 973-992, (2012); Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Malo, Pekka, Good debt or bad debt: Detecting semantic orientations in economic texts, Journal of the Association for Information Science and Technology, 65, 4, pp. 782-796, (2014); Alsayat, Ahmed, Improving Sentiment Analysis for Social Media Applications Using an Ensemble Deep Learning Language Model, Arabian Journal for Science and Engineering, 47, 2, pp. 2499-2511, (2022); Liu, Kunlin, Emoticon smoothed language models for twitter sentiment analysis, Proceedings of the National Conference on Artificial Intelligence, 2, pp. 1678-1684, (2012); Azzouza, Noureddine, Twitterbert: Framework for twitter sentiment analysis based on pre-trained language model representations, Advances in Intelligent Systems and Computing, 1073, pp. 428-437, (2020); Xlm T Multilingual Language Models in Twitter for Sentiment Analysis and Beyond; Dombert Domain Oriented Language Model for Aspect Based Sentiment Analysis; Shim, Heereen, LETS: A Label-Efficient Training Scheme for Aspect-Based Sentiment Analysis by Using a Pre-Trained Language Model, IEEE Access, 9, pp. 115563-115578, (2021)","","Institute of Electrical and Electronics Engineers Inc.","","2023 International Conference on Sustainable Communication Networks and Application, ICSCNA 2023","","Theni","196100","","9798350313987","","","English","Conference paper","Final","","Scopus","2-s2.0-85182994689"
"M., Mateev, Mihail","Mateev, Mihail (57207859298)","57207859298","Predictive Analytics Based on Digital Twins, Generative AI, and ChatGPT","2023","Proceedings of World Multi-Conference on Systemics, Cybernetics and Informatics, WMSCI","2023-September","","","168","174","0","7","10.54808/WMSCI2023.01.168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178660815&doi=10.54808%2FWMSCI2023.01.168&partnerID=40&md5=cf7dc43680388f6f2d1b4355d0562c5b","University of Architecture, Civil Engineering and Geodesy, Sofia, Bulgaria","Mateev, Mihail, Department of Computer Aided Engineering, University of Architecture, Civil Engineering and Geodesy, Sofia, Bulgaria","ChatGPT (Chat Generative Pre-Trained Transformer) is one of the latest technologies in modern Artificial Intelligence (AI) and probably the technology with the highest impact in this area for the near future. The latest version of ChatGPT - GPT-4 has improved in several areas, including Predictive Analytics. Generative AI and Ghat GPT can be used in different areas - not only to generate human-like content easily but also in different business domains in the modern industry, like the construction industry. This research gives an overview of the application of Generative AI, particularly ChatGPT, for predictive analytics in different areas focusing on the construction and building industry. The paper analyzes options to use Generative AI together with another essential for modern analysis technology - Digital Twins in two different aspects: 1) To design and build systems for Predictive Analytics 2) To implement Cognitive Digital Twins, The research used prototypes based on Microsoft Power Platform (Power Virtual Agents, Power Automate), Open AI, and Azure Digital Twins, which can offer predictive analytics in the construction industry. The article includes results, providing information about cost savings and time reduction when using Generative AI for predictive analytics in the construction industry. © 2023 Elsevier B.V., All rights reserved.","Ai; Artificial Intelligence; Chatgpt; Digital Twin; Generative Ai; Gpt-4; Industry 4.0; Iot; Machine Learning; Predictive Analytics; Cognitive Systems; Construction Industry; E-learning; Internet Of Things; Learning Systems; Machine Learning; Predictive Analytics; Business Domain; Chat Generative Pre-trained Transformer; Generative Artificial Intelligence; Gpt-4; High Impact; Human Like; Iot; Latest Technology; Machine-learning; Power; Industry 4.0","Cognitive systems; Construction industry; E-learning; Internet of things; Learning systems; Machine learning; Predictive analytics; Business domain; Chat generative pre-trained transformer; Generative artificial intelligence; GPT-4; High impact; Human like; IoT; Latest technology; Machine-learning; Power; Industry 4.0","","","","Gpt 4 Generative Pre Trained Transformer 4, (2023); Gpt 4 Technical Report, (2023); Imitating Human Behaviour with Diffusion Models, (2023); Industry 4 0, (2020); Microsoft Research, (2018); Microsoft Research, (2023); Openai Chatgpt Generated Literature Review Digital Twin in Healthcare, (2022); Yitmen, Ibrahim, An adapted model of cognitive digital twins for building lifecycle management, Applied Sciences (Switzerland), 11, 9, (2021); Arxiv Org, (2016); Medium, (2022)","Callaos, N.; Gaile-Sarkane, E.; Hashimoto, S.; Lace, N.; Sanchez, B.; Savoie, M.","International Institute of Informatics and Cybernetics","et al.; Google; International Academy for Systems and Cybernetic Sciences (IASCYS); International Institute of Informatics and Systemics (IIIS); MITRE Corporation; The Standish Group","27th World Multi-Conference on Systemics, Cybernetics and Informatics, WMSCI 2023","","Virtual, Online","194591","27710947","9781950492664; 9781950492640; 9781713880325; 9781950492657; 9781950492794","","","English","Conference paper","Final","","Scopus","2-s2.0-85178660815"
"","","","8th China Conference on Knowledge Graph and Semantic Computing, CCKS 2023","2023","Communications in Computer and Information Science","1923 CCIS","","","","","361","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176944442&partnerID=40&md5=31c7f557ca86da031421f9b1bdf59b96","","","The proceedings contain 28 papers. The special focus in this conference is on Knowledge Graph and Semantic Computing. The topics include: A Generalized Strategy of Chinese Grammatical Error Diagnosis Based on Task Decomposition and Transformation; conversational Search Based on Utterance-Mask-Passage Post-training; financial Fraud Detection Based on Deep Learning: Towards Large-Scale Pre-training Transformer Models; GERNS: A Graph Embedding with Repeat-Free Neighborhood Structure for Subgraph Matching Optimization; feature Enhanced Structured Reasoning for Question Answering; conditional Knowledge Graph: Design, Dataset and a Preliminary Model; ODKG: An Official Document Knowledge Graph for the Effective Management; CCD-ASQP: A Chinese Cross-Domain Aspect Sentiment Quadruple Prediction Dataset; move Structure Recognition in Scientific Papers with Saliency Attribution; causE: Towards Causal Knowledge Graph Embedding; Moral Essential Elements: MEE-A Dataset for Moral Judgement; improving Adaptive Knowledge Graph Construction via Large Language Models with Multiple Views; single Source Path-Based Graph Neural Network for Inductive Knowledge Graph Reasoning; a Graph Learning Based Method for Inductive Knowledge Graph Relation Prediction; LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base; Robust NL-to-Cypher Translation for KBQA: Harnessing Large Language Model with Chain of Prompts; in-Context Learning for Knowledge Base Question Answering for Unmanned Systems Based on Large Language Models; a Military Domain Knowledge-Based Question Answering Method Based on Large Language Model Enhancement; Advanced PromptCBLUE Performance: A Novel Approach Leveraging Large Language Models; exploring the Logical Expressiveness of Graph Neural Networks by Establishing a Connection with C<inf>2</inf> ; research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information; harvesting Event Schemas from Large Language Models; NTDA: Noise-Tolerant Data Augmentation for Document-Level Event Argument Extraction; Event-Centric Opinion Mining via In-Context Learning with ChatGPT; relation Repository Based Adaptive Clustering for Open Relation Extraction. © 2023 Elsevier B.V., All rights reserved.","","","","","","","Wang, H.; Han, X.; Liu, M.; Cheng, G.; Liu, Y.; Zhang, N.","Springer Science and Business Media Deutschland GmbH","","8th China Conference on Knowledge Graph and Semantic Computing, CCKS 2023","","Shenyang","304039","18650937; 18650929","9789819671748; 9789819664610; 9783032026743; 9783032008831; 9783032026712; 9789819671779; 9783031949425; 9789819666874; 9783031936968; 9783031941207","","","English","Conference review","Final","","Scopus","2-s2.0-85176944442"
"D.D., Johnson, Daniel D.; D., Tarlow, Daniel; C.J., Walder, Christian J.","Johnson, Daniel D. (57220839563); Tarlow, Daniel (36840330700); Walder, Christian J. (12141574600)","57220839563; 36840330700; 12141574600","R-U-SURE? Uncertainty-Aware Code Suggestions By Maximizing Utility Across Random User Intents","2023","Proceedings of Machine Learning Research","202","","","15262","15306","0","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174411111&partnerID=40&md5=0f692706f1ca31555627bfee9e9bfeb3","Google LLC, Mountain View, United States; University of Toronto, Toronto, Canada","Johnson, Daniel D., Google LLC, Mountain View, United States, University of Toronto, Toronto, Canada; Tarlow, Daniel, Google LLC, Mountain View, United States; Walder, Christian J., Google LLC, Mountain View, United States","Large language models show impressive results at predicting structured text such as code, but also commonly introduce errors and hallucinations in their output. When used to assist software developers, these models may make mistakes that users must go back and fix, or worse, introduce subtle bugs that users may miss entirely. We propose Randomized Utility-driven Synthesis of Uncertain REgions (R-U-SURE), an approach for building uncertainty-aware suggestions based on a decision-theoretic model of goal-conditioned utility, using random samples from a generative model as a proxy for the unobserved possible intents of the end user. Our technique combines minimum-Bayes-risk decoding, dual decomposition, and decision diagrams in order to efficiently produce structured uncertainty summaries, given only sample access to an arbitrary generative model of code and an optional AST parser. We demonstrate R-U-SURE on three developer-assistance tasks, and show that it can be applied different user interaction patterns without retraining the model and leads to more accurate uncertainty estimates than token-probability baselines. We also release our implementation as an open-source library at https://github.com/google-research/r_u_sure. © 2023 Elsevier B.V., All rights reserved.","Machine Learning; Open Source Software; Program Debugging; Decision-theoretic; End-users; Generative Model; Language Model; Random Sample; Random Users; Software Developer; Structured Text; Theoretic Model; Uncertainty; Uncertainty Analysis","Machine learning; Open source software; Program debugging; Decision-theoretic; End-users; Generative model; Language model; Random sample; Random users; Software developer; Structured text; Theoretic model; Uncertainty; Uncertainty analysis","","","We would like to thank Jacob Hegna, Hassan Abolhassani, Jacob Austin, and Marc Rasi for contributing ideas toward early designs of the R-U-SURE system, Maxim Tabachnyk, Chris Gorgolewski, Vladimir Pchelin, Yurun Chen, Ilia Krets, Savinee Dancs, Alberto Elizondo, Iris Chu, Ambar Murillo, Ryan McGarry, Paige Bailey, and Kathy Nix for useful discussions and for collaborating on code completion applications of R-U-SURE, and Miltiadis Allamanis for providing valuable feedback on the paper draft. We would also like to thank Abhishek Rao, Alex Polozov, Joshua Howland, Kefan Xiao, and Vedant Misra for providing the language models and evaluation data used for our experimental results, and the members of Google Brain's Machine Learning for Code team for useful feedback throughout the project.","Abbas, Ahmed, FastDOG: Fast Discrete Optimization on GPU, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2022-June, pp. 439-449, (2022); Allamanis, Miltiadis, Mining idioms from source code, 16-21-November-2014, pp. 472-483, (2014); A Gentle Introduction to Conformal Prediction and Distribution Free Uncertainty Quantification, (2021); Program Synthesis with Large Language Models, (2021); Training A Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback, (2022); Grounded Copilot how Programmers Interact with Code Generating Models, (2022); Bhattacharyya, Apratim, Accurate and Diverse Sampling of Sequences Based on a 'Best of Many' Sample Objective, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 8485-8493, (2018); Bhattacharyya, Sumanta, Energy-based reranking: Improving neural machine translation using energy-based models, 1, pp. 4528-4537, (2021); Theory of Computing Systems, (2018); Language Models are Few Shot Learners, (2020)","Krause, A.; Brunskill, E.; Cho, K.; Engelhardt, B.; Sabato, S.; Scarlett, J.","ML Research Press","","40th International Conference on Machine Learning, ICML 2023","","Honolulu; HI","191855","26403498","9781713845065","","","English","Conference paper","Final","","Scopus","2-s2.0-85174411111"
"B., Chen, Boyang; Z., Wu, Zongxiao; R., Zhao, Ruoran","Chen, Boyang (57748843700); Wu, Zongxiao (58531464900); Zhao, Ruoran (58531760100)","57748843700; 58531464900; 58531760100","From fiction to fact: the growing role of generative AI in business and finance","2023","Journal of Chinese Economic and Business Studies","21","4","","471","496","0","106","10.1080/14765284.2023.2245279","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167582269&doi=10.1080%2F14765284.2023.2245279&partnerID=40&md5=7f70054284b840517cd44aec690c97ba","China Agricultural University, Beijing, China; University of Edinburgh Business School, Edinburgh, United Kingdom","Chen, Boyang, China Agricultural University, Beijing, China, University of Edinburgh Business School, Edinburgh, United Kingdom; Wu, Zongxiao, University of Edinburgh Business School, Edinburgh, United Kingdom; Zhao, Ruoran, University of Edinburgh Business School, Edinburgh, United Kingdom","Generative Artificial Intelligence (AI), such as ChatGPT by OpenAI, has revolutionized the business world, with benefits including improved accessibility, efficiency, and cost reduction. This article reviews recent developments of generative AI in business and finance, summarizes its practical applications, provides examples of the latest generative AI tools, and demonstrates that generative AI can revolutionize data analysis in industry and academia. To test the ability of generative AI to support decision-making in financial markets, we use the ChatGPT to capture corporate sentiments towards environmental policy by inputting text extracted from corporate financial statements. Our results demonstrate that the sentiment scores generated by ChatGPT can predict firms’ risk-management capabilities and stock return performance. This study also highlights the potential challenges and limitations associated with generative AI. Finally, we propose several questions for future research at the intersection of generative AI with business and finance. © 2023 Elsevier B.V., All rights reserved.","Chatgpt; Generative Ai; Natural Language Processing; Practical Applications; Sentiment Analysis","","","","This study was supported by the State Scholarship Fund (No. 202206350067).","Agarwal, Sumit, The information value of credit rating action reports: A textual analysis, Management Science, 62, 8, pp. 2218-2240, (2016); Journal of Electronic Business Digital Economics, (2023); What Will Chatgpt Revolutionize in Financial Industry, (2023); Exploring the Role of Artificial Intelligence in Enhancing Academic Performance A Case Study of Chatgpt, (2022); An, Jiafu, ChatGPT: tackle the growing carbon footprint of generative AI, Nature, 615, 7953, (2023); Beam, Emily A., Social media as a recruitment and data collection tool: Experimental evidence on the relative effectiveness of web surveys and chatbots, Journal of Development Economics, 162, (2023); Generative Artificial Intelligence Gai Ethics Taxonomy Applying Chat Gpt for Robotic Process Automation Gai Rpa as Business Case, (2023); Beraja, Martin, Data-intensive Innovation and the State: Evidence from AI Firms in China, Review of Economic Studies, 90, 4, pp. 1701-1723, (2023); Generative AI at Work, (2023); Sparks of Artificial General Intelligence Early Experiments with Gpt 4, (2023)","","Routledge","","","","","","14765292; 14765284","","","","English","Article","Final","","Scopus","2-s2.0-85167582269"
"S., Sasubilli, Sravani; M., Verma, Mridula","Sasubilli, Sravani (58139777100); Verma, Mridula (57213336078)","58139777100; 57213336078","InFi-BERT 1.0: Transformer-Based Language Model for Indian Financial Volatility Prediction","2023","Communications in Computer and Information Science","1753 CCIS","","","128","138","0","0","10.1007/978-3-031-23633-4_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149910372&doi=10.1007%2F978-3-031-23633-4_10&partnerID=40&md5=993b7559b2d1c1b7a4a5a0e0e99b1b77","University of Hyderabad, Hyderabad, India; Institute for Development and Research in Banking Technology India, Hyderabad, India","Sasubilli, Sravani, University of Hyderabad, Hyderabad, India; Verma, Mridula, Institute for Development and Research in Banking Technology India, Hyderabad, India","In recent years, BERT-like pretrained neural language models have been successfully developed and utilized for multiple financial domain-specific tasks. These domain-specific pre-trained models are effective enough to learn the specialized language used in financial context. In this paper, we consider the task of textual regression for the purpose of forecasting financial volatility from financial texts, and designed Infi-BERT (Indian Financial BERT), a transformer-based pre-trained language model using domain-adaptive pre-training approach, which effectively learns linguistic-context from annual financial reports from Indian financial texts. In addition, we present the first Indian financial corpus for the task of volatility prediction. With detailed experimentation and result analysis, we demonstrated that our model outperforms the base model as well as the previous domain-specific models for financial volatility forecasting task. © 2023 Elsevier B.V., All rights reserved.","Domain-adaptive Pre-training; Financial Volatility Prediction; Indian Financial Corpus; Textual Regression; Transformer-based Models; Computational Linguistics; Finance; Domain Specific; Domain-adaptive Pre-training; Financial Domains; Financial Volatility Prediction; Indian Financial Corpus; Language Model; Learn+; Pre-training; Textual Regression; Transformer-based Model; Forecasting","Computational linguistics; Finance; Domain specific; Domain-adaptive pre-training; Financial domains; Financial volatility prediction; Indian financial corpus; Language model; Learn+; Pre-training; Textual regression; Transformer-based model; Forecasting","","","Supported by Ministry of Electronics and Information Technology (MeiTy), Government of India and IIT Bhilai Innovation and Technology Foundation (IBITF) under the project entitled ”Blockchain and Machine Learning Powered Unified Video KYC Framework”.","Finbert Financial Sentiment Analysis with Pre Trained Language Models, (2019); Arslan, Yusuf, A Comparison of Pre-Trained Language Models for Multi-Class Text Classification in the Financial Domain, 03-06-21, pp. 260-268, (2021); Au, Willy, FinSBD-2021: The 3rd Shared Task on Structure Boundary Detection in Unstructured Text in the Financial Domain, 03-06-21, pp. 276-279, (2021); Barbaglia, Luca, Financial Forecasting with Word Embeddings Extracted from News: A Preliminary Analysis, Communications in Computer and Information Science, 1525 CCIS, pp. 179-188, (2021); Stock Movement Prediction with Financial News Using Contextualized Embedding from Bert Arxiv Preprint Arxiv, (2021); De Stefani, Jacopo, Machine learning for multi-step ahead forecasting of volatility proxies, CEUR Workshop Proceedings, 1941, pp. 17-28, (2017); undefined; Corr, (2018); Don T Stop Pretraining Adapt Language Models to Domains and Tasks, (2020); Kogan, Shimon, Predicting risk from financial reports with regression, pp. 272-280, (2009)","Koprinska, I.; Mignone, P.; Guidotti, R.; Jaroszewicz, S.; Fröning, H.; Gullo, F.; Ferreira, P.M.; Roqueiro, D.; Ceddia, G.; Nowaczyk, S.; Gama, J.; Ribeiro, R.; Gavaldà, R.; Masciari, E.; Ras, Z.; Ritacco, E.; Naretto, F.; Theissler, A.; Biecek, P.; Verbeke, W.; Schiele, G.; Pernkopf, F.; Blott, M.; Bordino, I.; Danesi, I.L.; Ponti, G.; Severini, L.; Appice, A.; Andresini, G.; Medeiros, I.; Graça, G.; Cooper, L.; Ghazaleh, N.; Richiardi, J.; Saldana, D.; Sechidis, K.; Canakoglu, A.; Pido, S.; Pinoli, P.; Bifet, A.; Pashami, S.","Springer Science and Business Media Deutschland GmbH","","Workshops on SoGood, NFMCP, XKDD, UMOD, ITEM, MIDAS, MLCS, MLBEM, PharML, DALS, IoT-PdM 2022, held in conjunction with the 21st Joint European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2022","","Grenoble","290969","18650937; 18650929","9789819671748; 9789819664610; 9783032026743; 9783032008831; 9783032026712; 9789819671779; 9783031949425; 9789819666874; 9783031936968; 9783031941207","","","English","Conference paper","Final","","Scopus","2-s2.0-85149910372"
"J., Chen, Jia; T., Chen, Tao; M., Shen, Mengqi; Y., Shi, Yunhai; D., Wang, Dongjing; X., Zhang, Xin","Chen, Jia (59872701500); Chen, Tao (57747250000); Shen, Mengqi (57561903200); Shi, Yunhai (57562283600); Wang, Dongjing (55522665700); Zhang, Xin (56104504300)","59872701500; 57747250000; 57561903200; 57562283600; 55522665700; 56104504300","Gated three-tower transformer for text-driven stock market prediction","2022","Multimedia Tools and Applications","81","21","","30093","30119","0","11","10.1007/s11042-022-11908-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127604439&doi=10.1007%2Fs11042-022-11908-1&partnerID=40&md5=a9545ba8d78e109b45c8158321e5c1f4","Hangzhou Dianzi University, Hangzhou, China; Hangzhou Dianzi University, Hangzhou, China","Chen, Jia, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Chen, Tao, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Shen, Mengqi, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Shi, Yunhai, School of Media and Design, Hangzhou Dianzi University, Hangzhou, China; Wang, Dongjing, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Zhang, Xin, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China","Effective stock market prediction can significantly assist individual and institutional investors to make better trading decisions and help government stabilize the market. Therefore, a variety of methods have been proposed to tackle the issue of stock market prediction recently. However, it is still quite challenging to effectively extract the correlations and temporal information from multivariate time series of market data and integrate various kinds of features as well as auxiliary information, which is important for improving the performance of stock market prediction. This paper proposes an entirely Transformer based model, namely Gated Three-Tower Transformer (GT3), to incorporate numerical market information and social text information for accurate stock market prediction. Firstly, we devise a Channel-Wise Tower Encoder (CWTE) to capture the channel-wise features from transposed numerical data embeddings. Secondly, we design a Shifted Window Tower Encoder (SWTE) with Multi-Temporal Aggregation to extract and aggregate the multi-scale temporal features from the original numerical data embeddings. Then we adopt the encoder of vanilla Transformer as a Text Tower Encoder (TTE) to obtain the high-level textual features. Furthermore, we design a Cross-Tower Attention mechanism to assist the model to learn the trend-relevant significance of each daily text representation by leveraging the temporal features from SWTE. Finally, we unify CWTE, SWTE, and TTE as the GT3 model through a self-adaptive gate layer to perform end-to-end text-driven stock market prediction by fusing three types of features effectively and efficiently. Extensive experimental results on a real-world dataset show that the proposed model outperforms state-of-the-art baselines. © 2022 Elsevier B.V., All rights reserved.","Attention Mechanism; Feature Fusion; Stock Market Prediction; Text-driven; Transformer; Commerce; Data Mining; Embeddings; Financial Markets; Forecasting; Investments; Towers; Attention Mechanisms; Data Embedding; Features Fusions; Institutional Investors; Numerical Data; Stock Market Prediction; Temporal Features; Temporal Information; Text-driven; Transformer; Signal Encoding","Commerce; Data mining; Embeddings; Financial markets; Forecasting; Investments; Towers; Attention mechanisms; Data embedding; Features fusions; Institutional investors; Numerical data; Stock market prediction; Temporal features; Temporal information; Text-driven; Transformer; Signal encoding","","","This research is supported by Natural Science Foundation of Zhejiang Province under No.LQ21F020015 and No.LQ20F020015.","Akita, Ryo, Deep learning for stock prediction using numerical and textual information, (2016); Arroyo-Fernández, Ignacio, Unsupervised sentence representations as word information series: Revisiting TF–IDF, Computer Speech and Language, 56, pp. 107-129, (2019); Bagnall, Anthony J., The great time series classification bake off: a review and experimental evaluation of recent algorithmic advances, Data Mining and Knowledge Discovery, 31, 3, pp. 606-660, (2017); Basak, Suryoday, Predicting the direction of stock market prices using tree-based classifiers, North American Journal of Economics and Finance, 47, pp. 552-567, (2019); Chand Publishing, (2008); Bollen, Johan, Twitter mood predicts the stock market, Journal of Computational Science, 2, 1, pp. 1-8, (2011); Olshen Ra, (1984); Butler, Kirt C., Efficiency and inefficiency in thinly traded stock markets: Kuwait and Saudi Arabia, Journal of Banking and Finance, 16, 1, pp. 197-210, (1992); Dami, Sina, Predicting stock returns of Tehran exchange using LSTM neural network and feature engineering technique, Multimedia Tools and Applications, 80, 13, pp. 19947-19970, (2021); Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019)","","Springer","","","","","","13807501; 15737721","","MTAPF","","English","Article","Final","","Scopus","2-s2.0-85127604439"
"M., Felice, Mariano; S., Taslimipoor, Shiva; Ø.E., Andersen, Øistein E.; P.J., Buttery, Paula J.","Felice, Mariano (55832587800); Taslimipoor, Shiva (55485832700); Andersen, Øistein E. (57199056874); Buttery, Paula J. (8576871000)","55832587800; 55485832700; 57199056874; 8576871000","CEPOC: The Cambridge Exams Publishing Open Cloze dataset","2022","","","","","4285","4290","0","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144347623&partnerID=40&md5=311e8387b1a8a3595edafd5d16bd7462","Department of Computer Science and Technology, Cambridge, United Kingdom","Felice, Mariano, ALTA Institute, Department of Computer Science and Technology, Cambridge, United Kingdom; Taslimipoor, Shiva, ALTA Institute, Department of Computer Science and Technology, Cambridge, United Kingdom; Andersen, Øistein E., ALTA Institute, Department of Computer Science and Technology, Cambridge, United Kingdom; Buttery, Paula J., ALTA Institute, Department of Computer Science and Technology, Cambridge, United Kingdom","Open cloze tests are a standard type of exercise where examinees must complete a text by filling in the gaps without any given options to choose from. This paper presents the Cambridge Exams Publishing Open Cloze (CEPOC) dataset, a collection of open cloze tests from world-renowned English language proficiency examinations. The tests in CEPOC have been expertly designed and validated using standard principles in language research and assessment. They are prepared for language learners at different proficiency levels and hence classified into different CEFR levels (A2, B1, B2, C1, C2). This resource can be a valuable testbed for various NLP tasks. We perform a complete set of experiments on three tasks: gap filling, gap prediction, and CEFR text classification. We implement transformer-based systems based on pre-trained language models to model each task and use our dataset as a test set, providing promising benchmark results. © 2022 Elsevier B.V., All rights reserved.","Blank-filling; Cambridge Examinations; Language Learning; Open Cloze; Second Language Testing; Classification (of Information); Natural Language Processing Systems; Statistical Tests; Text Processing; Blank-filling; Cambridge; Cambridge Examination; Filling In; Language Learning; Language Testing; Open Cloze; Second Language; Second Language Testing; Standard Type; Filling","Classification (of information); Natural language processing systems; Statistical tests; Text processing; Blank-filling; Cambridge; Cambridge examination; Filling in; Language learning; Language testing; Open cloze; Second language; Second language testing; Standard type; Filling","","","","Materials for the Guidance of Test Item Writers, (2005); Manual for Language Test Development and Examining, (2011); Clark, Kevin, ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS, (2020); Research Notes, (2015); Common European Framework of Reference for Languages Learning Teaching Assessment, (2001); Cui, Yiming, Consensus attention-based neural networks for Chinese reading comprehension, pp. 1777-1786, (2016); Devlin, Jacob, BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019); Donahue, Christopher H., Enabling language models to fill in the blanks, Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 2492-2501, (2020); Felice, Mariano, Entropy as a proxy for gap complexity in open cloze tests, International Conference Recent Advances in Natural Language Processing, RANLP, 2019-September, pp. 323-327, (2019); Felice, Mariano, Constructing Open Cloze Tests Using Generation and Discrimination Capabilities of Transformers, Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 1263-1273, (2022)","Calzolari, N.; Bechet, F.; Blache, P.; Choukri, K.; Cieri, C.; Declerck, T.; Goggi, S.; Isahara, H.; Maegaard, B.; Mariani, J.; Mazo, H.; Odijk, J.; Piperidis, S.","European Language Resources Association (ELRA)","3M; Emvista; et al.; Google; SADILAR; Vocapia","13th International Conference on Language Resources and Evaluation Conference, LREC 2022","","Marseille","184830","","9791095546726","","","English","Conference paper","Final","","Scopus","2-s2.0-85144347623"
"J.L., Ochoa, José Luis; Y., Alemán, Yuridiana","Ochoa, José Luis (14007289700); Alemán, Yuridiana (55346536100)","14007289700; 55346536100","TeamMX at PoliticEs 2022: Analysis of Feature Sets in Spanish Author Profiling for Political Ideology","2022","CEUR Workshop Proceedings","3202","","","","","0","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137364174&partnerID=40&md5=e0ba53f8c4045bac1583d37f173b32ed","Universidad de Sonora, Hermosillo, Mexico; Tecnológico de Monterrey, Monterrey, Mexico","Ochoa, José Luis, Universidad de Sonora, Hermosillo, Mexico; Alemán, Yuridiana, Tecnológico de Monterrey, Monterrey, Mexico","Natural Language Processing (NLP) is evolving more and more every day and it is becoming a very powerful tool, especially when it works in combination with Machine Learning algorithms, as it is making ventures into areas in which it was not well known, such as automatic programming systems based on the GPT-3 model, the market or sales prediction, even, the risk detection in banking systems on the basis of written exchanges between branch managers or directors of the same bank. The so-called short texts, comments/reviews made on social networks like Twitter, Facebook or Youtube, are becoming relevant in several domains. The corpus provided by the IberLEF 2022 Task - PoliticEs was used for extract political ideology information, it was focused on the identification of the gender, the profession, and the political spectrum from a binary (Left, Right) and multi-class perspective (Left, Right, Moderate-Left and Moderate-Right). Eight methods are proposed, six of them didn't have the expected results, but contributed to the two best ones. We implemented a customized stopwords study for our research in collaboration with experiments such as Best unique words per category, Set-based study, Transition point and others to extract the features, then Random Forest, SVM and Neural Network algorithms with default parameters and the Scikit learn tool were used to identify the categories. Obtaining a Macro F1 value of 0.7984 and the highest value achieved was 0.8270 in the category of Profession. © 2022 Elsevier B.V., All rights reserved.","Author Profiling; Authorship Analysis; Authorship Attribution; Linguistic Features; Natural Language Processing; Decision Trees; Linguistics; Machine Learning; Natural Language Processing Systems; Sales; Social Networking (online); Author Profiling; Authorship Analysis; Authorship Attribution; Features Sets; Language Processing; Linguistic Features; Machine Learning Algorithms; Natural Language Processing; Natural Languages; Political Ideologies; Learning Algorithms","Decision trees; Linguistics; Machine learning; Natural language processing systems; Sales; Social networking (online); Author profiling; Authorship analysis; Authorship attribution; Features sets; Language processing; Linguistic features; Machine learning algorithms; Natural language processing; Natural languages; Political ideologies; Learning algorithms","","","","Power of Natural Language Processing Harvard Business Review, (2022); Zhang, Min, A commentary of GPT-3 in MIT Technology Review 2021, Fundamental Research, 1, 6, pp. 831-833, (2021); Archak, Nikolay, Show me the money!: Deriving the pricing power of product features by mining consumer reviews, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 56-65, (2007); Collovini, Sandra, Relation extraction for competitive intelligence, Lecture Notes in Computer Science, 12037 LNAI, pp. 249-258, (2020); Numbers in Politics Comparative Quantitative Analysis Modeling in Foreign Policy Orientation and Election Forecasting, (2019); Election Prediction with Twitter Data Via Nlp and Machine Learning Algorithms Tweets User Description and Sentiment Analysis, (2022); Xiong, Kai, Heterogeneous graph knowledge enhanced stock market prediction, AI Open, 2, pp. 168-174, (2021); Liu, Yang, ARSA: A sentiment-aware model for predicting sales performance using blogs, pp. 607-614, (2007); Nopp, Clemens, Detecting risks in the banking system by sentiment analysis, pp. 591-600, (2015); Khanbhai, Mustafa Muzahir, Using natural language processing to understand, facilitate and maintain continuity in patient experience across transitions of care, International Journal of Medical Informatics, 157, (2022)","Montes-y-Gomez, M.; Gonzalo, J.; Rangel, F.; Casavantes, M.; Alvarez-Carmona, M.A.; Bel-Enguix, G.; Escalante, H.J.; Freitas, L.; Miranda-Escalada, A.; Rodriguez-Sanchez, F.; Rosa, A.; Sobrevilla-Cabezudo, M.A.; Taule, M.; Valencia-Garcia, R.","CEUR-WS","","2022 Iberian Languages Evaluation Forum, IberLEF 2022","","A Coruna","182341","16130073","9789666544899; 9788073780029; 9788024810256; 9789986342748; 9788073781712; 9782954494807; 9788024823911; 9789562361989; 8024810255; 807378002X","","","English","Conference paper","Final","","Scopus","2-s2.0-85137364174"
"E., Cardenas, Erika; C., Shorten, Connor; T.M., Khoshgoftaar, Taghi M.; B., Furht, Borko","Cardenas, Erika (57721228700); Shorten, Connor (57209776315); Khoshgoftaar, Taghi M. (7006211475); Furht, Borko (7004960599)","57721228700; 57209776315; 7006211475; 7004960599","A Comparison of House Price Classification with Structured and Unstructured Text Data","2022","Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS","35","","","","","4","3","10.32473/flairs.v35i.130668","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131143938&doi=10.32473%2Fflairs.v35i.130668&partnerID=40&md5=92a4d0db89b700ebf91431fd77984df3","Florida Atlantic University, Boca Raton, United States","Cardenas, Erika, Florida Atlantic University, Boca Raton, United States; Shorten, Connor, Florida Atlantic University, Boca Raton, United States; Khoshgoftaar, Taghi M., Florida Atlantic University, Boca Raton, United States; Furht, Borko, Florida Atlantic University, Boca Raton, United States","Purchasing a home is one of the largest investments most people make. House price prediction allows individuals to be informed about their asset wealth. Transparent pricing on homes allows for a more efficient market and economy. We report the performance of machine learning models trained with structured tabular representations and unstructured text descriptions. We collected a dataset of 200 descriptions of houses which include meta-information, as well as text descriptions. We test logistic regression and multi-layer perceptron (MLP) classifiers on dividing these houses into binary buckets based on fixed price thresholds. We present an exploration into strategies to represent unstructured text descriptions of houses as inputs for machine learning models. This includes a comparison of term frequency-inverse document frequency (TF-IDF), bag-of-words (BoW), and zero-shot inference with large language models. We find the best predictive performance with TF-IDF representations of house descriptions. Readers will gain an understanding of how to use machine learning models optimized with structured and unstructured text data to predict house prices. © 2023 Elsevier B.V., All rights reserved.","Economics; Houses; Text Processing; House's Prices; Machine Learning Models; Meta Information; Performance; Price Prediction; Structured Text; Tabular Representations; Term Frequencyinverse Document Frequency (tf-idf); Text Data; Unstructured Texts; Machine Learning","Economics; Houses; Text processing; House's prices; Machine learning models; Meta information; Performance; Price prediction; Structured text; Tabular representations; Term frequencyinverse document frequency (TF-IDF); Text data; Unstructured texts; Machine learning","","","We acknowledge partial support by the NSF NRT-HDR (2021585). Opinions, findings, conclusions, or recommendations in this paper are the authors\u2019 and do not reflect the views of the NSF.","International Conference on Advanced Intelligent Systems and Informatics, (2016); Proceedings of the Ncta 8th International Confer Ence on Neural Computation Theory and Applications, (2016); Bency, Archith John, Beyond spatial auto-regressive models: Predicting housing prices with satellite imagery, pp. 320-329, (2017); Financial Time Series Forecasting with Tern Recognition, (2021); Journal of Real Estate Finance and Economics, (2017); Pile an 800gb Dataset of Diverse Text for Language Modeling, (2020); Hausler, Jochen, News-based sentiment analysis in real estate: a machine learning approach, Journal of Property Research, 35, 4, pp. 344-371, (2018); Johnson, Justin M., Survey on deep learning with class imbalance, Journal of Big Data, 6, 1, (2019); Law, Stephen, Take a look around: Using street view and satellite images to estimate house prices, ACM Transactions on Intelligent Systems and Technology, 10, 5, (2019); Pancerz, Krzysztof, From unstructured data included in real-estate listings to information systems over ontological graphs, pp. 298-303, (2017)","Bartak, R.; Franklin, M.; Keshtkar, F.","Florida Online Journals, University of Florida","","35th International Florida Artificial Intelligence Research Society Conference, FLAIRS-35 2022","","Jensen Beach; FL","277889","23340762; 23340754","","","","English","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131143938"
"D., Dottori, Davide","Dottori, Davide (23469053800)","23469053800","Robots and employment: evidence from Italy","2021","Economia Politica","38","2","","739","795","0","38","10.1007/s40888-021-00223-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104884020&doi=10.1007%2Fs40888-021-00223-x&partnerID=40&md5=840746989e951a1e11ab35f0683e8844","Banca d’Italia, Ancona, Italy","Dottori, Davide, Local Economic Research and Analysis Division, Banca d’Italia, Ancona, Italy","Increased robot diffusion has raised concerns for its possible negative impact on employment. Following an empirical approach in line with those applied to the US and Germany with contrasting results, this paper provides evidence about the effect of robots on employment outcomes in Italy (second European economy for robot stock) from the early 1990s up to 2016, both at the local labour market (LLM) level and at the worker level. In order to purge from demand and other confounding shocks, the identification relies on an instrumental variables strategy based on robots’ sectoral growth in other European countries. No harmful impact on total employment emerges from the LLM analysis; the estimated effect is negative when limited to manufacturing employment, but its statistical significance is weak or absent once concurrent trends relating to trade and ICT are controlled for. Results at the worker level show that incumbent workers in manufacturing were not damaged on average, with an overall positive (though not large) employment effect, driven by longer working relationships with the original firm; conditional on remaining at the original firm, the impact is also positive on wages. On the other hand, robot diffusion turns out to have contributed to reshaping the sectoral distribution of the new labour force inflows towards less robot intensive industries. © 2021 Elsevier B.V., All rights reserved.","Automation; Employment; Local Labour Markets; Matched Employer–employee Data; Robot","","","","","Acemoglu, Daron, Skills, tasks and technologies: Implications for employment and earnings, Handbook of Labor Economics, 4, PART B, pp. 1043-1171, (2011); Aea Papers and Proceedings, (2020); Acemoglu, Daron, The race between man and machine: Implications of technology for growth, factor shares, and employment, American Economic Review, 108, 6, pp. 1488-1542, (2018); Acemoglu, Daron, Automation and new tasks: How technology displaces and reinstates labor, Journal of Economic Perspectives, 33, 2, pp. 3-30, (2019); Acemoglu, Daron, Robots and jobs: Evidence from us labor markets, Journal of Political Economy, 128, 6, pp. 2188-2244, (2020); New Evidence from France Tech Rep, (2020); Institute of Labor Economics Iza, (2019); OECD Publishing, (2016); Polanyi S Paradox and the Shape of Employment Growth, (2014); Autor, David H., Is automation labor share–displacing? Productivity growth, employment, and the labor share, Brookings Papers on Economic Activity, 2018, Spring, pp. 1-87, (2018)","","Springer Science and Business Media Deutschland GmbH","","","","","","11202890; 1973820X","","","","English","Article","Final","","Scopus","2-s2.0-85104884020"
"A., Nandy, Abhilash; S., Adak, Sayantan; T., Halder, Tanurima; S.M., Pokala, Sai Mahesh","Nandy, Abhilash (57207912673); Adak, Sayantan (57219743843); Halder, Tanurima (57224806908); Pokala, Sai Mahesh (57224832945)","57207912673; 57219743843; 57224806908; 57224832945","cs60075 team2 at SemEval-2021 Task 1: Lexical Complexity Prediction using Transformer-based Language Models pre-trained on various text corpora","2021","","","","","678","682","0","7","10.18653/v1/2021.semeval-1.87","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138899307&doi=10.18653%2Fv1%2F2021.semeval-1.87&partnerID=40&md5=25b7fee7d6add0eb6bb93a0a6af1e58f","Indian Institute of Technology Kharagpur, Kharagpur, India","Nandy, Abhilash, Indian Institute of Technology Kharagpur, Kharagpur, India; Adak, Sayantan, Indian Institute of Technology Kharagpur, Kharagpur, India; Halder, Tanurima, Indian Institute of Technology Kharagpur, Kharagpur, India; Pokala, Sai Mahesh, Indian Institute of Technology Kharagpur, Kharagpur, India","This paper describes the performance of the team cs60075 team2 at SemEval 2021 Task 1 - Lexical Complexity Prediction. The main contribution of this paper is to fine-tune transformer-based language models pre-trained on several text corpora, some being general (E.g., Wikipedia, BooksCorpus), some being the corpora from which the CompLex Dataset was extracted, and others being from other specific domains such as Finance, Law, etc. We perform ablation studies on selecting the transformer models and how their individual complexity scores are aggregated to get the resulting complexity scores. Our method1 achieves a best Pearson Correlation of 0.784 in sub-task 1 (single word) and 0.836 in sub-task 2 (multiple word expressions). © 2025 Elsevier B.V., All rights reserved.","Correlation Methods; Semantics; Complex Datasets; Language Model; Pearson Correlation; Performance; Single Words; Subtask; Text Corpora; Transformer Modeling; Wikipedia; Computational Linguistics","Correlation methods; Semantics; Complex datasets; Language model; Pearson correlation; Performance; Single words; Subtask; Text corpora; Transformer modeling; Wikipedia; Computational linguistics","","","","Complex A New Corpus for Lexical Complexity Predicition from Likert Scale Data; Bada, Michael A., Concept annotation in the CRAFT corpus, BMC Bioinformatics, 13, 1, (2012); Chen, Tianqi, XGBoost: A scalable tree boosting system, 13-17-August-2016, pp. 785-794, (2016); Cho, Kyunghyun, Learning phrase representations using RNN encoder-decoder for statistical machine translation, pp. 1724-1734, (2014); Learning Phrase Representations Using Rnn Encoder Decoder for Statistical Machine Translation, (2014); Christodoulopoulos, Christos E., A massively parallel corpus: the Bible in 100 languages, Language Resources and Evaluation, 49, 2, pp. 375-395, (2015); Corr, (2018); Hochreiter, Sepp, Long Short-Term Memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Mt Summit, (2005); Leroy, Gondy A., A user-study measuring the effects of lexical simplification and coherence enhancement on perceived and actual text difficulty, International Journal of Medical Informatics, 82, 8, pp. 717-730, (2013)","Palmer, A.; Schneider, N.; Schluter, N.; Emerson, G.; Herbelot, A.; Zhu, X.","Association for Computational Linguistics (ACL)","ACL Special Interest Group on the Lexicon (SIGLEX)","15th International Workshop on Semantic Evaluation, SemEval 2021","","Virtual, Online","182482","","9781954085701","","","English","Conference paper","Final","All Open Access; Green Final Open Access; Green Open Access","Scopus","2-s2.0-85138899307"
"C., Chai, Chuanguo; K., Tan, Kaiyuan; G., Fan, Guijuan; Y., Han, Yong; J., Li, Jingming; M., Li, Ming; X., Long, Xinping; B., Tan, Bisheng; H., Huang, Hui","Chai, Chuanguo (56381003400); Tan, Kaiyuan (55842740600); Fan, Guijuan (55568138300); Han, Yong (55387642200); Li, Jingming (55523016300); Li, Ming (56994218000); Long, Xinping (8435025200); Tan, Bisheng (8658099700); Huang, Hui (56290102600)","56381003400; 55842740600; 55568138300; 55387642200; 55523016300; 56994218000; 8435025200; 8658099700; 56290102600","Theoretical prediction of decomposition temperature of typical heat-resistant explosives","2020","Chemical Physics Impact","1","","100005","","","0","3","10.1016/j.chphi.2020.100005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126169509&doi=10.1016%2Fj.chphi.2020.100005&partnerID=40&md5=4f8f4c3ae71d361b0ff277dba15d5427","China Academy of Engineering Physics, Mianyang, China; China Academy of Engineering Physics, Mianyang, China","Chai, Chuanguo, Institute of Chemical Materials, China Academy of Engineering Physics, Mianyang, China; Tan, Kaiyuan, Institute of Chemical Materials, China Academy of Engineering Physics, Mianyang, China; Fan, Guijuan, Institute of Chemical Materials, China Academy of Engineering Physics, Mianyang, China; Han, Yong, Institute of Chemical Materials, China Academy of Engineering Physics, Mianyang, China; Li, Jingming, Institute of Chemical Materials, China Academy of Engineering Physics, Mianyang, China; Li, Ming, Institute of Chemical Materials, China Academy of Engineering Physics, Mianyang, China; Long, Xinping, China Academy of Engineering Physics, Mianyang, China; Tan, Bisheng, Institute of Chemical Materials, China Academy of Engineering Physics, Mianyang, China; Huang, Hui, China Academy of Engineering Physics, Mianyang, China","With the approaching exhaustion of shallow-ground gas and oil, heat-resistant explosives are in highly demand in oil/gas ultra-deep and ocean well development. However, the prediction method on decomposition temperatures of heat-resistant explosives is still yet to be determined. In this paper, based on the decomposition reaction of “trinitrotoluene mechanism”, the influences of the enthalpy changes, entropies, Gibbs free energies, conversion temperatures and resonance energies on corresponding decomposition temperatures were studied. A theoretical relation was proposed after a genetic-algorithm optimization. Based on this relation, the decomposition temperatures of LLM-105 derivatives and its isomers were discussed. The results showed that the proposed relation coincided well with the decomposition temperatures of typical aromatic explosives. Furthermore, the decomposition temperatures of LLM-105, LLM-105I2 and ANPZ,TANPyO were predicted high and can be taken as new heat-resistant explosive candidates. © 2022 Elsevier B.V., All rights reserved.","Conversion Temperature; Decomposition Temperature; Genetic Functional Approximation; Heat-resistant Explosive; Standard Entropy","","","","","Agrawal, J. P., Recent trends in high-energy materials, Progress in Energy and Combustion Science, 24, 1, pp. 1-30, (1998); Sikder, Arunkanti, A review of advanced high performance, insensitive and thermally stable energetic materials emerging for military and space applications, Journal of Hazardous Materials, 112, 1-2, pp. 1-15, (2004); Gospodinov, Ivan, Energetic Functionalization of the Pyridazine Scaffold: Synthesis and Characterization of 3,5-Diamino-4,6-dinitropyridazine-1-Oxide, European Journal of Organic Chemistry, 2018, 8, pp. 1004-1010, (2018); Zhang, Jiaheng, Thermally stable 3,6-dinitropyrazolo[4,3-c]pyrazole-based energetic materials, Chemistry - An Asian Journal, 9, 10, pp. 2953-2960, (2014); Zhang, Shuhai, Preparation and characterization of LLM-105 cocrystal explosives, Advanced Materials Research, 900, pp. 251-255, (2014); Van Krevelen, D. W., Properties of Polymers, (2009); Prediction of Polymer Properties, (1996); Thermochim Acta, (1979); Keshavarz, Mohammad Hossein, A novel approach for assessment of thermal stability of organic azides through prediction of their temperature of maximum mass loss, Journal of Thermal Analysis and Calorimetry, 129, 3, pp. 1659-1665, (2017); Keshavarz, Mohammad Hossein, Relationship between thermal stability and molecular structure of polynitro arenes, Indian Journal of Engineering and Materials Sciences, 16, 1, pp. 61-64, (2009)","","Elsevier B.V.","","","","","","26670224","","","","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85126169509"
"A., Eliyana, Anis; W., Istyarini, Wiwik","Eliyana, Anis (57196352579); Istyarini, Wiwik (57196354786)","57196352579; 57196354786","The estimation and the fulfi llment scenarios of human resources of sharia banking in Indonesia","2017","Journal of Islamic Economics, Banking and Finance","13","1","","188","204","0","3","10.12816/0051162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032721120&doi=10.12816%2F0051162&partnerID=40&md5=cfa00f14369302495e4e212522b3c8d1","Universitas Airlangga, Surabaya, Indonesia; Faculty of Economics, Jakarta, Indonesia","Eliyana, Anis, Department of Management, Universitas Airlangga, Surabaya, Indonesia; Istyarini, Wiwik, Universitas Al Anwar, Faculty of Economics, Jakarta, Indonesia","This study aims to test the role of Sharia in improving employees' performance. There are some variables of Sharia such as banking estimation and followership based on talent management. Besides, the consequence variables are knowledge sharing and employees' performance. The rapid growth of Sharia Banking faces problems of minimum human resources in quantity and quality. In 2020, the need human resources of Sharia banking will at least reach 179,646 consisting of 165,274 employees in low Sharia quality as executors, and 14,374 employees in middle to high Sharia quality for the banking managerial and leader positions. In three short term scenarios, Sharia banking absorbs 50% of Sharia human resource supply which is considered as a realistic scenario until 2018. In long-term period, ideal condition can be reached if the first scenario can be executed so that the balance of supply and demand will happen. This means Sharia banking industry will be more competitive and growing fast. © 2020 Elsevier B.V., All rights reserved.","Employee Engagement; Human Capital; Human Resource Management; Management Development; Performance Management","","","","","Mencetak Sdm Bank Syari Ah Yang Berkompeten, (2011); Bartel, Ann P., Productivity Gains from the Implementation of Employee Training Programs, Industrial Relations, 33, 4, pp. 411-425, (1994); Strategic Employment Policy an Organizational Systems Perspective, (1991); Handbook of Industrial and Organizational Psychology, (1991); Strategy and Human Resources Management, (1991); Research Frontiers in Industrial Relations and Human Resources, (1992); Handbook of Industrial and Organizational Psychology, (1992); Guzzo, Richard A., THE EFFECTS OF PSYCHOLOGICALLY BASED INTERVENTION PROGRAMS ON WORKER PRODUCTIVITY: A META‐ANALYSIS, Personnel Psychology, 38, 2, pp. 275-291, (1985); Manajemen Dasar Pengertian Dan Masalah, (2009); Academy of Management Journal, (1995)","","Islamic Bank Training and Research Academy info@ibtra.com","","","","","","20704666; 20704658","","","","English","Article","Final","","Scopus","2-s2.0-85032721120"
